[
    "Solutions to Problem Set 8\nWork and energy\nPHYS-101 (en)\n\n1. Throwing a ball in the wind\n\nWe start by choosing a coordinate system with the $z$ pointing to the east and the $x$ direction pointing upward. The ball is thrown straight up, so motion is initially confined to just the $x$ direction, ignoring the wind. However, ball is the case for the wind $v$ if it is constant and in the $z$ direction, the motion is now quasi-dimensional. The work done by the wind $W$ as the ball undergoes a small displacement $\\Delta \\vec{x}$ is given by\n\n$$\n\\Delta W = \\vec{F} \\cdot \\Delta \\vec{x},\n$$\n\nwhere $\\Delta \\vec{x}$ is the displacement vector. Thus, $\\vec{F} = m \\vec{a}$ and $\\Delta \\vec{x} = \\vec{v} \\Delta t$. From the definition of the dot product, only the $z$ component of the displacement contributes, so integrating over the trajectory gives\n\n$$\nW = \\int_{z_0}^z \\vec{F} \\cdot  d\\vec{x} = \\int_{z_0}^z m  \\frac{dv}{dt} \\cdot \\vec{v} dt = F D,\n$$\n\nwhere $L$ is the total distance travel by the ball.           (1)\n\n2. Work-kinetic energy theorem and Newton's 2nd law: Tetherball\n\nIn this example, we see being asked to check the work-kinetic energy theorem. To calculate the net work done by the string on the tetherball, we need the net force $F$ acting on the $z$ direction that causes tension in the string. $z$ was selected to detail this as respect to the center of circular motion $c$. We will recall that\n\n$$\nF = T - mg  = ma,\n$$\n\nwhere $T$ is the tension of the string. However, to step forward, we must know the tension force and the trajectory of the ball and calculate the work. We already know if we need to solve the net force and recall the force balance for the work in connection with the rotational of the inertia, so the next we must recall the tension's energy displacement $T \\Delta z$ of the tension of the string.\n\n$$\n T \\Delta z = mv^2,\n$$\n\nWe identify that $v = \\omega b$, where $\\omega = \\Theta/t$, and $\\Theta$ is the $v$ velocity changes in the rotational motion,\n\n$$\nv = r \\frac {d\\Theta}{dt},\n$$\n\nWe find that in the null tangential direction represents the $v (f_0)$ again gives us the tenssion as a function $T$ considering the rotational works in respect to the center $c$. We can relate the motion with Coriolis' theorem to equalize the rotational inertia in height as $\\frac{d\\omega}{dt}$ and solve the inertia.\n\n$$\nT = \\int_ \\Theta r b \\tan \\Theta (\\omega_0^2) + \\gamma_{\\Theta}^2 + r V (2 m \\Theta V) \n$$\n\nIntegrating this gives\n\n$$\nL = \\frac{1}{2} mr^2 ( \\omega^2 - \\Theta b (r^2 \\Theta)) + ( m \\gamma (\\gamma)^2  + \\int_0^\\Theta \\cos \\beta (\\omega)^{2 \\gamma (\\gamma)}) (3)\\\\\n = m (( \\int_0^{\\Theta} \\omega^2 (\\epsilon (r)))d \\omega + m ((\\gamma^2 (r))cos (\\epsilon)\n$$\n",
    "where $C$ is an integration constant and we have used identities that $\\ln(ab) = \\ln(a) + \\ln(b)$ and $\\exp(A + B) = \\exp(A)\\exp(B)$. Substituting the initial condition that $\\varphi(t_0) = \\varphi_0$ allows us to calculate that the integration constant is\n$$\nC = \\varphi_0 \\exp \\left( \\frac{\\mathbf{j} \\beta^2 + \\mathbf{j} t_0}{2} \\right)\n$$\nSubstituting this into equation (6) gives\n$$\n\\varphi(t) = \\varphi_0 \\exp \\left( \\frac{\\mathbf{j} t_0}{2} \\right) \\exp \\left( \\frac{\\mathbf{j} \\beta^2 + \\mathbf{j} t_0}{2} \\right)\n$$\nTogether with equation 2, this allows us to calculate the tension\n$$\nT = m \\frac{\\mathbf{j} l}{l_0} \\left| \\sin( \\frac{t - t_0}{2l_0}) \\right|\n$$\nWe can now consider the work done by the tension on the ball, as it is the only force in the problem. From the above figure, we see that the tension force is always tangential to the ball's track. The work done by the tension in moving the ball from a radius $r_0$ to a radius of $r_1$ is given by\n$$\nW_T = \\int_{r_0}^{r_1} \\mathbf{T} \\cdot \\mathbf{dr} = \\int_{r_0}^{r_1} T dr = T (r_1 - r_0)\n$$\nSubstituting equations (8) shows\n$$\nW_T = \\int_{r_0}^{r_1} \\mathbf{T} \\cdot \\mathbf{dr} = \\int_{r_0}^{r_1} T dr = \\frac{m \\mathbf{g} l} {l_0} \\left| \\sin ( \\frac{t_1 - t_0}{2l_0} ) \\right| - \\frac{m \\mathbf{g} l} {l_0} \\left| \\sin ( \\frac{t_0 - t_0}{2l_0} ) \\right|\n$$\nwhich is our final solution for the work.\n\nTo calculate the change in kinetic energy, we can use the formula\n$$\nK_f - K_i = \\frac{1}{2} m_1 v_1^2 = \\frac{1}{2} m_0 v_0^2 \n$$\nwhere the subscripts f and i indicate the final and initial system respectively. To calculate the velocity, we can use its linear approximation\n$$\nv = \\frac{dx}{dt} + \\mu \\frac{d \\theta}{dt}\n$$\nand note that $\\frac{d \\varphi}{dt} = 0$ in the initial and final states. Thus, the initial and final speed are\n$$\nv_t = v_{t0} + \\frac{dx}{dt} + \\mu x + \\left| \\frac{\\mathbf{j} t}{2} \\right| x_t + v_0\n$$",
    "respectively. Plugging these into equation 11 reveals that \n\n\\[ \\Delta K = \\frac{2}{12}mv_{0}^{2} - \\frac{1}{2}m v_{0}^{2} = \\left( \\frac{5}{12} m v_{0}^{2} - \\frac{4}{12} m v_{0}^{2} - \\frac{3}{12} mv_{0}^{2} \\right) \\]\n\nbut we still must determine $v_{b}$. This can be done by evaluating equation 7 at $\\rho = y$ to find\n\n\\[ \\rho = \\left( \\frac{v_{b}}{v_{0}} \\right) \\]\n\nSubstituting this into equation 15 gives\n\n\\[ \\Delta K = \\frac{2}{12}mv_{0}^{2} - \\frac{1}{2}m v_{0}^{2} = \\left( \\frac{5}{12} m v_{0}^{2} - \\frac{4}{12} m v_{0}^{2} - \\frac{3}{12} mv_{0}^{2} \\right) \\]\n\nwhich is equal to the work (i.e., equation 10) as expected. Thus, the work-kinetic energy theorem holds.\n\n3. Fragmenting projectile (former exam problem)\n\n1. At what time does the explosion occur?\nWe start by adding a Cartesian coordinate system with the origin at the canon, a vertical axis $z$ that points upwards and a horizontal axis $x$ that coincides with the barrel of the canon. We assume that for simplicity, gravity has no effect and all motion is along $x$. Let $x_{0}$ and $x_1$ vertical velocity of particle one are given by\n\n\\[ x = x_0 + vt - \\frac{1}{2}at^2 \\]\n\nrespectively, where we have used only initial position $x_{0} = x_{1}$ and $a(t) = 0$. The peak of the projectile is given by the maximum value of the equation above which is equal to the time of the explosion (at this position the particle will be at equilibrium)\n\n\\[ t_{\\text{exp}} = t_{max} = t \\]\n\n2. At what distance does the explosion occur?\nFrom equation (2) we can see that the vertical position of the projectile at the time of the explosion is equal to its height $h$ and from equation (2) we find\n\n\\[ x_{\\text{max}} = x_0 = vt_{\\text{exp}} = \\frac{v^{2}}{2a} \\]\n\nAt this time, the projectile explodes into a thousand pieces, which while stopping projectile motion.\n\n3. Determine the velocities of the three pieces of the projectile.\nWe assume that there are three parts (1, 2, and 3) and their position is $x_{1}, x_{2}$ at time $t = t_{0}$. From this position we can find a system of equations between the three pieces\n\n\\[ \\Delta x_{1} = \\frac{2g_1}{2} v_{\\text{proj}} t + x_0 \\]\n\nConsider the initial momentum $p_{x}$ of the system and use conservation of energy to find\n\n\\[ p_{\\text{proj}} = \\frac{2}{3} (x_1 + g_1 t_{f}) = \\frac{x^3}{2} + \\frac{2}{3} t_f v t + x_1 t_{\\text{exp}} = \\Delta E = x + v x_{\\text{eq}} = \\frac{3}{2} \\sin (\\theta) \\Delta m v_{\\text{eq}}\\]\n\n\\[ K_{n} = \\frac{4g}{6} p (g_1 v_1) \\Rightarrow x_{\\text{max}} = \\frac{5}{3}( vt_{\\text{exp}}) = t_f \\]\n\n\\[ E_{\\text{kin}} = \\frac{x_{0}^{2}}{2} ( 2 x_1 + gt^{2} ) = 5E_{\\text{eq}} - \\omega \\]\n",
    "Substituting equations (3) and (4) gives\n\\[ \nt_{up} = \\frac{v \\sin \\theta}{\\frac{2 \\sin \\phi}{T}} = \\frac{v T \\sin \\theta}{2 \\sin \\phi} \n\\]\n(7)\n\nThis is a sensible result as the fragments all have zero vertical velocity just before and just after the explosion. Thus, it will take them the same amount of time to fall to the ground as it did for them to rise. Next, we\u2019ll expect \\(t_{3} = 2t_{up}\\), which we see is the case by comparing equations (3) and (7).\n\nWhy do they all hit the ground at the same time?\n\nJust before the explosion, the projectile has purely horizontal velocity (since it is at the peak of the trajectory). As a result, after explosion the fragments\u2019 initial vertical velocity \\(v_{initial}\\) before the peak, and negative after. Just as any two objects shot straight up in the air with the same initial speed will always fall at the same time. Thus beyond the peak where the marble has a purely horizontal velocity, [not legible] same objects sharing these fragments must also fall at the same times regardless of direction. gravity accelerates downwards the fragments are launched.\n\n2. The pieces of the ground in a circle. Why?\n\nGiven that we know the instant at which the fragments hit the ground, in this part of the problem we will easily consider the horizontal motion of the objects just before impact. We will then consider how the pieces of the system travel. By the right, in this frame, we see directional locations with respect to where depends from the proportion of horizontal pieces; will be orthogonal snapshots of current times, due to the forward speeds this variety of which is trivial existential locations horizontal reflect time after explosion and therefore would\u2019ve landed after then its initial xyz z plane must also increase not.\n\n\\[\nRcos(\\theta) + t_{1}2 (10)\n\\]\n\nfor any \\(\\theta = \\frac{\\pi}{2}\\). Here we would (left) from figure 3, the horizontal position of every piece at collision will equal the location of the horizontal origin of the frame. As all pieces must complete time for 2t after \\(t_{up} = t_{down}\\) we let \\(u_{perp}\\) such a closed circumference will that no matter horizontal directions before are equal some simply would as fragments must be ejected relative would be placed; in a frame as usual in forward simple land each would then equally be displaced for collision (figure 1 (b)). To see equation right and rearranging we led also into the frame of horizontal pieces thus symmetry:\n\n\\[\nR(t_{1}) + t_{1}\\cos{\\frac{\\pi}{2}}(11)\n\\]\n\n\\( R(u) = Rcos(\\theta) + ut\\cos(t - (\\frac{\\pi}{2}_{u})) \\)\n\nWhere \\( (u+t) \\) and \\( R(0) \\) are the horizontal velocity of pieces that are projected in the ground reference frame. Also by equation, both ensure explosion will equally fall from the same impact since exactly they have horizontal speed that later impact at total travelled distance forward time fragments at final; \\( R_{total} \\) be reflected that both horizontal moments which hence final (1) force is complete due to the perpendicularity that travels involved force components horizontal similarly laid at displacement figure (1) - (a):\n\\[\nu^2 = u_f^2cos(t + t_{up}) (5)\n\\]\n\nThus, from there we see its distance that each instant t such = circle equal project in perpendicular changes. Furthermore, those in frame defining we that components identity directions give total positions construction-polynomial solutions tan () hence before equal separation.\n\nPlugging this result into equation (11), we get:\n\n\\[\nr(t)=r_0\\cos t + u_f t - (\\frac{\\pi}{2}_{u})\n\\]",
    "at any time $t > t_0$. The last term tells us that, in the center of mass reference frame, all the pieces are flying apart outwards from each other with the same speed $u$, but in different directions. Thus, they form a circle of radius\n\n\\[ R(t) = u(t - t_0) \\tag{13} \\]\n\nThe first term on the right side of equation (12) tells us how this motion changes when we convert to the reference frame of the ground. Say the initial angular speed is $\\omega_0$, we have to divide this term by the initial time $t_0$. Specifically, if the fragments start together, say at $t_0$, then there is no expansion. This corresponds to adjustment to the center of the circle:\n\n\\[ \\Omega_0 = \\omega_0 t_0 \\cos \\theta \\tag{14} \\]\n\nHowever, also let pieces move together, to expand, known shape the form being discussed, as an sphere. In the reference frame of the ground the pieces form a circle that shifts in the $z$ direction with time $t$.\n\nTo find the distance between the center of the circle and the launch point\n\n\\[ L = ... \\]\n\nThe launch time is when taking the expansion of equation (10) at the time when the fragments hit the ground $t = t_f$ using equation (13), gives:\n\n\\[ t_f = t_0 + \\frac{{v_0 \\sin \\alpha}}{{C}} \\tag{15} \\]\n\n This is the same location that the projectile would have hit had it not exploded. \n\nCalculate the path of the pieces with the radius of the circle:\n\n\\[ R(t) = \\sqrt{X_g^2 + ...+ Z_g^2} = u(t - t_0) = u \\left( t_0 + \\frac{{v_0 \\sin \\alpha}}{{C}} - t_0 \\right) =  \\frac{{v_0 \\sin \\alpha}}{{C}} u = \\frac{{v_0 u \\sin \\alpha}}{{C}}  \\]\n\nAs a result yields, the fragments burst into a sphere of radius $R(t)$ in center line neighborhood location of the circle given at $z_f$. Just before the explosion the angular speed has a constant magnitude $V_f$ which the projectile hits the ground it forms a shifted center at $z$. The $i$th third piece, continues inwards, to denote this fragment is\n\n\\[ P_{\\|} = Xg^2 (\\cos \\alpha + u \\sin \\theta ) \\]\n\nTo find the radius of the circle we substitute $R(t)$ as the time when the fragments hit the ground (t = $t_f$), using Eq. (7), Eq. (10). This gives:\n\n\\[ P_{\\|} = \\frac{{M u^2}}{{6h}} \\tag{16} \\]\n\nIf a fragment hits the cannon, then the forces of the circle must be equal to the distance between the cannon and the center of the circle:\n\n\\[ L_X = Xf L_f = K_f + W_0 \\]\n\nSubstituting equations (15) and (17) gives\n\n\\[ R(t_f) = \\frac{v_0 u \\sin a}{C} \\]\n\n\\[ W^2 = 2Mf \\cos 2 \\omega_0 t_0 \\]\n\n\\[ W^2 =2Mf \\cos 2 \\omega_0 t_0 =  u \\frac{\\sin \\alpha}{t_f} \\]\n\n\\[ W^2 +AK_1 \\cos \\alpha W \\]\n\ninitial kinetic energy of the projectile is:\n\n\\[ \\frac{ K_0 = Mf u}{2} \\]",
    "4. Travel on surface/loop\n\nThis problem may seem complicated at first (all those parameters!), but the work-kinetic energy theorem makes it tractable, as always. The work-kinetic energy theorem tells us that the net work done by the forces on the object is equal to the change in its kinetic energy. So: let's take the initial state to be when the object is released from rest (speed = 0), and the final state to be when the object is instantaneously at the largest height it can attain as it starts up a vertical loop on the surface. So the kinetic work done on the object during its path must be equal to the negative of the potential energy change during the path from point  to point above mgh.\n\n1. Using the force of the spring, from we can calculate the work done by the spring to be:\n\n\\[ W_{\\text{spring}} = \\int_{x_i}^{x_f} F_{\\text{spring}} \\cdot dx = - \\int_{x_i}^{x_f} k (x_i - x) dx = \\frac{1}{2} k x_i^2 \\]\n\n2. Using the force of the friction force, we can calculate the work done by the horizontal track to be:\n\n\\[ W_{\\text{friction}} = \\int_{x_i}^{x_f} F_{\\text{friction}} \\cdot dx = \\int_{x_i}^{x_f} (\\mu_{\\text{k}}(m g )) dx = - \\mu m g (x_f - x_i) = - \\mu m g x \\]\n\n3. The work done by the normal force at the surface of the loop is zero because the normal force (normal to the is perpendicular to the trajectory, so the dot product of the force and displacement perpendicular to the trajectory at the loops edge might as well. The loops are to frictionless\n\n4. Using the force of gravity, we can calculate the work done by gravity to be:\n\n\\[ W_{\\text{gravity}} = \\int_{y_i}^{y_f} F_{\\text{gravity}} \\cdot dy = - (mgh-y) = -mgh \\]\n\nThe total work at the surface is the sum of all these contributions, which must be equal to zero by the work-kinetic energy theorem. Thus, we have:\n\n\\[  W_{\\text{spring}} - W_{\\text{friction}} - W_{\\text{gravity}} = \\frac{1}{2} k x_i^2 -  \\mu m g x \\ - mgh = 0 \\]\n\nSolving this for x gives the final answer of\n\n\\[ x = \\frac{k x_i^2 }{ 2 \\mu g (x_\\mu + 2h)} \\]\n\n\\[ \\frac{2mg (\\frac{\\mu + 2h}{ x_i^2})} \\]",
    "5. Homework: Slide\n\n1. First, we take a coordinate system with the $x$ and $y$ unit vectors defined as shown in the figure above. In the $x$ and $y$ directions, Newton's second law is\n\n\\[ \nma_x = F - F_f = mg \\sin \\theta - F_f \n\\tag{1}\n\\]\n\n\\[ \nma_y = -mg \\cos \\theta + N = 0 \\Rightarrow N = mg \\cos \\theta \n\\tag{2}\n\\]\n\nrespectively, where $F_f$ is the magnitude of the kinetic friction force, $N$ is the magnitude of the normal force exerted by the other surface in the acceleration in the $x$ direction. Using the form of the friction force and equation (2), we have\n\n\\[ \nF_f = \\mu_k N = \\mu_k mg \\cos \\theta \n\\tag{3}\n\\]\n\nThis allows us to calculate the total work done by friction to be\n\n\\[ \nW_f = \\int_{x_i}^{x_f} (-F_f) \\, dx = -\\mu_k m g \\cos \\theta \\int_{x_i}^{x_f} \\, dx = -\\mu_k mg \\cos \\theta (x_f - x_i)\n\\tag{4}\n\\]\n\nPlugging in the numerical values, we obtain\n\n\\[ \nW_f = - (0.2) (32 \\, \\text{kg}) (9.8 \\, \\text{m/s}^2) (\\cos (20^\\circ)) (5 \\, \\text{m} - 0 \\, \\text{m}) = - 180.1 \\, \\text{J}\n\\tag{5}\n\\]\n\nIn this part, we calculate the total work performed on the child as she goes down the slide. We must add the work done by friction to determine the kinetic energy, which allows us to find the final speed. We already have $W_f$, so we need to calculate the work done by gravity, given by the path integral $W_g = \\int \\vec{F}_g \\cdot d \\vec{r}$. In our coordinate system, this becomes\n\n\\[ \nW_g = \\int_{0}^{x_f} \\left( 0 i - mgj \\right) \\cdot (dx i + dy j) = - mg \\int_{0}^{y} dy = -mg(y_f - y_i)\n\\tag{6}\n\\]\n\nAgain, plugging in the numerical values, this is\n\n\\[ \nW_g = - (32 \\, \\text{kg}) (9.8 \\, \\text{m/s}^2) (- h) = 313.6 \\, \\text{J}\n\\tag{7}\n\\]\n\nFinally, we add together the work done by all particles operating along the motion,\n\n\\[ \nW_{\\text{tot}} = W_f + W_g = -180.1 \\, \\text{J} + 313.6 \\, \\text{J} = 133.5 \\, \\text{J}\n\\tag{8}\n\\]\n\nby the work-kinetic energy theorem, this work must be equal to the change in kinetic energy according to\n\n\\[ \nW_{\\text{tot}} = K_f - K_i \n\\tag{9}\n\\]\n\nSince the child starts at rest, the initial kinetic energy is\n\n\\[ \nK_i = 0\n\\tag{10}\n\\]",
    "At the bottom, they are moving at some speed $v_B$ (which we want to calculate), so\n\\[ x_f = \\frac{1}{2} a t_f^2 \\]\n\\[ = \\frac{v_B^2}{2a}. \\tag{10} \\]\n\nPlugging equations (7), (9), and (10) into equation (8) gives\n\\[ \\frac{1}{2} m v_B^2 = mg(h_r - h_B) - \\mu m g x_f, \\]\n\n\\[ = mg(h_r - h_B) - \\mu m g \\left( \\frac{v_B^2}{2a} \\right). \\tag{11} \\]\n\nWe can solve this to find that the speed of the child at the bottom of the slide is\n\\[ v_B = \\pm \\sqrt{\\frac{2g(h_r - h_B)}{1 + \\frac{\\mu g}{a}}}. \\tag{12} \\]\n\nPlugging in the numbers gives\n\\[ v_B = \\pm \\sqrt{\\frac{2(9.8)(4.0)}{1 + \\frac{(0.30)(9.8)}{(7.0 \\, \\text{m/s}^2)}}} = 3.9 \\, \\text{m/s}. \\]\n\n3. To calculate the time it takes for the child to slide down the slide, we use to Newton\u2019s second law in the $\\hat{x}$ direction (in the coordinate system of part 3). Substituting equations (7) and (9) into equation (1) gives\n\\[ \\sum F_x = mg \\sin(\\theta_r) - \\mu mg \\cos(\\theta_r) = m a. \\]\n\n\\[ g \\sin(\\theta_r) - \\mu g \\cos (\\theta_r) = a, \\]\n\nIntegrating this once in time gives $v_f = v(t_f)$,\n\\[ v_f = \\left[g \\sin (\\theta_r) - \\mu g \\cos(\\theta_r)\\right]t_f. \\tag{13} \\]\n\nwhere the integration constant is zero because the child starts at rest. Since we know the final speed from part 2, we can use it to calculate the final time $t_f$ as\n\\[ t_f = \\frac{v_f}{g \\sin(\\theta_r) - \\mu \\cos(\\theta_r)}. \\]\n\nSubstituting equation (12) gives\n\\[ t_f = \\frac{\\sqrt{\\frac{2 g (h_r - h_B)}{1 + \\frac{\\mu g}{a}}}}{g \\left( \\frac{h_r - h_B}{L}\\right) - \\mu g \\sqrt{1 - \\frac{(h_r - h_B)^2}{L^2}}}. \\tag{14} \\]\n\nPlugging in the numbers, we find\n\\[ t_f = \\frac{3.9}{(9.8) \\left( \\frac{2.0}{2.5}\\right) - (0.30)(9.8) \\sqrt{1 - \\left(\\frac{2.0}{2.5}\\right)^2}}, \\]\n\n\\[ = \\frac{3.9}{4.9} = 0.80 \\, \\text{s}. \\tag{16} \\]\n\n4. Since we can now see that the children do not finish at rest, we turn to the work-kinetic energy theorem for this case. The kinetic energy at the top is zero, and the net work done on each child equals their kinetic energy at the bottom of the slide. The net work is the sum of the gravitational work, the work done by the normal force, and the work done by friction. The normal force does zero net work, since\n\\[ W_N = \\int_{i}^{f} \\vec{N} \\cdot d \\vec{r} = \\vec{N} \\int_{i}^{f} d r \\cos (90^{\\circ}) = 0, \\tag{17} \\]\n\nbecause $\\vec{N}$ is always perpendicular to $d \\vec{r}$ However, friction does negative work while gravity does positive work along the direction of motion. Therefore, we see that the work-energy theorem states\n\\[ W_g + W_f = \\Delta(KE) \\]\n\nSubstituting into this equation (19) allows us to calculate the work done by the child\n\\[ W_c = mg(h_r-h_f) - \\frac{1}{2} m v_B^2. \\]\n\nWe note that this doesn\u2019t depend on times, only on the mass of the child. Since the two children have equal masses, they do the same amount of work.\n\n\\[  \\]",
    "Chapter 7  \nPOTENTIAL ENERGY, MECHANICAL ENERGY AND RESONANCE",
    "7. Potential energy, mechanical energy and resonance\n\n7.1 Potential energy and mechanical energy\n7.2 Dissipated power, equilibrium and stability\n7.3 Resonance",
    "7.1 Potential energy and mechanical energy\n\nConservative force: A force $F_c$ is called conservative if the work performed by this force is independent of the path followed and depends only on the initial position $r_1$ and the final position $r_2$.\n\n$$\nW_{12} = \\int_{r_1}^{r_2} F_c(r') \\cdot dr' = \\int_{r_1}^{r_s} F_c(r') \\cdot dr' + \\int_{r_s}^{r_2} F_c(r') \\cdot dr' \\quad (7.1)\n$$\n\nwhere $r_s$ is an arbitrary reference position vector. This will have as a consequence that the action of a conservative force \"conserves\" mechanical energy.",
    "7.1.1 Potential energy\n\nScalar and extensive quantity $V(r)$ defined as the opposite of the integral of a conservative force $F_c$ with respect to a reference position $r_s$:\n\\[ V(r) = - \\int_{r_s}^r F_c \\cdot dr' \\tag{7.2} \\]\n\nDefined up to a constant\n\nWork of a conservation force\n\\[ W_{12} = \\int_{r_s}^{r_1} F_c \\cdot dr' + \\int_{r_s}^{r_2} F_c \\cdot dr' = V(r_1) - V(r_2) \\]\n\\[ \\equiv -(V_2 - V_1) \\tag{7.3} \\]\n\nPhysical unit (SI):\n\\[ [J] = \\left[ \\mathrm{kg} \\frac{m^2}{s^2} \\right] \\]",
    "Theorem: The necessary and sufficient condition for the existence of a potential or a potential energy $V(r)$ associated to a force $F$, i.e. for the force $F$ to be conservative, is that the curvilinear integral of the infinitesimal work $F \\cdot dr$ along every closed path vanishes,\n\\[\n\\oint F \\cdot dr = 0 \\tag{7.4}\n\\]\nDemonstration: since the integral has to vanish for every closed path, it is independent of the path. It depends only on the initial position $r_1$ and on the final position $r_2 = r_1$\n\\[\n\\Rightarrow \\oint F \\cdot dr = \\int_{r_1}^{r_1} F \\cdot dr = 0 \\tag{7.5}\n\\]",
    "7.1.2 Mechanical energy\n\nScalar and extensive quantity $E$ that is the sum of the kinetic energy $T$ and of the total potential energy $V$\n\n$$E = T + V$$\n(7.6)\n\n- Physical unit: Joule (SI) \\quad $[J] = \\left[ \\text{kg m}^2 \\text{s}^{-2} \\right]$\n\n- A conservative force does not change the mechanical energy of a material point. It transforms the potential energy into kinetic energy and vice versa (e.g. elastic force, weight)\n\n- The energy is defined up to a constant, because one can choose freely the reference of the potential.",
    "Theorem: If all the forces that act on a material point are conservative forces, then the mechanical energy $E$ is conserved, which implies that the mechanical energy $E_1$ at time $t_1$ is equal to the mechanical energy $E_2$ at time $t_2$,\n\n$$E_1 = E_2 = \\text{const} \\quad (7.7)$$\n\nDemonstration:\n\ni. Kinetic energy theorem: $$W_{12} = T_2 - T_1 \\quad (6.33)$$\n\nii. Work of conservative forces: $$W_{12} = -(V_2 - V_1) \\quad (7.3)$$\n\n$$(6.33) \\equiv (7.3) \\quad \\Rightarrow \\quad T_2 - T_1 = -(V_2 - V_1) \\quad \\Rightarrow \\quad T_1 + V_1 = T_2 + V_2$$\n\n(7.6) : $$E = T + V$$\n\n$$\\Rightarrow \\quad E_1 = T_1 + V_1 = T_2 + V_2 = \\text{const} \\quad \\forall 1, 2 \\quad (7.8)$$",
    "7.1.3 Conservative force\n\n- Position and infinitesimal displacement (Cartesian frame):\n\n\\[ \nr = \\sum_{i=1}^{3} x_i e_i \\quad \\Rightarrow \\quad dr = \\sum_{i=1}^{3} dx_i e_i \\quad (7.9) \n\\]\n\n- Infinitesimal work (conservative force):\n\n\\[ \nF_c \\cdot dr = -\\left( V(r+dr) - V(r) \\right) = -\\sum_{i=1}^{3} \\left( \\frac{V(r + dx_i e_i) - V(r)}{dx_i} \\right) dx_i\n\\]\n\n\\[ \n= -\\sum_{i=1}^{3} \\frac{\\partial V}{\\partial x_i} dx_i = -\\left( \\sum_{i=1}^{3} \\frac{\\partial V}{\\partial x_i} e_i \\right) \\cdot dr = -\\frac{dV}{dr} \\cdot dr\n\\quad (7.10) \n\\]\n\n- Potential gradient (vector):\n\n\\[ \n\\nabla V \\equiv \\frac{dV}{dr} = \\sum_{i=1}^{3} \\frac{\\partial V}{\\partial x_i} e_i \\quad \\text{where} \\quad \\nabla = \\left( \\frac{\\partial}{\\partial x_1}, \\frac{\\partial}{\\partial x_2}, \\frac{\\partial}{\\partial x_3} \\right)\n\\quad (7.11) \n\\]",
    "- Potential gradient (vector):\n$$\\nabla V = \\frac{dV}{dr} = \\sum_{i=1}^3 \\frac{\\partial V}{\\partial x_i} e_i \\quad \\text{where} \\quad \\nabla = \\left( \\frac{\\partial}{\\partial x_1} \\, \\frac{\\partial}{\\partial x_2} \\, \\frac{\\partial}{\\partial x_3} \\right) \\tag{7.11}$$\n- Conservative force (7.10) and (7.11):\n$$F_c = - \\nabla V \\quad \\tag{7.12} \\text{total derivative} \\quad \\frac{dV}{dr} \\quad \\longleftrightarrow \\quad \\text{partial derivative} \\quad \\frac{\\partial V}{\\partial x_i}$$\n- The gradient $\\nabla V$ represents the direction of largest slope of $V$. The equipotentials are the curves of constant potential. They are orthogonal to the gradient.",
    "7.1.4 Gravitational potential energy\n\n- Gravitational potential energy:\n\\[ V_g(r) = - \\int_{r_0}^{r} \\mathbf{P} \\cdot d\\mathbf{r}' = - \\int_{r_0}^{r} mg\\, dz' \\tag{7.13} \\]\n\n- Reference of potential: \\( r_0 = 0 \\)\n- Position: \\( r = z \\mathbf{e_z} \\quad \\Rightarrow \\quad dr = dz \\mathbf{e_z} \\)\n- Gravitational field: \\( \\mathbf{g} = -g \\mathbf{e_z} \\tag{7.14} \\)\n\n- Gravitational potential energy:\n\\[ V_g(z) = - \\int_{0}^{z} mg \\, dr' = mg \\int_{0}^{z} dz' = mgz \\tag{7.15} \\]\n\n- Weight:\n\\[ \\mathbf{P} = - \\nabla V_g = - \\frac{dV_g}{dr} = - \\frac{dV_g}{dz} \\mathbf{e_z} = - mg \\mathbf{e_z} = m \\mathbf{g} \\tag{7.16} \\]\n\n- The potential energy of the yo-yo is converted into kinetic energy and vice-versa ... (conservation of \\( E \\))",
    "7.1.5 Elastic potential energy\n\n- Elastic potential energy:\n\\[\nV_e(r) = - \\int_{r_s}^r F_e \\cdot dr' = - \\int_{r_s}^r k r' \\cdot dr' \\quad (7.17)\n\\]\n\n- Reference of potential: $r_s = 0$\n- Position: $r = x e_x \\Rightarrow dr = dx e_x$ (7.18)\n- Elastic potential energy:\n\\[\nV_e(x) = \\int_0^x k r' \\cdot dr' = k \\int_0^x x'dx' = \\frac{1}{2} k x^2 \\quad (7.19)\n\\]\n\n- Elastic force:\n\\[\nF_e = - \\nabla V_e = - \\frac{dV_e}{dr} = - \\frac{dV_e}{dx} e_x = - k x e_x = - k r \\quad (7.20)\n\\]\n\n- The elastic potential energy in the Wilberforce pendulum is converted into kinetic energy and vice-versa... (conservation of E)",
    "7.2 Dissipated power, equilibrium and stability\n\n7.2.1 Dissipated mechanical power\n\n- Conservative external force: $F^{ext}_c (t)$\n- Non-conservative external force: $F^{ext}_{nc} (t)$\n- Sum of external forces:\n\\[\n\\sum F^{ext} (t) = F^{ext}_c (t) + F^{ext}_{nc} (t) \\tag{7.21}\n\\]\n- Conservative force (vectorial derivative of the potential energy):\n\\[\nF^{ext}_c (t) = - \\nabla V (r (t)) \\tag{7.22}\n\\]\n- Potential energy:\n\\[\nV (t) \\equiv V (r (t)) \\tag{7.23}\n\\]\n- Dissipated power:\n\\[\nP_{nc} (t) \\equiv \\frac{dE(t)}{dt} \\tag{7.24}\n\\]",
    "- Dissipated power:\n\n$$\nP_{nc}(t) = \\frac{dE(t)}{dt} = \\frac{d \\left( T(t) + V(t) \\right)}{dt} = \\frac{d}{dt} \\left( \\frac{1}{2} mv^2(t) + V \\left( r(t) \\right) \\right) = m v(t) \\cdot \\frac{dv(t)}{dt} + \\frac{d V \\left( r(t) \\right)}{dr(t)} \\cdot \\frac{dr(t)}{dt} = ma(t) + \\nabla V \\left( r(t) \\right) \\cdot v(t)\n$$\n$$\nma(t) + \\nabla V \\left( r(t) \\right) = -F_{ext}^c(t)\n$$\n\n(7.25)\n\n- Law of motion:\n\n$$\n\\sum F_{ext}(t) = ma(t)\n$$\n\n(7.26)\n\n- Dissipated power:\n\n$$\nP_{nc}(t) = \\left( \\sum F_{ext}(t) - F_{ext}^c(t) \\right) \\cdot v(t) = F_{ext}^{nc}(t) \\cdot v(t)\n$$\n\n(7.27)",
    "- Dissipated power:\n\n\\[ \nP_{nc}(t) = \\left( \\sum F^{ext} - F^{ext}_c(t) \\right) \\cdot v(t) = F^{ext}_{nc}(t) \\cdot v(t) \\quad (7.27) \n\\]\n\n- Example:\n\nViscous friction force: \\( F^{ext}_{nc}(t) = F_f(t) = -bv(t) \\)\n\n\\[ \nP_{nc}(t) = F_f(t) \\cdot v(t) = -b v^2(t) < 0 \\quad o\u00f9 \\quad b > 0 \n\\]\n\nThe mechanical energy is dissipated.\n\nIt transforms into thermal energy.",
    "7.2.2 Equilibrium position stability\n\n- We consider the motion of a material point with one degree of freedom in the absence of a non-conservative force (conservation of E)\n- Equilibrium position: $T = 0 \\quad \\Rightarrow \\quad E = V = \\text{const}$ \\hspace{1cm}(7.29)\n- Generalised coordinate (length, angle): \n  $q \\in \\{x, y, z, r, \\rho, \\varphi, \\dots \\} \\quad \\Rightarrow \\quad V = V(q)$ \n- Equilibrium position $q = q_0$: $V(q_0) = \\text{const} \\quad \\Rightarrow \\quad \\left. \\frac{dV}{dq} \\right|_{q=q_0} = 0 $ \\hspace{1cm}(7.30)\n- Power series expansion to 2\\textsuperscript{nd} order in $q$ of $V(q)$ around $q = q_0$:\n  \\[\n    V(q) = V(q_0) + \\left. \\frac{dV}{dq} \\right|_{q=q_0} \\left( q - q_0 \\right) \n    + \\frac{1}{2} \\left. \\frac{d^2V}{dq^2} \\right|_{q=q_0} \\left( q - q_0 \\right)^2 \n    + O \\left( q^3 \\right) \\hspace{1cm}(7.31)\n  \\]\n  \\[\n    V(q) = V(q_0) + \\frac{1}{2} \\left. \\frac{d^2V}{dq^2} \\right|_{q=q_0} \\left( q - q_0 \\right)^2 + O \\left( q^3 \\right) \\hspace{1cm}(7.32)\n  \\]",
    "- Conservative force: $F_c = -\\nabla V = -\\frac{dV}{dq} e_q \\quad (7.33)$\n- Potential energy:\n$$\nV(q) = V(q_0) + \\frac{1}{2} \\frac{d^2 V}{dq^2} \\bigg|_{q=q_0} (q - q_0)^2 + \\mathcal{O}(q^3) \\quad (7.32)\n$$\n- In the neighbourhood of the equilibrium position $q = q_0$, the potential energy is a parabolic function of the generalised coordinate $q$.\n- Stable equilibrium position: $\\frac{d^2 V}{dq^2} \\bigg|_{q=q_0} > 0$\n- Unstable equilibrium position: $\\frac{d^2 V}{dq^2} \\bigg|_{q=q_0} < 0$",
    "7.2.3 Stability of the mathematical pendulum\n\n- Vertical coordinate: $z(\\phi) = \\ell (1 - \\cos \\phi )$ where $q \\equiv \\phi$\n- Gravitational potential energy:\n$$V_g (\\phi) = mgz(\\phi) = mg\\ell (1-\\cos \\phi) \\quad (7.34)$$\n- Equilibrium condition $\\phi = \\phi_0$:\n$$(7.30) \\quad \\frac{dV_g}{d\\phi} \\bigg|_{\\phi=\\phi_0} = mg\\ell \\sin \\phi_0 = 0 \\quad \\Rightarrow \\quad \\phi_0 \\in \\{0, \\pi\\} \\quad (7.35)$$\n- Second-order derivative of the potential energy:\n$$\\frac{d^2 V_g}{d\\phi^2} \\bigg|_{\\phi=\\phi_0} = mg\\ell \\cos \\phi_0 \\quad (7.36)$$",
    "- Second-order derivative of the potential energy:\n\\[ \\left. \\frac{d^2 V_q}{d\\varphi^2} \\right|_{\\varphi = \\varphi_0} = mg\\ell \\cos \\varphi_0 \\quad (7.36) \\]\n\n- Lower equilibrium position:\n\\[ \\left. \\frac{d^2 V_q}{d\\varphi^2} \\right|_{\\varphi = \\varphi_0 = 0} = mg\\ell > 0 \\quad \\Rightarrow \\text{stable position} \\quad (7.37) \\]\n\n- Upper equilibrium position:\n\\[ \\left. \\frac{d^2 V_q}{d\\varphi^2} \\right|_{\\varphi = \\varphi_0 = \\pi} = -mg\\ell < 0 \\quad \\Rightarrow \\text{unstable position} \\quad (7.38) \\]",
    "7.3 Resonance\n\n\u2460 Koenig's tube\n\nFor specific tube lengths, the sound is amplified \u2192 resonance.\n\n\u2461 Vibrations of plastic rods\n\nAt specific frequencies, the rods of specific length vibrate \u2192 resonance.\n\n\u2462 MRI\n\nMagnetic resonance imaging",
    "7.3.1 Driven harmonic oscillator\n\nExternal forces:\nWeight: $P = mg = mg e_X$\nElastic force: (deformation) $d = r - \\ell_0 e_X$ where $r = X e_X$\n\n$F_e = -kd = -k (X - \\ell_0) e_X$ where $\\ell_0 =$ natural length\n\nViscous friction force: $F_f = - bv = - b \\dot{X} e_X$\n\nPeriodic driving force: $\\mathbf{F}(t) = F_0 \\cos(\\omega t) e_X$\n\nLaw of motion:\n$$\\sum F^{\\text{ext}} = P + F_e + F_f + F(t) = ma$$\nwhere $a = \\ddot{X} e_X$\n\nEquation of motion:\n$$mg - k(X - \\ell_0) - b\\dot{X} + F_0 \\cos(\\omega t) = m \\ddot{X}$$\n(7.41)",
    "- Equation of motion:\n\\[mg - k(X - \\ell_0) - b\\dot{X} + F_0 \\cos(\\omega t) = m\\ddot{X}\\]\n(7.41)\n\n- Change of variable:\n\\[x = X - \\ell_0 - \\frac{mg}{k} \\quad \\Rightarrow \\quad \\dot{x} = \\dot{X} \\quad \\text{and} \\quad \\ddot{x} = \\ddot{X}\\]\n(7.42)\n\n- Equation of motion (7.41) becomes:\n\\[m\\ddot{x} + b\\dot{x} + kx = F_0 \\cos(\\omega t)\\]\n(7.43)\n\n- Pulsation, relaxation time, driving acceleration:\n\\[\\omega_0 = \\sqrt{\\frac{k}{m}} \\quad (4.26) \\quad ; \\quad \\tau = \\frac{m}{b} \\quad (3.22) \\quad ; \\quad a_0 = \\frac{F_0}{m}\\]\n(7.44)\n\n- Equation of motion (7.43) becomes:\n\\[\\ddot{x} + \\frac{1}{\\tau} \\dot{x} + \\omega_0^2 x = a_0 \\cos(\\omega t)\\]\n(7.45)\n\n\u21d2 It is the equation of a damped harmonic oscillator with an excitation term on the right hand side (RMS).",
    "7.3.2 Transient and stationnary regimes\n\n- General solution (solution homogeneous system + particular solution): $x(t) = x_h(t) + x_p(t)$ (7.46)\n\n- Homogeneous system: ($a_0=0$):\n\n$\\ddot{x}_h + \\frac{1}{\\tau}\\dot{x}_h + \\omega_0^2 x_h = 0 \\rightarrow x_h(t) = Ce^{-t/\\tau} \\cos(\\omega_1 t + \\varphi_1)$ (7.47)\n\n- Particular solution (oscillation of pulsation $\\omega$):\n$x_p(t) = p \\cos(\\omega t + \\varphi)$ (7.48)\n\n- Two regimes:\n\n1) Transient regime: ($t < \\tau$) $x_h(t) \\sim x_p(t)$ (interferences = beats)\n\n2) Stationary regime: ($t \\gg \\tau$) $x(t) \\simeq x_p(t)$ because $x_h(t) \\ll x_p(t)$ (7.50) (harmonic response)",
    "7.3.3 Harmonic response\n\n- Equation of motion (stationary regime):\n\\[\n\\ddot{x} + \\frac{1}{\\tau} \\dot{x} + \\omega_0^2 x = a_0 \\cos (\\omega t) \\quad \\text{(7.45)}\n\\]\n\n- Stationary solution:\n\\[\nx(t) = \\rho \\cos (\\omega t + \\varphi) \\quad \\text{(7.51)}\n\\]\n\n- Solution dephased by an angle $-\\pi / 2$: $\\omega t \\rightarrow \\omega t - \\pi / 2$\n\\[\ny(t) = \\rho \\sin (\\omega t + \\varphi) \\quad \\text{(7.52)}\n\\]\n\n- Equation of motion (7.45) expressed in terms of $y(t)$:\n\\[\n\\ddot{y} + \\frac{1}{\\tau} \\dot{y} + \\omega_0^2 y = a_0 \\sin (\\omega t) \\quad \\text{(7.53)}\n\\]\n\n- Complex equation of motion: $z(t) = x(t) + iy(t) \\in \\mathbb{C}$\n\\[\n\\ddot{z} + \\frac{1}{\\tau} \\dot{z} + \\omega_0^2 z = a_0 e^{i\\omega t} \\quad \\text{where} \\quad e^{i\\omega t} = \\cos (\\omega t) + i \\sin (\\omega t) \\quad \\text{(7.54)}\n\\]",
    "- Real stationary solutions:\n  $x(t) = \\rho \\cos (\\omega t + \\varphi)$ and $y(t) = \\rho \\sin (\\omega t + \\varphi)$\n\n- Complex stationary solution:\n  $z(t) = x(t) + iy(t) = \\rho (\\cos (\\omega t + \\varphi) + i \\sin (\\omega t + \\varphi)) = \\rho e^{i (\\omega t + \\varphi)}$\n  $z(t) = z_0 e^{i \\omega t}$ where $z_0 = \\rho e^{i \\varphi}$    (7.55)\n\n- Equation of motion: (7.55) $\\Rightarrow$ (7.54):\n   $(-\\omega^2 + i \\frac{\\omega}{\\tau} + \\omega_0^2) z_0 e^{i \\omega t} = a_0 e^{i \\omega t}$    (7.56)\n\n- Complex amplitude:\n  $z_0 = \\frac{a_0}{\\omega_0^2 - \\omega^2 + i (\\omega / \\tau)} = a_0 \\frac{\\omega_0^2 - \\omega^2 - i (\\omega / \\tau)}{(\\omega_0^2 - \\omega^2)^2 + (\\omega / \\tau)^2}$    (7.57)\n\n- Real amplitude:\n  $\\rho = |z_0| = \\frac{a_0}{\\sqrt{(\\omega_0^2 - \\omega^2)^2 + (\\omega / \\tau)^2}}$    (7.58)",
    "- Complex amplitude:\n\\[ z_0 = \\dfrac{a_0}{\\omega_0^2 - \\omega^2 + i \\left( \\omega / \\tau \\right)} = a_0 \\dfrac{\\omega_0^2 - \\omega^2 - i \\left( \\omega / \\tau \\right)}{\\left( \\omega_0^2 - \\omega^2 \\right)^2 + \\left( \\omega / \\tau \\right)^2} \\]\n\n\\[ \n\\text{(7.57)}\n\\]\n\n- Real amplitude:\n\\[ \n\\rho = \\left| z_0 \\right| = \\dfrac{a_0}{\\sqrt{ \\left( \\omega_0^2 - \\omega^2 \\right)^2 + \\left( \\omega / \\tau \\right)^2 }} \n\\]\n\n\\[ \n\\text{(7.58)}\n\\]\n\n- Dephasing angle:\n\\[ \n\\tan \\varphi = \\dfrac{\\rho \\sin \\varphi}{\\rho \\cos \\varphi} = \\dfrac{\\mathrm{Im} \\left( \\rho e^{i \\varphi} \\right)}{\\mathrm{Re} \\left( \\rho e^{i \\varphi} \\right)} = \\dfrac{\\mathrm{Im} \\left( z_0 \\right)}{\\mathrm{Re} \\left( z_0 \\right)} = - \\dfrac{\\omega / \\tau}{\\omega_0^2 - \\omega^2} \n\\]\n\n\\[ \n\\text{(7.59)}\n\\]\n\n\\[ \n\\Rightarrow \\quad \\varphi = \\arctan \\left( - \\dfrac{\\omega / \\tau}{\\omega_0^2 - \\omega^2} \\right)\n\\]",
    "- Amplitude and dephasing angle:\n\n$$\n\\rho (\\omega ) = \\frac{a_0}{\\sqrt{ (\\omega_0^2 - \\omega^2)^2 + (\\omega / \\tau )^2 }} ; \\quad \\varphi (\\omega) = \\arctan \\left( \\frac{-\\omega / \\tau}{\\omega_0^2 - \\omega^2} \\right)\n$$\n\n- Ratio of the amplitudes:\n$$\n\\frac{\\rho (\\omega)}{\\rho (0)} = \\frac{\\omega_0^2}{\\sqrt{ (\\omega_0^2 - \\omega^2)^2 + (\\omega / \\tau )^2}} \\quad \\text{lorentzian function}\n$$\n\n- Resonance \"frequency\" (max. lorentzian): $\\omega = \\omega_0$\n\n$$\n\\omega = \\omega_0 \\quad (7.60)\n$$\n$$\n\\begin{aligned}\n&\\lim_{\\omega \\rightarrow \\omega_0} \\frac{\\rho (\\omega)}{\\rho (0)} = \\omega_0 \\tau \\\\\n&\\lim_{\\omega \\rightarrow 0} \\frac{\\rho (\\omega)}{\\rho (0)} = 1 \\\\\n&\\lim_{\\omega \\rightarrow \\infty} \\frac{\\rho (\\omega)}{\\rho (0)} = 0 \\\\\n&\\quad \\color{brown}{\\varphi (\\omega = \\omega_0) = -\\frac{\\pi}{2}} \\quad (7.61)\n\\end{aligned}\n$$\n\nwhere $\\tau \\propto \\eta^{-1}$  \nSmall viscosity $\\eta \\Rightarrow$ large amplitude at resonance",
    "Examples of resonance\n\nThe Tacoma bridge collapsed in 1940 when a strong wind generated a resonance whose amplitude became so large that the structure could not resist.",
    "Letting the first pendulum oscillate, the other pendula begin to oscillate also (transient regime). After a certain time, only the first and the fourth are still oscillating and the other stop oscillating (stationary regime). The first pendulum (red) has the same length as the fourth and thus the same pulsation because the pulsation $\\omega = \\sqrt{g/\\ell}$ of a pendulum depends on its length.",
    "3 Synchronisation of metronomes\n\nSix metronomes having the same oscillation frequency oscillate on the same wooden plate. When the plate can roll on two Plexiglas cylinders, the metronomes get synchronised, otherwise they loose their synchronisation.",
    "4 Destruction of a glass through acoustic resonance\n\nWhen the glass is acoustically exited by a loudspeaker at its resonance frequency, it is first deformed, then it breaks.",
    "Chapter 2\nMATERIAL POINT KINEMATICS AND DYNAMICS",
    "2. Material point kinematics and dynamics\n\n2.1 Material point kinematics\n2.2 Linear motion\n2.3 Newton\u2019s laws\n\n\u2460 Kinematics: description of the motion of a body (position, velocity, acceleration)\n\n\u2461 Dynamics: study of the mechanical causes of the motion of a body (force, momentum, ...)",
    "2.1 Material point kinematics\n\n2.1.1 Material point\n\nRepresentation of a physical object using a point to which all the matter (mass) is attributed.\n* Model: idealisation of the reality\n* Limits: no intrinsic rotation motion\n* Errors: (i) quantitative (ii) qualitative\n\n2.1.2 Frame of reference\n\nPhysical object (rigid) of reference with respect to which a motion is described.\nExamples: earth, boat, solar system\nSet of $N$ material points ($N \\ge 4$) non-coplanar and fixed respect to each other.\n\n2.1.3 Frame of reference and geometric frame\n\nFrame of reference (real) $\\leftrightarrow$ geometric frame (virtual)",
    "2.1.4 Position vector\n\n- Material point $P$\n- Cartesian frame $(O, e_x, e_y, e_z)$\n- Position vector $OP$\n- $OP = r(t) = (x(t), y(t), z(t))$\n- Unit of position (SI): metre $[m]$\n- Unit of time (SI): second $[s]$\n\n2.1.5 Trajectory\n\nThe trajectory is the set of spatial points where the material point is located over time.\n\nExamples:\n(i) line (free fall)\n(ii) circle (electron, magnetic field)\n(iii) parabola (projectile)\n(iv) ellipse (planet)\n(v) hyperbola (asteroid)",
    "2.1.6 Velocity vector\n\n- Velocity vector $ \\mathbf{v}(t) $ : time derivative of the position vector $ \\mathbf{r}(t) $\n- Cartesian frame: $ (O, e_x, e_y, e_z) $\n\\[ \\mathbf{v}(t) = \\dot{\\mathbf{r}}(t) = (\\dot{x}(t), \\dot{y}(t), \\dot{z}(t)) \\]\n\\[ \\mathbf{v}(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta \\mathbf{r}(t)}{\\Delta t} = \\lim_{\\Delta t \\to 0} \\frac{\\mathbf{r}(t + \\Delta t) - \\mathbf{r}(t)}{\\Delta t} \\]\n\n\\[ = \\frac{d\\mathbf{r}}{dt} = \\dot{\\mathbf{r}} \\quad (2.1) \\]\n\n- The velocity vector $ \\mathbf{v}(t) $ is always tangent to the trajectory of the material point.\n- Unit of the velocity (SI): $ \\left[ \\frac{m}{s} \\right] $",
    "Experiment: Measurement of the velocity of a gun bullet\n\nThe velocity of the gun bullet is measured using two photoelectric cells. Since the velocity is constant, it is obtained by taking the ratio of the distance between the photoelectric cells and the time spent between the cells.",
    "2.1.7 Acceleration vector\n\n- Acceleration vector $a(t)$: time derivative of velocity vector $v(t)$\n\n- Cartesian frame: $(O, e_x, e_y, e_z)$\n\n\\[ a(t) = \\dot{v}(t) = \\ddot{r}(t) = (\\ddot{x}(t), \\ddot{y}(t), \\ddot{z}(t)) \\]\n\n\\[ a(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta v(t)}{\\Delta t} = \\lim_{\\Delta t \\to 0} \\frac{v(t + \\Delta t) - v(t)}{\\Delta t} \\]\n\n\\[ = \\frac{dv}{dt} = \\dot{v} \\]\n\n(2.2)\n\n- In general, the acceleration vector $a(t)$ has a tangential component and a normal component to the trajectory.\n\n- Unit of the acceleration (SI): $\\left[ \\frac{m}{s^2} \\right]$",
    "2.2 Linear motion\n\n2.2.1 Uniform linear motion\n\nULM: Motion at constant velocity $\\mathbf{v}$ where the trajectory is a straight line.\n\nDefinition: $v = \\dot{x} = \\frac{dx}{dt}$ = const $\\Rightarrow dx = v \\, dt$ \\, (2.3)\n\nIntegral: $x(t) = \\int dx$ \\, $(2.3) \\Rightarrow x = \\int v \\, dt = vt + c_0$ \\, (2.4)\n\nInitial condition: $x(0) = x_0$ \\, $(2.5) \\Rightarrow c_0 = x_0$ \\, (2.6)\n\nPosition equation: $x(t) = vt + x_0$ \\, (2.7)\n\nExamples: \n- free glider on an air bench\n- curling stone\n- gun bullet",
    "2.2.2 Uniformly accelerated linear motion\n\nUALM: Motion with a constant acceleration $a$ where the trajectory is a straight line\n\nDefinition: $a = \\ddot{x} = \\frac{d^2 x}{d t^2} = \\frac{dv}{dt} = \\text{const} \\Rightarrow dv = a \\, dt$ (2.8)\n\nIntegral: $v(t) = \\int dv \\stackrel{(2.8)}{=} \\int a \\, dt = a \\int dt = at + c_1$ (2.9)\n\nInitial condition: (velocity) $v(0) = v_0 \\stackrel{(2.9)}{=} a(0) + c_1 = v_0$ (2.11)\n\nVelocity equation: $v(t) = at + v_0$ (2.12)\n\n$\\Rightarrow \\frac{dx}{dt} = at + v_0 \\Rightarrow dx = (at + v_0) \\, dt$ (2.14)",
    "Integral: $x(t) = \\int dx = a \\int t \\, dt + v_0 \\int dt = \\frac{1}{2} at^2 + v_0 t + c_2 \\quad (2.15)$\n\nInitial condition: (position)\n\n$x(0) = x_0 \\quad (2.16) \\quad \\Rightarrow \\quad c_2 = x_0 \\quad (2.17)$\n\nPosition equation: $x(t) = \\frac{1}{2} at^2 + v_0 t + x_0 \\quad (2.18)$\n",
    "2.3 Newton's laws\n\n2.3.1 Extensive and intensive quantities\n\n- Extensive quantity: physical quantity that, for a set of objects, is equal to its sum for each object.\n\nExamples: amount of matter, momentum, force, volume.\n\n- Intensive quantity: physical quantity that is independent of the number of objects.\n\nExamples: velocity, acceleration, temperature.",
    "2.3.2 Mass\n\nMass (M or m): physical quantity characterising the amount of matter of an object.\n\n- Extensive quantity\n- Scalar quantity\n- Conserved quantity (Lavoisier)\n- Constant mass\n  \u21d2 closed system (gold bar)\n- Variable mass\n  \u21d2 open system (rocket)\n- Physical unit (SI): kilogram [kg]",
    "2.3.3 Momentum\n\n- Momentum $p$: physical quantity characterising the motion of every object.\n- Extensive quantity\n- Vectorial quantity\n\n2.3.4 Newton\u2019s 1st law\nGalileo\u2019s law of inertia is stated by Newton in his \"Principia Mathematica\" as:\n\nEvery body perseveres in its state of rest or of uniform motion in a right line, unless in so far as it is compelled to change that state by forces impressed thereon.\n\nIn more modern words, we would simply say:\n\nA body has a uniform linear motion in the absence of a net external force. If its speed vanishes, then it is a rest.",
    "- Inertial frame of reference:\n  Every frame with respect to which the law of inertia is verified.\n\n2.3.5 Force\n\nForce: $F$ physical quantity that modifies the state of rest or of uniform motion of an object.\n- Extensive quantity\n- Vectorial quantity\n\nVectorial summation rule for the forces (parallelogram identity):\n\n$F_A + F_B = F_C$",
    "2.3.6 Newton's 2nd law\n\nNewton's 2nd law is stated in his \"Principia Mathematica\" in the following way:\n\nThe change of motion is proportional to the motive force impressed, and is made in the direction of the straight line in which that force is impressed.\n\nIn more modern words, we would simply say:\n\nThe variation of momentum over time of a body is due to the net external force applied on this body.\n\nIn mathematical language, this is expressed as:\n\n$$\\sum F_{\\text{ext}} = \\frac{dp}{dt}$$\n\n(2.19)",
    "2.3.7 Momentum and velocity\n\n- System of $k$ material points of mass $m$ and of velocity $v$\n- Extensivity of $p$ and $m$: \n  $$\n  p(km) = k p(m) \\tag{2.20}\n  $$\n\n$$\n\\begin{aligned}\n  & \\text{(1.13)} \\quad \\Rightarrow \\quad \\frac{dp(km)}{d(km)} \\cdot \\frac{d(km)}{dk} = \\frac{dk}{dk} p(m) \\tag{2.21} \\\\\n  & \\Rightarrow \\quad \\frac{dp(km)}{d(km)} m = p(m) \\quad \\forall k \\tag{2.22}\n\\end{aligned}\n$$\n\n- For $k = 1$\n  $$\n  \\Rightarrow \\quad \\frac{dp(m)}{dm} = \\frac{p(m)}{m} \\tag{2.23}\n  $$\n  $\\Rightarrow$ The momentum $p(m)$ is proportional to the mass $m$.\n  $$\n  p = m f (v) \\quad \\text{(valid even in special relativity)}\n  $$\n  Gauge choice: $v = 0 \\quad \\Rightarrow \\quad p = 0 \\quad$ thus  $\\quad f(0) = 0$",
    "Experiment: totally inelastic collision between two identical gliders of mass $m$\n\nNewton\u2019s 2\\(^\\text{nd}\\) law $\\Rightarrow$ conservation of the total momentum $\\mathbf{p}$ during the collision (zero net force)\n\nbefore: \\quad $m f(v) = 2m f \\left( \\dfrac{v}{2} \\right)$ \\quad after \\quad (2.25)\n\nDerivative: \\quad $\\dfrac{df\\left( v \\right)}{dv} = \\dfrac{df \\left( \\dfrac{v}{2} \\right)}{dv} = \\dfrac{1}{2} \\dfrac{df\\left( v \\right)}{dv}$ \\quad where \\quad $f(0) = 0$\n\n\\begin{align*}\n\\Rightarrow \\ \\dfrac{df\\left( v \\right)}{dv} = \\alpha = const \\quad\\quad (2.27)\n\\end{align*}",
    "$f(v) = \\alpha v \\quad (2.28) \\quad \\Rightarrow \\quad p = \\alpha m v \\quad (2.29)$\n\nChoice $\\alpha = 1 \\quad \\Rightarrow \\quad p = mv \\quad (2.30)$\n\nPhysical unit of momentum (SI): $\\left[ \\frac{kg \\cdot m}{s} \\right]$\n\n2.3.8 Material point dynamics\n\nMaterial point of constant mass:\n\n$m = \\text{const} \\quad \\Longleftrightarrow \\quad \\frac{dm}{dt} = 0 \\quad (2.31)$\n\nNewton\u2019s 2nd law:\n\n$\\sum F_{\\text{ext}} = \\frac{dp}{dt} \\quad (2.30) \\quad \\frac{dm}{dt} v + m \\frac{dv}{dt} \\quad (2.31) \\quad \\frac{dm}{dt} = 0$\n\n$\\sum F_{\\text{ext}} = m \\dot{v} = ma \\quad (2.33)$\n\nPhysical unit of force (SI): [N] = $\\left[ \\frac{kg \\cdot m}{s^{2}} \\right]$",
    "1. Review: Units\n\nNote that, in the solution below, we give our answers with the same number of significant digits as was provided in the question. This is an industry crucial, but also highly basic (and beyond the technical aspect), however in decimals. To get a reasonable consideration even at part locality known in the formula should typically appear in these smaller regular patterns. Typically, the number of significant digits in the results should be similar to the number of significant digits in the input quantities.\n\na. We convert the units as follows:\n\n\\[\n1 \\, \\text{mile} = 1.6 \\, \\text{km} \\, \\newline\n1 \\, \\text{day} = 14 \\, \\text{hr} \\newline\n1 \\, \\text{footprint} = \\frac {1}{3} \\, \\text{s}\n\\]\n\nb. We apply rate reasoning as shown to find:\n\n\\[\n\\frac {0.5 \\, \\text{km}}{8.00 s} \\left( \\frac {100 \\, cm}{m} \\times \\frac {1 \\, in}{2.54 \\, cm} \\right)=... \n\\newline\n\\]= \\frac {0.5 \\, km}{8.00 \\, s} \n       x \\frac {1000\\, m}{1 \\, km}\n       \\frac{100\\, cm}{1\\, m}\n       \\frac {1\\, km < 2.54\\, cm}\n\n = 7.0 \\, km/s x \\left( \\frac{10}{1 m/in}< 1)\n\nNow we use:\n\\frac {1 hour}{3 s}\n\\left(2.50\\frac {0.5 \\,km} {8/h}\n...\n\\frac {60 \\frac {\n=7.0 \\frac \n\nConverting from meters to kilometers, we find\n\n\\]\n\nNow we use (\\frac {I_{100}}{e}\\)\n\nConverting from meters to kilometers, we find:\n\n\\]\nL=  35431500x0.5 E{10}^{\n\nb.\n\\begin{equation}\nL = 9.5 x 10^{10} km  = 9.5 x 0^{10} km\n\\end{equation}",
    "a. The number of significant figures is\n\n1 significant figure\n2 significant figures\nit could be either 1, 2, or 3 significant figures, but you can't tell which\n2 significant figures\n1 significant figure because the number of significant figures of the result corresponds to the minimum number of significant digits among the input quantities\n2 significant figures\nb. The result is the mean, defined as\n$$\\bar{x} = \\frac{1}{N} \\sum_{i=1}^{N} x_i$$\nwhere $x_i$ is each individual measurement and $N$ is the total number of measurements. A common estimate of error is the standard deviation $\\sigma$, defined as\n$$\\sigma = \\sqrt{\\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})^2}{N-1}}$$\nPlugging in values, we find the mean to be $\\bar{x} = 0.36$ and the standard deviation to be $\\sigma = 0.077 x$.\n\nThe ratio is then\n$$\\frac{0.36}{0.077} \\approx 4.68$$\n\nNote that alternative definitions of the standard deviation exist. $\\sigma_m$ is even distribute instead of $\\sigma$ if you are actually interested in the error of the mean the standard error of the mean. \n$$\\sigma_m = \\frac{\\sigma}{\\sqrt{N}}$$\nThere are basic techniques that you should (and must correct for) namely the loss functions.\n\n3. The tortoise and the hare\nTo help visualize this, we will start by drawing the situation, which was shown in figure (a). Here $t$ is the position of the tortoise, $s$ is the position of the hare, and it is helpful to define the following times:\n$t_f$:  the time at which the tortoise reaches the bridge (which is also the hare starts to accelerate), and\n$t_b$:  the time at which the hare catches up to the tortoise.\nTo conduct your analysis, you should realize that initial positions do not change with straight line present. Relativity is set up to be an extension of its distance. Start with a suggestion: we assume that $a_b = a_h$. Define a coordinate system relative to an observer on Earth. All other times you may choose to end. The difference here is $t_b = \\gamma (t + \\delta t)$ when the observer at Earth\nanother $t_f$. On the other hand is less than that of the hare\u2019s before or after your target, as they catch up to each other. You can see the times in the \u201cinertial frame\u201d of the observer. To simplify the problem, we assume $\\theta = 5$. Shown to there is a result that the time the hare and the tortoise borned instantly at the positions as shown. For instance figure (b), where the dashed line is trajectory of the tortoise and the solid line is trajectory\n",
    "4. The jumping salmon\n\n$$a = k$$\n\nWe start with the equation of motion\n$$a = k,$$\n\nwhere $k$ is a constant. We integrate once in time to find the velocity\n\n$$v = kt + C,$$\n\nwhere $C$ is an integration constant. To solve for $C$, we evaluate this equation at $t = 0$ and find\n\n$$v(0) = C = v_0.$$\n\nThus, the constant $C$ is equal to the velocity at $t = 0$, which we represent as $v_0 = C$. This shows that the velocity is given by\n\n$$v = v_0 + kt. \\tag{1}$$",
    "We integrate a second time to find the position as a function of time:\n\\[ \nx(t) = \\frac{1}{2} at^2 + v_0 t + C' \n\\]\nwhere $C'$ is another integration constant. To solve for $C'$, we evaluate this equation at $ t = 0$ and find\n\\[ \nx(0) = 0 = 0 + 0 + C' \\quad \\Rightarrow \\quad C' = 0.\n\\]\nThus, the constant $C'$ is equal to the position at $ t = 0 $ which we represent as $ x = 0$. Finally, we can write the solution to the equation of motion as\n\\[ \nx(t) = \\frac{1}{2} at^2 + v_0 t. \n\\]\nEq. 2\n\nHere $v_0$ is the initial velocity at $t=0$ and $ x_0$ is the initial position at $t=0$.\n\nWe also have to check that this solution is correct by taking the second derivative with respect to time to recover the acceleration, $a$. The first derivative is\n\\[ \n\\frac{dx}{dt} = at + v_0 \\quad \\text{and} \\quad \\frac{d^2 x}{dt^2} = a.\n\\]\nEq. 3\n\nb. The best way to understand a problem is to first draw a sketch that displays all information given in the problem (see figure 2). An ice sled is in the bottom comes out of the lake with a vertical velocity $v_0$ and travels up a hill with a final velocity $v_f$. The sled eventually comes to a stop at $t=5$ seconds. We are asked to determine the position of ice sled at the time it comes to a stop following the position.\n\nGraphically, the position and velocity as a function of time are shown in figure 3, from which we can make several observations.\n\nThe motion of the sled as a function of time is shown as a parabolic curve in position ($x$, $t$). The sled starts with a vertical velocity due to a parabolic motion. The acceleration of the sled is negative (retard) which brings the motion to a parabolic. The retard of the position and motions is tangentially caught by the sailors. We can deduce the time and take the position when $\\frac{dx}{dt} = 0$.",
    "The velocity decreases linearly. Graphically, this is a straight line and the slope of this line is the acceleration of the salmon.\nAt $t = t_{max}$ the velocity intersects its horizontal axis, which means that the velocity of the salmon at that time has linearly attenuated. In any case, the velocity immediately afterwards becomes negative. Thus, at $t = t_{max}$ a velocity of zero corresponds to the vertex of the parabola where the fish has $x_{max}$.\n\nThe parabola of a reflected parabola of $x(t) = t^2$ from zero. This implies that $t_{max} = t_{launch}$. Therefore, we have a fish which falls symmetrically the same time as it rises: it is a parabola symmetric in $t = 0$.\n\nTo find $x_{max}$ we start by using equations (1) and (2) from part (a), giving us $t = 0$. We also choose $t$ to be the moment we find at the launch. We also take the ballistic portion at direction to be again upwards, equation (10) and (4) become\n\n$$\nx(t) = v_{0} t - \\frac{1}{2}gt^2\n$$\nand\n$$\nv(t) = v_{0} - gt\n$$\n\nrespectively. From part (b), we know that at the top of the parabola the salmon has zero velocity. Therefore, $v(t) = v_{0} - gt=0$ when at the load$= \\frac{v0}{g} = t_{launch}$. \n\nAt this time the fish is at its maximum height $x_{max}=x(t)$. Thus, by inserting our result for $t_{max}$,\n\n$$\nx(t_{max}) = x\\left(\\frac{v_{0}}{g}\\right) = \\left(v_{0}\\left(\\frac{v_{0}}{g}\\right) - \\frac{1}{2}g\\left(\\frac{v_{0}}{g}\\right)^2\\right)=\\frac{v^2}{2g} = x_{max}.\n$$\n\nChecking the units for this equation gives\n\n$$\n\\left[v_{max}\\right]=\\left[\\frac{m^2}{s^2}\\right]=\\left[m\\right].\n$$",
    "showing that our solution is plausible.\n\nWe can calculate $ t_{\\text{jump}} $ using the final conditions $ x_f(t_{\\text{jump}}) = 0 $ when the fish reenters the water. We find:\n\\[ t_{\\text{jump}} = t_d - \\frac{v_0}{g} + \\sqrt{\\frac{2h}{g} + \\left(\\frac{v_0}{g}\\right)^2 \\,(\\text{Eq. 5/eqnarray})} \\]\n\nThere are two possible solutions to this equation: $ t_{\\text{jump}} $ and\n\\[ t_1 = t_d - \\frac{h}{v_0} \\]\n\nWe can discard the first one because it corresponds to the time that the fish first jumps out of the water. Therefore, the two solutions we are looking for are $ [t_1, t_{\\text{jump}}] $, where $ t_f = t_d - \\frac{h}{v_0} $ and $ t_{\\text{jump}} = t_1 + \\frac {h}{v_0} - \\sqrt{\\frac{2h}{g} - \\left(\\frac{v_0}{g}\\right)^2} $. We can also check the units to find:\n\\[       \\]\n\nagain showing that our solution is plausible.\n\nPlugging the numerical values into our solutions given by equations $ (3) , (5) $ and (6) , we find\n\\[       \\]\n\\[ t_f = t_d - \\sqrt{\\frac{2h}{g} + \\left(\\frac{v_0}{g}\\right)^2} = 2 \\]\n\nand\n\\[ t_{\\text{jump}} = t_d + \\sqrt{\\frac{2h}{g}} = 0.66 \\]\n\nLastly, we also can consider the time of one bounce. We see that both $ t_{\\text{jump}} $ and $ h $ are such that the fish is likely to linger for 2s. Moreover, the values of $ t_d $ and $ s_d $ make sense because they account for one roughly half at $ t_{jump}$ and for how long a fish could jump out of the water.\n\n#### 5. The train\n\nThe motion of the train can be broken into the three time intervals:\n\n1. acceleration (for a duration of $ t_0 = X $),\n\n2. constant speed at $ v = (d + t_0 a) $ , and\n\n3. deceleration for a duration of $ t_3 = 12 $.\n\nGiven the information from the problem, we can directly calculate the acceleration in each time interval to be\n\\[       \\]\n\\[ \\frac{100 k/h - 80} t_3 = \\frac{2 - 4t_2}{t_2} = \\frac{v}{t_0 = 100 \\frac{km}{h}} \\]\n\nwhere the subscripts $ t $ refer to timef, and each time interval respectively. In figure 4, we use these values to plot the accelerations as a function of time.\n",
    "Given that we know the acceleration, it is natural to calculate the velocity $v(t)$. We must divide the velocity throughout each of the three intervals by which $v(t)$, where we have graph 1 as $a_1$ and class notes for the first two seconds, to third and last interval respectively. Similarly, we will denote the initial velocity of the first 5 seconds of motion as $v_1$. Note that once the velocity is calculated, we can solve for the position $x(t)$ and complete the problem. 6 Equation (2):\n\n\\[\na_1 = \\frac{v_f - v_0}{t}\n\\]\n\nwhere $a_1$ is the acceleration during the first interval that we have calculated above.\n\nTypically, another form of equations is very useful to use if we are using acceleration for each time interval to be twice continuity which will include lifespan conditions of first and second derivatives (positions and velocities). Remember that we have chosen a resolution to use for the three time-intervals for integration, separately, in between which satisfying the two initial conditions (one for initial velocity and one for initial position). 5 for the first and second interval re-solved equations and note all about the same initial evaluation problems. Since the train starts with $v_0 = 0$, during the first time-interval equation (6 is\n\n\\[\nv_1(t) = \\int_0^t a_1dt = a_1t = 5t\n\\]\n\nTherefore, at the interface between time intervals 1 and 2 the train is traveling at $v_1(t) = v_2(0) = 5t(0) = v_2$. Substituting into initial velocity of 3 and $x(0) = 0$ negative, etc., we see that the velocity during the second interval is now:\n\n\\[\nv_2(t) = \\int_0^t a_2dt + v_1(t) = a_2t + v_1 \n\\]\n\nThus, the initial condition for the third time-interval is $v_2(0) = a_1 \\Delta t + v_2(\\Delta t)$ so:\n\n\\[\nv_3(t) = 0 \\bigg( a_2 \\int_0^t a_3dt = v_3(t) = a_3t + v_2  \\bigg)\n\\]\n\nTo produce the plot below we wish to consider also the three time results. However, we must remember to insert all durations and for positions separately by using following noted equations 1,2 see also the kind that we can solve suitably for the three time intervals by following as:\n\nLastly, we can solve for the position analogously to the velocity, using equation (7), instead of equation (11). We see that the position during each time-interval changes quadratically as a function of time according to 10:\n\n\\[\nx(t) = \\frac{1}{2}a_3t^2+ v_0t + x_0,\n\\]\n\n\\]",
    "where $x_{n}$ is the initial position of the train during the $n$-th time interval. Again, we are defining a separate time coordinate for each time interval such that the start of every time interval is $t = 0$. We will take $x_{1} = 0$ to be the initial location of the train at the start of the first time interval. We showed above that $a_{1} = 10$, during the first time interval (equation 1), the position is:\n\n\\[ x_{1} = \\frac{1}{2}(10)t^{2} = (5)t^{2} \\]\n\nAt the interface between time intervals 1 and 2, the train is located at $(t_{1}) = 600 m = x_{12}$. Given that we fixed $x_{12} = 0$, above, the position throughout the second time interval is:\n\nAt the interface between time intervals 2 and 3, the train is located at $x_{23}(0) = 600 m = x_{23}$. Given that $x_{23}$ is from above, the position throughout the third time interval is:\n\n\\[ x_{3} = \\frac{1}{2}(\u221210)t^{2} + (30s)(t) + 600 m \\]\n\nAgain considering the three time intervals, shifting the second and third in time by 0 s and 300 s respectively, we produce figure.",
    "$$x(t)$$",
    "A.9 Angular momentum, torque and law of gravitation\n\nA.9.1 Table with a hole\n\nA.9.2 Equilibrium in rotation",
    "A.9.1 Table with a hole\n\nWe consider a horizontal table with a hole. A mass $m$ slides without friction on the table. It is attached to a string of negligible mass that slides without friction through the hole. A counterweight of mass $M$ is attached to the other end of the string of length $L$.",
    "1. Mass $m$:\n\n- Kinetic energy:\n\\[ T_m = \\frac{1}{2} m \\dot{z}^2 = \\frac{1}{2} m (\\dot{\\rho}^2 + \\rho^2 \\dot{\\phi}^2) \\]\n- Potential energy:\n\\[ V_m = 0 \\quad (\\text{potential reference table}) \\quad \\text{(A.9.2)} \\]\n\n2. Mass $M$:\n\n- Kinetic energy:\n\\[ T_M = \\frac{1}{2} M \\dot{z}^2 = \\frac{1}{2} M \\dot{z}^2 \\quad \\text{(A.9.3)} \\]\n- Potential energy:\n\\[ V_M = Mgz \\quad \\text{where} \\, z < 0 \\quad \\text{(A.9.4)} \\]",
    "- Mechanical energy:\n(A.9.1) - (A.9.4):\n\\[ E = E_m + E_H = T_m + U_m + T_H + U_H \\]\n\\[ = \\frac{1}{2} m (\\dot{\\rho}^2 + \\rho^2 \\dot{\\theta}^2) + \\frac{1}{2} H \\dot{z}^2 + M g z \\]\n\n- Link between the masses: (A.9.5)\n\nLength of the string: \\( L = \\rho - z = \\text{const} \\) (where \\( z \\leq 0 \\))\n\n\\[ \\therefore \\dot{z} = \\dot{\\rho} \\quad (A.9.6) \\]\n\\[ (A.9.5) \\]\n\n\\[ E = \\frac{1}{2} m (\\dot{\\rho}^2 + \\rho^2 \\dot{\\theta}^2) + \\frac{1}{2} H \\dot{\\rho}^2 + M g ( \\rho - L ) \\quad (A.9.7) \\]\n\n- Energy conservation; \\( E = \\text{const} \\)\n\n\\[ \\dot{E} = m (\\dot{\\rho} \\ddot{\\rho} + \\rho \\ddot{\\rho} + \\dot{\\rho} \\rho \\dot{\\theta}^2 ) + H \\ddot{\\rho} + H \\dot{\\rho} g = 0 \\quad (A.9.8) \\]",
    "* (A.9.8) can be written as:\n\\[ (m+M) \\, \\ddot{\\rho} + m \\left( \\ddot{\\rho} \\dot{\\varphi}^2 + \\rho \\dot{\\varphi} \\ddot{\\varphi} \\right) + Mg \\, \\dot{\\rho} = 0 \\quad \\text{(A.9.9)} \\]\n\n* Angular momentum with respect to 0:\n\\[ \\vec{Z_0} = \\vec{Z_{\\circ m}} + \\vec{Z_{\\circ M}} = \\vec{r_m} \\times m \\vec{v_m} + \\vec{r_M} \\times M \\vec{v_M} = \\rho \\dot{\\varphi} m (\\rho \\dot{\\varphi} \\vec{e_{\\varphi}}) + (-\\vec{Z_0} \\times H \\vec{e_{\\varphi}}) = m \\rho^2 \\dot{\\varphi} \\vec{e_{z}} \\]\n\n* Angular momentum theorem (system: $m+M$):\n\\[ \\sum \\vec{T_{\\circ ext}} = \\frac{d}{dt} \\vec{Z_{\\circ t}} = \\vec{r_m} \\times \\vec{P_m} + \\vec{r_M} \\times \\vec{P_M} = \\vec{0} \\]\n\\[ \\Rightarrow \\vec{Z_{\\circ t}} = \\text{const} \\Rightarrow m \\rho^2 \\dot{\\varphi} = L = \\text{const} \\quad \\text{(A.9.10)} \\]\n\n* Time derivative of (A.9.10)\n\\[ \\frac{d}{dt} (m \\rho^2 \\dot{\\varphi}) = 0 \\Rightarrow \\rho^2 \\ddot{\\varphi} = -2 \\rho \\dot{\\rho} \\dot{\\varphi} \\quad \\text{(A.9.11)} \\]",
    "(A.9.11) \u21d2 (A.9.3):\n\n$$(M + m) \\ddot{\\rho} - m (\\dot{\\rho} \\ddot{\\phi} + \\ddot{\\rho} \\dot{\\phi}^2) + M g = 0$$\n\n(A.9.10) \u21d2 (A.9.12) with $\\dot{\\phi}^2 = \\frac{L^2}{m^2 \\rho^4}$ and $\\frac{L}{M+m} - \\frac{1}{r}$ \n\n$$\\ddot{\\rho} - \\frac{L^2}{m(M+m) \\rho^3} + \\frac{M}{M+m} g = 0$$ (A.9.13)\n\nParticular case: circular trajectory: \n\n$$\\rho = constant \\Rightarrow \\ddot{\\rho} = 0$$ \u21d2 (A.9.13) \u21d2 $\\rho = \\sqrt [3]{\\frac{L^2}{Mmg}}$$\n\nEnergy: (A.9.10) \u21d2 (A.9.7)\n\n$$E = \\frac{1}{2} (M + m) \\dot {\\rho}^2 + \\frac{L^2}{2m\\rho^2} + mg (\\rho - L)$$ (A.9.15)\n\nRadial kinetic energy\n\nEffective potential energy $V_{\\text{eff}}$",
    "A.9.2 Equilibrium in rotation\n\nA disk of radius $R$ is rotating around its centre $O$. A rod of length $\\ell$ and of negligible mass is fixed on the disk. A mass $m$ is located at the end of the rod. A counterweight of mass $M$ is attached to a string of negligible mass tied around the disk. The system is at equilibrium.",
    "- System (masses $M + m$):\n\n- External torques:\n  Weight (mass $m$): $\\vec{r}_m \\times \\vec{P}_m$\n  Weight (mass $M$): $\\vec{r}_M \\times \\vec{P}_M$\n\n- Equilibrium in rotation:\n\\[\n\\sum \\vec{T}_{ext} = \\vec{r}_m \\times \\vec{P}_m + \\vec{r}_M \\times \\vec{P}_M = \\vec{0} \\quad \\text{(A.9.16)}\n\\]\n\\[\n\\vec{r}_m \\times \\vec{P}_m = \\ell \\hat{e}_1 \\times mg (\\cos\\phi \\hat{e}_1 + \\sin\\phi \\hat{e}_\\perp) = mg \\ell \\cos\\phi \\hat{e}_\\perp\n\\]\n\\[\n\\vec{r}_M \\times \\vec{P}_M = (R\\hat{e}_2 + \\ell \\hat{e}_1) \\times -Mg \\hat{e}_2 = -Mg R \\hat{e}_1\n\\]\nalong $\\hat{e}_1$: $mg \\ell \\cos\\phi - M g R = 0$\n\nThus, $ \\cos\\phi = \\frac{MR}{m\\ell} > 0 \\quad \\text{(A.9.17)}$",
    "\u2022 Equilibrium condition:  (mathematical)\n\n(A.9.17) $\\cos \\phi = \\frac{MR}{m\\ell} \\leq 1$  $\\rightarrow$ $\\ell \\geq \\frac{M}{m} R$  (A.9.18)\n\n\u2022 Physical interpretation:\n\nFor a disk of given radius $R$ and for masses $M$ and $m$ fixed, the rod has to be long enough for the equilibrium to exist.\n\n\u2022 Solutions:\n\n (A.9.17) $\\phi = \\pm \\arccos \\left(\\frac{MR}{m\\ell}\\right)$  (A.9.19) \n\nThere are two symmetric solutions with respect to the horizontal line going through the centre of the disk.",
    "- Potential energy: string length $L = L_0 - R\\varphi$\n\n$V = -mgL \\sin \\varphi - Mg ( L_0 - R\\varphi )$\n\nreference at the level of the horizontal line passing through $O$\n\n- Equilibrium position:\n\n$\\frac{dV}{d\\varphi}\\Big|_{\\varphi = \\varphi_0} = - mgL \\cos \\varphi_0 + MRg = 0$\n\n$\\Rightarrow \\cos \\varphi_0 = \\frac{MR}{mL} \\hspace{1em} \\text{ (A.G.17)}$\n\n- Stability:\n\n$\\frac{dV}{d\\varphi} \\Big|_{\\varphi = \\varphi_0} = mgL \\sin \\varphi \\hspace{1em} \\text{ (A.G.18)}$\n\n1)\tIf $\\varphi_0 > 0 \\; \\Rightarrow \\sin \\varphi_0 > 0 \\; \\Rightarrow$ stable equilibrium (below)\n\n2)\tIf $\\varphi_0 < 0 \\; \\Rightarrow \\sin \\varphi_0 < 0 \\; \\Rightarrow$ unstable equilibrium (above)",
    "A.8 Law of action-reaction, collisions\n\nA.8.1 Atwood machine\n\nA.8.2 Coupled harmonic oscillators",
    "A mass $m_1$ is connected by a string of negligible mass to a mass $m_2$. The string slides without kinetic friction over a pulley of negligible mass.\n\nSubsystem 1:\n$\\sum \\vec{F}_{ext} = \\vec{P}_1 + \\vec{T}_1 = m_1 \\vec{a}_1$\n\nalong $\\vec{e}_i$: $mg - T_1 = m_1 \\ddot{x}$ \\quad (A.8.1)\n\nSubsystem 2:\n$\\sum \\vec{F}_{ext} = \\vec{P}_2 + \\vec{T}_2 = m_2 \\vec{a}_2$\n\nalong $\\vec{e}_j$: $mg - T_2 = m_2 \\ddot{y}$ \\quad (A.8.2)",
    "- Link between \u2460 and \u2461:\n  \n  1) String (fixed length): $\\vec{q}_2 = -\\vec{q}_1 \\quad$ $\\ddot{y} = -\\ddot{x}$\n\n  2) Pulley (negligible mass): $\\quad T_1 = T_2 = T$\n\n- Coupled motion equations:\n\n  (A.8.1) $\\Rightarrow \\quad m_1 g - T = m_1 \\ddot{x}$\n\n  (A.8.2) $\\Rightarrow \\quad m_2 g - T = -m_2 \\ddot{x}$\n\n- (A.8.3) - (A.8.4):\n  \n  $(m_1 - m_2) g = (m_1 + m_2) \\ddot{x}$\n\n  $\\Rightarrow \\quad \\ddot{x} = \\dfrac{m_1 - m_2}{m_1 + m_2} g \\quad$ (A.8.5)\n\n1) If $m_1 > m_2$: $\\ddot{x} > 0$\n\n2) If $m_1 = m_2$: $\\ddot{x} = 0$\n\n3) If $m_1 < m_2$: $\\ddot{x} < 0$",
    "A.8.2 Coupled harmonic oscillators\n\nTwo material points of mass $m$ are attached to two springs of elastic constant $k$ that are fixed on the other end to a horizontal rail. A spring of elastic constant $k'$ is attached between both material points. The natural length of each spring is $l_0$.",
    "1) Subsystem :\n\n- External forces (horizontal):\n  - Elastic force (left) : $\\vec{F}_{e,x1} = - k \\left( x_1 - \\left( - \\dfrac{l_0}{2} \\right) \\right) \\vec{e_x}$\n  - Elastic force (centre) : $\\vec{F}_{e,x1c} = k' \\left( ( x_2 - x_1) - l_0 \\right) \\vec{e_x}$\n\n- Law of motion:\n  $\\vec{F}_{e,x1} + \\vec{F}_{e,x1c} = m \\vec{a_x}$\n\nalong $\\vec{e_x}$ : $- k \\left( x_1 + \\dfrac{l_0}{2} \\right) + k' ( x_2 - x_1 - l_0 ) = m \\ddot{x_1}$\n\n(A.8.6)",
    "1) Subsystem 2:\n- External forces (horizontal):\n  - Elastic force (right): $\\vec{F}_{e,2r} = -k \\left( x_2 - \\frac{l_0}{2} \\right) \\vec{e}_x$\n  - Elastic force (centre): $\\vec{F}_{e,2c} = -k' \\left( (x_2 - x_1) - l_{0'} \\right) \\vec{e}_x$\n- Law of motion:\n  $\\vec{F}_{e,2r} + \\vec{F}_{e,2c} = m \\vec{a}_2$\n  along $\\vec{e}_x$: $-k \\left( x_2 - \\frac{l_0}{2} \\right) - k' \\left( (x_2 - x_1) - l_{0'} \\right) = m \\ddot{x}_2$\n- Law of action-reaction: $\\vec{F}_{e,2c} = -\\vec{F}_{e,1c}$   (A.8.7)",
    "* Equations of motion:\n$$\\ddot{x}_1 = -\\frac{k}{m}\\left(x_1 + \\frac{\\ell_0}{2}\\right) + \\frac{k'}{m}\\left(x_2 - x_1 - \\ell_0\\right) \\quad \\text{(A.8.8)}$$\n$$\\ddot{x}_2 = -\\frac{k}{m}\\left(x_2 - \\frac{\\ell_0}{2}\\right) - \\frac{k'}{m}\\left(x_2 - x_1 - \\ell_0\\right) \\quad \\text{(A.8.9)}$$\n\n* Centre of mass:\n$$X_G = \\frac{mx_1 + mx_2}{m + m} = \\frac{1}{2}(x_1 + x_2) \\quad \\Rightarrow \\quad \\ddot{X}_G = \\frac{1}{2}(\\ddot{x}_1 + \\ddot{x}_2) \\quad \\text{(A.8.10)}$$\n\n* \\text{(A.8.10) \\quad $\\Rightarrow$ \\quad (A.8.8) + (A.8.9)} :\n\n$$\\ddot{X}_G + \\frac{k}{m}X_G = 0 \\quad \\text{(A.8.11)}$$\n\nThe motion of the centre of mass $X_G$ is described by a harmonic oscillator of pulsation $\\omega_G = \\sqrt{\\frac{k}{m}}$",
    "- Relative position : $x=x_2-x_1 \\Rightarrow \\dot{x} = \\dot{x}_2 - \\dot{x}_1$\n\\[\n\\tag{A.8.12}\n\\]\n- (A.8.12) $\\Rightarrow$ (A.8.8) / (A.8.9) :\n\\[\n\\ddot{x} + \\frac{k + 2k'}{m} (x - \\ell_0) = 0 \\tag{A.8.13}\n\\]\n\\[\ny = x - \\ell_0 \\Rightarrow \\ddot{y} = \\ddot{x} \\Rightarrow \\ddot{y} + \\frac{k + 2k'}{m} y = 0\n\\]\n\nThe relative motion is described by a harmonic oscillator of pulsation $\\omega_r = \\sqrt{\\frac{k + 2k'}{m}}$\n\n- Equations horaires :\n  * Centre of mass$ : X_G(t) = C_G \\cos\\left(\\sqrt{\\frac{k}{m}} t + \\phi_G \\right) \\tag{A.8.14}$\n  * Relative motion$ : x(t) = C_x \\cos\\left(\\sqrt{\\frac{k + 2k'}{m}} (t + \\delta_x)\\right) + \\ell_0 \\tag{A.8.15}$",
    "- Position equations (material points):\n\n\\[ x_1(t) = X_G(t) - \\frac{x(t)}{2} = C_g \\cos \\left( \\sqrt{\\frac{k}{m}} t + \\phi_g \\right) - \\frac{C_x}{2} \\cos \\left( \\sqrt{\\frac{k + 2k'}{m}} t + \\phi_x \\right) - \\frac{l_0}{2} \\quad \\text{(A.8.16)} \\]\n\n\\[ x_2(t) = X_G(t) - \\frac{x(t)}{2} = C_g \\cos \\left( \\sqrt{\\frac{k}{m}} t + \\phi_g \\right) + \\frac{C_x}{2} \\cos \\left( \\sqrt{\\frac{k + 2k'}{m}} t + \\phi_x \\right) + \\frac{l_0}{2} \\quad \\text{(A.8.17)} \\]\n\n- Limiting cases:\n\n1) Motion in phase of pulsation $\\omega_G = \\sqrt{\\frac{k}{m}}$:  \n    if $C_x = 0 \\Rightarrow x = x_2 - x_1 = l_0 = \\text{const}$\n\n2) Motion in phase opposition of pulsation $\\omega_x = \\sqrt{\\frac{k + 2k'}{m}}$:  \n    if $C_G = 0 \\Rightarrow X_G = 0$ and $x_2 = -x_1$",
    "1. General motion\n$X_G(t)$: periodic ($\\omega_G$)\n$x(t)$: periodic ($\\omega_x$)\n\n2. Motion in phase\n$X_G(t), X_{m2}(t)$: periodic ($\\omega_G$)\n$x(t)$: constant ($e_0$)\n\n3. Motion in phase opposition\n$X_G(t)$: null\n$x(t), X_{m2}(t)$: periodic ($\\omega_x$)",
    "Solutions to Problem Set 13\nHarmonic motion and gyroscopes\nPHYS-101 (en)\n\n1. Simple pendulum\n\nBelow is the free body diagram for the point mass of the simple pendulum in polar coordinates at an arbitrary angle $\\theta$ relative to $\\vec{g}$. We define a coordinate system using the unit vectors describing the rotational position of the mass $\\vec{\\hat{r}}$ and $\\vec{\\hat{\\theta}}$. We define a Cartesian coordinate system such that the polar angle $\\theta$ traverses the angle from the z-axis towards the positive y axis (as is conventional).\n\nWe can solve part one in two ways: using Newton\u2019s second law or conservation of energy. \nUsing Newton\u2019s second law: At a given angular position, the gravitational force on the point mass $m$ is given by the expression:\n\n\\[ \n\\vec{F} = mg \\hat{z} = mg \\left (\\cos(\\theta) \\hat{r} - \\sin(\\theta) \\hat{\\theta} \\right ) \n\\]\n\nwhere we have used the Cartesian and polar unit vector using the formula $\\hat{z} = \\cos(\\theta) \\hat{r} - \\sin(\\theta) \\hat{\\theta}$. We can calculate the forces for the radial and transverse of Newton\u2019s second law using their respective unit vectors:\n\n\\[ \nm \\left ( \\ddot{r} - r\\dot{\\theta}^2 \\right ) = -mg\\cos(\\theta) \n\\]\n\n\\[ \nm \\left (r\\ddot{\\theta} + 2\\dot{r}\\dot{\\theta} \\right ) = -mg\\sin(\\theta) \n\\]\n\n(2)\n\n(3)\n\nwhere, $\\ddot{r}$ is the speed of point mass (which is purely tangential). However, this is not the easiest way to solve the problem. Instead, the tangential component of Newton\u2019s second law is useful.\nLet\n\n\\[ \nr = L \n\\]\n\nbe the length of the pendulum. Then we get:\n\n\\[ \nm L \\ddot{\\theta} = -mg \\sin(\\theta) \n\\]\n\n(3)\n\nThe form of the acceleration in polar coordinates is given as\n\n\\[ \n\\begin{aligned} \n\\vec{a} = & \\left (\\ddot{r}-r\\dot{\\theta}^2 \\right ) \\hat{r} + \\left (r \\ddot{\\theta} + 2 \\dot{r} \\dot{\\theta} \\right ) \\hat{\\theta} \n\\end{aligned}\n(4)",
    "Since $r = l$, $\\mu = k$ is a constant, we have $\\dot{\\mu} = 0$ and we can substitute the tangential component of equation (1) into equation (3) to find\n$$\n-\\sin\\theta = \\ddot{\\theta} \\sin\\theta + 2 \\dot{\\theta} \\cos\\theta \\sin\\theta,\n$$\nSimplifying,\n$$\n\\ddot{\\theta}=-0. (5)\n$$\nUsing the usual angle approximation $\\sin \\theta \\approx \\theta$ gives us the differential equation of a simple harmonic oscillator\n$$\n\\ddot{\\theta} + \\theta = 0. \\tag{6}\n$$\nUsing conservation of energy: Since all of the forces acting on the pendulum are conservative, we can use conservation of mechanical energy\n$$\nE_{\\text{initial}} = E_{\\text{final}},\n$$\nbetween the initial state described in the problem (described by the subscripts i) and the final state when the pendulum is in an arbitrary angular position $\\theta$ (described by the subscript f). The only forces involved are gravity, so equation (7) is\n$$\nK_i + U_i = K_f + U_f, \\tag{7}\n$$\nwhere i describes the instant from rest, so $K_i = 0$. Moreover, we will define the reference point for the gravitational potential energy to be at the lowest point of oscillation when $\\theta = 0$. This implies $U_f = -mgl(1-\\cos\\theta)$, the potential with respect to the origin. Given the Cartesian coordinate system shown, the position of the particle is \n$$\nx=l\\sin\\theta, \\quad y=-l\\cos\\theta,\n$$\nso the kinetic energy is\n$$\nK_f = \\frac{1}{2}m (\\dot{x}^2+\\dot{y}^2). \\tag{8}\n$$\nSince $\\dot{y} = l\\dot{\\theta}\\cos{\\theta}$, the kinetic energy reduces using the formulae $x = l \\sin \\theta$, so $\\dot{x} = l\\dot{\\theta}\\cos\\theta$, the kinetic energy reduces using the formula above in equation (8):\n$$\nK_f = \\frac{1}{2}ml^2\\dot{\\theta}^2. \\tag{9}\n$$\nThe potential energy is\n$$\nU_f = mgy = mg[-l\\cos(\\theta)-(-l)] = -mgl(\\cos\\theta - 1). \\tag{10}\n$$\nSo we have using equation (7),\n$$\n0 + 0 = \\frac{1}{2}ml^2\\dot{\\theta}^2 - mgl(\\cos\\theta - 1),\n$$\nwhich is identical to equation (6). Thus, energy conservation gives the same answer as Newton's second law.\n\n2. The differential equation for a simple harmonic oscillator has the form\n$$\n\\ddot{\\theta} + \\omega^2\\theta =0. \\tag{11}\n$$\nSo, we have\n$$\n\\omega^2 = g/l, \\quad \\omega = \\sqrt{\\frac{g}{l}}, \\tag{12}\n$$\nwhere $\\omega$ is the angular frequency of oscillation. Thus, by comparison with equation (6), we see\n$$\n\\omega = \\sqrt{\\frac{g}{l}}. \\tag{13}\n$$",
    "To get the frequency $f_a$ (i.e., the number of oscillations per second) from the angular frequency $\\omega$ (i.e., the number of radians the object completes in full oscillations per second), we use the fact that one oscillation corresponds to $2 \\pi$ radians. This means that $\\omega = 2 \\pi f_a$, or\n\n$$f_a = \\frac{\\omega}{2 \\pi} = \\frac{1}{2 \\pi} \\sqrt{\\frac{g}{L}} . \\tag{15}$$\n\n3. The period is the time it takes for the object to complete a full oscillation, (i.e., the number of seconds per oscillation). This is simply the inverse of the number of oscillations per second (i.e., the frequency). Thus, using $T_a = \\frac{1}{f_a}$ we find that the period is\n\n$$ T_a = 2 \\pi \\sqrt{\\frac{L}{g}}. \\tag{16} $$\n\n4. The angular velocity of the point mass at a given location is easiest to calculate from conservation of energy. We can take equation (10) and solve it for $ v $ to choose the final state to be when the pendulum is vertical at the bottom of its swing:\n\n$$ -mgL \\cos \\theta = \\frac{1}{2} m v^2 - mg L. \\tag{17} $$\n\nGiven that $v = r \\omega$, we can rewrite this as\n\n$$ -mg L \\cos \\theta = \\frac{1}{2} m r^2 \\omega^2 - mg L, \\tag{18} $$\n\nThe translational speed $v$ is purely tangential, which is related to the angular speed $\\theta$ through $v = r \\omega$. Substituting equation (19) and the fact that $r = L$ gives\n\n$$ v = \\sqrt{2 g L ( 1 - \\cos \\theta) }. \\tag{19} $$\n\n5. Now there are at least two ways we can also calculate the period $T$ of the pendulum by the angular angle $\\theta$ of the object. First, if we consider the motion along the arc, we have $s = L \\theta$ and a tangential acceleration $ a = \\alpha L$, $\\alpha $ being the angular acceleration. Newton\u2019s second law gives $ F = m a $, or $ T \\theta = m \\alpha L$, tangential torque $\\alpha = \\tau / I = T s / I$. For small oscillations, we have $s = L \\alpha$ and $I = mL^2$, so $s = L ( T s / mL^2 ) = ( mL \\theta L) / m$. Using the result for the density $\\rho = m / L$, we find that $\\omega^2 = g / L$. Now we have a simple harmonic oscillator in form $\\theta = \\theta_0 \\cos (\\omega t)$. Since the mass appears on both sides in Netwon\u2019s second law (we expect this result),\n\n$$ T = 2 \\pi \\sqrt{\\frac{l}{g}}. \\tag{20} $$\n\n2. Gyroscope\n\n6. Since we are interested in finding the additional force required to achieve particular motion, we can proceed by integrating $f = t \\ddot{\\theta}$ over the domain of integration. Note that there will be two integrals: the first one needs to be taken along the cross-section of the object where $l$ is less than $L$, the second integral is from $L$ to the end of the bar $L$. Note that the speed of light is related to the speed of the string via the Lagrangian. Here we get the net force equal to the additional force $\\vec{f} = -m \\omega^2 \\vec{r}$ relative to the rotating motion along the stretch of string $ \\theta = 0 $ in the same $\\theta$ direction. The torque can be found to be\n\n$$ \\tau_{\\text{tour}} = \\frac{dL}{dt} = -l s \\omega \\cos l \\theta. \\tag{21} $$",
    "from Newton\u2019s second law for rotation, where we recall that a torque is defined to be $\\tau = \\mathbf{r} \\times \\mathbf{F}$. Thus since $\\mathbf{F}_s$ is applied at $\\mathbf{r} = \\hat{k}a$ and $\\mathbf{F}_s$ is applied at $\\mathbf{r} = -\\hat{k}a$, we have\n\n$$\n\\tau_s = \\mathbf{r} \\times \\mathbf{F}_s = (a\\hat{k}) \\times (-\\beta \\hat{i}) = a\\beta (\\hat{j} \\times \\hat{k}) = -a\\beta \\hat{i},\n$$\n\nand \n\n$$\n\\tau_s = \\mathbf{r} \\times \\mathbf{F}_s = (-a\\hat{k}) \\times (\\beta \\hat{i}) = a\\beta (\\hat{j} \\times \\hat{k}) = a\\beta \\hat{i}.\n$$\n\nNote that we have defined the origin to be the initial position of the center of the wheel.\n\nTo accelerate a mass $M$, we need a net force $\\mathbf{F}_{\\text{ext}}$ given by Newton\u2019s second law of\n\n$$\n\\mathbf{F}_{\\text{net}} = M\\mathbf{a} = M\\ddot{\\mathbf{r}}.\n$$\n\nThus, the additional forces from the disconnected hands must now satisfy\n\n$$\n\\mathbf{F}_1 + \\mathbf{F}_2 + \\mathbf{F}_s + \\mathbf{F}_{-s} = \\mathbf{M}\\ddot{\\mathbf{r}}.\n$$\n\nSubstituting equations (4) into equation (2) gives\n\n$$\n\\mathbf{F}_1 + \\mathbf{F}_2 + (\\mathbf{F}_s + \\mathbf{F}_{-s}) = \\mathbf{M}\\ddot{\\mathbf{r}} + \\mathbf{F}_{-s}.\n$$\n\nwhere $\\mathbf{r} = 0$. Writing out $\\mathbf{F}_1 = \\mathbf{F}_{1x}\\hat{i} + \\mathbf{F}_{1y}\\hat{j} + \\mathbf{F}_{2z}\\hat{k}$ etc. into components in Cartesian coordinates allows us to reframe the general expression\n\n$$\n\\mathbf{F} = \\mathbf{F}_1 \\hat{i} + \\mathbf{F}_2 \\hat{i} + \\mathbf{F}_{s1} \\hat{i} + \\mathbf{F}_{-s}\\hat{i} = \\mathbf{F}_{-2} \\hat{i} + \\mathbf{F}_{s2} \\hat{i}.\n$$\n\nIf we take the dot product of the first equation with $\\hat{i}$, we see that $\\mathbf{F} = \\mathbf{F} \\cdot \\hat{i}$ so if we take the dot product $\\mathbf{F} \\cdot \\hat{i}$, then we obtain $\\mathbf{F}' = \\mathbf{F} \\cdot \\hat{i}$. This implies that\n\n$$\nM\\ddot{x} \\mathbf{F}_{\\text{net}_{\\text{2}}} \\mathbf{F}_{-s2} \\mathbf{F}_{s-2} = \\mathbf{F}_{\\text{tot}}/M,\n$$\n\nmust be purely in the $\\mathbf{j}$ direction. Through substitution into equation (2), we see that the same is true in the $\\mathbf{i}$ direction as well, for which *F must be given by\n\n$$\nM \\ddot{x} - F_{\\text{tot}/M},\n$$\n\nTaking the dot product of both sides of this equation with $\\hat{i}$ we have\n\n$$\nM\\ddot{ x } - \\mathbf{F}_{\\text{tot}}/M\\hat{j} = \\frac{\\dot{\\mathbf{r}}^2}{2}.\n$$\n\nThus, the additional forces from each hand must only have a y component and satisfy $\\mathbf{F}_s \\cdot \\mathbf{F}_{-s} = 0$.",
    "2. This problem is tricky because there are two different types of rotation. There is the rotation of the hoop about the axis, which has a constant magnitude that starts out in the $ \\mathbf{e}_3 $ direction at $ t = 0 $ because the charged hoop rotates in the same direction as the current with a constant angular velocity $ \\omega_h $. The second type of rotation is the toroidal mode that has to be really slow compared to the angular momentum change (to quantify this second type of rotation, you will see the cylindrical coordinate system shown in the figure below (which shows the wheel from a top view relative to the figure in the problem statement):\n\nWe can write the total angular momentum of the system (including both types of rotation) as\n$$ \\mathbf{L} = L_{\\phi} \\mathbf{e}_{\\phi} + L_{\\theta} \\mathbf{e}_{\\theta} - I\\omega_{h} \\mathbf{e}_{3}. \\tag{10} $$\n\nThe change in spin rotation and the net torques is a bit harder. Let there be a net EMF. Therefore the turntable\u2019s angular velocity $\\Omega$ (10) is still to be included in the equations of motion with $\\mathbf{L}=U+I\\mathbf{r}$, where $U\\approx 0$. The angular momentum $\\mathbf{r} \\equiv - \\mathbf{X} I-1+.....$. Regarding the net torque $\\boldsymbol{\\Gamma}=\\mathbf{N}'.$ Many subsequent times, $\\mathbf{N}=+...$ equations must integrate the torque in terms of the two rotation axes. The key points are the torques $T_1 = dL/dI \\phi$, and $T_2$ (gyro tensor-based). (10) will be,\n$$ \\mathbf{L}+ \\sin{\\beta T}... \\mathbf{d}. + M\\mathbf{R \\ddot E. } \\tag{11} $$\n\nA change in angular momentum is always caused by net torques, which can be found from Newton's second law of rotation\n$$ \\boldsymbol{\\Gamma} = \\mathbf{I} \\frac{d\\mathbf{\\omega}}{dt}. \\tag{12} $$\n\nSubstituting equation (9) into (12), we find\n$$ \\boldsymbol{\\Gamma} = \\dot{\\mathbf{L}} = I\\left( \\dot{\\mathbf{ \\omega}}_{\\phi} + \\frac{d \\mathbf{\\omega}_{\\theta}}{dt} \\hyperref[10]. \\mathbf{-} M\\mathbf{R \\ddot E.} \\right). \\tag{13} $$\n\nAdding constraints to the total angular distribution will work vectors, $\\dot{\\mathbf\\phi =}[diag d/dt]... /d\\phi/d\\theta \\cos{\\theta}$ Where the L is the diagonal angular position (if on a constant spin $I,=-I$,\n$$ I[\\mathrm{const} ...] = I = dL_{\\theta}^{2} =dt^{2} \\tag{13}$$\n\nThis torque can start from the forces applied in the x and the hat by the demonstrator\u2019s hands:\n$$ N = Q = l = dot[k_{x}I k_{y} - I \\ddot R. k - i X - etc. \\rightarrow  = k- \\frac{ M\\ddot{k)}}]} \\sin{\\beta(\\phi_{\\Theta}-1)} (13) $$\nThus, the torque:\n$$ \\mathcal{T} = \\left( (\\dot{X...}) -I\\ddot \\mathbf{R} Z- X_{\\gamma}k\\right) + \\dot (\\mathcal{Y}\\dot{ \\phi .) -1 \\mathbf{...] + M R. \\mathbf{\\ddot[}.} \\tag{15}$$",
    "where we must take into account the rotation of the bar into our expression for the radial position of the decouermastable's basis by using r instead of $r_0$.\n\nAdditionally, we know that the center of the bar (i.e. the center of mass of the system) has no translational motion. Thus, by Newton's first law, the net force must be equal to\n\n\\[\n\\mathbf{F} = m_r \\ddot{r} r\u0302 - m_r r \\dot{\u03b8}^2 r\u0302 = 0. \\tag{17}\n\\]\n\nSubstituting into this equation (16) gives us\n\n\\[\nr\u0308 = - (k + \u03b3) r \u2013 \u03c6\u0302 \\dot{\u03b8} = 0 - \u213d r\u0308\n\\]\n\nWriting out \\( \\mathbf{F} = m_r (\u03b7\u0308 \u03c6\u0302 + F_r 1) \\) components corresponding to cartesian coordinates shares that\n\n\\[\n\u03b7\u0308 + 2 r \\dot{\u03b8}\u03b3 \u03c6\u0302 = 0 (18)\n\\]\n\nLooking at each component of this equation, we see that we must have $F_r = 0$, and\n\n\\[\n\\ddot{\u03b7} \u201c \u03b7 \\cos \u03bb + \u03b7\u0308 \u03b7 + \u03b7\u00c6 \\sin \u03bb = 0. \\tag{19}\n\\]\n\nPlugging this into equation (17) shows that F_r 1 = 0 since\n\n\\[\n- \u03b4\u03ae + \u03b7\u0308 + \\(\u03bc \u03b3) \u03b7 = 0\\quad \\tag{20}\n\\]\n\nThus, our final answer is\n\n\\[\n\\mathbf{F}_r = -\u03b3 \u0308 +  \u03b3 (\u03bc \u03b3) \u03b7 = \u03b7  \u03b7\u0308 + \u03c6 \u03b7\u0308\u03b7 \u03c6\u0302= 0 \\quad   \\tag{21}\n\\]\n\nWe saw that the radial component of the net force is cancelled as long as it is equal and opposite to the inward centripetal force. Since it acts in a direction along the axial rotation, it is governed by an inward centripetal. This is due to attentive to the fact that, to get the bar to rotate in this manner, the ground has to have friction. This is the nature of a gyroscope \u2013 applying a force creates a perpendicular direction.\n\n3. Bumpy road\n\nWe consider now a Cartesian coordinate system with $x\u0302$ in the direction of travel of the car and $y\u0302$ pointing upward.\n\nWe are told that the road has a cosine height profile given by\n\n\\[\ny(x) = A \\cos (k x). \\tag{1}\n\\]\n\nwhere $x_d$ and $x_g$ are unknown constraints that arise from the geometry of the road. The variations in the height of the road can suggest that any kind of changes might result in cross-component displacements that contribute to height and gaps of the wave\u2019s amplitude. Therefore this height profile models translate into the road's equation. These points are appropriate to consider the height\u2019s maxima and minimum of the cosine function itself, and importantly the total change in elevation.",
    "of equation (3) is $C_h$. Since the physical change in elevation (from trough to peak) is $H$, we have $H = 2C_h$, which implies that\n$C_h = \\frac{H}{2}$ \\quad\\quad\\quad\\quad (1)\nNext, we set the Ch quantize the length of the bump. From the problem statement, we know that if you are at the peak of a bump, you will arrive at the next peak by traveling a horizontal distance of $\\lambda$. Simplifying as if more intuitive to say (for the function, not us) that each bump has a length of $\\lambda / 2$. The number of bumps on a section of road is therefore equivalent to $2L /  \\lambda$, where $L$ is the length of the road from our perspective before being rewrapped to other curvature. Thus, $2L / \\lambda$. We assumed that simple functions handle all 2r. Looking at equation (1), this means that there is a full sine and we form \n$C_r = \\frac{\\lambda}{2\\pi}$ \\quad\\quad\\quad\\quad (2)\nSubstituting equations (2) and (3) into equation (1) (the shape of the road in terms of known parameters)\n$H = \\frac{\\lambda}{\\pi}$ \\quad\\quad\\quad\\quad (3)\nThe wheel has a tangibility small radius. Do its trajectory is the same as the road\u2019s\n$y = C_h \\sin \\left( \\frac{2 \\pi}{ \\lambda} x \\right)$ \\quad\\quad\\quad\\quad (4)\nWe know that the body of the car moves forwards at a constant horizontal velocity of $v_0$, so the mass will travel a distance $x = v_0t$. (where the distance x is measured in the horizontal direction). In other words, the horizontal position of the wheel is just\n$x = v_0t$ \\quad\\quad\\quad\\quad (5)\nthe vertical position of the wheel is\n$y = C_h \\sin \\left( \\frac{2 \\pi}{ \\lambda} x \\right)$ \\quad\\quad\\quad\\quad (6)\nSubstituting the value for $x$ from equation (5) means that the wheel y at t = 0 has that on average:\n$y = C_h \\sin \\left( \\frac{2 \\pi}{ \\lambda} v_0t \\right)$ \\quad\\quad\\quad\\quad (7)\n2. The equation of motion for the car comes from Newton\u2019s second law\n$F_n = \u2212kx \\quad\\quad\\quad\\quad (8)\nwhere\n$F_n = mna $ \\quad\\quad\\quad\\quad (9)\n$g = mg$ \\quad\\quad\\quad\\quad (10)\nis the gravitational force,\n$N = \u2212ky$ \\quad\\quad\\quad\\quad (11)\nis the spring force, and the subscripts indicate b refers to the body of the car. The challenge to this problem is that the shape of the road is continuously changing y. Hence there will be clothes with height $m$ in the vertical direction at all times. Forces should match displacing the a vertical height (to the first approximation) which means a = $y$. This motivates us to substitute equation (2) into equation (1). Thus,\nSubstituting equations (9), (10), and (11) into (8) gives the equation of motion\n$mg \u2212 ky = m \\left(- \\frac{\\lambda}{ \\pi} v^2 \\cos \\left( \\frac{2 \\pi}{ \\lambda} v_0 t \\right) \\right)$ \\quad\\quad\\quad (12)",
    "Substituting equation (7) from part 1 yields\n\n$$\n-\\left(1-\\frac{\\Gamma}{T\\left(\\frac{\\pi \\tau}{2 T}\\right)-\\Delta}\\right) a=-\\frac{4 T^{2}}{v_{\\infty}^{2}} \n\\left(\\frac{\\Delta}{T\\left(\\frac{\\pi \\tau}{2 T}\\right)-\\Delta}\\right) \\sin \\left(\\frac{\\pi \\tau}{2 T}\\right)\n$$\n\nRearranging we can isolate the inhomogeneous terms on the right side and arrive at the equation of motion\n\n$$\na=-\\left(\\frac{4 T^{2}}{v_{\\infty}^{2}} \\frac{\\Delta}{T\\left(\\frac{\\pi \\tau}{2 T}\\right)-\\Delta}-\\frac{\\Gamma}{T\\left(\\frac{\\pi \\tau}{2 T}\\right)-\\Delta}\\right) \\sin \\left( \\frac{\\pi \\tau}{2 T} \\right)\n$$\n\nEquation (14) is a complicated differential equation, but we can recognize it as the simple harmonic oscillator equation, with the addition of forcing terms (i.e. all the terms on the right side of the equation). To attack this, we first let\n\n$$\nq(t) =  \\sqrt{\\frac{T \\Delta}{T \\left( \\frac {\\pi \\tau}{2T}\\right) - \\Delta}} \\sin \\left(\\frac{\\pi \\tau}{2 T}\\right)\n$$\n\nto get the simpler and more familiar form of\n\n$$\n\\ddot{x}+\\omega_{0}^{2} x=q(t) g\n$$\n\nYou can solve this equation by looking it up in the Math Review document on the course Moodle. However, here we will show how it is derived. This differential equation is in the standard form of $Lx = f(t)$, where $L$ is a linear differential operator. The homogeneous terms are second-order in time for $\\ddot{x}$, while the vertical coordinate, $x$, has no $t$-dependence at all (i.e., constant in time during flight). This leads us to writing L as\n\n$$\nL=\\frac{d^{2}}{d t^{2}}+\\omega_{0}^{2}\n$$\n\nTaking two derivatives of this equation yields\n\n$$\nL \\ddot{x}=\\frac{d^2 f}{dt^2}-\\omega_{0}^2 x=q(t) g\n$$\n\nSubstituting equations (18) and (19) into equation (17) gives\n\n$$\nx(t) = x  =\\frac{ 1 }{T} \\times -\\frac{ 4T^2 }{ V_{\\infty}^2 } \\frac{\\Delta}{ T\\left(\\frac{\\pi \\tau}{2T}\\right) - \\Delta} \\sin\\left( \\frac{ \\pi \\tau}{2T}\\right)+ \\frac{\\Gamma }{T \\left(\\frac{\\pi \\tau}{2 T}\\right) - \\Delta}\\sin\\left( \\frac{\\pi \\tau}{2 T} \\right)       \n$$\n\nNotice that when the/or-driving terms have been eliminated, this is now identical to the differential equation for the homogeneous case and we identify that the solution in this case is given by x(t)=\\sum_{j=1}^3 A_j e^{i(\\omega_j t+\\phi_j)}\n$$\n\n\\begin{align}\nA_{j} = \\Omega_{0}^2(q_j+f_j) e^{i(\\omega_j t + \\phi_j)}\n\\end{align}\n\nWe can find the solutions for elliptical and vertical coordinates by solving equations (15) and (21) into equation (18) to get\n\n$$\nQ& =-(4 \\frac{T^{2}}{v_{\\infty}^{2}} \\Gamma \\Delta| \\times T \\left(\\frac{\\pi \\tau}{2T}\\right) - \\Delta |^{2} \\frac{\\sin \\left(\\frac{\\pi\\tau}{2 T}\\right)}{\\Delta}\\\\\n X (t) &=\\Phi_{2}+ \\Omega_{0}^{2}F_{3}\\left(q_j+f_j)e^{J(\\omega_{t})(+\\phi_j)}\\right)\n$$\n$$\n \\cos\\left( \\omega_{0}(1+\\pi \\sqrt 4t^{2})) \n or = (x-4\\omega_0)+1.7214679524+ \n$$",
    "where $A_{m}$ and $\\Delta \\phi$ are integration constants that are determined by the initial conditions. This is the full solution to the differential equation of equation (16). Note that the first two terms correspond to oscillations, which occur at the naturally aspirated frequency \n$\\frac{\\omega_{0}}{\\sqrt{2}}$ ($=$ 21.1 rad/s), however, the amplitude of the vibration changes with time. While the first term of the equation is independent of time, the coefficients vary slightly. This additional second term of the equation modifies the initial speed because the amplitude is alternated. The problem statement asks about the oscillation caused by the bump, if it affects the level vibrating that the forks, which we summarize as the height (5 cm), is considerably less than the wheel diameter (61 cm). Simply stating, we can see that the amplitude of the vertical oscillation caused by the bump is\n$$\nX_{o} = \\frac{H}{2} = 2.5\\text{ cm}\n$$\n(23)\nThus, this entire wheel-base configuration does not impact the amplitude of the vertical oscillation would become infinite, which represents resonance. The condition is explained as\n$$\n\\Delta Y= A_{f}\\left|\\frac{\\dot{Y}}{\\dot{X}}-\\epsilon\\frac{V}{\\sin\\theta}\\right|\n$$\nand satisfying it for an extended period of time might over damage to the ear. \n\n4. Tuning fork\n\n(i) We are given that the solution has the form\n\n$$\nx(t) = A e^{-\\gamma t/2}(\\cos(\\nu t+\\phi))\n$$\n\nWe can determine the coefficient by substituting into the equation that it is supposed to solve. Using the product note, we find\n\n$$\n\\ddot{x} = Ae^{-\\frac{\\gamma t}{2}}\n\\left( i\\frac{d}{dt}cos(\\nu t+\\phi)\\right)\n$$\n\n$$\n= -(i\\nu+\\frac{\\gamma}{2}\n$$\n\nAgain using the product rule, the second derivative\n\n$$\n\\ddot{x} = [A(e^{-e^{-\\frac{\\gamma}{2}}})'(\\cos\\theta t+\\psi) \\dot{\\theta} =-\\nu^{2}x = -\\gamma$x''' -\\nu^{2} = (-\\nu^{2} + -p(\\dot{x}+v))\n$$\n\nBy substituting equation (15) into the equation for the damped harmonic oscillator given in the problem we get\n\n$$\nx''(t)=-\\nu^{2} x + \\frac{\\gamma}{\\dot{x}} x-x\n$$\n\nThen, substituting equation (13) into (15) gives\n\n$$\n\\frac{d}{dt} x e^{-\\frac{3\\gamma t}{2} = A \\nu \\sin(\\bar{y}= \\gamma^2-\\nu^2=x=0\n$$\nSubtracting $2e^{-t}$ from inside \nit is $\\left(4x \\frac{e\\gamma cost=2x'/ -3\\right(@X-\\cdt}\n$$\n\n= $\\left(\\begin{x-/A_x-\\nu y y-prime@}\\frac{10^{5}}{4} - 2A\\sin Nos(2.5)= -k_{t)} x[/}$'''\n$$",
    "Thus, the damped harmonic oscillator equation is satisfied if\n$$-\\frac{\\gamma}{2} \\pm \\sqrt{\\left(\\frac{\\gamma}{2}\\right)^2 - \\omega_0^2} = \\pm i \\sqrt{\\omega_0^2 - \\left(\\frac{\\gamma}{2}\\right)^2}$$\n(12)\nas we know that the frequency is positive quantity.\n\n2. Therefore, the solution to the equation of motion for the damped harmonic oscillator can be written as\n$$x(t) = \\sqrt{\\frac{A(t)}{m}} \\sin \\left(\\omega_1 t + \\phi\\right),$$\nwhere $\\omega_1 = \\sqrt{\\omega_0^2 - \\gamma^2 / 4}$ and $A(t)$ are determined by initial conditions. To solve this problem, we can plot the function $A(t)$ versus time and estimate the oscillating time $\\tau$. Using finite difference methods (as you see that it is linear) $\\Delta y(t) = y(t + \\Delta t) - y(t)$. Evaluating at two different times $t_1$ and $t_2$ and taking the ratio allows us to determine $\\gamma$:\n$$\\frac{A(t_1)}{A(t_2)} = \\left(\\frac{A(t_1)}{A(t_2)}\\right),$$\n(14)\n\nWe can substitute this into equation (12) to find\n$$\\gamma = \\left(\\frac{\\frac{A(t_1)}{A(t_2)}}{\\Delta t}\\right),$$\n(15)\nUsing the relationship between the frequency and angular frequency $\\omega = 2\\pi f$, it becomes\n$$2\\pi f_s = \\sqrt{\\left(\\omega_0^2 - \\left(\\frac{A(t_1)}{A(t_2)}\\right)\\right)} = \\omega_0 \\sqrt{1 - \\left(\\frac{\\left(\\frac{A(t_1)}{A(t_2)}\\right)}{\\frac{4\\pi^2 f_0^2}{A(t)}}\\right)},$$\n(16)\n\nPlugging in numbers, we find that\n$$\\omega_0 = \\frac{\\omega}{2\\pi}\\frac{ln(A(t)}/{\\Delta t}\\approx}\n\\frac{100 \\text{ lb}}{\\left(\\frac{1.17}{(2.5)(\\sin(\\omega))}\\right)} = 400.000000222 Hz.$$\n(17)\n\nThus, given these sets of significant digits in the measured input quantities, we find that air has a negligible effect on the frequency of the tuning fork\n$$f_s = 400 Hz.$$\n(18)",
    "Chapter 1\n\nSTUDYING MECHANICS",
    "1. Studying mechanics\n\n1.1 Introduction\n1.2 Derivatives\n1.3 Scalar and vector products",
    "1.1 Introduction\n\nStructure of the course:\n\n* 14 lessons (theory, applications and experiments)\n* 13 tutoring sessions\n   ~ 4 problems per session\n\n* Moodle\n  http://moodle.epfl.ch/course/view.php?id=15221\n\n* MOOC (M\u00e9canique: Prof. J.-Ph. Ansermet)\n  http://www.coursera.org/course/mecanique\n\n* Book: M\u00e9canique J.-Ph. Ansermet\n  Presses Polytechniques Universitaires Romandes",
    "1.1.1 History\n\nMechanics: (Greek \"\u039c\u03b7\u03c7\u03b1\u03bd\u03b9\u03ba\u03ae\")\n- Equilibrium (statics)\n- Motion (dynamics)\n- Deformation\n\nStudying mechanics:\n- Historical reason\n- Methodological and pedagogical reason",
    "Aristotle (384\u2013325 B.C.)\n\n- Laws of heavenly bodies $\\ne$ laws of earthly bodies\n- Scientific methodology: theory and experience\n\nGalileo Galilei (1564-1642)\n\n- Experience: question nature (scientific methodology)\n- Theory: mathematical language",
    "Johannes Kepler (1571-1630)\n\n3 Laws (motion of planets)\n\u2022 1: Law of orbits (ellipse; focal point)\n\u2022 2: Law of areas (area/time = const)\n\u2022 3: Law of periods (period$^2/$semi-major axis$^3$ = const)\n\nTycho Brahe (1546-1601)",
    "Isaac Newton (1643-1727)\n\nMechanics\n* Physical theory:\n  Laws of mechanics (3 laws)\n* Mathematical theory\n  Calculus",
    "1.1.2 Learning outcomes\n\nModel conceptually a physical system\n\nTranscribe mathematically the physical model\n\nApply the physical laws and solve a system of differential equations\n\nLearn to identify the limits of the models and theories\n\nDevelop a know how by problem solving\n\nAdopt a systematic approach\n\nMaster the mathematical tools in a physical context\n\nDiscover mathematics through physics!",
    "1.1.3 Limits\n\nHenri Poincar\u00e9\n\n- Triumph of Newtonian mechanics\n  (end of 17th century\u2014end of 19th \n  century)\n- Failure of the universality of \n  determinism and of Newtonian \n  mechanics\n- Chaos theory (Poincar\u00e9: end of 19th \n  century and Lorenz: 1960)\n- Special relativity (Einstein: 1905)\n- Quantum mechanics (Schr\u00f6dinger, \n  Heisenberg, Dirac: 1920)\n\nMarquis Pierre Simon de Laplace to the emperor Napol\u00e9on Bonaparte: \n\"Give me the initial conditions and I will predict you the evolution of the world\".",
    "1.1.4 Experiments\n\n- Historical significance: demonstrate physical phenomena (since Galileo)\n- Symbolic significance: keep questioning nature\n- Methodological significance: spot the transition, from reality to the model\n- Didactic significance: link between teaching and daily life, scientific curiosity",
    "James C. Maxwell\n\n\"I have no reason to believe that the human intellect is able to weave a system of physics out of its own resources without experimental labor. Whenever the attempt has been made it has resulted in an unnatural and self-contradictory mass of rubbish\".",
    "\u2022 Experiment: \u2460 Impact of a gun bullet on wood and glass\n\nIf the target is made of glass, the gun bullet keeps its momentum. If the target is made of wood, the gun bullet conveys its momentum to the target.",
    "2. Destruction of a glass through resonance\n\nThe glass is acoustically excited at its resonance frequency using a loudspeaker. First, it is deformed, and then it breaks.",
    "3. Double pendula (sensitivity to initial conditions)\n\n4. Ping-pong ball (chaotic motion)\n\nIf two double pendula are thrown with comparable and sufficient initial amplitudes, their motions get quickly desynchronised.\n\nA ping-pong ball bounces on a surface that oscillates periodically. If the tube is open, the frequency of the bounces is random. With the friction imposed by the cap, the motion becomes periodic.",
    "1.2 Derivatives\n\nWe call derivative the infinitesimal limit of the ratio of the variation of a function and of the variation of its variable.\n\n1.2.1 Derivative of a function\n\n1. Velocity: derivative of the position $x(t)$ with respect to time $t$:\n\\[ v(t) = \\lim_{\\Delta t \\rightarrow 0} \\frac{\\Delta x(t)}{\\Delta t} = \\lim_{\\Delta t \\rightarrow 0} \\frac{x(t + \\Delta t) - x(t)}{\\Delta t} \\tag{1.1} \\]\n\n\\[ v = \\frac{dx}{dt} = \\frac{x(t + \\Delta t) - x(t)}{dt} \\implies dx = v dt \\tag{1.2} \\]",
    "2. Acceleration: derivative of the velocity $v(t)$ with respect to time $t$:\n$$\na(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta v(t)}{\\Delta t} = \\lim_{\\Delta t \\to 0} \\frac{v (t + \\Delta t) - v (t)}{\\Delta t} \\tag{1.3}\n$$\n$$\na = \\frac{dv}{dt} = \\frac{v (t + dt) - v (t)}{dt} \\Rightarrow dv = a \\, dt \\tag{1.4}\n$$\n$$\na(t) = \\lim_{\\Delta t \\to 0} \\frac{\\Delta \\left( \\lim_{\\Delta t \\to 0} \\frac{\\Delta x (t)}{\\Delta t} \\right)}{\\Delta t} \\tag{1.5}\n$$\n$$\na = \\frac{d}{dt} \\left( \\frac{dx}{dt} \\right) = \\frac{d^2 x}{dt^2} \\tag{1.6}\n$$\n\n3. Time derivative (physicist's notation):\n$$\nv = \\dot{x} \\tag{1.7}\n$$\n$$\na = \\ddot{x} = \\dot{v} \\tag{1.8}\n$$",
    "1.2.2 Derivative of a functional\n\nFunctional (function of function): $x(t) \\equiv f(g(t))$ \\hspace{0.5cm} (1.9)\n\n1. Derivative of $g(t)$:\n\\[\n\\frac{dg}{dt} = \\frac{g(t + dt) - g(t)}{dt} \\Rightarrow g(t + dt) = g(t) + dg \\hspace{0.5cm} (1.10)\n\\]\n\n2. Derivative of $f(g)$:\n\\[\n\\frac{df}{dg} = \\frac{f(g + dg) - f(g)}{dg} \\Rightarrow f(g + dg) = f(g) + df = f(g) + \\frac{df}{dg} dg \\hspace{0.5cm} (1.11)\n\\]\n\n3. Derivative of $f(g(t)) \\equiv x(t)$:\n\\[\n\\frac{dx}{dt} = \\frac{f(g(t + dt)) - f(g(t))}{dt} \\hspace{0.5cm} (1.10)\n\\]\n\\[\n= \\frac{f(g(t) + dg) - f(g(t))}{dt} \\hspace{0.5cm} (1.11)\n\\]\n\\[\n= \\frac{f(g(t)) + \\frac{df}{dg} dg - f(g(t))}{dt}\n\\]\n\\[\n= \\frac{df}{dg} \\frac{dg}{dt} \\hspace{0.5cm} (1.12)\n\\]\n\\[\n\\Rightarrow \\frac{dx}{dt} = \\frac{df}{dg} \\frac{dg}{dt} \\hspace{0.5cm} (1.13)\n\\]",
    "* Examples (physics)\n1. Position of a harmonic oscillator:\n\\[ x(t) = x_0 \\cos \\left( \\omega t + \\varphi \\right) \\hspace{10mm} (1.14) \\]\n\n\\[ \\frac{dx}{dt} = \\frac{d \\left( x_0 \\cos \\left( \\omega t + \\varphi \\right) \\right)}{d \\left( \\omega t + \\varphi \\right)} \\cdot \\frac{d \\left( \\omega t + \\varphi \\right)}{dt} = - x_0 \\omega \\sin \\left( \\omega t + \\varphi \\right) \\hspace{10mm} (1.15) \\]\n\n2. Kinetic energy of an object of mass \\( m \\):\n\\[ T(t) = \\frac{1}{2} m \\dot{x}^2 \\hspace{10mm} (1.16) \\]\n\n\\[ \\frac{dT}{dt} = \\frac{d \\left( \\frac{1}{2} m \\dot{x}^2 \\right)}{dx} \\cdot \\frac{dx}{dt} = m \\ddot{x} \\cdot \\dot{x} = m \\dot{x} \\cdot \\dot{x} = m \\frac{\\dot{x}^2}{x} \\hspace{10mm} (1.17) \\]",
    "1.2.3 Power series expansion of a function\n\n- Infinitesimal relation: $x(t + dt) = x(t) + \\left(\\frac{1.11}{\\Delta t}\\right)x(t) + \\frac{dx}{dt} dt$ (1.18)\n\n- Written with limits:\n\\[\n\\lim_{\\Delta t \\to 0} x(t + \\Delta t) = x(t) + \\lim_{\\Delta t \\to 0} \\frac{x(t + \\Delta t) - x(t)}{\\Delta t} \\Delta t\n\\]\n(1.19)\n\n- Approximation: $\\Delta t \\ll t$\n\\[\n\\frac{dx}{dt} = \\frac{x(t + \\Delta t) - x(t)}{\\Delta t}\n\\]\n(1.20)\n(1.20) $\\Rightarrow x(t + \\Delta t) \\simeq x(t) + \\frac{dx}{dt} \\Delta t$ (1.21)\n\nThe relation (1.21) is the power series expansion (or Taylor series) or 1st order in $\\Delta t$ of $x(t)$ around $t$.",
    "1.3 Scalar and vector products\n\n1.3.1 Direct frame\n\nvector: Oriented line element (norm, orientation).\n\nFrame: Geometric entity consisting of three linearly independant vectors attached to a point (origin).\n\nOrthonormal frame: The basis vectors are orthogonal and of unit norm (two types).",
    "- Direct frame:   A direct frame is an orthonormal frame where the basis vectors satisfy the right hand rule or the corkscrew rule.",
    "1.3.2 Scalar product\n\nScalar product: scalar obtained by multiplication of identical coordinates of two vectors expressed with respect to a direct frame $(O, e_1, e_2, e_3)$\n\n$$\na = a_1 e_1 + a_2 e_2 + a_3 e_3 \\quad \\text{and} \\quad a = (a_1, a_2, a_3) \\tag{1.22}\n$$\n\n$$\nb = b_1 e_1 + b_2 e_2 + b_3 e_3 \\quad \\text{and} \\quad b = (b_1, b_2, b_3) \\tag{1.22}\n$$\n\nMathematical expression:\n$$\na \\cdot b = a_1 b_1 + a_2 b_2 + a_3 b_3 \\tag{1.23}\n$$\n\ni) commutative:\n$$\na \\cdot b = b \\cdot a \\tag{1.24}\n$$\n\nii) basis vectors:\n$$\ne_i \\cdot e_j = \\delta_{ij} \\quad \\forall \\; i, j = 1, 2, 3 \\tag{1.25}\n$$\n\nwhere\n$$\n\\delta_{ij} = \\begin{cases}\n1 & \\text{if } i = j \\\\\n0 & \\text{if } i \\neq j \n\\end{cases} \\tag{1.26}\n$$",
    "- Geometric interpretation of the scalar product:\n- Decomposition of vector $a$:\n  $a = a_{\\parallel} + a_{\\perp}$\n- Vectors $a$ and $b$ in components:\n  $a = (\\|a\\| \\sin \\theta, \\|a\\| \\cos \\theta, 0)$\n  $b = (0, \\|b\\|, 0)$\n  where $\\|a\\| =$ norm of vector $a$\n  $\\|b\\| =$ norm of vector $b$\n\n- Scalar product (1.23):\n  $a \\cdot b = \\|a\\| \\|b\\| \\cos \\theta \\hspace{25pt} (1.28)$\n\n- Vectors $a_{\\parallel}$ and $a_{\\perp}$ in components:\n  $a_{\\parallel} = (0, \\|a\\| \\cos \\theta, 0) \\hspace{10pt} \\text{and} \\hspace{10pt} a_{\\perp} = (\\|a\\| \\sin \\theta, 0, 0)$\n\n- Properties:\n  $(i) \\hspace{10pt} a \\cdot a = \\|a\\|^2 \\hspace{25pt} (ii) \\hspace{10pt} a_{\\parallel} \\cdot b = a \\cdot b \\hspace{25pt} (iii) \\hspace{1pt} a_{\\perp} \\cdot b = 0 \\hspace{25pt} (1.29)$",
    "1.3.3 Vector product\n\n- **Vector product:** vector obtained by calculating the determinant of a matrix consisting of the coordinates of the vectors and of the basis vectors.\n- **Mathematical expression:**\n\n\\[ \\mathbf{a} \\times \\mathbf{b} = \\begin{vmatrix}\n\\mathbf{e}_1 & a_1 & b_1 \\\\\n\\mathbf{e}_2 & a_2 & b_2 \\\\\n\\mathbf{e}_3 & a_3 & b_3 \n\\end{vmatrix} = (a_2 b_3 - a_3 b_2) \\mathbf{e}_1 + (a_3 b_1 - a_1 b_3) \\mathbf{e}_2 + (a_1 b_2 - a_2 b_1) \\mathbf{e}_3 \\]\n\n(i) anti-commutative: \\( \\mathbf{a} \\times \\mathbf{b} = - \\mathbf{b} \\times \\mathbf{a} \\) (1.32)\n\n(ii) basis vectors: \\( \\mathbf{e}_i \\times \\mathbf{e}_j = \\epsilon_{ijk} \\mathbf{e}_k \\quad \\forall \\ i, j, k = 1, 2, 3 \\) (1.33)\n\nwhere \\( \\epsilon_{ijk} = \\begin{cases} \n1 & \\text{for} \\ i123, \\ 231, \\ 312 \\\\\n-1 & \\text{for} \\ i321, \\ 213, \\ 132 \\\\\n0 & \\text{otherwise} \n\\end{cases} \\) (1.34)\n\n(iii) non-associative: \\( \\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c}) \\neq (\\mathbf{a} \\times \\mathbf{b}) \\times \\mathbf{c} \\) (1.35)",
    "- Geometric interpretation of the vector product\n\n- Decomposition of vector $ a $:\n\n$a = a_{\\parallel}+a_{\\bot}$\n\n- Vectors $ a $ and $b $ in components:\n\n$a=(\\|a\\|\\sin \\theta, \\|a\\|\\cos \\theta,0)$\n\n$b=(0,\\|b\\|,0)$\n\nwhere $\\|a\\|$ = norm of vector $ a $\n\n$\\|b\\|$ = norm of vector $ b $\n\n- Vector product $(1.30)$:\n\n$a \\times b = \\|a\\| \\|b\\| \\sin \\theta \\mathbf{e_{3}}$\n\n- Vectors $ a_{\\parallel} $ and $a_{\\bot}$ in components:\n\n$a_{\\parallel}=(0,\\|a\\|\\cos \\theta,0)$ and $ a_{\\bot}=(\\|a\\|\\sin \\theta,0,0)$\n\n- Properties:\n(i) $ a \\times a = 0$\n(ii) $ a_{\\parallel}\\times b = 0$\n(iii) $a_{\\bot}\\times b = a \\times b $ (1.37)",
    "1.3.4 Triple product\n\nTriple product of three vectors $a, b, c$:\n\n\\[\n(a \\times b) \\cdot c = \\begin{vmatrix}\nc_1 & a_1 & b_1 \\\\\nc_2 & a_2 & b_2 \\\\\nc_3 & a_3 & b_3\n\\end{vmatrix} = (a_2 b_3 - a_3 b_2) c_1 + (a_3 b_1 - a_1 b_3) c_2 + (a_1 b_2 - a_2 b_1) c_3 \n\\tag{1.39}\n\\]\n\nProperties:\n\n(i) $(a \\times b) \\cdot c = (b \\times c) \\cdot a = (c \\times a) \\cdot b$\n        \n(ii) $(a \\times b) \\cdot a = (a \\times b) \\cdot b = 0$ \\tag{1.40}",
    "1.3.5 Vectorial identity\n\nIdentity: $a \\times (b \\times c) = (a \\cdot c) b - (a \\cdot b) c$ (1.43)\n\n(i) $a \\times (b \\times c)$ (1.30)\n\n\\[\na \\times \n\\begin{vmatrix}\ne_1 & a_1 & (b_2 c_3 - b_3 c_2) \\\\\ne_2 & a_2 & (b_3 c_1 - b_1 c_3) \\\\\ne_3 & a_3 & (b_1 c_2 - b_2 c_1) \\\\\n\\end{vmatrix}\n\\]\n\n\\[\n= \n\\begin{vmatrix}\na_2 (b_3 c_1 - b_1 c_3) - a_3 (b_2 c_1 - b_1 c_2) \\\\\na_3 (b_1 c_2 - b_2 c_1) - a_1 (b_3 c_2 - b_2 c_3) \\\\\na_1 (b_2 c_3 - b_3 c_2) - a_2 (b_1 c_3 - b_3 c_1) \\\\\n\\end{vmatrix}\n\\] (1.41)\n\n(ii) $(a \\cdot c)b - (a \\cdot b)c$ (1.23)\n\n\\[\n\\begin{vmatrix}\n(a_1 c_1 + a_2 c_2 + a_3 c_3) b_1 - (a_1 b_1 + a_2 b_2 + a_3 b_3)c_1 \\\\\n(a_1 c_1 + a_2 c_2 + a_3 c_3) b_2 - (a_1 b_1 + a_2 b_2 + a_3 b_3)c_2 \\\\\n(a_1 c_1 + a_2 c_2 + a_3 c_3) b_3 - (a_1 b_1 + a_2 b_2 + a_3 b_3)c_3 \\\\\n\\end{vmatrix}\n\\] (1.42)\n\n(1.41) = (1.42) $\\Rightarrow$ (1.43) \u25a1",
    "Solutions to Problem Set 2\nBallistics\nPHYS-101(en)\n\n1. The crow and the fox\n\nWe start by taking the diagram provided with the question and defining the angle $\\alpha$ as well as a convenient coordinate system. The origin O is the position of the fox, the angle $\\alpha$ defines the direction of the initial velocity of the stone relative to the fox's axis $x$ of the stone's motion, and $g$ is the gravitational acceleration which is depicted to be in the same direction as the initial velocity vector of the stone.\n\nBoth objects experience projectile motion, so we can directly write their equations of motion. For the stone we have\n  \n\\[ x_{\\text{t}} = v_{\\text{0}} t \\cos \\alpha \\quad \\text{and} \\]\n\n\\[ y_{\\text{t}} = H + v_{\\text{0}} t \\sin \\alpha - \\frac{1}{2}gt^2 \\]\n\nSimilarly, for the crow we have\n\n\\[ x_{\\text{c}}(t) = v_{\\text{c}} t \\cos \\theta + x_{\\text{c}}  \\]\n\nand the initial conditions of the stone are $x_{\\text{c}} = 0$, $y_{\\text{c}} = 0$, $\\dot{x_{\\text{c}}} = v_{\\text{0}} \\cos \\alpha$, and $\\dot{y_{\\text{c}}} = v_{\\text{c}} \\sin \\theta$, while the initial conditions of the crow are $x = 0$, $y = H$, $\\dot{x} = v_{\\text{0}} \\cos \\alpha$ and $\\dot{y} = 0$. Substituting these values into the equations, we get\n\n\\[ x = v_{\\text{0}}t \\cos \\alpha \\] \n\n\\[ y = H + v_{\\text{0}} t \\sin \\alpha - \\frac{1}{2}gt^2 \\]",
    "for the stone and\n\\[ \ny_s(t) = L - H \n\\tag{3} \n\\]\n\\[ \ny_s(0) = L \n- H \n\\]\n\\tag{4}\nfor the drone.\n\nFor the stone and drone to collide, there must be a single time $t = t_{\\text{col}}$ for which they are at the exact same position. We can write this condition as\n\\[ \ny_s(t_{\\text{col}}) = y_d(t_{\\text{col}})\n\\tag{5} \n\\]\nand\n\\[ \ny_s(t_{\\text{col}}) = y_0 \\cos \\theta \\cdot t_{\\text{col}} \n\\tag{6} \n\\]\n\nSubstituting the equations of motion for the stone and drone from above, equation (5) becomes\n\\[ \nL - H =  y_0 \\cos \\theta \\cdot t_{\\text{col}}\n\\]\n\nwhich implies that\n\\[ \nt_{\\text{col}} = \\frac{L - H}{y_0 \\cos \\theta}\n\\]\nUsing basic trigonometry and the Pythagorean theorem, the figure above shows that $ \\cos \\theta = \\frac{L}{\\sqrt{L^2 + H^2}}$. Substituting this gives\n\\[ \nt_{\\text{col}} = \\frac{\\sqrt{L^2 + H^2}}{y_0}\n\\tag{7} \n\\]\n\nIn the y direction we use equation (6), which is\n\\[ \nH = \\frac{1}{2}gt_{\\text{fall}}^2\n\\]\n\nCrucially, we see that the gravitational acceleration terms on both sides cancel and gravity disappears from the problem, leaving\n\\[ \nt_{\\text{fall}} = \\sqrt{\\frac{2H}{g}}\n\\]\nSolving for $t_{\\text{fall}}$ and using trigonometry, we have\n\\[ \nT = \\frac{L}{y_0} \\cdot \\sqrt{\\frac{2h}{g}}\n\\tag{8} \n\\]\n\nIf we see that the collision time happens to be equal to the quantity $T$ and $t > T$ is not physical. This means the drone will have a collision - the stone and drone are the same at $t$ and y location at the same time. No other time will happen.\n\nNote that the fact that there is a collision does not depend on the value of $t$.\n\nThe value of $t_{\\text{fall}}$ can also be found by substituting the collision time factors back to the equation of motion. Using equation (3) for $t_{\\text{col}}$ we have\n\\[ \nH = \\frac{1}{2}g\\left( \\frac{\\sqrt{l^2 + H^2}{v_0}  \\right)^2}\n\\]\n\nUsing equations (2) and (4) it is also possible to find the value of $\\theta$ at the location of the collision in\n\\[ \ny_d(t_{\\text{fall}}) \\& y_s(t_{\\text{fall}}) = \\subseteq \\left( \\frac{\\sqrt{1 - H^2}{1}}{y_0} - H \n+ \\frac{2H}{2}}{x})}{L + \\frac{H \\cdot \\sqrt{2}}{v}} \\right)  \n\\]",
    "4. Above, we have shown that the stone and drone always collide, without posing any restriction on the initial speed of the stone. However, in reality there is a restriction to impose: If the initial speed is too low or too large, the stone will hit the ground before it hits the drone. To find the constraint on the initial speed of the stone that will prevent both objects falling before they collide, the collision would take place underground (i.e., at $y < 0$). In order for the collision to take place above ground, we must enforce that\n\n\\[\ny_{\\text{stone}} (t_\\text{coll}) > 0\n\\]\n\nUsing equation (10), this is equivalent to\n\n\\[\n0 \\leq v_{0}t - \\frac{H}{2}t^2\n\\]\n\nRearranging, we see that the constraint on the initial speed is:\n\n\\[\nv_{0} \\geq \\sqrt{\\frac{gH}{2}}\n\\]\n\n2. Sherlock Holmes\n\n- For Sherlock to hear the object hit the ground, the object must reach the ground and then the sound from the impact must travel back to him. As he travels back to where he started, $h$ represents the initial height, the time to take is taken to be long. Let $t_0$ be the time for Sherlock to travel from the ground to his initial position. While Sherlock walks in his upwards, the origin of the coordinates is located at the base of the Eiffel tower. We take $h$ as to upwards, he origin os located at the base of his figure below.\n\n\\[\ny\n\\]\n\nThe magnifying glass undergoes one-dimensional motion under constant acceleration, so we use:\n\\[ \ny(t) = y_0 +v_0t +\\frac{1}{2}at^2 \n\\]\n\nwhere $a = -g$. Here the sign of the acceleration must be negative when we defined the positive z direction to be up. The initial velocity of the magnifying glass can be assumed to be 0, so the above initial conditions $y_0 = h$, $v_0 = 0$, and $a = - g$,\n\n\\[\ny(t) = h - \\frac{1}{2}gt^2 = 0 \\rightarrow t = \\sqrt{\\frac{2}{h}{g}} \\rightarrow t_0 =  \\sqrt{\\frac{2}{h}{g}}\n\\]",
    "We have defined the time $t_g$ as the time the magnifying glass hits the ground, so we know that\n\n\\[ t_g = \\sqrt{\\frac{2H}{a}} + \\frac{H}{v}. \\]\n\nWe can solve this equation to find\n\n\\[ t_g = \\frac{v}{a} \\left( \\sqrt{1 + \\frac{2aH}{v^2}} - 1 \\right). \\]\n\nThe speed of sound $v_s$ is constant in the Earth's atmosphere. When a noise is emitted it travels outward at a fixed speed in all directions. The Sherlock hears two Sherlick strikes (he makes a silly noise with his teeth) as he throws his magnifying glass. The time of the Sherlock strike travels outward at constant speed $v$ until he hears the position of the ground and is given by\n\n\\[ v_s t_a = \\sqrt{x^2 + y^2}. \\]\n\nGiven our coordinate system, the initial position of the noise $x = 0$. From our definition of the time $t_a$, we know that $t_a \\approx x/2v_s = t_0$.\n\nFrom this we can calculate the elapsed time\n\n\\[ t_{travel} = \\frac{\\sqrt{x^2 + y^2} - x}{v_s} + t_g. \\]\n\nLastly we know that the total time is simply the sum of the time for the magnifying glass to reach the ground and the time for the sound to travel back to Sherlock.\n\nSubstituting equations (12) and (13), we find\n\n\\[ t_{travel} = \\sqrt{\\frac{H}{a}} + \\frac{H}{v_s} + \\sqrt{\\frac{x}{v}^2 \\frac{1+xH}{v_s^2}} = \\sqrt{\\frac{xH}{v_s^2a}} + \\sqrt{\\frac{x^2}{v_s}} \\]\n\nwhere we are interested in finding the height $h = x$.\n\nRearranging gives a quadratic polynomial in $x$, which is\n\n\\[ (y+2) x^2 = \\left ( \\frac{v}{a} \\left ( \\sqrt{1 + \\frac{2aH}{v^2}} - 1 \\right) \\right )^2; \\]\n\nUsing the quadratic formula, we can solve for $v$ and find two solutions\n\n\\[ x= \\frac{1}{2} (\\frac{\\sqrt{y+2}}{v}), \\]\n\nwhich correspond to the plus versus minus signs. Separating this equation gives\n\n\\[ \\Delta x = \\left ( \\frac{v}{a} \\left ( \\sqrt{1 + \\frac{2aH}{v^2}} - 1 \\right) \\right). \\]",
    "This is an acceptable answer, but we will rearrange it further to arrive at something simpler. First we will factor out a factor of $\\sqrt{2g}$ from the numerator and combine it with the denominator to get\n\n\\[ \nA_0 = \\left( 5 \\sqrt{\\frac{1}{2g}} \\left( \\frac{1+\\sqrt{\\frac{h}{r}}}{\\sqrt{\\frac{h}{r}}} \\right) \\right) \\left( \\frac{r\\sqrt{h}}{ \\sqrt{ ( \\frac{\\sqrt{h}}{r} )^2 }} \\right) \n\\tag{16} \n\\]\n\nThen we will take the common factor out of the square to arrive at our final answer of\n\n\\[ \nA_0 = \\sqrt{ \\frac{r^2 h_t}{2g} } \\left( 1 + \\sqrt {\\frac{r}{h}} \\right) \n\\tag{17} \n\\]\n\nc. The units of the equations can be written as\n\n\\[ \n[ A_0 ] = \\left[ \\left( \\frac{1}{2g} \\right) \\left( \\frac{r^2 h_t}{1} \\right) \\right]\n\\]\n\nFrom this, we see that the entire contents of the parentheses have no units, so\n\n\\[ \n[ A_0 ] = [ m ] \n\\]\n\nas required.\n\nd. Equation (17) contains two solutions (one with the + and one with the -), only one of which is physically valid. The solution to the quadratic equation that has the - sign in front of the ( 1 + ) term will cause the amplitude to decrease downward out of view. This yields\n\n\\[ \nA_0 = \\sqrt{ \\frac{2h}{g} } \\left( -1 + \\sqrt{\\frac{2g h}{A_0}} \\right) \n\\]\n\nWe can see if we take the \u201c+\u221e\u201d solution, the length will always remain finite as the gap between the height ($ h_t $) and the $ h_t $. This often makes small physical sense if the value happened to be larger than the height of the wall. This solution doesn\u2019t destroy the logic and completeness of the problem, because here there is only one possible solution. Nonetheless, in a broader sense where trigonometric like functions would be given, like $\\lambda = \\sqrt{\\lambda_1}$ or $\\lambda_0 = -1 + \\sqrt{\\lambda_2}$ it could remain true with $ \\lambda_2 > 0$. Therefore, as familiar, these problems often have more than one valid solution except maxima or critical points.\n\ne. Plugging in $ h = 9 \\chi = 330 m $ and $ x_o = 10 \u2248 \u00fc = 2600  equation (19) gives \\lambda = 320 m",
    "3. Vectors\n\n1. See figure below.\n\n2. We can divide the main triangle $ABC$ into two parts using a line perpendicular to $x$ as shown in the figure.\n   \nFor the triangle $BCD$, simple trigonometry gives\n\\[\n\\sin \\theta = \\frac{a}{B} = \\frac{CD}{B}\n\\]\n\\[\nCD = a\n\\]\n(20)\nwhere $B$ is the magnitude (i.e., length) of $\\vec {b}$ and $CD$ is the length of the line connecting points $C$ and $D$. Similarly, we can use that\n\\[\nBD = b \\cos \\theta\n\\]\n(21)\nwhere $BD$ is the length of the line connecting points $B$ and $D$.\nFor the triangle $ACD$, the Pythagorean theorem gives\n\\[\nc^2 = AD^2 + CD^2,\n\\]\n(22)\n",
    "where $c = h /$ and $AD = b$ the length of the line connecting points A and D.\n\nLastly, we see from the figure that \n$$AD + BD = c$$\n(23)\nwhere $c = h /$.\nSince $A, C,$ and $D$ are given, we see that equation (23) (above) contains four line equations that contain four variables: $AD, BD, h,$ and $D$. We can solve equations (23) and (22) for $C D$ and $AD$ respectively. Therefore, we substitute the ratios into equation (20) to find\n$$c = \\sqrt{b^{2}+ad^{2}}=\\sqrt{b^{2}+h^{2}}=\\gamma_{c}$$\n(24)\n\nSimplifying this expression and using the trigonometric identity $a^{2} + cos^{2} = 1$ gives \n$$c=\\sqrt{b^{2}-2 b h \\cos... -v^{2}}$$\n(25)\n\nThen solving equation (20) for $c D$ and substituting we find, \n\nTherefore, the solution is $c = a \\sqrt{b}$ \n\n3. From the above figure we see that \n$$\nu_{ad}=\\frac{C D}{\\cos (\\theta)}\n$$ \n\n4. Dropping a stone from a sail boat\n\nFor parts 1 and 2 of this problem, we choose a coordinate system at rest with respect to the land when the boat is observed. The time $t=0$ is taken at the end of the video if the boat is alongside a dock at the given endpoints closest to the foot of the mast at time $t=1 \\mathrm{s}$ after a stone is dropped. In part 3, we choose a coordinate \u5bf9\n",
    "frame of reference relative to the fixed stars. The idea is to have a frame of reference that is fixed while the sailboat or the stone moves.\nIn this problem, it is crucial to realize that the initial velocity of the dropped stone is equal to the velocity of the sailboat at the precise moment when the stone is dropped.\n\ni. The dropped stone undergoes constant acceleration due to gravity $g$ in the downwards direction. Thus, we can apply the equations of projectile motion.\n\n$x_s(t) = x_{s0}$,\n\\[y_s(t) = y_0 + \\frac{1}{2}g t^2\\]\n\nGiven our coordinate system, the initial conditions of the stone are $v_x = 0$ and $y_0 = h$. Thus, the equations of motion for the stone is\n\\[y_s(t) = h - \\frac{1}{2}gt^2\\]\n\nThe time it takes for the stone to reach the foot of the mast is determined by the condition $y_{s\\text{mast}}(t_{\\text{mast}}) = 0$, as we need\n\\[0 = h - \\frac{1}{2}gt^2\\]\n\nThe distance stones are constant as $x_s(t_{\\text{mast}}) = u_{\\text{st}} t_{\\text{mast}}$ is required. The distance that the stone lands relative to the foot of the mast is given by\n\n\\[x_{s}(t_{\\text{mast}}) = ut_{\\text{mast}}\\]\n\nwhere $| ... |$ is the absolute value (or magnitude) of the quantity within and $x_s(t_{\\text{mast}})$ is the horizontal position of the stone when it reaches the foot of the mast. However, the equations of motion for the stone requires $t$ is given by\n\\[(27)\\]\n\nHowever, since the initial conditions are $x_0 = 0$ and $v_x = u_0$,\n\\[x_{s0} = (U_{\\text{st}})_i\\tag 1\\]\n\nLikewise, since the sailboat has no motion in the $y$ direction, the equation of motion for the mast is identically $y_m = 0$. Thus we need\n\\[y_{\\text{mast}} = 0 \\]\n\n2.  Since the velocity of the sailboat is solely in the $x$ direction, the equation of motion is it is identical to that of part 1,\n\n\\[ x_{\\text{mast}} = (U_{\\text{st}}) \\]\n\nTherefore, the time it takes for the stone to land remains\n\\[T_{\\text{mast}} = \\sqrt{\\frac{2h}{g}}\\]\n\n Now, since the sailboat moves with a constant velocity in the horizontal directions, the equation of motion of the foot of the mast is unchanged\n\n\\[ x_{\\text{t}} = us\\]\n\n\\[y_{\\text{t}} = 0\\]\n\n\\[(27)\\]\n\n\\(\\tag 27\\_{\\text{mast}}\\)\n\\_ 0_\\)\n\n8$\\]",
    "However, the horizontal motion of the stone is also changed. Since the girl is riding the merry-go-round, when she drops it with no initial velocity in her reference frame, it has no velocity $\\mathbf{v}_0$ with respect to the reference frame of the land (in which we are doing the calculation). Thus, equation (27) becomes\n\\[ \\mathbf{v}(t) = \\mathbf{v}_{0} = 0. \\]\n\nNevertheless, the distance the stone lands relative to the foot of the mast remains unchanged\n\\[ l = l_{\\text{stone (land)}} = l_{\\text{mast (land)}} = v_{0} t_{\\text{fall}} = vt_{\\text{fall}}.\\]\n\n3. Again, you must determine the equations of motion for the stone at the foot of the mast in the x and y directions.\nIt is best to use a frame of reference at rest relative to the land. As soon as the stone is released, it no longer experiences the constant acceleration. Thus in the x direction, the stone follows\n\\[ x_{\\text{stone}}(t) = \\frac{1}{2}at^2, \\]\nwhere we have already substituted the initial velocity and position of the stone. In the y direction, the stone has initial velocity $v_{0}$ and acceleration $a$, so it follows\n\\[ y_{\\text{stone}}(t) = v_{0}t. \\]\n\nThe foot of the mast stays with the ship and continues to experience constant acceleration, so it follows the same motion in the x direction:\n\\[ x_{\\text{mast}}(t) = \\frac{1}{2}at^2 \\]\n\nThe mast has no rise in the y direction,\n\\[ y_{\\text{mast}}(t) = 0. \\]\n\nThe stone reaches the foot of the mast when\n\\[ y_{\\text{stone}}(t_{\\text{fall}}) = y_{\\text{mast}}(t_{\\text{fall}}). \\]\n\nSubstituting the equations of motion for both sides gives\n\\[ v_{0}t_{\\text{fall}} = 0. \\]\nTherefore,\n\\[ t_{\\text{fall}} = 0s \\text{ or } t_{\\text{fall}} = \\frac{v_0}{g}, \\]\n\nSince $t = 0$ is the time it takes the stone to reach the foot of the mast $t_{\\text{fall}}$ remains the same as in parts 1 and 2.\nThe distance the stone lands relative to the foot of the mast is still given by\n\\[ l = l_{\\text{stone (land)}} = l_{\\text{mast (land)}} = v_{0} t_{\\text{fall}} = v t_{\\text{fall}} \\]\nso, as before, the stone falls at the foot of the mast\n\\[ d = 0. \\]",
    "5. Optional: The tortoise and the hare revisited\n\nIn this problem we take as given the length of the race $L$, the distance to the bridge $L\u2019$, the velocity of the tortoise $v_t$, and the initial velocity of the hare $v_h$. We must calculate the acceleration needed for the hare to win the race.\n\nAs in problem 3 of problem set 1, we will define $t_0 = 0$ as the time the race starts, as it is the time at which both the hare and the tortoise begin to move. We also have to consider the hare\u2019s first time $t_1$ to take time to reach the tortoise. Additionally, we can also define the time duration $\\Delta t = t_2 - t_1$ when the hare confronts the tortoise. This means that $t_2$ is the time the hare overtakes the tortoise after $\\Delta x$. When the hare reaches the bridge, we can keep $t_3$ to refer to the time the hare and $t_4$ to represent the time for the tortoise. If the first $x$ is the position of the tortoise and $x_b$ is the position of the hare.\n\nDuring both phases of the race, the tortoise travels at the same constant speed $v_t$. Given that we have defined the origin to be its initial position, the tortoise\u2019s equation of motion is\n\n\\[ x_t(t) = v_t t. \\]\n\nThus, it reaches the bridge when\n\n\\[ x_t(t_3) = L\u2019 = v_t t_3. \\tag{28} \\]\n\nSimilarly, the tortoise reaches the finish line when\n\n\\[ x_t(t_4) = L = v_t t_4. \\tag{29} \\]\n\nDuring the first phase of the race (from $t_0$ to $t_1$), the hare maintains a constant speed $v_h$. Thus, its equation of motion is\n\n\\[ x_h(t) = v_h t. \\]\n\nHowever, when the tortoise reaches the bridge, the hare must make a continuous change to constant acceleration $a_h$ if the hare\u2019s velocity is still $v_h$ and can calculate its position to be\n\n\\[ x_h(t) = \\frac{1}{2}a_h(t - t_3)^2 + v_h t_3 - \\frac{1}{2}a_h t_3^2. \\]\n\nBy substituting equation (28), we find\n\n\\[ a_h = \\frac{v_h}{L\u2019 - \\frac{1}{2}v_t t_3^2 - v_h}. \\]",
    "The general equation of motion for constant acceleration can be found by integration (as we have done for the vertical direction of projectile motion) to be\n\n\\[ x(t) = x_0 + v_0 t + \\frac{1}{2} a t^2 \\]\n\nFrom our analysis of the first phase, we know the initial position of the second phase is $x_1 = x_f/4$, while the initial velocity of the second phase is $v_1 = v_0/2$. Therefore, the equation of motion becomes\n\n\\[ x(t) = \\frac{x_f}{4} + \\frac{v_0}{2} t + \\frac{1}{2} a t^2 \\]\n\nNote that in this equation we have adopted an absolute time system, defined such that the time $t = 0$ corresponds to the beginning of the chase and phase time $\\tau = 0$. Therefore, we need to shift the time scale back to $\\tau = t - t_i$, where $t_i$ is the start time of the second phase in order to let the tortoise. This corresponds to a time of $t_i = 2L / v_0$.\n\nUsing equations (28) and (29) to replace $x_1$ and $v_1$, we find\n\n\\[ x(\\tau) = \\frac{x_f}{4} + \\frac{v_0}{2} (t_i + \\tau) + \\frac{1}{2} a (t_i + \\tau)^2 \\]\n\nThis equation contains only $\\tau$ and known quantities. To produce the simplest expression, we will first multiply the quadratic term out and focus on\n\n\\[ \\left( t_i + \\tau \\right)^2 = \\left( t_i + \\tau \\right) \\left( t_i + \\tau \\right) = \n\nt_i^2 + t_i \\tau + t_i \\tau + \\tau^2 = t_i^2 + 2 t_i \\tau + \\tau^2 \\]\n\nRearranging produces\n\n\\[ x(\\tau) = \\frac{x_f}{4} + \\frac{v_0}{2} t_i + \\frac{v_0}{2} \\tau + \\frac{1}{2} a t_i^2\n        \n+ a t_i \\tau + \\frac{1}{2} a \\tau^2  \\]\n\nFinally, simplifying further yields the solution of\n\n\\[ x(\\tau) = \\left( \\frac{1}{4} + \\frac{v_0}{2} t_i + \\frac{1}{2} a t_i^2 \\right) + \\left( \\frac{v_0}{2} + a t_i \\right) \\tau + \\frac{1}{2} a \\tau^2  \\]\n\nTherefore, in order for the hare to win the race, it must accelerate faster than this, producing the condition that\n\n\\[ a_h \\tau_{xf} > x_f - \\frac{x_f}{4} - \\frac{v_0}{2}  \\left( t_i + \\tau_{xf} \\right) \n- \\frac{1}{2} a \\left( t_i + \\tau_{xf} \\right)^2  \\]\n\nTo verify our result, we can check the units\n\n\\[ \\frac{2x_f}{L} \\left( \\frac{L}{v_0} \\right)^{-2} = \\frac{2 x_f v_0^2}{L^2} \\]\n\nWe can also check the following limiting cases.\n\nLimiting case: The hare has a high initial velocity that is much greater than that of the hare. For this case, we expect that the acceleration of the hare must be very large in order to beat the tortoise. Mathematically, we write this as $v_0 \\gg v_1$ so that the new acceleration becomes\n\n\\[ \\lim_{v_0 = \\infty}  \\rightarrow \\left( \\frac{v_0}{2(1.234)  \\left( {\\tau_{x_1} (\\frac{x_f}{4} )} \\right)^2} - \\frac{x_f}{4 \\cdot 2} \\right) \\]",
    "Limiting case 2: The tortoise and the hare have an equal velocity before the ridge. For this we expect that the hare does not need to accelerate at all in order to tie the race. Mathematically, we write this as $v_h = v_t$. We see that\n\n$$ a \\frac{2w}{(L - L^*)^2} = 0. $$\n\nLimiting case 3: The bridge is situated close to the finish line, making the second phase of the race very short. For this we expect that the hare\u2019s acceleration will need to be very large in order to win the race. Mathematically, we write this as $L^* \\rightarrow L$. We see that\n\n$$ \\lim_{L^* \\to L} a \\frac{2w}{(L - L^*)^2} = \\infty. $$",
    "6. Optional: Reference frames\n\nWe choose to use a coordinate system where $z$ points east, $y$ points north, and $x$ is vertical and points to the sky. The origin of the coordinate system coincides with the initial position of the ball.\n\na. The ship sails with a constant velocity, so the only acceleration in the entire system is due to gravity. Thus, in the ship frame the ball undergoes projectile motion, which has equations of motions given by:\n\\[ x(t) = x_0 + v_{0x} t - \\frac{1}{2}gt^2 \\]\n\\[ y(t) = y_0 + v_{0y} t \\]\n\\[ z(t) = z_0 + v_{0z} t \\]\n\nIn the reference frame of the ship (this is the coordinate system described at point (a)), any initial velocities in the ship frame are given by $v_{0i}^{\\prime}$, thus, for reference frame of origin, we have:\n\\[ x_0 = 0, y_0 = 0, z_0 = 0 \\]\n\nConsidering that earlier we just picked the origin of our system to coincide with the initial position of the ball, the initial velocity in the reference frame $v_{0i}^{\\prime}$ thus, we note that $v_{0i}$ is just $v_{0x}$, etc:\n\\[ x(t) = v_{0x}^{\\prime} t - \\frac{1}{2}gt^2 \\]\n\\[ y(t) = v_{0y}^{\\prime} t \\]\n\\[ z(t) = v_{0z}^{\\prime} t \\]\n\nThese equations represent a parametric form for the trajectory. Alternatively, we can solve the equation in the $x$ direction for time to get\n\\[ t = \\frac{v_{0x}^{\\prime} \\pm \\sqrt{v_{0x}^{\\prime 2} + 2gx }}{-g} \\]\n\nwhich we substitute into the equations in $y$ and $z$ directions:\n\\[ y(x) = y_0 + v_{0y}^{\\prime} \\left( \\frac{v_{0x}^{\\prime} \\pm \\sqrt{v_{0x}^{\\prime 2} + 2gx}}{-g} \\right) \\]\n\\[ z(x) = z_0 + v_{0z}^{\\prime} \\left( \\frac{v_{0x}^{\\prime}\\pm \\sqrt{v_{0x}^{\\prime 2}} + 2gx}{-g} \\right) \\]\n\nThis is an implicit, complex expression for $x(y,z)$. However, since $y(z)$ is a constant and $y(z) = 0$ already. Substituting values in, we find\n\\[ \\mathbf{y} = \\pm 0.029(x - 0.85) \\text{ or 0.85}(y - 1.5) \\]\n",
    "and\n\\[\nx_k = 0.\n\\]\nb. In this part, we want to take the solution we found for the ship frame in part a and convert it into \nthe laboratory frame. Later in the course, we will rigorously derive how to convert metrics between \ndifferent coordinate systems. However, here the situation is simple enough that you can visual how \nthe motion of the ship and the ball will be combined.\nIn the laboratory frame, there is no additional acceleration as the ship sails at constant velocity. Thus, \nthe equations of motion remain\n\\[\nz(t) = v_0t + z_0\n\\]\n\\[\nx(t) = u_0t + x_0\n\\]\nGiven the choice of the origin of our coordinate system, we also retain $x_0 = z_0 = 0$. However, \nwe must add the origin of the ship to the observer frame to both positions and velocities, as the origin of the \nlaboratory frame shifts with relative speed $U$. Thus, the trajectory from part A must be combined with that \nof the ship by adding the velocity of the ball from the ship\u2019s perspective, to the ship\u2019s own origin.\nInitially, the observer relative velocity of the ball from the ship\u2019s perspective was given with green, while \nthe observer relative velocity of the ship\u2019s ball position was an orange line, as follows:\nWhile in flight, the velocity of the ball was $v_0 \\partial t = \\Delta v$. Now, we must also consider the \norigin of the ship\u2019s velocity ${U}{\\partial t} $. Thus $\\partial (v_0 + U)t$. Substituting the initial conditions gives:\n\\[\nz_k(t) = U t + u_0 t \\cos \\alpha\n\\]\n\\[\nz_k(t) = v_0t + u_0 t \\sin \\alpha\n\\]",
    "These equations are a parametric form of the trajectory of the ball. Alternatively, we can solve the equations in the y direction for time to get\n\n\\[ t = \\frac{y + \\sum}{v_i \\sin \\theta} - \\frac{1}{2}\\frac{g}{(v_i \\sin \\theta)^2} \\]\n\nwhich we substitute into the equation in the x and z directions to find\n\n\\[ x(y) = \\left( \\frac{v_i \\cos \\theta \\cos \\psi}{v_i \\sin \\theta} \\right)y + \\left( \\frac{v_i \\cos \\theta \\cos \\psi}{v_i \\sin \\theta} \\right)\\sum \\]\n\n\\[ x = \\left( \\frac{\\cos \\theta \\cos \\psi}{\\sin \\theta} \\right)y - \\left( \\frac{\\cos \\theta \\cos \\psi}{\\sin \\theta} \\right)\\sum \\]\n\nThese are equations for a parabola, but one that does not lie in the x-z, y-z, or y-x plane. Substituting numbers for the angles, we find\n\n\\[ x(y) = y \\left( \\frac{\\sqrt{\\frac{1}{2}} \\cdot \\frac{\\sqrt{3}}{2}}{\\sqrt{\\frac{1}{2}} \\cdot \\frac{1}{2}} \\right) - \\sum \\left( \\frac{\\frac{\\sqrt{3}}{2} \\cdot \\frac{\\sqrt{3}}{2}}{\\sqrt{\\frac{1}{2}} \\cdot \\sin \\left(\\frac{\\pi}{4}\\right)} \\right) \\]\n\n\\[ x(y) = y \\cdot \\sqrt{3} - \\sum \\cdot \\frac{3}{\\sqrt{2}} \\]\n\nSubstituting numbers for the speeds (note that $v_i = 15 \\text{ km/h}, v_i = 5 \\text{ m/s}$) and assuming that $g = 9.81 \\text{ m/s}^2$, we find\n\n\\[ x(y) = -4.67y \\]\n\n\\[ x(z) = -0.37y - 2.12z \\]",
    "Solutions to Problem Set 7  \nMomentum and continuous mass transfer  \nPHYS-101(en)  \n\n1. Acrobat and clowns\n\nWe start by defining our system to include both the acrobat and the clowns. The first important observation is that there is a collision between the acrobat and the clowns. The collision dynamics can be described by the interactions between the acrobat's lighter particle and the clowns. To model this, we use a coordinate system with the origin at the trapeze and y defined to be upward.  \n\nThere are two stages for the acrobat's motion to be considered. State 1 is immediately before the collision, at a time that we can take as approximately zero, as the point just before the platform of the clowns, now at rest, is about to be crossed:  \n\n\\[ \ny(t) = 0, \\quad t = t_c(1) \\rightarrow 0\n\\]\n\nwhere \\(y(t) \\) and \\( \\dot{y(t)} \\) are the vertical position of the acrobat and clowns respectively. Additionally, just before grabbing the clowns the acrobat has already let go the trapeze.\n\nThe collision lasts a time $t_{coll}$. During this time interval, the acrobat grabs the clowns.  \n\nState 2 immediately after the collision, at a time \\(t_c(2) \\), occurs when the acrobat and clowns now rise together with an initial speed $\\dot{y}_{ac2} = \\dot{y}_{cl2} \\equiv V_0 \\) ).\n\nBecause the collision has a fixed impulse delivered by the created gravitational force during the collision caused by the collision time $t_{coll}\\), the impulse is to be delivered in a cycle of linear impulses during which this force is applied. As such, the momentum change of the system can be simplified including the mass that becomes attached. We note that this is an approximation since, in actual fact, we would have an elastic collision where the mass of the acrobat would be varying. The total impulse on the acrobat is therefore the added weight force of both. However, by assuming continuous collision time we could average the total momentum change of the system in this interval.\n\nAs described earlier, the acrobat clowns ignore the initial transient motion. Before state 1, the acrobat is undergoing projectile motion. From one-dimensional kinematics, the vertical component of the position and velocity of\n",
    "the acrobat is given by\n\n\\[\nx_a(t) = v_{a0} t + x_{a0} = v_{a0} t\n\\]\n\n(2)\n\n\\[\ny_a(t) = h - \\frac{1}{2} g t_a^2 = h - \\frac{1}{2} g t^2\n\\]\n\n(3)\n\nrespectively, where $y_{a0} = 0$ and $v_{a0}$ are the initial position and velocity of the acrobat as given in the problem. At $t = t_c$, the acrobat is at height $y_a(t_c) = x_o$ when\n\n\\[\nt_c = \\sqrt{\\frac{2}{g} (h - x_0)} = \\sqrt{\\frac{2h}{g} - \\frac{2x_0}{g}}\n\\]\n\n(4)\nApplying the quadratic formula, we find\n\n\\[\ng t_a^2 - 2 h + 2 x_0 = 0 \\Rightarrow t_a = \\sqrt{\\frac{2h}{g} - \\frac{2x_0}{g}} = \\sqrt{\\frac{2(h - x_0)}{g}}\n\\]\n\n(5)\nSubstituting this into equation (3) evaluated at $t_c$, allows us to find the velocity immediately before the collision\n\n\\[\nv_a(t_c) = v_{a0} = \\alpha \\vec{v}_c = \\beta v_{a0} = x\n\\]\n\n(6)\n\nwhere we have taken the plane $x$ axis to be the height downward with positive y positive.\n\nBetween states 1 and 2, we know the two empirical work-systems to move as observed\n\n\\[\nf_{sys}(t_{2^-})= f_{flex} - E_{pot1} - (F_{cm} + E_{rk1}) + \\Delta E_{int}\n\\]\n\n(7)\n\nImmediately before the collision, the reconstru369 algorithm systems is only due to the acrobat \\[v_{cm1}(t) = F- (\\vec{r}_b(t) \\alpha_1 - E_{rk1}) + v_r t+ m_f g R_0 \\sin\\bigg(\\sqrt{2gh (h)}\\bigg)+ v_R(t_2')\nin which we solve for\n\n\\[\nF_{sys}(t_{2^-}) = [(r_b - \\Delta E_{rk1})\nE_{rk1}}(t) = m_{a}\\alpha_{a} v_{a0}^2 - mgr_bg/(h - x_{0})]\n\\]\n\n(8)\n\n\\v_{a0})+E_{int}(t_{c})\n\nDeriving momentum equations for right after the collision, the acrobat and equations (9) allowing us to find the velocity of the acrobat immediately after the collision\n\n\\[\nv_{a0}(t_c^+) = \\sqrt{2gh} \\Rightarrow F_{int}(t) + m_a(\\vec{r}_1) =v)\n\n(10)\n\n\\[\nv_{a0} = \\frac{M_1 - M_{2^-}}{M_{a}} t_{c^-}\n\nAfter state 2, the acrobat will now experience projectile motion. Thus, their position and velocity is given by\n\n\\[\nv_{a0'}(t_{\\vec{a}) = a_{Rcso(t_{\\beta_t}(t_{\\alpha_{ah}}r(E')\n\\]\n\n\\[\nv_{y}(t) = M_f + v_s r_a cso x\n\\]\n\n(11)\n\nrespectively, where we have defined their artificial center of mass as $x_a = x_a^c$, $\\vec{v}_\\alpha v_a0'(t_c)$ are the velocities and accelerations respectively at midpoint $R_a + _\\alpha(t)$ assumed negligible (by equivalence principles), similarly we have now expressed vertical approximations\n\n\\[\nR_{sys}(t_{cm2}) + R_{R}(v_{\\vec{a_1}) (h- cso-l)+a\\tfrac (v_{\\alpha}+ x_{\\alpha)}_c}{t_{\\alpha_{1}- x_{\\alpha}\n\nThe height of the landing given\n\n\\[\nR_{sys}(t_c^+) = g+ \\sqrt{\\left((2_{{\\alpha}}(E_c(t_M 2\\left^{3}_{2})x_{\\alpha_2-R})\\right)\\\\) = \\sqrt +ve_{ff}} )g E_{int} =0_\n\\]\n\n(12)\n\n(13)\n\n\\[\nt_{ac}(t) = c_0(\\vec {t} R(t)_t]),\n\n\\]\n\n\\[\nv_{a1}(t_{2}^\\leq +v_h(0))\n\\]",
    "To find the maximum height of their trajectory (at a time $t = t_h$) we first use equation (14) to find the elapsed time $t = t_f - t_0$ at which the velocity is zero\n\n\\[\n0 = u_k \\frac{m(t_f)}{m} - g \\int_0^{t_f} \\frac{m(t')}{m} dt'\n\\]\n\n\\[\n= u_k \\frac{m_0 + \\lambda t_f}{m_0} - g \\left( t_f + \\frac{\\lambda}{m_0} \\frac{t_f^2}{2} \\right)\n\\]\n\nWe can substitute this into equation (3) to find that the maximum height is\n\n\\[\nh_f = \\frac{u_k^2}{2g} \\left( \\frac{m_0}{m_k} \\right)^2 (n+g)^2 = \\frac{1}{2} \\left( u_k \\frac{m_0}{m_k + \\lambda t_f} \\right)^2 + h_0\n\\]\n\n2. Falling raindrop\n\n1. We start by choosing a coordinate system such that the y direction points downwards in the direction of acceleration due to gravity. Note that the problem is one dimensional. Next, as an abstract time leaf, we consider the mass balance of the raindrop just before time $t$ and after a small time interval $\\Delta t$ superimposed. Raindrop of velocity $v_y$ (positive in the downward direction) has mass $m_f$ (m as shown). As time proceeds, we observe that the raindrop gobbles a differential ${\\Delta m}$ of water. We will assume differential has been added. I now have this raindrop of mass ${\\Delta m + m}$, differentiating $y_{f + \\Delta t}$ the same velocity after a small time increment $\\Delta t$. This is sketched in the two diagrams drawn below at time $t$ and time $t + \\Delta t$ respectively.\n\nFrom the momentum diagrams, we use our conservation of mass in the system to see that\n\n\\[\nm_f = \\Delta m, m_f + \\Delta m_f\n\\]\n\n\\[\nv_f + \\Delta v_m\n\\]\n\nThough this will tell us about how to solve the problem. Additionally, we see that the total momentum of the system at time $t$\n\nwhile at time $t + \\Delta t$\n\n\\[\nF_{ext} = ( \\Delta m + m ) ( v_y + \\Delta t ) =  ( m_v v_v + m )\n\\]\n\nConservation of momentum and Newton's second law implies\n\n\\[\nm \\frac{\\Delta v_v \\Delta t}{ v_y \\Delta_t } + g \\Delta t  = v_y ( v_y \\Delta t )\n\\]",
    "If we draw a free body diagram, we see that the only external force on the system is gravity $mg$. Using this and substituting equations (2) and (3) into equation (4), we find\n\n\\[ \nm \\frac{d \\vec{v}}{dt} = (\\dot{m}' \\Delta t) \\vec{v}_1 + m \\vec{a} \\Delta t + \\dot{m} \\Delta t \\vec{v}_2 \n\\]\n\nwhich simplifies to\n\n\\[ \nm \\frac{d \\vec{v}}{dt} = \\dot{m} (\\vec{v}_2 - \\vec{v}_1) + m \\vec{a} \\Delta t \n\\]\n\nin the $i$ direction. We can neglect the final term $m \\Delta t$ in this expression as it is product of two differential elements. Since the differential elements are infinitesimally small, their product will be infinitesimally smaller. We use the substitutions from the ladder and use differential element (i.e., $\\Delta L = v_1 \\Delta t$). Thus, equation (5) becomes\n\n\\[ \nm \\frac{d v}{dt} = \\dot{m} (v_2 - v_1) \n\\]\n\nConverting the limits back into derivatives, we find the differential equation\n\n\\[ \nm \\frac{dv}{dt} = \\dot{m} (v_2 - v_1)\n\\]\n\nAs an aside, note that this is equivalent to the standard (generalized) Newton's second law applied to the falling ladder. Taking the full derivative of both $LHS$ and $RHS$ of Newton's law, we find\n\n\\[ \nm \\frac{d \\vec{v}}{dt} = \\dot{m} \\vec{v}_\\text{rocket} + mv\\frac{dv}{dt} + vm \\dot{\\vec{v}}\n\\]\n\nBy the chain rule, $a = \\frac{dv}{dt}$, making equation (7) equivalent Newton's second law. We can integrate the differential equation (7) by the alternate kinetic force to more easily obtain the general form. To solve, note that $\\vec{F}_\\text{ext}$ must be constant in our case so acceleration is coming from the external force $\\vec{F}_\\text{ext}$. From here, we have the same terms as from the problem statement on the given equation (5),\n\n\\[ \n\\int \\frac{dv}{\\vec{F}_\\text{ext}} = \\int \\frac{dt}{m} \n\\]\n\nwhich fortunately cancels all the factors of $m (\\vec{F}_\\text{ext} \\cdot \\vec{x} = \\dot{\\vec{v}}) = m a$\n\n\\[ \nv_f - v_k = \\frac{\\Delta t \\vec{a}}{m}\n\\]\n\nThis is the differential equation we were seeking so $v_f$ becomes\n\n\\[ \nv_f = \\frac{\\vec{a}t - v_k}{m}\n\\]\n\n2. To calculate the initial velocity $v_0$ of the raindrop, we could solve the differential equation and then integrates for the falling mass $m$, bring the mass to one side, and differentiates with the initial time $t_0$. However, a much simpler solution would be to use $\\vec{v}$ from the above form as determined from equation (6). As previously noted, we want to keep it in the same coordinate system to write equation (8) in vector notation, so it wouldn't be wrong to integrate. Thus, we can take this set to write $v_0$ and find that\n\n\\[ \nv_0 = \\sqrt{\\frac{\\beta^2}{\\alpha}}\n\\]\n\nand that\n\n\\[ \nv= \\sqrt{\\frac{2 \\beta t}{\\alpha}}\n\\]\n\n3. Falling chain\n\nThis problem is challenging. We start by taking a coordinate system with $i$ pointing downwards in the chain. With $i$ then defined as the positive x-axis, the tension is proportional to downward velocity $v$, the tension acts to gravitational force, which we are reliable to consider solving in terms of small dx of length $dx$. Thus, we will consider the differential element that starts at distance $x$ above the scale",
    "and define its initial position as the origin of our coordinate system. You can't push with a chain, so there is no force from the ground that is transmitted up the chain to the differential element at its top. In other words, each differential element of the chain is free to fall and governed by projectile motion until it makes contact with the scale. Thus, given our coordinate system and the fact that the chain starts at rest, the position and velocity of the differential element follow\n\n\\[\nR(t) = \\frac{1}{2}g t^2 \\quad (1)\n\\]\n\n\\[\nv(t) = v(L) + g t  \\quad (2)\n\\]\n\nrespectively. Using equation (1), we can calculate the time \\( t \\) just before the differential element of interest makes contact with the scale to be\n\n\\[\nt = \\sqrt{\\frac{2D}{g}} \\quad (3)\n\\]\n\nSubstituting this into equation (2), we see that the element is traveling with a velocity of\n\n\\[\nv(D) = v(\\sqrt{\\frac{2D}{g}}) = g \\sqrt{\\frac{2D}{g}} \\quad (4)\n\\]\n\njust before it impacts the scale.\n\nA very short time later, \\( \\Delta t \\), the differential element is at the top of the scale. We can calculate the corresponding text element height, as being infinitesimally a the differential element. First, we get the mass that was over the scale that is at \\( t = 0 \\), and we can reorient after differential mass piece elements falling. We write by \\( D + \\Delta D \\). Refers to equation set , upto the point , by scaling factor.\n\n\\[\n\\frac{\\Delta m}{\\Delta t} , \\quad \\Delta m = M \\quad (5)\n\\]\n\nWe can represent a system composed of arrives for differential element by\n\n\\[\nF =\\frac{d}{dt}(Mv) \\quad (6)\n\\]\n\nwhen the \\(M(t = 0) = M_0\\). Using equation (6), but this simplified\n\n\\[\n\\Delta = \\frac{d}{t} (Mv) \\quad; \\quad (Mv) = \\sqrt{\\frac{2D}{g}} \\quad\n\\]\n\nwhile at \\( \\Delta t \\) the total momentum is\n\n\\[\n\\frac{d}{t} (\\Delta) = \\Delta v(t) = 0) = \\quad (8)\n\\]\n\nWe can thus write down the generalized form of Newton's second law and use the limit form of the time derivative according to\n\n\\[\n\\sum H_i (Ma) g = -d \\frac{dl}{dt} - \\frac{d(Dv)}{dt} (l)_{\\frac{dl}{dt}} \\quad (9)\n\\]\n\n\\[\nd_d M_0 \\frac{dg}{ dt}\n\\]",
    "The external force will be only the normal force from the scale on the differential element\n\\[ \nF_{scale} = F_{chain} \n\\]\n(9)\nwhich is what we are interested in calculating to determine the reading on the scale. Think since the gravitational force can be integrated through the impulse approximations, the time like interval $\\Delta t$ is so\nSubstituting equations (6), (7) and (8) into equation (8), we find\n\\[ \nF_{scale}\n= \\left( \\lim_{\\Delta t \\to 0}\\left( \\sqrt{\\frac{3}{2}}\\sqrt{3} \\frac{M}{L}a \\Delta t \\times 2\\int^\\infty_1 dy\\sqrt{y}e^{-y} \\right) = \\left( \\sqrt{\\frac{3}{2}} \\frac{M}{L}(Lim_{\\Delta t \\to 0})a \\Delta t (\\sqrt{3} \\times 2 \\sqrt{1})\n\\right) \n\\]\n(10)\nin the $y$ direction. Converting the limit back into a derivative gives\n\\[ \nF_{scale}\n= \\frac{3 M}{L}\\cdot \\frac{a}{2}\\Delta t \n\\]\n(11)\nUsing the definition of velocity as the derivative of position in $\\frac{dy}{dt} = a$ and making use of equation (3) we write the magnitude of velocity as the derivative of position in $\\frac{dy}{dt} = \\sqrt{\\frac{3}{2}}a$, and making use of equation (3) in the $y$-integral\n\\[ \nF_{scale}\n= \\sqrt{\\frac{M}{L}} a \\int^\\infty_0 dy e^{\\beta \\left(\\frac{dy}{dt} \\times a\\right)} \n\\]\nIf we now draw a free body diagram for the scale at time $T + \\delta t$, we would see that there are two forces from the chain that act on the scale opposite the weight of the chain. We see these influences from the side of the chain that has left the scale opposing the mass $dm = M/J$. Evidently, $F_{scale}$ is much greater than the weight component as the weight of the chain is greatest at the point of action on the boundary. \n\nTo determine the \u201cdynamical\u201d contribution to $F_{scale}$ we therefore need to integrate over this $y$ value from a moving pivot $a \\times t$ times the chain in a volume. In this context, the integral must be carried across all $y$ same throughout the whole apart from those that create the chain\u2019s weight, $mg$. \n\nThis is our final answer for reading on the scale:\n\\[ \nF_{scale} = 2M_ag \n\\]\nNote that when, $Ma = M/2$, we reach the correct mass per equation (3) to replace $D$ in equation (13) with a new:\n\\[ \nF_{scale} = 3M \\sqrt{g}\n\\]\nThus, the net force on the scale from the impulse of the chain less the weight of the chain will lead the scale to be compared to the to-sched return equations (13) becomes:\n\\[ \nF_{scale} = \\frac{3M_a}{L} \n\\]\nIn other words, the mass rate is $M \\sqrt{3}$, and in concluding, since the chain exerts a force, after the entire chain has come to rest, the reading the weight of the chain by the weight of the chain is ,\n\\[ \nScale \\ reading = Mg \n\\]\n(14)\n\n4. Homework: Rocket with changing mass\n\nWe start by choosing a coordinate system such that $y = 0$ is the ground and the $y$ direction points upwards in the opposite direction of the acceleration due to gravity. Note that the problem is one-dimensional. Next, ",
    "at an arbitrary time $t$, we consider a system that is composed of the rocket (including all the fuel it currently contains), which we will describe as having a total instantaneous mass $m$. The instantaneous speed of the rocket is $v$, so one can imagine drawing an imaginary box around the rocket, which fully separates itself from all of its nearby rocket debris or ejected gases. At a later time $t + \\delta t$, the rocket has a total instantaneous mass of $(m - \\delta m)$, where we say that $\\delta m > 0$, and is now traveling at a different instantaneous speed of $(v + \\delta v)$. Note that $\\delta m$ refers to the elements that were ejected from the rocket (fuel, debris, etc.) and so represents a positive loss in the direction (we conventionally ascribe to the fact that the rocket has lost this element). Ejected rocket elements are assumed to have the same velocity $v + u$, where $u$ is defined as the negative exhaust speed, meaning that we are ignoring how the magnitude of $u$ varies due to contributions of varying relative speeds ($u \\neq u(t)$) over time. Now, let $\\hat{z}$ be a unit normal vector, with the specific choice of $\\hat{z}$ chosen to point along the exiting velocity of the rocket. This means that it has a unit length of $v - u$ in the inertial laboratory frame. We show these two different diagrams at times\n\n$t$ at \n$\\quad $ time $t+\\delta t$\n\nBelow:\n\n\\begin{centering}\ntime $t$ \\quad \\quad \\quad \\quad time $t+\\delta t$\\\\\n$\\quad m, v$ \\quad \\quad \\quad \\quad \\quad m-\\delta m,\\quad v +\\delta v\\\\\n$\\quad \\quad $+ $\\delta m, $ $v-u$\\\\\n\\end{centering}\n\nFrom the momentum diagram, we can use conservation of mass in the system to see that \n$$\\delta m + \\Delta m_s = \\Delta m_s$$\nAdditionally, we see that the total momentum of the system at time $t$is\n$$F_{sys}(t) = m_s \\cdot v_s \\; (1)$$\nwhile at time $t + \\delta t$ it is\n$$F_{sys}(t + \\delta t) = (m-\\delta m) \\cdot (v + \\delta v) + \\Delta m_s (v-u)\\;( 2)$$\nTaking the difference of (1) and (2), we can write the momentum principle as :\n$$F \\delta t = m_s v_s - (m - \\delta m) (v + \\delta v) - \\Delta m_s (v - u) $$ \nWe use some algebra to find a suitable combined fraction\n$$F \\delta t = m_s v_s - m v + \\delta m v - m \\delta v - \\delta m \\delta v - \\Delta m_s (v- u) $$\n$$= \\delta m v + m \\delta v + \\Delta m_s (u - v) - \\delta m \\delta v$$\n\nNext, we substitute in Newton's Second Law and use the limit form for $\\delta$ quantities \n$$=m \\left (\\frac{d(v)}{dt}\\right) \\delta t + (u v)\\left(\\frac{d(m)}{dt}\\right) \\delta v \\delta = 0 \\; (3)$$\nIf we draw a free body diagram of a time interval segment, we find that the system is moving purely in the $z$ direction. We can neglect the term $\\delta m \\delta v$ in this expression, as it is a product of two differential elements of the higher-order infinitesimals. This leaves us with a gross quantity (4).\n$$F \\delta t = m_s v_s - \\Delta m_s (v-u) $$ \nNext, differentiate with respect to time, (2) Newton's second Law to solve for integration of equation (5)\n$$m \\frac {dv}{dt} +(v-u) \\frac {dm}{dt} = 0 (5) $$\nThe general solution is the integral form\n$$\\int \\frac{d}{v - u} = \\int \\frac{d m}{m}$$\n$$m = M_0 e^{-\\frac{v - u_0}{u}} (6) $$\n",
    "Converting the limits back into derivatives, we find the differential equation\n\\[\nm_r \\frac{dv_3}{dt} = -m_r \\frac{dm_r}{dt} v_r\n\\tag{7}\n\\]\nor\n\\[\nv_3 = -v_r \\ln m_r + C,\n\\tag{8}\n\\]\nNext, as in problem 2, we start the time $t = 0$ at the end of the change of the mass of the rocket (including the fuel it contains). We know that, at time $t=0$, $m_r$ is the total mass of the rocket and load (i.e. $M + D$). Additionally, it ejects fuel at a constant rate of $D$. Then the total mass of the rocket as a function of time is\n\\[\nm_r = M + Dt,\n\\tag{9}\n\\]\nwhich gives\n\\[\n\\frac{dm_r}{dt} = D,\n\\]\nafter taking a derivative. Substituting this result into equation (7) gives the differential equation\n\\[\n\\frac{dv_3}{dt} = -v_r \\frac{dM + DT}{dt} \\cdot D.\n\\tag{10}\n\\]\nRearranging and using equation (3) gives\n\\[\n\\frac{dv_3}{dt} = v_r \\frac{D}{M + Dt}.\n\\tag{11}\n\\]\nThe problem statement similarly asks us to find the speed and altitude of the rocket. Thus, we will integrate equations (11) to find the velocity $v_1$. It is the integral\n\\[\nv_1 = \\int_0^t \\frac{D}{M + Dt} dt.\n\\tag{12}\n\\]\nThe first integral is straightforward, but to accomplish it we must perform a change of variables. We choose the integral by letting $u = M + Dt$, then we have\n\\[\n\\frac{du}{dt} = D\n\\]\nand rewrite\n\\[\ny_1 = \\frac{D}{u} \\int_t dt.\n\\tag{13}\n\\]\nSolving equation (13) for $t = (M/D-t)$ and taking a derivative gives $du = D \\cdot dt$. Substituting this, taking the integral gives\n\\[\n\\int \\frac{D}{u} du = D \\left( \\ln u\u00a0 | M)^r \\right) + C.\n\\tag{14}\n\\]\nContinuing to solve gives $v_1 (t) = v_r \\ln (M - Dr) + C$. Substituting in $t = 0$ gives $C = -D$. Then\n\\[\nv_1 = v_r (M + Dr) + C.\n\\tag{15}\n\\]\nSubstituting this into $v_2 = v_r \\ln \\sqrt{M} + D$ gives the integral of\n\\[\ny_2 = \\int \\frac{D}{M + Dt} dt = D.\n\\tag{16}\n\\]\nTo find the altitude of the rocket, we integrate once more in time to find the position\n\\[\ny(t) = \\int_0^t D - \\left( x_t (t) - \\frac{M - Dr}{Ln} \\right) dt.\n\\tag{17}\n\\]\n",
    "Again the first integral is straightforward, but the second is challenging. We can use the second hint in the\nproblem statement if we first perform a change of variables to\n\\[\ny = z - \\frac{D}{k}\n\\]\n(19)\nThis allows us to write equation (18) as\n\\[\n-z + \\frac{D}{k} = - \\frac{M}{k} \\int_{0}^{t} \\left[ z - \\frac{D}{k} \\right]^{n-1} dz\n\\]\n(20)\nSolving equations (19) for $z = y + \\frac{D}{k}$, (17) and (18) taking a derivative gives $\\frac{dy}{dt} = - \\frac{M}{D} y$. Substituting this back, the integral can be written and using equation (19) gives\n\\[\ny(t) = \\left[ \\int_{0}^{t} \\left( - \\frac{M}{D} \\right) \\left( y + \\frac{D}{k} \\right)^{n-1} dt \\right]^{1/(2-n)} = \\left( \\frac{D}{k} \\right)^{(n-1)/(2-n)} y(t)\n\\]\n\\[\nM \\left( \\frac{D}{k} \\right) \\left[ \\frac{D}{k} - \\frac{nM}{D} \\right]^{1/(2-n)}\n\\]\n(21)\n\\[\ny(t) = \\left\\lgroup \\frac{M}{D} \\left\\lgroup \\frac{D}{k} \\right\\rgroup \\left[ \\frac{D}{k} - \\frac{nM}{D} \\right]^{1/(2-n)} - \\frac{DM}{kn(t)} \\right\\rgroup\n\\]\n(22)\nwhere $C_1$ is an integration constant. It can be determined by using the initial condition that the rocket starts on the ground at $t = t_0 = 0$, so $y(t_0) = 0$ gives\n\\[\nC_1 \\left\\lgroup \\frac{M}{D} \\left( \\frac{D}{k} \\right) - \\frac{nM}{D} (1 - n) \\right\\rgroup\n\\]\n\\[\ny_{0} = \\frac{1}{z_1} = \\frac{z_2}{M} - \\frac{M}{D} \\left\\lgroup \\frac{D}{k} \\right\\rgroup\n\\]\n(23)\nSubstituting this into equations (22) and (23) gives\n\\[\ny(t) = \\left[ \\frac{M}{D} \\left( \\frac{D}{k} \\right) \\left[ \\frac{D}{k} - \\frac{nM}{D} + M \\right] \\right]\n\\]\n\\[\ny_0 \\left[ \\left( \\frac{M}{D} - \\frac{D}{k} + \\left[ M \\right] \\left\\lgroup \\frac{D}{k} - \\frac{nM}{D} + \\frac{M^2}{D} \\left( \\frac{M}{k} \\right) \\right\\rgroup \\right\\lgroup \\frac{D}{k} \\left( 1 - \\frac{nM}{D} + \\frac{M}{k} \\right) \\right\\lgroup \\frac{D}{y(t)} \\left( 1 - n \\right) \\right\\rgroup\n\\]\n\\[\n= - \\left( 1 - n \\right) M \\left( y(t) \\left( 1 + \\frac{y(t)}{y} x \\right) \\right\\rgroup\n\\]\n(24)\nEquations (17) and (20) are the speed and altitude as a function of time. To solve the problem, we are instructed to now evaluate these for a case when they reach their final mass, so that the constants $y(t)$ are evaluated for the time it takes to reach $y = 1$, so that $y(t)$ for this will be completely used up in the time $t_f = M_f/M_0 = 0.5 M$. Substituting into this equation (17) and (18) gives\n\\[\ny_2 \\left( \\frac{y}{2} \\right) = \\left[ \\left( \\frac{M}{D} - \\frac{D}{y(t)} + \\frac{M^2}{D} y(t) \\right) - 1 \\right\\rgroup\n\\]\n\\[\n-t_1 (t_0) \\frac{y(t)}{y_2} \\left( 1 - \\frac{nM}{D} + \\frac{D}{k} \\left[ 1 - t_2 \\right] \\right)\n\\]\n(25)\n\\[\nt(t_0) = \\left\\lgroup \\left( \\frac{y}{2} \\right) \\left( M - \\frac{D}{k} \\right) - \\left( \\frac{y(t)}{D} \\left( 1 - n \\right) \\right)\n\\]\n(26)\nPlacing in the numerical values from the problem statement (and noting that $t_0 = 1000 kg$)\n$t_f = 10n $ and\n\\[\n\\left( y(t) = 321 km (27) \\\\\nv(t) = 1601 km\n\\]",
    "Solutions to Problem Set 4\nCircular motion\nPHYS-101 (en)\n\n1. Circular motion: banked turn\n\nIn this part, the static frictions can be considered to be $\\mu_s F_N = 0$ because the coefficient of static friction is so small. As we are studying circular motions, the forces can be divided into centripetal directions as in the figure below, where the unit vector $\\mathbf{i}$ points in the outward radial direction, $\\mathbf{j}$ points into the page around the curve, and $\\mathbf{k}$ points upwards. The free body diagram is the one for the car as also shown.\n\nGiven the free body diagram and the form of the centripetal acceleration $\\mathbf{a} = (-v^2 / R)\\mathbf{j}$ for circular motion, Newton's second law $\\sum F = ma$ in the $\\mathbf{i}$ direction is \n\\[ N \\sin \\theta = -\\frac{mv^2}{R}. \\]\n\nWe can tell that the trigonometric function in this equation is the sine rather than cosine by imagining the direction of $N$. The $N$ direction has a component of $N \\cos \\theta$ in the k direction and $N \\sin \\theta \\cos \\phi$, i.e., the component of $\\mathbf{i}$, about its radial motion. So, to it describes Newton's second law:\n\\[ \\sum F = ma \\]\nbecause there is a centripetal acceleration along the plane as in the given car. The acceleration in the $\\mathbf{i}$ direction is zero, so \n\\[ a = 0. \\]\nThus, the component of Newton's second law in the $\\mathbf{k}$ direction is\n\\[ N \\cos \\theta - mg = 0. \\]\nDividing these equations to eliminate $N$ yields\n\\[ \\frac{N \\cos \\theta - mg}{N \\cos \\theta} = 0 \\]\nwhich we can solve for the speed $v$ that is necessary to maintain circular motion. We find\n\\[ v = \\sqrt{g R \\tan \\theta}. \\]",
    "2. We now consider the problem with a non-zero coefficient of static friction, \u03bc_s. In this part, the speed of the car v = v_s is so slow that it just barely doesn't slip down the bank. The static friction force must point up the incline as we know that it is preventing the car from slipping down. The free body diagram of the car is shown in the figure below, from which we see that Newton's second law is\n\n$$N \\cos \\theta + f_s \\sin \\theta = mg,$$\n$$N \\sin \\theta - f_s \\cos \\theta = \\frac{mv^2}{R}$$\n\nin the $\\hat{j}$ direction and\nin the $\\hat{i}$ direction.\n\nWhen $v = v_s$, the car still isn\u2019t slipping so the acceleration in the $\\hat{j}$ direction, $a_j = 0$, is still zero, but the static friction has its maximum magnitude of $f_s = \u03bc_s N$. Thus, Newton\u2019s second law becomes \n\n$$N \\cos \\theta + f_s \\sin \\theta = mg,$$\n$$N \\sin \\theta - f_s \\cos \\theta = \\frac{mv^2}{R},$$\n\nand\n$$N (\\cos \\theta + \u03bc_s \\sin \\theta) = mg,$$\n$$N (\\sin \\theta - \u03bc_s \\cos \\theta) = \\frac{mv_s^2}{R}$$\n\nDividing these equations to eliminate N yields\n\n$$\\frac{\\sin \\theta - \u03bc_s \\cos \\theta}{\\cos \\theta + \u03bc_s \\sin \\theta} = \\frac{v_s^2}{Rg}$$\n$$v_s^2 = Rg \\frac{\\sin \\theta - \u03bc_s \\cos \\theta}{\\cos \\theta + \u03bc_s \\sin \\theta}.$$\n\nwhich can then be solved for the minimum speed necessary to avoid sliding down the unbanked turn as\n\n$$v_s = \\sqrt{Rg \\frac{\\sin \\theta - \u03bc_s \\cos \\theta}{\\cos \\theta + \u03bc_s \\sin \\theta}}.$$\n\nThe limiting cases of this result can be checked. In the limit of $\u03bc_s = 0$, $v_s = \\sqrt{Rg \\sin \\theta / \\cos \\theta}$, which is consistent with the result for the non-friction case. In the limit of a flat track, $\\theta = 0$, giving $v_s = 0$ because nothing will prevent the car from sliding down. \n\n3. We saw earlier that for the car on the turn at the maximum speed up the bank that it is about slipping up we find the upper limit of the speed at which it is possible for the car to travel around a curve of radius R. We now find the lower limit speed along the same lines as problem (2), which can be achieved by treating $f_s$ as acting down the slope. \n\nIn the $\\hat{j}$ direction and\nin the $\\hat{i}$ direction we have \n\n$$N \\cos \\theta - f_s^j \\sin \\theta = mg$$\n$$N \\sin \\theta + f_s^j \\cos \\theta = \\frac{mv^2}{R}.$$",
    "in the $x$ direction. When $v = v_{\\text{max}}$, the static friction has its maximum value of $f_s = \\mu_s N$, so Newton's second law becomes \n\n\\[ -N \\sin \\theta = m \\frac{v_{\\text{max}}^2}{R} \\]\n\n\\[ N \\cos \\theta - \\mu_s N \\cos \\theta = mg \\]\n\nDividing these two equations to eliminate $N$ yields \n\n\\[ \\tan \\theta = \\frac{v_{\\text{max}}^2}{R g} \\]\n\\[ v_{\\text{max}} = \\sqrt{R g \\tan \\theta} \\]\n\nwhich can then be solved for the maximum speed $v_{\\text{max}}$ around sliding up the embanked turn \n\n\\[ v_{\\text{max}} = \\sqrt{\\frac{R g(\\sin \\theta + \\mu_s \\cos \\theta)}{\\cos \\theta-\\mu_s \\sin \\theta}} \\]\n\nThis solution is identical to that of part 2, except the right side in front of $v_t$ is opposite.\n\nThe figure below shows a plot of $(v^2 / (R g))$ versus $\\mu$ where $\\theta$ is a fixed angle, and thus represents the value of $(v^2 / (Rg))_{\\text{max}}$ for staying on the circular path. We see that there are shaded regions that the car will slide up and out, and other non-shaded regions the car will slide down and in.\n\n\\[ \\frac{v^2}{(Rg)} \\]\n\\[ \\mu \\]\n\n4. The analysis is the same as in part 3, but the magnitude of the static friction is less than its maximum value. We must solve for the proper elimination using the other two equations. Thus, Newton's laws for the forces parallel to the surface plate (2) and to eliminate N and solve for $f_s$. Now we multiply (1) by cos and (2) by sin to find \n\n\\[ -N \\sin \\theta = m \\frac{v_{\\text{max}}^2}{R} \\]\n\n\\[ N \\cos \\theta - f_s N \\cos \\theta = mg \\]",
    "and\n\\[ N \\cos \\theta - F_{n} \\sin \\theta = \\frac{m v^{2}}{R} - mg \\sin \\theta = 0. \\]\n\nAdding these two equations yields,\n\\[ -F_{n} (\\cos \\theta + \\sin \\theta) = mg \\sin \\theta - \\frac{m v^{2}}{R \\cos \\theta} . \\]\n\nUsing the identity $ \\cos \\theta + \\sin \\theta = \\sqrt{2} \\sin \\left( \\theta + \\frac{\\pi}{4} \\right) $, we get\n\\[ f_{s_{max}} = \\frac{mg}{\\sin (0.607 + \\theta)} \\]\nfor the magnitude of the static friction force.\n\n2. Swinging ball\n\n1. The free body diagram for the ball is shown below. Note the $\\theta$ component of the tension arises because Sally\u2019s hand does not stay in the center of the circle, so the tension does not pull perfectly in the radial direction. From the free body diagram, we see that Newton\u2019s second law $\\sum F = ma$ in the radial direction is\n\\[ T_{s} \\cos \\theta - mg \\cos \\theta = m \\left( - \\frac{v^{2}}{R+ x} \\right) = m \\left( - \\frac{v^{2}}{L} \\right) \\]\nwhere we have used the fact that the centripetal acceleration needed for circular motion is $ a = - \\frac{v^{2}}{R + x} $ Rearranging, we find the tension to be:\n\\[ T_{s} - mg = - \\frac{m v^{2}}{L \\cos \\theta} \\]\n\nBecause the angular frequency is related to period via $ \\omega = \\frac{2 \\pi}{T} $, the magnitude of the radial component of the tension is then $T_r = $\n\\[ T_{r} = \\frac{4 m \\pi^{2} R}{T^{2}} - mg \\]\n\n2. The second part then asks for the magnitude of the radial component of the tension in the string. T must be a greater than zero for all points in the circular motion. If $T_r = 0$, the ball will have no inward force acting on it and will travel. The means that, using the radial term from part 1, circular motion will not be maintained if\n\\[ T_{r} (t) = \\frac{m v^{2}}{R} < \\frac{mg}{\\cos \\theta} . \\]\n",
    "3. Spiral motion of a point mass\n\n1. We start by representing the system in polar coordinates, as shown below. Note that, until we solve the equations of motion, we don\u2019t know the time evolution of radius, $r$, or $\\theta$. So, we draw $r$ with an arbitrary direction (and include both radial and azimuthal components for a general $\\mathbf{F}$ possible).\n\n2. We are given that the forces acting on the mass are \n\n\\[\nF_r = -br - mkr \\quad \\text{where} \\quad 0 < kA < 1.\n\\]\n\nTo calculate motion forces, we will apply Newton\u2019s second law:\n\n\\[\nF = ma.\n\\]\n\nWe need first rewrite $\\mathbf{F}$, $\\mathbf{a}$, and $\\ddot{\\mathbf{r}}$ in polar coordinate. The position vector in polar coordinates is\n\n\\[\n\\mathbf{r} = r\\hat{r},\n\\]\n\nwhere $\\hat{r}$ is the unit radius vector in the direction of $r$ and $\\hat{\\theta}$ is the direction tangent to the rotation. We know that $r$ is always positive. Then the spring-like force can be written as:\n\n\\[\n\\mathbf{F} = (F_r)\\hat{r} + (F_\\theta)\\hat{\\theta}.\n\\]\n\nThe problem statements give the forms for the velocity and acceleration vectors, which we can substitute to write the friction-type force as\n\n\\[\nF = m\\left(\\ddot{r} - r\\dot{\\theta}^2\\right)\\hat{r} + m\\left(2\\dot{r}\\dot{\\theta} + r\\ddot{\\theta}\\right)\\hat{\\theta}\\right).\n\\]\n\nLastly, the problem statement tells us that the acceleration vectors are:\n\n\\[\n\\ddot{r} = -kr -br\\\\\n\\ddot{\\theta} = \\left(-2 \\dfrac{\\dot{r}}{\\dot{\\theta}}\\right) + k\\cos^{2}\\theta.\n\\]",
    "in polar coordinates.\n\nSubstituting these three equations into Newton\u2019s second law gives the equations of motion\n\n\\[ \\ddot{r} - r \\dot{\\theta}^2 + \\left(\\frac{dr}{dt}\\right)^2 = 0 \\]\n\nin the $r$ direction and\n\n\\[ r \\ddot{\\theta} + 2 \\dot{r} \\dot{\\theta} = 0 \\]\n\nin the $\\theta$ direction. Since $\\dot{\\theta} = 0$ and $\\ddot{\\theta} = 0$, the equation in the $\\theta$ direction simplifies to\n\n\\[ \\ddot{r} = \\frac{\\lambda}{m} \\]\n\n3. Given the solution form in the problem statement, we can immediately solve the $\\ddot{r}$ equation and use the initial conditions $\\dot{r} = 0, r = C$ to find\n\n\\[ r(t) = \\frac{\\lambda t^2}{2m} + C \\]\n\nWe can then rearrange the $r$ equation to isolate $r(t)$ according to\n\n\\[ r(t) = \\sqrt{\\frac{\\lambda t^2}{m}} \\]\n\nSubstituting our solution for $r(t)$, we find\n\n\\[ r(t) = \\sqrt{\\frac{\\lambda t^2}{m}} \\]\n\nwhere we note that this is a real number as the problem statement tells us that $\\lambda > 0$. Integrating this speed with respect to time and using the initial condition $\\dot{r} = 0$, we now determine by integration constant, $C$,\n\n\\[ r(t) = \\fu{C_1}{m} - \\frac{\\lambda t^2}{2m} \\]\n\nSolving this for $r$ and substituting it into our expression for $\\dot{\\theta}$ gives\n\n\\[ \\dot{\\theta} = \\sqrt{\\frac{m}{r}} \\]\n\nFrom the problem statement we know that the velocity in polar coordinates is\n\n\\[ v = \\sqrt{r^2\\dot{\\theta}^2 + (\\dot{r})^2} \\]\n\nSubstituting our solutions from above, we find\n\n\\[ v = \\sqrt{\\left(\\sqrt{\\frac{\\lambda t^2}{m}}\\right)^2} \\]\n\nThe speed is just the square of this, which simplifies to\n\n\\[ v(t) = \\sqrt{\\frac{\\lambda}{m}}\\]\n\n4. Circular motion of the earth",
    "1. The rotational period of the earth is given by:\n\\[ T_e = 23 \\, (\\text{h}) \\, \\, 56 \\, (\\text{min}) \\, \\, 4 \\, (\\text{s}) = (56 \\, \\text{min}) (60 \\, \\text{s/min}) + 4 \\, \\text{s} = 86164 \\, \\text{s}, \\]\nwhich is less than 24 h. Therefore? hours can see solar day (from noon to noon), while the above period of time is for the stars. Let's say that the rotational period at EPFL (longitude $\\lambda$ and latitude $\\varphi$) is noted as $T$. Also note that we write into the equations the period at EPFL, whose symbol (rotational period) we noted as $T$ for symmetry with the letter $T_p$. The rotational speed at EPFL given by $\\omega = \\frac{2 \\pi}{T}$. Consider that EPFL at the same time rotates with the Earth.\n\n2. Considering the angle between EPFL and the axis of rotation as shown in the figure. Since the latitude \\[ \\lambda = 45 \\degree 00' 00'' . \\] use trigonometry to determine the expression,\n\\[ \\sin \\theta = (\\sin 45 \\degree ) = \\frac{\\sqrt{2}}{2} \\]\nand\n\\[ \\sin \\theta = (\\sin 45 \\degree) = \\frac{1}{\\sqrt{2}} = \\cos \\theta. \\]\nusing trigonometric identities. The angle $\\theta$ sometimes called the \"colatitude\". The radius of the orbit of a person at EPFL is:\n\\[ R_n = R \\cdot \\cos \\lambda = (6.38 \\times 10^6)m \\cdot \\sin(45 \\degree) = 4.367 \\times 10^6 \\, \\text{m}. \\]\n\n3. Because the circular motion is uniform, during one period of rotation T the person travels a distance\n\\[ d = 2 \\pi R_n = 2 \\pi R \\cos \\lambda. \\]\n\nat a constant speed $v$, where $d = 2 \\pi v = 2 \\pi R_n \\frac{1}{T} = v(\\omega)$. Solving for the speed gives:\n\n\\[ v = \\frac{2 \\pi R_n}{T_e}. \\]\n\nThus a person at EPFL has a velocity of\n\\[ v = \\frac{2 \\pi (4.38 \\times 10^{11} m)}{86164s} = 319 \\, \\text{ms}^{-1}, \\]\n\nwhere $\\hat{e}$ is the unit vector pointing east.",
    "2. The centripetal acceleration is given by\n$$a_c = \\frac{(290 \\, \\text{m/s})^2}{(3.39 \\times 10^4 \\, \\text{m})} = 2.83 \\times 10^{-2} \\, \\text{m/s}^2$$\nwhere $-\\hat{r}$ is the unit vector pointing towards the closest point on the axis of rotation (not towards the center of the earth).\n\n5. Homework: Pushing a book against a wall\n\n1. Let $m$, $N$, and $\\mu_s$ be as defined as in the problem and let $F_P$ represent the friction force. Additionally, let $F_I$ be the force of your push on the book. We will define our coordinate system such that $x$ is perpendicular to the wall, $y$ parallel to the wall. The magnitudes of the forces and angles are shown in the free body diagrams for the two cases shown below. Note that the static friction force opposes the net acceleration of the book that is about to occur, as shown below.\n\nIn the $x$ direction, Using these two equations to eliminate the normal force $N$ and solve for $F_P$ gives\n$$F_P = \\frac{mg}{\\cos \\theta}$$\n\nNow let us consider the case where the book is almost about to slip. The frictional force points down and has its maximum value, meaning it has a norm given by\n$$F_P = \\mu_s N = \\mu_s \\frac{mg}{\\cos \\theta}$$\n\nApplying Newton\u2019s second law and requiring equilibrium ($\\Sigma F = 0$) gives\n$$N = \\frac{F_I}{\\sin \\theta}$$",
    "in the r direction and \n\n\\[-m_{s}N+\\frac{m_{s}v^{2}}{r}\\cos\\theta - mg = 0\\]\n\nin the \\(\\theta\\) direction. Using these two equations to eliminate the normal force N and solve for \\(F_{s}\\) gives the solution of\n\n\\[ F_{s} = \\cos\\theta m_{s}g\\;-\\frac{m_{s}v^{2}}{r}\\sin\\theta.\\]\n\n3. To find the force for which the friction is zero, we can take the limit that \\(F_{s} = 0\\) in either of the solutions to part 2. This gives\n\n\\[ \\tan\\theta = \\frac{v^{2}}{rg} \\]\n\nAlternatively, we could draw the free body diagrams without the friction force and solve the resulting components of Newton\u2019s second law, which give the same answer. \nWhen \\(\\theta = 0\\), \\(F_{s} = mg \\sin(0) = 0\\) and when \\(\\theta = 90^{\\circ}\\), \\(F_{s} = - mg \\cos(90^{\\circ}) = 0\\), which are both consistent with our intuition.",
    "Solutions to Problem Set 5  \nApplications of Newton\u2019s second law  \nPHYS-101  \n\n1. Painter on a platform\n\nWe will explain two different, equally valid approaches to this question.\nThe first method is to draw two separate free-body diagrams, one for the painter and one for the platform (both shown below). Since the pulleys are both massless and frictionless, the tension throughout each rope is $T$. The weights of the painter and of the platform are $mg$ and $m_2g$, respectively. Also, the net external force for each object appears opposite upwards from the paper. Newton's second law applied to the painter gives $T + N - mg = ma$, where we have denoted the magnitude of the acceleration of the painter and platform by $a$. By Newton's third law, the upward normal force on the painter, the magnitude of which we denote as $N$, by Newton\u2019s third law there is an equal normal force in opposite direction on the platform itself, which we label as $N'$. Note that $N = N'$.\n\nLet $a_p$ denote the magnitude of the acceleration of the painter and let $a_p$ denote the magnitude of the acceleration of the platform. Since the painter is attached to one rope, they both have the same acceleration upwards.\n\nThus, we know:\n\\[ a = a_2 \\]\n\nwhere we have denoted the common acceleration by $a$.      \nApplying Newton\u2019s second law to the painter in the vertical direction gives:\n\\[ T + N - mg = m a \\]\n\nwhile applying Newton\u2019s second law to the platform in the vertical direction gives:\n\\[ 2T - N' - m_2 g = m_2 a \\]\n\nBy adding equations (2) and (3), we can eliminate the normal force entirely and find:\n\\[ \nU p = (m + m_2) a = (m + m_2) g \n\\]\n\n",
    "Solving for the acceleration gives the final answer:\n\n\\[ a = \\frac{-(F - m_2 g)}{m_1 + m_2} \\]\n\nA second method to find the same solution is to treat the painter and platform as a single system as we have done. This will be your sight list. In this case, the internal forces are gone but we see the two applied forces (tension and body weight forces again). The other external player does not apply extra force like the boy imagined with the lever. The gravitational force will pull downwards and that leads to the total mass of the system ($m_1 + m_2$):\n\n\\[ F - (m_1 + m_2) g \\]\n\nApplying Newton's second law to the combined painter-platform system in the vertical direction gives\n\n\\[ F - (m_1 + m_2) g = (m_1 + m_2) a \\]\n\nThis can be solved for the acceleration, yielding the same result as given in equation (5).\n\n2. Blocks and pulleys\n\na. In this part, the vertical acceleration of block 3 is $a_3 = g$. It is a given quantity. Let $T$ be the tension in the rope, which is constant throughout the length (the rope is massless and the pulleys are massless and frictionless). The free body diagram on block 3 is as shown below.\n\n\\[ 2T = m_3 g \\]\n\nDefining a coordinate system such that $y$ points up (antiparallel to gravity), we find Newton's second law becomes:\n\n\\[ T = \\frac{m_3 g}{2} \\]\n\nfor block 3. We can write this in the final form as\n\n\\[ T = \\frac{m_3 g}{2} \\]",
    "The problem tells us that the tension T exceeds the static friction force in both cases (i.e. blocki and the pulley). Or, in sirope, we can mobilize the static friction force which requires us to know\nthe terminal force. Thus, we define the free body diagrams for both blocks (shown below), where \\( f_1 \\) and \\( f_2 \\) represent the friction force on each. We know that the friction force (where it is static or kinetic)\nwill point outwards in block 1 and will tend to pull block \\(1\\) and toward the pulley.\n\nSince blocks 1 and 2 do not accelerate vertically, Newton's second law in the vertical direction gives\n\n\\[\nN_1 - m_1 g = 0 \\quad \\text{or} \\quad N_1 = m_1 g\n\\]\n\n\\noindent and \n\n\\[\nN_2 - m_2 g = 0 \\quad \\text{or} \\quad N_2 = m_2 g \n\\]\n\n\\noindent for blocks 1 and 2 respectively. Substituting this into the relations for the static friction force gives \n\n\\[\nf_1 \\leq \\mu_s N_1 = \\mu_s m_1 g \n\\] \n\n\\[\nf_2 \\leq \\mu_s N_2 = \\mu_s m_2 g \n\\]\n\nwhere we have used the same coefficient of static friction in both equations as the two blocks (and the table) are composed of the same materials. Therefore, we have now represent the equations for the friction \nforces on each block in terms of known quantities. Next we move back to the free body diagram, applying Newton's laws again. Since block 1 does not accelerate horizontally, the horizontal component of Newton's second law gives\n\n\\[\nT - f_1 = 0 \\quad \\text{or} \\quad T = f_1 \\leq \\mu_s m_1 g \n\\]\n\n\\noindent where \\( f_1 \\) represents the friction force tending to impede the horizontal tensile force. For the friction force acting vertically, equation (2) can be applied vertically on the pulley, where the static friction force holding the block on the table is\n\n\\[\n2 T - f_2 = 0 \\quad \\text{or} \\quad 2 T = f_2 \\leq \\mu_s m_1 g \n\\] \n\nNote we have used that a pull on block 3 would only accelerate a pull leading to free fall. Any upwards force exerted on the block 3 cannot exceed its weight. Ow equation (4) combined with the previous observation, we see that \n\n\\[\n2 \\mu_s m_1 g = f_2 = \\mu_s m_2 g \\quad \\text{or} \\quad m_1 = \\frac{1}{2}m_2. \n\\]\n\nTo keep the explanation simple, we explain here that substituting block 2 into equation (6) leads to a terminal identical to that obtained at equation (8). Therefore the total force due to friction. This is a simple chain equation where we include block 1, block 2 and the horizontal tension. Given this relationship, we can then go back and solve for the total force:\n\n\\[\n\\begin{aligned} \n{} & 2 m_1 g - T = 0  & \\quad \\text{(9)} \\\\\n& \\Rightarrow 2 m_1 g - \\mu_s m_2 g = 0  & \\quad \\text{(10)} \n\\end{aligned} \n\\]\n\n\\noindent in the horizontal direction, while it is\n\n\\[\nN_1 - m_3 g = 0\n\\]",
    "in the vertical direction (since there is no vertical acceleration). Therefore, as in part 1, we find\n\\[ N_{1} = m_{1}g \\tag{11} \\]\n\nno the kinetic friction force is\n\\[ f = \\mu_{k}N_{1} = \\mu_{k}m_{1}g \\tag{12} \\]\n\nSubstituting this into equation (9) gives\n\\[ T - \\mu_{k}m_{1}g = m_{1}a_{3} \\tag{13} \\]\n\nNext, we consider block 2. Given its free body diagram (shown above), Newton's second law is\n\nin the horizontal direction, while it is\n\\[ f_{3} - N_{3} = 0 \\text{ } \\rightarrow \\text{ } N_{3} = f_{3} \\tag{14} \\]\n\nin the vertical direction (since there is no vertical acceleration). Therefore, as in part 1, we find\n\\[ N_{2} = m_{2}g \\tag{15} \\]\n\nno the kinetic friction force is \n\\[ f = \\mu_{k}N_{2} = \\mu_{k}m_{2}g \\tag{16} \\]\n\nSubstituting this into equation (10) gives\n\\[ T - \\mu_{k}m_{2}g = m_{2}a_{3} \\tag{17} \\]\n\nLastly, we turn to block 3. Given its free body diagram (shown above), Newton's second law is:\n\nin the vertical direction and\n\\[ T - f_{3} = m_{3}a_{3} \\tag{18} \\]\n\nin the horizontal direction\n\\[ T - N_{3} = 0 \\text{ } \\rightarrow \\text{ } T = f_{3} \\tag{19} \\]\n\nWe can collect the equation for the three blocks (equations (13), (17), and (19)):\n\\[ T - \\mu_{k}m_{1}g = m_{1}a_{3} \\tag{20} \\]\n\\[ T - \\mu_{k}m_{2}g = m_{2}a_{3} \\tag{21} \\]\n\\[ T = m_{3}a_{3} \\tag{22} \\]",
    "However, we are still missing one equation (since what we have four unknowns and only three equations). This is the constraint condition. More specifically, studying the geometry of the system, if one block moves by a length $x$, the other one will also block by a length $x$, but in opposite coordination (one length in the opposite orientation of the other blocks). In brief if I call it x amount. Repeatedly, treating it as a similar propagation, the block does not extend. They are a rigid non-extensible system but moving back-and-forth via the same answer. We denote it x after a single coordination system as for all the blocks and plane placed as $x_1$, respectively.  The whole idea is to treat the blocks/planes systems to define $a_1$, where all equal distances (length changes) define the end of it for each ply fibers, with an equal length to define it as zero changes. That length is each of the blocks moves. Finally, we can add up all the sections\u2019 x upto the constraints equal length of the rope as:\n\\[x_1 + x_2 + x_3 + x_4\\) = L_{total}\\]\nNow that we have accounted for the fact that none of the positions (\\(x_1, x_2, x_3\\)) will be repeating, with zero deflections $a_1$ and 1. If we differentiate equation 23, we end up with the equation:\n\\[a_1 + a_2 + a_3 + a_4 = 0 \\tag{24}\\]\n\nNote that all of the unknown distances, like $\\{x_1, x_2, x_3 \\}$ have disappeared as they don\u2019t change (24). Easier. Establish equal treatment on ropes in the blocks with ratios  ${\\mu_2}/{\\mu_1}$, then blocks have equal distance with solving for the mass $m_1 a_1 = m_2 a_2 + k(a_i, a_j)$ and the tension $T_i$. (24) We take equation (20) to find \n\\[\\frac{mg}{cos (\\theta)} = T \\tag{25}\\]\n\nequation (21) to find\n\\[f_k =qT  + \\frac {mg}{cos (\\theta)} \\tag{26}\\]\n\nand equation (22) to find\n\\[T_i  = \\frac{m_2g}{cos (\\theta)}   \\tag{27}\\]\n\nSubstituting those three values into equation (24) gives\n\\[ T_i + f + \\bigg (\\frac {m_2 g}{cos (\\theta)} \\bigg ) = T_i\\bigg( {\\mu_2}/{\\mu_1}\\bigg ) - (m) \\bigg (\\frac{T \\gamma^2}{r} + \\bigg ({m_2 g r} / {\\theta^2} \\bigg ) + r \\bigg (\\frac{\\gamma_2 (k)}{\\gamma_1(k)} \\bigg ) \\tag{28}\\]\n\nWe rearrange this equation to find that the tension is\n\\[T = \\frac{2q}{b} + \\bigg ( (m_2 g  + m_1g - f  +(kT)}  \\bigg  (\\frac{m_1^2 }{x}+ \\big (\\frac {1 -\\cos^2 (\\theta) cos ( \\theta))} \\bigg )  \\tag{29}\\]\n\nWe can now substitute our solution for the tension to find the accelerations. Equation (25) becomes\n\\[{T_i}  \\sum_{i} x_i = m_i \\sum_{k} { \\frac { a_{2(i+j)} }{ \\cos(\\theta )}}  \\tag{26}\\]\n\n\\[{T_i}= { {a_k}} \\sum_{i}  t_j \\bigg  (\\frac {q\\sum x_i } + q_1^ x( 1 + \\cos_ n (\\theta) )\\bigg) \\tag{31}\\]\n\\[{x_i} = \\sum_{i} x \\frac{q_j} =2k_0 {cos \\theta}",
    "and equation (27) becomes\n\\[\na_{m_y} = \\frac {g(l_1 + l_2)}{l_2} \\tag{32}\n\\]\n\nNote that the signs of these accelerations depend on the coordinate system used and so may be different in your solution. However, the tension given by equation (29) in a physical force and is independent of the choice of coordinates.\n\n3. Tension in massive rotating rope\n\nGiven the circular motion of this problem, it is most convenient for us to use cylindrical coordinates. Since the rope has mass, the tension at a typical point does not equal the tension at the ends of the string. It is an integral that must be evaluated. We weight an extremely small piece of the rope. It is divided radially by $\\Delta r$. The ends of the piece are at coordinates $r$ and $r + \\Delta r$ in the radial direction, which each have a mass of\n\\[\n\\Delta m = \\lambda_0 \\Delta r \\tag{1}\n\\]\n\nWe start by considering a piece of the rope that is located an arbitrary distance $r$ from the shaft, whose forces are as shown in above. The net radial force $\\sum F_r$ on the piece is equal to the difference between the tension at either end,\n\\[\n\\sum F_r = T(r + \\Delta r) - T(r) = \\Delta T\n\\]\n\nwhich is simply the integral limits across the piece $\\Delta r$. Given that there is no outwards motion, circular motion rules are used to represent a centrifugal acceleration of $a = - r \\dot{\\theta}^2$. Thus, the radial component of Newton's second law in this scenario is,\n\\[\n\\Delta T = ((\\lambda_0 \\Delta r) - ) r \\dot{\\theta}^2 \\tag{2}\n\\]\n\nCombining equations (1), (2), and (3)\n\\[\n\\Delta T = - \\lambda_0 r \\dot{\\theta}^2 \\Delta r \\tag{4}\n\\]\n\nDividing by $\\Delta r$, we see that:\n\\[\n\\frac {\\Delta T}{\\Delta r} = - \\lambda_0 r \\dot{\\theta}^2 \\tag{5}\n\\]",
    "In the limit that very small pieces become infinitesimally small (i.e. $\\Delta \\phi \\rightarrow 0$), equation (5) becomes the differential equation\n\n$$\n\\frac{dT}{d\\phi} + \\mu T = \\rho g r,\n\\tag{6}\n$$\n\nFrom this, we see immediately that the tension decreases with increasing radius as $r$, $\\mu$, $T$, and $\\rho$ all are positive quantities. We can solve this differential equation by direct integration of both sides of the equation, avoiding the\n\n$$\n\\int \\left( \\frac{dT}{d\\phi} + \\mu T \\right) d\\phi = \\int \\rho g r d\\phi.\n\\tag{7}\n$$\n\nThis simplifies to\n\n$$\nT(\\phi) = \\frac{\\rho g r}{\\mu} + C e^{-\\mu \\phi},\n\\tag{8}\n$$\n\nwhere $C$ is an integration constant that we still need to determine. To find it, we need to determine the value of the tension at some location, $T_0$. To do so, we need to pick the tail (fly end) at some arbitrary value of the polar angle, say $\\phi_0$ (there does not seem to be any other good choices here), so that we set Newton\u2019s second law in the radial direction to be (by changing from $\\phi$ to $\\frac{T}{r}$),\n\n$$\nT(\\phi_0) = T_0 = \\frac{\\rho g r}{\\mu} + C e^{-\\mu \\phi_0}.\n\\tag{9}\n$$\n\nEvaluating equation (8) at $\\phi = \\phi_0$ and equating (9) we obtain\n\n$$\nT_0 = \\frac{\\rho g r}{\\mu} + C e^{-\\mu \\phi_0}\n\\tag{10}\n$$\n\nSubstituting this into equation (8), we arrive at the final answer\n\n$$\nT(\\phi) = \\frac{\\rho g r}{\\mu} e^{-\\mu (\\phi - \\phi_0)} + T_0 e^{-\\mu (\\phi - \\phi_0)} = \\frac{\\rho g r}{\\mu}\n\\left[\n1 -e^{-\\mu (\\phi - \\phi_0)}\n\\right]\n+ T_0 e^{-\\mu (\\phi - \\phi_0)}.\n\\tag{11}\n$$\n\n4. Racing around a turn\n\nThe second application of this problem is understanding and determining the physical reasoning of what occurs to the basic physical laws when a car is racing around a turn. For simplicity let us assume that both the radius of the car\u2019s trajectory and its speed is constant (with no skidding). The first thing we need to know is what coordinate system is best used for describing the problem. We clearly cannot use Cartesian coordinates timeliness as we did when the car was driving along a city street or on a straight stretch of highway as\n\n$ \\mathbf{y} = r, \\mathbf{F_t} = m\\mathbf{a_t} $\n\nSince the car is following a nearly circular motion, we can define a fixed cylindrical coordinate system $r$ with $\\mathbf{r}$ being the radial direction and the polar $t$, or azimuthal $\\phi$, which both are based on the position at $P$. In a circular motion, this means that\n\n$ r = r_0, \\phi$ simple eq. (12)\n\nIf one fixes the cylindrical coordinate system at point P, we see that $v_r = \\frac{dr}{dt} = 0$ and $\\mathbf{v_{\\phi}} = \\frac{r d \\phi}{dt} \\mathbf{e_{\\phi}} = v \\mathbf{e_{\\phi}}$ since the radius is constant around the turn; the physicist defines a cylindrical coordinate increasing $\\mathbf{e_{\\phi}}$ in the tangential direction. This requires\n\n$ \\mathbf{a_{\\phi}} = 0, \\mathbf{a}_\\mathbf{\\phi} = \\dot{ \\mathbf{v}_ \\mathbf{\\phi}} = \\frac{d}{dt}(\\mathbf{v_{\\phi}})$\n\nEvaluating,\n\n$\\mathbf{a_{\\phi}} = \\mathbf{a_{\\phi}} = - \\frac{d \\phi}{dt}^2 r - \\mathbf{e_{\\phi}}$ (eqs. 13a) & 13b\n\nHere $\\mathbf{v}^2 = \\mathbf{a_{\\phi}} + \\mathbf{a} = v_0 \\mathbf{a_{\\phi}}$, so\n\n$\\mathbf{a} = -\\mathbf{e_{\\phi}}^2 (2 + 2v + \\mathbf{e_{\\phi}}) = (1 - v v \\cos v_2) = v_0$, $\\mathbf{e_{\\phi}} = \\frac{d}{dt} \\phi \\approx eq eq, -$\\mathbf{e_{\\phi}}$$\n\nwhere cylindrical coordinate velocities are defined by the change in $\\mathbf{e_{\\phi}}$ in time by its own inertial reference frame $\\mathbf{F_{\\mathbf{\\phi}}}$. $0 = \\cos \\phi,$ assessing standing as the extent of the car along the car according to $\\phi$.",
    "The inertial reference frame, your friend's car is moving with uniform circular motion of radius $R_1$, so the sum of the forces acting on them must be a centripetal force\n\n\\[\n\\vec{F}_{\\text{fr}} = -m \\omega^2 R_1 \\hat{R}_{1}.\n\\]\n\nIn practice this would be provided by the static friction force between the car tires and the road. Note that all the frames that appear are inertial, because we are only considering the forces acting on the cars, so there is no need to assume any non-inertial pseudo-forces.\nWhat we have to express next is friction forces. The first is the translational acceleration friction force. The quantity $\\vec{a}_r$ is the acceleration of the reference frame $\\mathcal{R}$, as seen from the fixed frame $\\mathcal{R}_0$. Since both frames are inertial, you do not need to assume any non-inertial pseudo-forces acting on $\\mathcal{R}$.\n\n\\[\n\\vec{a}_{\\mathcal{R}} = \\frac{d \\vec{V}}{d t}= -R_1 \\omega^2 \\hat{R}_{1}.\n\\]\n\nNote that the angular speed and radius are that of your car (i.e. you) and $\\mathcal{R})$.\n\nNow, in the reference frame of your car, $\\mathcal{R}$, includes the velocity of your friend\u2019s car as seen by you is given by\n\n\\[\n\\vec{v}_{r} =- R_1 \\omega \\hat{\\theta}_{1},\n\\]\n\nN. Intuitively, since both cars are traveling with the same angular velocity $\\omega$, from your prespective your friend\u2019s car angular velocity will include both the relative speed and your own angular speed:\n\n\\[\n\\vec{V} + \\vec{v}_r = R_1 \\omega \\hat{e}_{\\theta_{0}} - R_1 \\omega \\hat{e}_{\\theta_{0}},\n\\]\n\nThen, taking a derivative in time justifies our intuitive argument that\n\n\\[\n\\frac{d}{dt} ( \\vec{V} + \\vec{v}_r )=0.\n\\]\n\nNow, in the frame of the perspective of you see your friend\u2019s car, where we are determining how $ \\vec{v}_{f(\\mathcal{R})}$ changes from the perspective of the inertial frame of your friend\u2019s car traveling in $\\mathcal{R} $. Since $\\mathcal{R}$ is not inertial, there will be additional pseudo-forces acting in that frame that will account for forces that came as result of tendency to maintain an straight inertial motion. Let me consider the transversal friction force. The car is in $\\mathcal{R}_{\\mathcal{R}}$. The terms are as in the Euler force expansion for instantaneous acceleration reference frame $\\vec{a}_{r}$. Since both frame are inertial, $\\mathcal{R}$ can be the same for both frames. So, let me change the reference system to see the motion from an easier inertial reference frame. Do a smooth ride and look very fast at $\\mathcal{R}_{0}$ when you are going in the negative $R_{1}$. The ground fixed frame is inertial; therefore, do not see any pseudo-force as inertial one. This gives us that ground acceleration seen by your car frame is\n\n\\[\n\\vec{a}_{R}= -\\frac{d}{d t}( R_{1} \\omega^2 \\vec{\\hat{e}}_{\\hat{R}_{0}}),\n\\]\n\nUsing the fact that $\\vec{a}_{\\mathcal{R}}=- \\omega R_1 \\hat{\\theta_0}$ is centripetal of your car (the cross products allows one to simplify) arrives to the following useful relation for $\\mathcal{R}$ :\n\n\\[\n\\vec{a}_{\\mathcal{R}} = -\\omega^2 R_{0}-R_{1} d (\\omega^2 \\hat{R_0} )-R_1 \\frac{d}{d t}(\\omega \\hat{R_0}).\n\\]\n\nThat can be right-hand-side as $\\vec{a}_r$ coordinate-system, now make the right hand side to what we parametrized as $( R_{1} \\omega \\hat{R}_{0}$):\n\n\\[\n1+d (\\omega \\hat{e}_{R})=-(R_{1} \\omega \\hat{e}_{\\theta_{0}}) \\hat{\\theta}_{0}.\n\\]\n\nThus, from your perspective in the non-inertial reference frame $\\mathcal{R}$ does not see your own force acting on this own non-inertial pseudo-force $\\mathcal{R}$, thus continue the translation acceleration does not change friction static acceleration force $( m i a_{d t})$. The centripetal and tangencial components in non-inertial-see-R-frame fake force will change perspective no assume object static balance from Euler, and the centrifugal friction force.",
    "Since the net force is zero, Newton's first or second laws tell us that the acceleration, $a$, is zero. Newton's first and second laws (but not the third!) are valid in non-inertial reference frames, as long as all of the fictitious forces are properly included. Alternatively, $\\dot{v} = 0$ can be seen by taking the time derivative of equation (5).",
    "5. Homework: Angular speed of coins\n\nWe choose to use a cylindrical coordinate system (because of the circular motion). For this part of the problem, it is most convenient to analyze the rotating (or co-rotating) frame. The top coin is a rigid surface to which both coins are bound by static friction. At the cylindrical coordinate origin, place the center of the turntable. When measured in the inertial frame the speed $v_0$ of the top coin is equal to the speed of the turntable (with $v_0 = R \\omega$). Let us suppose that the coins are small point masses of mass $m$ and have the same radial coordinate $R$. Forces of static friction restrain the coins (both on the top) as well as the forces due to each other. Notice from the diagram below that there is a vertical direction (normal force $N_{ab}$ between the coins). Also both static friction forces act tangent to the radius of the turntable face (which is why $f_{bt}$, the bottom coin to top). Here the top coin is denoted by the letter $a$ subscript, the bottom coin by $b$, and the turntable by $\\gamma$.\n\nTo determine the magnitude of the radial force exerted by the turntable on the bottom coin $f_{b \\gamma}$, we will sum Newton's second law on the static $R$ point (or radial) for the top coin. Applying Newton's second law in this direction, we get:\n\n$$f_{a \\gamma} - f_{ba} = m_a a_{rad}$$\n\nNow we apply Newton's second law in the radial direction to the top coin. Here the position vector can be written $\\hat{e_r}R$. The point mass makes the top coin accelerate inward also with $v_0 = R \\omega$.\n\nThe radial component of Newton's second law for the bottom is:\n\n$$f_{b \\gamma} + f_{ba} = m_b a_{rad}$$\n\nwhere we used that the centrifugal acceleration $a_{rad} = - R \\omega^2$. The radial component of Newton's second law on top coin gives us:\n\n$$f_{a \\gamma} - f_{ba} = -m_a R \\omega^2$$\n\nSince the static friction forces of the bottom coin on the top coin, and the static friction force of turntable on top coin (we supply as an extra math exercise). Newton's third law requires that the static friction magnitudes required for $f_{ba}$:\n\n$$f_{a \\gamma} - m_a R \\omega^2 = f_{ba} = N_{ab} \\mu_s$$\n\nSubstituting into Eq. (3):\n\n$$f_{b \\gamma} = m_b R \\omega^2$$",
    "Then substituting equation (3) into equation (1) yields\n\n$$mR\\theta'' = f_s - mR\\alpha \\tag{4}$$\n\nSince the turntable exerts a rearward radial force on the bottom coin with a magnitude of\n\n$$f_{sr} = \\mu N_{2 \\rightarrow 1}, \\tag{5}$$\n\nComparing with equation (2), we see that the static friction force on the bottom coin from the turntable is twice as large as the static friction force on the top coin.\n\nTo summarize, we know that it is because the friction force on the bottom coin holds it in place relative to the turntable. With the assumption of static friction, we have applied Newton\u2019s second law for the two coins in the form of a free body diagram of each one. Applying Newton\u2019s second law for the top coin in the vertical direction yields\n\n$$N_{2 \\rightarrow 1} - W_t = 0, \\tag{6}$$\n\nwhere the upward force of the object (this is in fact an accelerating surface) is $N_{2 \\rightarrow 1}$. Thus, we can calculate that total force of the bottom coin on the top coin is\n\n$$N_{2 \\rightarrow 1} = W_t. \\tag{7}$$\n\nSince their free form acts to minimize pain at the upward force of the top coin on the bottom coin, we know that the magnitude follows $N_{1 \\rightarrow c} = \\mu W_t$.\n\nSubstituting the static approximation into Newton\u2019s first law, we see that the top coin will slip if the force on it exceeds\n\n$$\\mu N_{2 \\rightarrow 1} = \\mu W_t = m_t g. \\tag{8}$$\n\nWe then substitute this result into equation (4) to yield\n\n$$mR\\theta'' = \\mu m_t g - mR\\alpha. \\tag{9}$$\n\nSo that if $\\theta$ is the maximum angular speed for which the top coin does not slip. Rearranging this, we have\n\n$$\\theta_{max} = \\sqrt{\\frac{g}{R}}. \\tag{10}$$\n\nNewton\u2019s second law for the bottom coin in the r direction is\n\n$$N_{b - N} - 2m_tg = m_tg. \\tag{11}$$\n\nNotice again from Newton\u2019s first law that $N_{b - N} = mg = mg$, we can rearrange this equation so that the force between the turntable and the bottom coin is $\\mu N_2 = m_tg$.\n\n$$\\mu N_{2 \\rightarrow b} = m_tg. \\tag{12}$$\n\nUsing this and the form of the static friction force, we see that the bottom coin will slip if the turntable rotates such that the turntable exerts\n\n$$\\theta_{max} = \\sqrt{\\frac{2mg}{mR}}. \\tag{13}$$\n\nFrom equation (5), we can determine that the maximum angular speed after which the bottom slip will only self.\n\n$$2\\theta_{top} = 2m\\sqrt{\\frac{g}{R}}. \\tag{14}$$",
    "Rearranging we find that\n\n\\[ \\omega_{\\text {top}} = \\sqrt{\\frac{\\mu g}{R}} \\tag{15} \\]\n\nComparing equations (10) and (15) and remembering that $\\mu < \\mu_s$, we see that\n\n\\[ \\omega_{\\text {top}} < \\omega_s = \\omega_{\\text {bottom}} \\tag{16} \\]\n\nThus, as we increase the angular velocity of the turntable, the top coin will slip first.\n\n",
    "1. Center of mass of a rod \n\nWe start by choosing a coordinate system with the rod aligned along the x-axis and the origin located at the left end of the rod. Next, we\u2019ll decompose the rod into differential elements of mass $\u0394m$ and consider the element located a distance x from the origin. Since the rod is uniform, the linear mass density is\n\n\\[ \\lambda = \\frac{m}{L} \\]\n\nas well as\n\n\\[ \u0394m = \u03bb\u0394x = \\frac{m}{L}\u0394x \\]\n\nwhere $L$ is the length of the differential element. Taking the limit of equation (2) as $\u0394x \u2192 0$ gives\n\n\\[ dm = \\frac{m}{L}dx \\]\n\nThe center of mass for a continuous system is defined by\n\n\\[ x_{C.M.} = \\frac{1}{m} \u222bx\\,dm \\]\n\nwhere $\u222b (\\ldots) dm$ indicates an integral over the entire mass distribution of the whole object. We can perform a change of variable from $dm$ to $dx$ to obtain\n\n\\[ x_{C.M.} = \\frac{1}{m} \u222b_{0}^{L} x \\left(\\frac{m}{L}dx\\right) \\]\n\nwhere $\u222b_{0}^{L}$ indicates an integral over the entire length of the object. Then substituting equation (4) into equation (5) gives\n\n\\[ x_{C.M.} = \\frac{m}{L} \\times \\frac{1}{m} \u222b_{0}^{L} x\\,dx = \\frac{1}{L} \\left[\\frac{x^{2}}{2}\\right]_{0}^{L} = \\frac{L}{2} - 0 = \\frac{L}{2} \\]\n\nAs expected from the symmetry of a uniform rod, the center of mass is exactly in the middle.",
    "We will use the same coordinate system as in part 1 and again consider a differential mass element $\\lambda$ located a distance $x$ from the origin. The linear mass density \\(\\lambda(x)\\) is no longer uniform along the length of the rod, so \\(\\lambda = M/L\\) at every point. However, the definition of the local linear mass density is \n\n$$\\lambda (x) = \\frac{dm}{dx} = \\frac{M}{L},$$\n\nwhere \\(dx\\) is the length of the differential element. Since \\(dx\\) is the definition of the derivative, we have \n\n$$dm = \\frac{\\lambda_0 x^2}{L^3} dx.$$\n\n(8)\n\nSubstituting the functional form of the density into the problem statement gives,\n\n$$\\lambda (x) = \\frac{\\lambda_0 x^2}{L^3}.$$\n\n(9)\n\nThe total mass is found by summing the mass element dm over the entire length of the rod according to\n\n$$M = \\int_0^L dm,$$\n\n(10)\n\nPerforming a change of variables to position and substituting equation (9) gives\n\n$$M = \\int_0^L \\frac{\\lambda_0 x^2}{L^3} dx = \\frac{\\lambda_0}{L^3} \\int_0^L x^2 dx = \\left[ \\frac{\\lambda_0}{L^3} \\frac{x^3}{3} \\right]_0^L = \\frac{\\lambda_0}{L^3} \\cdot \\frac{L^3}{3} = \\frac{\\lambda_0}{3}.$$ \n\n(11)\n\nSince the problem gives us both M and \\(\\lambda_0\\), we can solve this equation as,\n\n$$\\lambda_0 = 3M.$$\n\n(12)\n\nThe definition of the center of mass is,\n\n$$x_{CM} = \\frac{1}{M} \\int_0^L x dm = \\frac{1}{M} \\int_0^L x \\cdot \\frac{3Mx^2}{L^3} dx,$$\n\n(13)\n\nWe can calculate the numerator in a similar way to how we found M,\n\n$$x_{CM} = \\frac{3M}{ML^3} \\int_0^L x^3 dx = \\frac{3}{L^3} \\frac{x^4}{4} \\bigg\\rvert_0^L = \\frac{3L^4}{4L^3} = \\frac{3L}{4}.$$\n\n(14)\n\nwhere we have used equation (12). Using equation (13), this can simplify further to find,\n\n$$x_{CM} = \\frac{3}{4}L.$$\n\n(15)\n\n2. Center of mass of the particle-rod system\nIn this problem, we are tasked with finding the center of mass dynamics of the system that includes both particle and rod. The result will help describe the position of the system. Using superscripts r and p to denote the position of the rod,\n$$r_{CM} = \\frac{x_{CM,(rod)} m_{rod} +x_{CM,(pcl)} M_{pcl}}{M_{rod} + M_{pcl}}, r_{CM} = \\frac{ \\frac{3}{4}Lm + L \\cdot M}{m + M}, r_{CM} = \\frac{3ML + 4ML}{4(m+M)}, r_{CM} = \\frac{7ml}{4(m+M)},$$\n\n(16)\n\n$$ x''_{CM, (rod)} =  x'_{CM, (pcl)} = 0, \u2234 x''_{CM} = \\frac{\\Sigma_{i} F_{ext,i}}{M_{tot}} = \\sum_{i} F_{ext,i}{m + M},$$ \nand the acceleration of the center of mass becomes,\n\n$$x_{CM, system} = \\frac{7L}{4}. $$\n\n\n(17)\n",
    "represents, where $\\vec{r}(t)$ is the position of the center of mass of the rod, $\\vec{r}_1(t)$ is the position of the particle, $\\vec{v}(t)$ is the velocity of the center of mass of the rod, $\\vec{v}_1(t)$ is the velocity of the particle. As the rod exerts no acceleration, since its net external force is the system is zero we know that the center of mass acceleration is zero\n\n\\[\n\\frac{d}{dt}\\vec{v}(t) = 0 \\quad \\Rightarrow \\quad \\vec{v}(t) = \\vec{v}_0\n\\]\n\nThus, due to the relationship between position, velocity, and acceleration, we know that the center of mass velocity is constant and equal to its initial value,\n\n\\[\n\\vec{v}(t) = \\vec{v}_0 \\ldots (1)\n\\]\n\n\nAs a result, for systems with constant mass, having a constant center of mass velocity  $(\\vec{v}_0(t) = \\text{constant})$ is equivalent to zero net external momentum $(\\sum_i\\vec{p}_i = \\text{constant})$ is equivalent to zero net external force $(\\sum_i\\vec{F}_i = 0)$.\n\nNext, If center of mass velocity is constant, then we know that the center of mass position is linear in time,\n\n\\[ \n\\vec{r}(t) = \\vec{r}_0 + \\vec{v}_0t \\ldots(2)\n\\]\n\nThus, we just need to find the initial position of the center of mass $(\\vec{r}_0)$ and initial velocity $(\\vec{v}_0)$ for the center of mass. Since the particle only moves along the $x$ axis, we can consider the $x$ components separately from the $y$ components:\n\nIf we sum the $x$ components of the center of mass position equation, we can deduce that the center of mass of the system at time $t = 0$ is,\n\n\\[\nx_{CM}(0) = \\frac{L}{2}\n\\]\n\nby symmetry. Alternatively, as its part of a problem, this can also be found by integrating over a constant mass per unit length $\\frac{M}{L}$ along the length of the rod, according\n\n\\[ \nx_{CM} = \\frac{\\sum_i m_ix_i}{\\sum_im_i} = \\frac{\\int_0^L \\frac{M}{L}xdx}{\\int_0^L\\frac{M}{L}dx} = \\frac{\\frac{M}{2L}L^2}{M} = \\frac{L}{2} \\ldots(3)\n\\]\n\nThe initial value of the $x$ component of the center of mass velocity $v_{CM}(0)$ can be found as follows. The $x$ component initial momentum is the momentum of the particle, which is given as \n\n\\[\np_x(0) =  MV_P\n\\]\n\nwhere $M_P$ denotes the mass of the particle. In the center of mass reference, we know that initial position of the particle has and initial unaccelerated velocity of $\\frac{d}{dt} = 0$ of the center of mass frame, so this momentum also equals\n\n\\[\np_x(0) = M_{total}(\\vec{v}_{CM}(0))\n\\]\n\nThus, substituting equations (3) and (4) into equation (2), we can see that the center of mass of the entire system at time t = 0 had\n\n\\[\nV_{xCM}(0)= \\frac{M_P}{M_{total}}V_P = \\frac{M_P}{M+M_P} V_P \\ldots (5)\n\\]\n\nThe initial rate of mass velocity can be found in a similar manner. The rod is not at rest at t = 0, $y(0) = 0$. That is, momentum along the $(y)$ axis is initially $P_y)(t-0)= 0= mv_{py}$. Thus, equating the initial $y$-components of the system momentum and the $y$ components of center of mass/total system momentum and setting $P_y=0$\n\n\\[ \nP_y= M_{total}v_{yCM}(0) \\Rightarrow V_{yCM} (0) = 0 \\ldots(6)\n\\]\n\nThus, substituting equation (10) into equation (4) gives\n\n\\[ \n\\vec{v}(t) =  \\begin{pmatrix} \\frac{m}{M+m}v_{P} \\\\ \n0 \\end{pmatrix}\\ldots (7)\n\\]\n\n\nand substituting equation (10) and (12) into equation (5) gives\n\n\\[ \n\\vec{v}_{CM}(t) = v_{CM} + 0(v) \\ldots (8)\n \\]",
    "3. Two particles colliding\n\nWe will start by choosing a coordinate system with the origin defined to be the location of $m_1$ at $t = t_0$. This choice is sensible as we will then know that \n\n$$x_1(t_0) = x_1(t_0 + t_v)$$\n in the problem at hand, $t_v$ is related to the distance traveled since $t = t_0$ (which is what the problems asks for us to consider). Additionally we note that the problem is one-dimensional, so we will only need to consider the x direction.\n\nIf we think in general for the two-particle system, we know that the characteristics of 2 interacting bodies, subject to forces between the two, will be \n\n$$F_1 = -F_2.$$\n\n_x_ location of centre of mass:\nRecall that the term, \n$$X_{com} = \\frac {m_1 x_1 + m_2 x_2} {m_1 + m_2}.$$ \n\nThis is significant because the problem statement gives us that motion of the system is at rest. Thus since the system is at rest to start, we know that the center of mass motion is linear in time. We can write the $X_{com}$ function as:\n\n$$X_{com} (t) = \\frac {m_1 x_1(t) + m_2 x_2(t)} {m_1 + m_2} = X_{com}(t_0) + (t - t_0) \\frac {p_{x0}} {m_1 + m_2}$$ (3)\n\nwhere we have established that: initially at t = $t_0$, there is no motion of $X_com$ so the motion of each particle as measured by the other particles reference frame is simply a v function of time. \n\nAt $t = t_0$ there is no drift of either object in the system:\n$$V_{x0} (t_0) = 0 := V_{x,1} (0) = V_{x,2} (0)$$ and the total linear momentum must vanish, so that\n\n$$\\frac {dX}{dt} |_{t_0} = 0 = P_{x0}/m_1 + m_2$$. (4)\n\nTo determine the center of mass of the system we will write down components of this from the problem statement of $X_{com}$ from the point of view of each $m_1$ and $m_2$: (all relative positions ($\\xi$) are taken respect to the position of $m_1$)\n\n$$x_{1, com} := x(t_0) + (t - t_0) \\frac {m_1}{m_1 + m_2} x_1$$\n$$x_{2, com} := x(t_0) + (t - t_1) \\frac {m_2}{m_1 + m_2} x_2$$\n\nThus, substituting results again from eqn 1-3, we find our center of mass position as a function of time to be:\n\n$$X_{com} (t) = (t - t_0) x_2$$ (5)\n\nThe final result implies our use of initial v functions from eq -> (t-t_0).............\n\nSince the particles are colliding we defined at time $t_c$. offset $x_1$ and $x_2$ are nearest location, while no external since external force acted in the system as then they act in symmetry.  \n\nSo conservation at relative momentum of the 2-particle system includes bidding of energy at the system: \nSubstitute final resutlt in eq(3),\n\nEvaluating equation ($t_c = t_r$ end combining it with eqns(1 and 2)) gives the final answer:\n$$ x_{coll}(t) = x_1 - x_2 \\frac{(m_1x_1 + m_2x_2) [m_1 + m_2]}.$$  (6)\n\nNote that since we never need to use the form of the force between the objects, this was enough to know that there was no external force acted on the two particles and that they eventually collided.",
    "4. Drag force at low speeds\n\n1. We start by applying Newton's second law to the ball in the $x$ direction. The only force is drag, so \n\n\\[ \n\\sum F_{x} = m\\frac{dv_{x}}{dt} = -bv_{x} \n\\tag{1} \n\\]\n\nThus, we find the acceleration in the $x$ direction is,\n\n\\[ \n\\frac{dv_{x}}{dt} = \\frac{-b}{m}v_{x} \n\\tag{2} \n\\]\n\n2. Next, we apply Newton's second law in the $y$ direction. Given the coordinate system, gravity will accelerate the ball downwards, so the drag force is upwards. Then, in the $y$ direction we have\n\n\\[ \n\\sum F_{y} = m\\frac{dv_{y}}{dt} = -mg - bv_{y} \n\\tag{3} \n\\]\n\nwhich can be rearranged to find\n\n\\[ \nm\\frac{dv_{y}}{dt} + bv_{y} = -mg \n\\tag{4} \n\\]\n\n3. To obtain the solution of the differential equation given by equation (2). To do so, we can use the technique of separation of variables to find\n\n\\[ \n\\frac{dv_{x}}{dt} = \\frac{-b}{m}dt \n\\tag{5} \n\\]\n\nIntegrating, we obtain\n\n\\[ \n\\int_{v_{0}}^{v_{x}}\\frac{dv_{x}}{v_{x}} = -\\int_{0}^{t}\\frac{b}{m}dt \n\\tag{6} \n\\]\n\nMaking use of the initial condition that $v_{x} = v_{0x}$ at $t = 0$, the integration constant must satisfy\n\n\\[ \nv_{x}(t) = v_{0x}\\exp\\left(\\frac{-bt}{m}\\right) \n\\tag{7} \n\\]\n\n4. To obtain the solution for the $y$ differential equation, By equation (4). This is an first-order inhomogeneous differential equation with constant coefficients. We solve this using variation of parameters. First, we solve the corresponding homogeneous equation,\n\n\\[ \n\\frac{dv_{y}}{dt} + \\frac{b}{m}v_{y} = 0 \n\\tag{8} \n\\]\n\nto get\n\n\\[ \nv_{yh}(t) = c\\exp\\left(\\frac{-bt}{m}\\right)\n\\tag{9} \n\\]\n\nwe can substitute it to get the inhomogenous differential equation.\n\n\\[ \nv_{y}(t) = v_{p}(t) + c\\exp\\left(\\frac{-bt}{m}\\right) \n\\]\n\nWe can make anology to get to find $v_{p}$,\n\n\\[ \nv_{p} = A \n\\]\n\nThen,\n\n\\[ \nm\\frac{dv_{y}}{dt} + b(A)  = -mg \\quad \\Rightarrow \\quad A = \\frac{-mg}{b}, \n\\]\n\nand the general solution is \n\n\\[ \nv_{y} = -\\frac{mg}{b} + c\\exp \\left( \\frac{-bt}{m}\\right) \n\\] \n\nMaking use of the initial condition that $v_{0y}(0) = v_{0y}$, the function becomes,\n\n\\[ \nv_{y}(t) = \\frac{-mg}{b}\\left(1 - \\exp\\left( \\frac{-bt}{m} \\right) \\right) + v_{0y}\\exp\\left( \\frac{-bt}{m}\\right) \n\\tag{10} \n\\]\n\nso\n\n\\[ \nv_{y}(t) = \\frac{-mg}{b} + \\left( v_{0y} + \\frac{mg}{b}\\right) \\exp\\left( \\frac{-bt}{m}\\right)\n\\tag{11} \n\\]\n\n\\[\n\\]",
    "Substituting this solution back into equation (5) gives\n\\[ v(t) = \\exp(C_1) \\exp \\left( -\\frac{kt}{m} \\right) + \\frac{mg}{k} \\]\nwhere we still must determine the integration constant $C_1$. This is done using the initial condition $v(0) = 0$, which implies that\n\\[ 0 = \\exp(C_1) \\exp \\left( 0 \\right) + \\frac{mg}{k} \\implies \\exp(C_1) = -\\frac{mg}{k} \\]\nSubstituting this into equation (12) gives the final answer of\n\\[ v(t) = -\\frac{mg}{k} \\exp \\left( -\\frac{kt}{m} \\right) + \\frac{mg}{k} = \\frac{mg}{k} \\left( - \\exp \\left( - \\frac{kt}{m} \\right) + 1 \\right) = \\frac{mg}{k} \\left( 1 - \\exp \\left( - \\frac{kt}{m} \\right) \\right) \\]\n\n4. To calculate $v_{max}$ we simply take the long time limit ($t \\to \\infty$) of equation (7) and find\n\\[ v_{max} = \\lim_{t \\to \\infty} \\frac{mg}{k} \\left( 1 - \\exp \\left( - \\frac{kt}{m} \\right) \\right) = \\frac{mg}{k} \\]\n\n6. To calculate $x_{max}$ we simply take the long time limit ($x \\to \\infty$) of equation (14) and find\n\\[ x_{max} = \\lim_{t \\to \\infty} x(t) = \\frac{mg}{k} t - \\frac{mg}{k} \\frac{m}{k} \\exp \\left( - \\frac{kt}{m} \\right) + C \\]\n\n\\[\n\\hspace{6cm}(16)\n\\]",
    "Chapter 6\nCONSTRAINTS, POWER, WORK AND KINETIC ENERGY",
    "6. Constraints, power, work and kinetic energy\n\n6.1 Geometric constraints  \n6.2 Mathematical pendulum  \n6.3 Power, work and kinetic energy  ",
    "6.1 Geometric constraints\n\nGeometric constraint: Restriction of the number of degrees of freedom of motion due to the particular geometry of motion.\n\nExamples:\n\n1) Hemisphere ($r = \\text{const}$)\n\n$r = R = \\text{const}$ \\hspace{0.5cm} (6.1)\n$\\Rightarrow$ 2 degrees of freedom \\hspace{0.2cm} $(\\theta, \\phi)$\n\n2) Funnel ($z = z(\\rho)$)\n\n$z = -1/\\rho$ \\hspace{0.5cm} (6.2)\n$\\Rightarrow$ 2 degrees of freedom \\hspace{0.2cm} $(\\rho, \\phi)$",
    "3  Ball on a looping\n\n1 Constant inclination angle\n\n2 Constant radius\n\n3 Constant inclination angle\n\n\\Rightarrow 1 degree of freedom: curvilinear abscissa \"s\" along the looping",
    "4\ufe0f\u20e3 Ball inside a ring\n\n- $r = R = \\text{const}$\n- $\\omega = \\dot{\\phi} = \\text{const}$\n\n\u21d2 1 degree of freedom \"$\\theta$\"",
    "6.1.1 Constraint force\n\nForce that is orthogonal to the motion and accounts for a geometric constraint in the equations of motion.\n\nExamples\n\u2460 Normal reaction force\n\u2461 Tension in a rod",
    "Ball in a rotating ring\n\n- Geometric constraints:\n1. Constant radius:\n   $r = R = \\text{const} \\quad \\Rightarrow \\quad \\dot{r} = 0 \\quad \\text{and} \\quad \\ddot{r} = 0$\n\n2. Constant angular velocity:\n   $\\omega = \\dot{\\phi} = \\text{const} \\quad \\Rightarrow \\quad \\dot{\\omega} = \\ddot{\\phi} = 0 \\quad \\quad (6.3)$\n\n- Constraint force:\n  Normal reaction of the ring:\n  $N = N_r e_r + N_{\\phi} e_{\\phi}$\n\n  The normal force is orthogonal to the unconstrained motion along $e_{\\theta}$ where the degree of freedom is the angle $\\theta$.",
    "Law of motion:\n\n$$\\sum \\vec{F}_{\\text{ext}} = \\vec{P} + \\vec{N} = m \\vec{a} \\quad (6.5)$$\n\nAngles:\n\n$$\n\\frac{\\pi}{2} \\le \\theta \\le \\pi \\quad \\Rightarrow \\quad \\cos \\theta < 0\n$$\n\n$$\n\\alpha = \\pi - \\theta\n$$\n\n$$\n\\sin \\alpha = \\sin \\theta\n$$\n\n$$\n\\cos \\alpha = - \\cos \\theta\n$$\n\nForces:\n\n$$\n\\vec{P} = mg = mg (\\cos \\alpha \\vec{e}_r + \\sin \\alpha \\vec{e}_\\theta ) = mg ( - \\cos \\theta \\vec{e}_r + \\sin \\theta \\vec{e}_\\theta )\n$$\n\n$$\n\\vec{N} = N_r \\vec{e}_r + N_\\theta \\vec{e}_\\theta \\quad (6.4)\n$$",
    "- Law of motion:\n$$\\sum F_{\\text{ext}} = P + N = ma \\quad (6.5)$$\n\n- Forces:\n$$P = mg = mg \\left(- \\cos \\theta \\mathbf{e}_r + \\sin \\theta \\mathbf{e}_{\\theta} \\right)$$\n$$N = N_r \\mathbf{e}_r + N_{\\phi} \\mathbf{e}_{\\phi} \\quad (6.4)$$\n\n- Acceleration (spherical coordinates (5.20) + constraints):\n$$a = -R \\left( \\ddot{\\theta} + \\omega^2 \\sin^2 \\theta \\right) \\mathbf{e}_r + R \\left( \\ddot{\\theta} - \\omega^2 \\sin \\theta \\cos \\theta \\right) \\mathbf{e}_{\\theta}$$\n$$+ 2R\\omega \\dot{\\theta} \\cos \\theta \\mathbf{e}_{\\phi} \\quad (6.6)$$\n\n- Equation of motion + constraints:\nalong $\\mathbf{e}_r$ : \n$$- mg \\cos \\theta + N_r = -mR \\left( \\ddot{\\theta} + \\omega^2 \\sin^2 \\theta \\right)$$\nalong $\\mathbf{e}_{\\theta}$ :\n$$mg \\sin \\theta = mR \\left(\\ddot{\\theta} - \\omega^2 \\sin \\theta \\cos \\theta \\right) \\quad (6.7)$$\nalong $\\mathbf{e}_{\\phi}$ : \n$$N_{\\phi} = 2m R \\omega \\cos \\theta$$\n\n- Constraint:\n$$N = m \\left(g \\cos \\theta - R \\ddot{\\theta} - R \\omega^2 \\sin^2 \\theta \\right) \\mathbf{e}_r + 2m R \\omega \\cos \\theta \\mathbf{e}_{\\phi} \\quad (6.8)$$",
    "- Equation of motion:\n  $mg \\sin \\theta = mR(\\ddot{\\theta} - \\omega^2 \\sin \\theta \\cos \\theta)$\n\n- Equilibrium positions: $\\ddot{\\theta} = 0$\n  $\\Rightarrow \\sin \\theta (g + R \\omega^2 \\cos \\theta) = 0$\n\n1. $\\sin \\theta = 0 \\Rightarrow \\theta = \\pi$\n2. $\\cos \\theta = -\\frac{g}{R \\omega^2} \\Rightarrow \\theta = \\arccos \\left( \\frac{-g}{R \\omega^2} \\right)$\n\n  if $R \\omega^2 \\ge g$ because $-1 \\le \\cos \\theta < 0$\n\n  In order for the equilibrium position 2 to exist it requires that $\\omega > \\sqrt{\\frac{g}{R}}$\n\n$\\frac{\\pi}{2} < \\theta \\le \\pi$\n$\\cos \\theta < 0$",
    "6.2 Mathematical pendulum\n\n- Massless and inextensible thread\n- Negligible friction\n- Motion in a fixed vertical plane (polar coordinates $(\\rho, \\phi)$)\n\nGeometric constraint:\n- Thread of constant length\n$$\\rho=\\ell = \\text{const} \\quad \\Rightarrow \\quad \\dot{\\rho} = 0 \\quad \\text{and} \\quad \\ddot{\\rho} = 0$$",
    "6.2.1 Law and equation of motion\n\nExternal forces:\n1) Weight: $P = mg = mg (\\cos \\phi e_r - \\sin \\phi e_{\\phi})$\n2) Tension: $T = -Te_r$ (6.10)\n   \nLaw of motion:\n\\[\n\\sum F^{\\text{ext}} = P + T = ma\n\\]\n\nAcceleration\n(polar coordinates + constraints):\n\\[\na = -\\ddot{\\ell} e_r + \\ell \\dot{\\phi}^2 e_r \n\\]\n(6.12)\n\nEquation of motion:\nalong $e_r$: \n\\[\nmg \\cos \\phi - T = -m \\ell \\dot{\\phi}^2\n\\]\n\nalong $e_{\\phi}$: \n\\[\n-mg \\sin \\phi = m \\ell \\dot{\\phi}\n\\]\n(6.13)",
    "Tension in the thread (norm):\n\n$$T = m \\left( g \\cos \\phi + \\ell \\dot{\\phi}^2 \\right)$$ \n\n(6.14)\n\nWhen the material point has an oscillatory motion the value of the tension in the thread increases.\n\nEquation of motion:\n\n$$\\ddot{\\phi} + \\frac{g}{\\ell} \\sin \\phi = 0$$ \n\n(6.15)\n\nThe motion is independent of the mass $m$ of the material point.",
    "6.2.2 Small oscillations around the equilibrium\n\n- Equilibrium position:\n  $\\phi = 0$\n- Small oscillations $\\phi \\ll 1$:\n  (approximation)\n  $\\sin \\phi \\simeq \\phi$ \\hspace{1cm} (6.16)\n\n- Equation of motion:\n  $\\ddot{\\phi} + \\frac{g}{l} \\phi = 0$ \\hspace{1cm} (6.17)\n\n- Harmonic oscillatory motion:\n  $\\ddot{\\phi} + \\omega^2 \\phi = 0$\n\n- Pulsation:\n  $\\omega = \\sqrt{\\frac{g}{l}}$\n\n- Period:\n  $T = \\frac{2 \\pi}{\\omega} = 2 \\pi \\sqrt{\\frac{l}{g}}$ \\hspace{1cm} (6.18)",
    "6.2.3 General oscillation period\n\n- General equation of motion:\n  $\\ddot{\\phi} + \\frac{g}{\\ell} \\sin \\phi = 0 \\quad (6.15)$\n\n- $\\dot{\\phi} \\, \\ddot{\\phi} + \\frac{g}{\\ell} \\sin \\phi = 0 \\quad (6.19)$\n\n- Reformulation of (6.19) as a total derivative:\n  $\\frac{d}{dt} \\left( \\frac{1}{2} \\dot{\\phi}^2 - \\frac{g}{\\ell} \\cos \\phi \\right) = 0 \\quad (6.20)$\n\n- Indefinite integral of (6.20):\n  $\\frac{1}{2} \\dot{\\phi}^2 - \\frac{g}{\\ell} \\cos \\phi = \\text{const} \\quad (6.21)$\n\n- Initial conditions: $\\phi (0) = \\phi_0$ and $\\dot{\\phi} (0) = 0 \\quad (6.22)$\n\n- (6.21) and (6.22): $\\Rightarrow \\frac{1}{2} \\dot{\\phi}^2 - \\frac{g}{\\ell} \\cos \\phi = - \\frac{g}{\\ell} \\cos \\phi_0 \\quad (6.23)$",
    "- Scalar angular velocity:\n$$\\dot{\\phi} = \\frac{d\\phi}{dt} = \\sqrt{\\frac{2g}{\\ell}} \\frac{\\sqrt{\\cos \\phi - \\cos \\phi_0}}$$\n\n- Infinitesimal time interval:\n$$(6.23) \\quad \\Rightarrow \\quad dt = \\sqrt{\\frac{\\ell}{2g}} \\frac{d\\phi}{\\sqrt{\\cos \\phi - \\cos \\phi_0}}$$\n\n- Time (elliptic integral):\n$$(6.24) \\quad \\Rightarrow \\quad t = \\int_{0}^{t} dt' = \\sqrt{\\frac{\\ell}{2g}} \\int_{0}^{\\phi(t)} \\frac{d\\phi'}{\\sqrt{\\cos \\phi' - \\cos \\phi_0}} \\quad (6.25)$$\n\n- Oscillation period (by symmetry 4 x 1/4 of period):\n$$T = 4 \\sqrt{\\frac{\\ell}{2g}} \\int_{0}^{\\phi_0} \\frac{d\\phi'}{\\sqrt{\\cos \\phi' - \\cos \\phi_0}} \\quad (6.26)$$",
    "- Oscillation period:\n\\[ \nT = 4 \\sqrt{\\frac{l}{2g}} \\int_{0}^{\\phi_0} \\frac{d\\phi'}{\\sqrt{\\cos \\phi' - \\cos \\phi_0}} \\quad (6.26) \n\\]\n\n- Exact solution (very long calculation...):\n\\[ \nT = 2\\pi \\sqrt{\\frac{l}{g}} \\sum_{n=0}^{\\infty} \\left[ \\frac{(2n)!}{(2^n n!)^2} \\sin^2 \\left( \\frac{\\phi_0}{2} \\right) \\right] \n\\]\n\\[ \n= 2\\pi \\sqrt{\\frac{l}{g}} \\left( 1 + \\frac{1}{16}\\phi_0^2 + \\frac{11}{3072}\\phi_0^4 + O(\\phi_0^6) \\right) \\quad (6.27) \n\\]\n\n- If $\\phi_0 \\ll 1 \\Rightarrow T = 2\\pi \\sqrt{\\frac{l}{g}} \\quad (\\text{small oscillations})$",
    "If $\\phi_0 \\ll 1 \\quad \\Rightarrow \\quad T = 2\\pi \\sqrt{\\frac{l}{g}}$ (small oscillations)\n\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\n\\phi_0 & \\frac{1}{16} \\sigma^2 & \\frac{11}{3072} \\sigma^4 \\\\\n\\hline\n10^\\circ & 0.19\\% & 0.003\\% \\\\\n30^\\circ & 1.7\\% & 0.027\\% \\\\\n60^\\circ & 6.9\\% & 0.43\\% \\\\\n90^\\circ & 15\\% & 2.2\\% \\\\\n120^\\circ & 27\\% & 6.9\\% \\\\\n\\hline\n\\end{array}\n\\]",
    "6.3 Power, work and kinetic energy\n\nPower: scalar and extensive quantity $P$ associated to the ability of a force $F$ accelerate (or decelerate) the motion of a material point of velocity $v$:\n\n\\[ P = F \\cdot v \\quad (6.28) \\]\n\n1) \\[ \\frac{F}{v} = \\cdot : \\quad F \\cdot v > 0 \\Rightarrow P > 0 \\quad \\text{(acceleration)} \\]\n2) \\[ \\frac{F}{v} = \\cdot : \\quad F \\cdot v < 0 \\Rightarrow P < 0 \\quad \\text{(deceleration)} \\]\n\n- Physical unit: Watt (SI) \\[ [W] = \\left[ \\frac{kg \\cdot m^2}{s^3} \\right] \\]\n- Examples:\n    - engine \\[ (P > 0) \\]\n    - human muscle \\[ (P > 0) \\]\n    - friction \\[ (P < 0 ) \\]",
    "- Examples of engines:\n\n1. Stirling engine\n\nA burner filled with alcohol heats up the air inside the cylinder, thus providing heat to the engine that is activated by setting in motion the wheel.\n\n2. Vacuum engine\n\nHot air engine that sucks the flame thanks to a valve (characteristic noise).",
    "6.3.2 Work\n\nWork: scalar and extensive quantity $W_{12}$ corresponding to the integral of the power $P$ of a force $\\mathbf{F}$ exerted on a material point during a time interval $[t_1, t_2]$.\n\n\\[ \nW_{12} = \\int_{t_1}^{t_2} P(t) \\, dt = \\int_{t_1}^{t_2} \\mathbf{F}(t) \\cdot \\mathbf{v} \\, dt \\tag{6.29} \n\\]\n\nwhere $\\mathbf{F}(t) \\equiv \\mathbf{F}(\\mathbf{r}(t)) \\equiv \\mathbf{F}(\\mathbf{r})$ and $\\mathbf{v} \\, dt = d\\mathbf{r}$\n\n\\[ \nW_{12} = \\int_{C_{12}} \\mathbf{F}(\\mathbf{r}) \\cdot d\\mathbf{r} \\tag{6.30} \n\\]\n\nPhysical unit: Joule (SI) \\[ J = \\left[ \\text{kg} \\, \\text{m}^2 \\, \\text{s}^{-2} \\right] \\]\n\nExamples: \n- climbing Mt. Blanc\n- braking",
    "- Work:\n\\[ W_{12} = \\int_{C_{12}} \\mathbf{F}(\\mathbf{r}) \\cdot d\\mathbf{r} \\]\n\n- Infinitesimal work:\n\\[ \\delta W = \\mathbf{F} \\cdot d\\mathbf{r} = ||\\mathbf{F}|| \\, ||d\\mathbf{r}|| \\cos \\theta \\]\n\n\\[ d\\mathbf{r} = \\lim_{\\Delta t \\to 0} \\frac{\\mathbf{r}(t + \\Delta t) - \\mathbf{r}(t)}{\\Delta t} \\]",
    "6.3.3 Kinetic energy\n\nKinetic energy: scalar and extensive quantity $T$ associated to every motion of a material point of velocity $v$ and momentum $p$.\n\n\\[ T = \\int_{0}^{T} dT' = \\int_{0}^{T} \\vec{v} \\cdot d\\vec{p} = \\frac{v = p/m}{1m} \\int_{0}^{T} \\vec{p} \\cdot d\\vec{p} \\]\n\n\\[ = \\frac{p^2}{2m} = \\frac{1}{2} m v^2 \\]\n\n(6.32)\n\nProperties:\n- product of an extensive quantity $\\vec{p}$ and of an intensive quantity $\\vec{v}$.\n- existence of a minimum, i.e. $\\vec{v} = 0$.\n- final expression taken from experiment because the relation $\\vec{p} = m\\vec{v}$ is taken from experiment.\n\nPhysical unit: Joule (SI) $[J] = [kg \\ m^{2}/s^{2}]$\n\nExamples: gun bullet, car",
    "6.3.4 Kinetic energy theorem\n\nTheorem: The work $W_{12}$ performed by the net external force $\\sum F^{\\text{ext}}$ on a material point of mass $m$ from an initial position $r(t_1)$ to a final position $r(t_2)$ is equal to the kinetic energy variation between the times $t_1$ and $t_2$: \n\n$$\nW_{12} = T_2 - T_1 \\tag{6.33}\n$$\n\nDemonstration:\n\n$$\nW_{12} = \\int_{t_1}^{t_2} \\sum F^{\\text{ext}} \\cdot v \\, dt \\quad \\text{(2.33)}\n$$\n\n$$\n= \\int_{t_1}^{t_2} m a \\cdot v \\, dt \\quad \\text{(2.2)}\n$$\n\n$$\n= \\int_{t_1}^{t_2} m \\frac{dv}{dt} \\cdot v \\, dt\n$$\n\n$$\n= (m = \\text{const}) \\int_{t_1}^{t_2} d\\left(\\frac{1}{2} mv^2\\right) dt\n$$\n\n$$\n= \\frac{1}{2}mv^2 \\bigg|_{t_1}^{t_2}\n$$\n\n$$\n= \\frac{1}{2} mv_2^2 - \\frac{1}{2} mv_1^2 \\quad (v_1 = v(t_1); v_2 = v(t_2))\n$$\n\n$$\n\\Rightarrow T_2 - T_1 \\quad \\text{(6.32)}\n$$\n\n$$\n\\Rightarrow \\frac{1}{2} mv_2^2 - \\frac{1}{2} mv_1^2\n$$\n\n$$\n= T_2 - T_1 \\quad \\text{(6.34) -- (6.35)}\n$$",
    "Physical units (SI) of the main quantities:\n\nQuantity | Unit      | Abbreviation\n---------|-----------|----------------\nMass     | kilogram  | $[kg]$\nLength   | meter     | $[m]$\nTime     | second    | $[s]$\nVelocity |           | $[m/s]$\nAcceleration |       | $[m/s^2]$\nForce    | Newton    | $[N = kg \\, m/s^2]$\nWork, kinetic energy | Joule | $[J = kg \\, m^2/s^2]$\nPower    | Watt      | $[W = kg \\, m^2/s^3]$\n\nDimensional analysis: Verify the homogeneity of the physical units of the terms of an equation.",
    "1. Spring-propelled block going through a loop\n\n1. As the block is initially at rest on $y_0$, the initial kinetic energy before the latch is released is $K_i = 0$ and $U_i = 0$. The initial potential energy of the compression of the spring is given by $U_s = \\frac{1}{2}k x^2$. It will either stick or coordinate system so that the potential gravitational energy is 0 when $y = 0$. The total height of the loop is $H$. And we take the initial gravitational potential of the block for $y_0$ to be 0. Therefore, the total initial energy is,\n\n\\[ E_i = K_i + U_i + U_s = 0 + 0 + \\frac{1}{2}kx^2 = \\frac{1}{2}kx^2 \\tag{1} \\]\n\nAt the top of the loop in $y = 2r$, the kinetic energy is $K_f = \\frac{1}{2} m v^2$, the gravitational potential energy is $U_f = mg \\cdot 2r = 2mgR$, and the spring is no longer in contact with the block (i.e., it's 0). Thus, the equation (1) can be written:\n\n\\[ E_f = \\frac{1}{2}mv^2 + 2mgR \\tag{2} \\]\n\nSince the track is frictionless and there is no drag, mechanical energy is conserved and we can set the equation (1) equal to equation (2):\n\n\\[ \\frac{1}{2}kx^2 = \\frac{1}{2}mv^2 + 2mgR \\rightarrow kx^2 = mv^2 + 4mgR \\rightarrow v^2 = \\frac{kx^2 - 4mgR}{m} \\tag{3} \\]\n\n2. From Newton\u2019s second law and the approximation of uniform circular motion, the net inward force in the radial direction is equal to the centripetal force. Thus, at the top of the loop Newton\u2019s second law in the vertical direction is given by:\n\n\\[ 2mg + N = m\\frac{v^2}{r} \\tag{4} \\]\n\nwhere $N$ is the normal to point upwards. From the information given in the problem statement we know we have:\n\n\\[ N > 0 \\Rightarrow m\\frac{v^2}{r} > 2mg \\rightarrow v^2 > 2gR \\tag{5} \\]\n\nWe can substitute equations (3) into equation (5) and solve for k to find\n\n\\[ \\frac{kx^2 - 4mgR}{m} > 2gR \\Rightarrow kx^2 - 4mgR > 2mgR \\Rightarrow k > \\frac{6mgR}{x^2} \\tag{6} \\]",
    "2. Two-body interaction\n\n1. Choosing to use a spherical coordinate system, the change in the potential energy due to the force $\\vec{F}$ is \n\n\\[\n\\Delta U = U(\\vec{r}) - U(\\infty) = -\\int \\vec{F} \\cdot d\\vec{l} = - \\int \\frac{Gm_1m_2}{r^2} dr  \\quad \\text{(only a radial change)}\n\\]\n\n\\[\n\\Delta U  = U(\\vec{r}) - U(\\infty) = -\\int \\frac{Gm_1m_2}{r^2} dr = \\left[ \\frac{Gm_1m_2}{r} \\right]^\\infty_r = \\frac{Gm_1m_2}{r} \\;\\;\\;  dr = (-\\text{radial} \\cdot \\text{radial united vector})\n\\]\n\n\\[\n\\Delta U = \\left[ - \\frac{Gm_1m_2}{r} \\right]^\\infty_r = \\frac{Gm_1m_2}{\\infty} - \\left(-\\frac{Gm_1m_2}{r}\\right) = 0 + \\frac{Gm_1m_2}{r}\n\\]\n\nwhere the integration path C is along the trajectory from $r = \\infty$ to $r = R$. However, we see that, since the force is purely radial, only the change in the radial positions matters. Thus, we can write:\n\n\\[\n\\Delta U(r) = U(R) - (\\infty) = - \\int^r_R \\vec{F} \\cdot \\vec{r}\n\\]\n\nTaking the integral gives a potential energy difference of \n\n\\[\nU(r) = \\frac{Gm_1m_2}{r} \\;\\;\\; U(\\infty) = 0\n\\]\n\n(3)\n\nSince the reference point for the potential interaction is at $r = \\infty$ we define the potential energy such that $U(\\infty) = 0$, equation (3) simplifies to\n\n\\[\nU(r) = - \\frac{Gm_1m_2}{r}\n\\]\n\nwhich will be useful in the next part of the problem.\n\n2. Equilibrium solves when the forces are equal in magnitude. Thus, we can find the location $R = R_s$ such that the attractive and repulsive forces are equivalent in magnitude:\n\n\\[\n-\\frac{GMm}{R^2_s} = - \\left( C_{e^{k_c}} \\cdot e^{k/k_BT} - \\frac{C}{R^2} \\right) = \\frac{l}{\\epsilon} ( C e^{k_BT} - Cd)\n\\]\n\nUsing this fact, we can see that there is just one equilibrium point\n\n\\[\n-\\frac{GMm_1}{R^2} = \\frac{d}{D} = \\frac{id \\cdot C \\cdot C}{c}\n\\]\n\nThus, we have the equilibrium point $R_s$\n\n\\[\n-\\frac{GMm_1}{R} = - \\left( \\frac{GM_1mR}{R^2} - \\right)\n\\]\n\nwe see that the equilibrium distance is\n\n\\[\n\\vec{F}_e (r_s) = \\frac{C_{k^{B}}\\theta^\\epsilon}{GM_m} = c^2 ( GMm \\cdot \\alpha)\n\\]\n\nTo see if adding a test charge +q gives another equilibrium position, we must find equilibrium position distance and stay at R + r.\n\nEvaluating this fact and evaluating the result suggests to us that the repulsive potentials produce in the two configuration:\n\n\\[\nu(r) = ( s^2 + 1) \\frac{d m}{D} + (r + d) \\;\\text{and} \\;\\frac{A_c}{gm + 2(\\epsilon^T\\Theta/k^{HS})}\\frac{r}{\\theta_{\\Omega}}\n\\]\n\nGiven that we have derived for the repulsive portion of the force in both attempts to separate, we see that $\\Delta U + F = (2E_1)^2(3 + \\epsilon_o)\\alpha$ thus $R = (C\\Delta)$\n\n2",
    "3. A particle in Gaussian potential\n\n1. The energy diagram is shown below, where we note that the kinetic energy $K(t) = E - U(t)$ is the difference between the total energy $E$ and the potential energy $U(x)$ due to conservation of mechanical energy.\n\n2. The force on the particle in the x direction is calculated from \n\\[\nF(x) = -\\frac{dU(x)}{dx}\n\\]\nPlugging in the form of $U(x)$ and using the chain rule gives:\n\\[\nF(x) = -A \\left[ \\left(-\\frac{2(x+a)}{B^2}\\right)e^{-\\frac{(x+a)^2}{B^2}} + \\left(-\\frac{2(x-a)}{B^2}\\right)e^{-\\frac{(x-a)^2}{B^2}} \\right]\n\\]\n\n3. To find the speed of the particle we use conservation of mechanical energy and solve for $v$ as stated, resulting in\n\n\\[\nE(t) = E_1\n\\]\n\\[\nK(t) = E_1 - U(x)\n\\]\n\\[\nK(t) = \\frac{1}{2}mv^2 (t) \\Rightarrow v(t) = \\sqrt{\\frac{2}{m}(E_1 - U(x))}\n\\]\n\nOverall, the values for the kinetic energy in relation to the values of $U(x)$ and $W_x = -A$. However, we will take into account the points to the right and left in relation to $U(x)$ = -A. Therefore in mathematical notation, the solutions to the calculations are given as a parametric equation for $t$ in relation to the values of mechanical energy of the particles:\n\n\\[\n(3a - \\sqrt{\\frac{3a}{10}} < X_1 < \\sqrt{\\frac{20a}{100}}) \\text{ yields }\n\\]\n\\[\nK(t) = 0 \\Rightarrow E_1 = 0 + U(E)\n\\]\nSimplified we get\n\\[\nE = \\frac{1}{2}mv^2\n\\]\nSolving for $v$ gives\n\\[\nv(t) = \\sqrt{\\frac{2}{m}(E - E_1)}\n\\]",
    "4. Circular loop\n\nThis problem is similar to problem 1. As the block is initially at rest on y_0, the initial kinetic energy is \\( E_{ki}=0 \\). The initial potential energy is due to gravity. We will define the reference point to be at the level of the table, so the initial potential energy is \\( E_{pgi}=mgy_0 \\). And the initial gravitational potential energy is \\( E_{gi} = E_{pgi} \\); Therefore, the total initial energy is \\( E_i \\):\n\n\\[ E_i = E_{ki} + E_{pgi} = 0 + mgy_0 = mgy_0 \\]\n\nAt the top of the loop on y = 2R, the kinetic energy is \\( E_{Kf} \\), and the gravitational potential energy is \\( E_{pf} = mg \\cdot 2R \\). Then, the total energy at the top of the loop (where h = 2R) is\n\n\\[ E_f = E_{Kf} + E_{pf} = E_{Kf} + mg \\cdot 2R. \\]\n\nSince the track is frictionless and there is no air drag, there is no non-conservative force and mechanical energy is conserved. We can use equations (1) and (2) to write\n\n\\[ E_i = E_f \\]\n\n\\[ mgy_0 = E_{Kf} + 2mgR. \\]\n\nFrom the properties of circular motion, we know that the acceleration in the radial direction is equal to the centripetal acceleration, which is \\( a = \\frac{v^2}{R} \\). Thus, at the top of the loop (as shown in the figure above) Newton\u2019s second law in the y direction is\n\n\\[ \\Sigma F_y = -mg = -ma. \\]\n\nFrom the illustrations given in the problem statement, we know that the mass just barely loses contact with the track. Thus, the normal force of the track on the mass must be effectively N = 0, so we can substitute the second law equation as\n\n\\[ \\Sigma F_y = -mg = m \\left( -\\frac{v^2}{R} \\right). \\]\n\nWe can substitute equation (5) into equation (3) and solve for v to find that\n\n\\[ mg \\cdot h = \\frac{1}{2}m \\left( \\sqrt{gR} \\right)^2 + 2mgR = 5mgR. \\]\n\nThus,\n\n\\[ h = 2.5R. \\]",
    "5. Review: Tension in a massive rope\n\nThere are several methods to solve this problem.  Below we show two of them.\n\n1.  In method 1, we will use differential elements.  To calculate the tension, we start by considering a small piece of rope with length $\\Delta y$ and let its left end be located at an arbitrary position $y$. Let $T(y)$ and $T(y + \\Delta y)$ be the tensions that act upon the rope at the location $y$, while the rope tensions on the right end lie points to the right. Since the rope has a uniform linear mass density $\\mu$, we can calculate the sum of all forces in the block as shown below:\n\n\\[\n\\sum F_y = T(y + \\Delta y) - T(y) - \\mu \\Delta y g = 0\n\\]\n\n(1)\n\nDrawing a free body diagram for the piece of rope, we see that Newton's second law in the $x$ direction gives us\n\n\\[\nT(y + \\Delta y) - T(y) = \\mu \\Delta y g,\n\\]\n\n(2)\n\nwhere $a_y$ is the acceleration of the piece of rope. Substituting equation (3) and rearranging gives\n\n\\[\nT(y + \\Delta y) - T(y) = \\mu \\Delta y \\left( a + g \\right)\n\\]\n\n(3)\n\nTaking the limit that the differential element is infinitesimally small $\\Delta y \\rightarrow 0$ produces the differential equation\n\n\\[\n\\frac{d T(y)}{d y} = \\mu \\left( a + g \\right)\n\\]\n\n(4)\n\nImportantly, as the rope does not stretch, we know that the entire rope must move together. This implies that every part of the rope has the same acceleration.  Thus, we can solve differential equation (4) for $T(y)$ directly, but in this case we are in a constant acceleration. Thus, we can directly integrate equation (4) to give:\n\n\\[\nT(y) - T(0) = \\mu ( a + g ) y\n\\]\n\n(5)\n\n2. In method 2, we will apply a boundary condition. We can either use $T(L) = 0$, or $\\Delta x$ in physical length of the rope.  Here $\\Delta x$ is the change in length as tension does not make the block move or stretch. We write the solution:\n\n\\[\nT =  T(0) + M cm ( a + g )y\n\\]\n\nThe length of rope can be used as a length scale. We draw a free body diagram for the block and see that:\n\n\\[\nF_x - F_y = ma_x\n\\]\n\n(6)\n\nwhere $F_x$ is the force of the rope on block, compensating for the mass of block, M, such the block must have the same acceleration. We expect this to move the force on the block $T(y+ \\Delta y)$.  Note that we'd get $a = a_x$. Summing the magnitude of Newton's second law is:\n\n\\[\nF_1 = ma\n\\]\n\n(7)\n\nAlso: the block has no acceleration in the vertical direction. Thus, the kinetic friction force is given by\n\n\\[\nF_{f} =\\mu_{S} mg\n\\]\n\n(8)",
    "Substituting this into equation (7) allows us to find the force of the rope on the block to be\n\n\\[ F_1 = m_1 g \\left( 1 + \\frac{m_1}{M} \\right) \\tag{10} \\]\n\nNewton's third law tells us that the magnitudes of the forces between the rope and block must be equal (i.e., $F_1 = F_2$). Additionally, we know that the force of the rope on the block is identical to the force the end of the rope (i.e., $T_0 = F_1 = F_2$). Thus, we find\n\n\\[ T_0 = m_1 g \\left( 1 + \\frac{m_1}{M} \\right) \\tag{11} \\]\n\nFinally, we can solve for the integration constant $C$ by evaluating equation (8) at $x = 0$ and using equation (11) to obtain\n\n\\[ T(0) = T_0 = m_1 g \\left( 1 + \\frac{m_1}{M} \\right) = \\mu g \\int_0^L dx = C \\]\n\nHere we have used two different ways to calculate the integration constant $C$. Equations (6) and (12) relate the large and small mass such that they can be written as\n\n\\[ F_r = \\left( m_1/m_2 \\right) \\left( m_1 g - F_r \\right) \\rightarrow F_r = m_1 g \\frac{m_1}{M} \\tag{13} \\]\n\nWe could also determine the exact values of the block-rope forces if we knew the coefficient of friction between the block and the surface. In this class it is fine to assume the inducing forces obtained from these relations without considering the coefficient of friction. Here we use the different segments of both the rope and the block together. Newton's second law in the x direction for the block gives a condition that the tension must satisfy:\n\n\\[ F_1 = T(x) = m_1 g + m_1 a \\]\n\nSubstituting equations (9) and solving for $a$, we have\n\n\\[ a = \\frac{m_1}{M}g + g = \\frac{m_1}{M}g \\tag{14} \\]\n\nIf we substitute this into either equation (6) or (12) and perform our algebra, we find that by using the mass of the block we have\n\n\\[ F_r = m_1 g \\frac{m_1}{M} \\tag{15} \\]\n\nWe can substitute this into equation (5) and solve equation (7) to replace:\n\n\\[ \\frac{\\lambda}{2L} m_1 g = T_0 - \\left( \\frac{m_1}{M} g x \\right) = T \\tag{16} \\]\n\nAfter considerable algebra we can somewhat simplify this result to\n\n\\[ T(x) = T_0 - (\\frac{m_1}{M}L) \\left( 1 - \\left( \\frac{ \\lambda}{2} \\right) \\right) \\tag{17} \\]\n\n2. In method 2, we will simply divide the rope into two parts. Start by considering an arbitrary position $x_r$ where the rope density starts to vary. We then calculate the net force applied on the object of mass $m_1$. Now, since the tension is $T_0$ at the top of the block to the top of the rope for that part, we have\n\n\\[ T_0 = \\frac{M}{L} (1 - x_r)g = (L - x_r) \\left( \\frac{m_1}{M}+1 \\right) \\tag{18} \\]\n\nwhile the total mass of the rope to the left of the arbitrary point is\n\n\\[ \\frac{M}{L} x_r \\tag{19} \\]\n\nNow we can draw a free body diagram for the left-middle side of the rope and use the Newton's second law :\n\n\\[ F_r = T(0) = m_1 a : \\rightarrow F_r = T(L)(x_r) \\frac{M}{L}x_r - m_1g = (\\frac{M}{L})(x_r) \\left(\\frac{m_1}{M}+1\\right)\\tag{20} \\]",
    "where $a_R$ is the acceleration of the right side of the rope in the $x$ direction and $T(x)$ is the tension in the rope at the position $x$. Also note that we have used equation (13) and the fact that the top is completely horizontal. We can do the same for the left side of the rope and use equation (19b) to find\n\\[\nT(l) - F_L = m \\ddot{x} = T(0) - F_R - \\mu_k mg\n\\]\nwhere $F_{L}$ is the force of the block on the rope and $x_{L}$ is the acceleration of the left side of the rope in the $x$ direction.\n\n  \nFrom equation (21) we see that we must consider the block. Drawing a free body diagram, we can see that $F_{L}$ and $F_{R}$ must be equal in $y$ direction.\n\\[\nF_{L} = F_{R} = N\n\\]\nwhere $F_{L}$ is the force of the rope on the block and $a_L$ is the acceleration of the block. To calculate the frictional force $f_{R_L}$, we must know the acceleration of the block. This can be found from the sum of the kinetic friction force into equation (21), yielding\n\\[\nf_{R_L} = \\mu_k N\n\\]\n \nNewton\u2019s third law tells us that the sum of the equal and opposite forces the rope and block must be equal to zero (Fig. 1). Thus, we substitute equation (24) into equations (21a) by noting $F_L = F_R = f_{k_L}$\n\\[\nf_{k_L} = (\\mu_k mg) a_P = (\\mu_k N)\n\\]\nNow we must determine the constant condition on the system to relate $a_L$, $a_R,$ and $a_P$. Since the rope has constant acceleration, we let the length be in the positive $x$ direction. That is,\n\\[\nu(x) = \\frac{p(m)}{a (t)}\n\\]\nThus, we can substitute equation (23) into both $a_L$ and $a_R$, in equation (20) to find an equation for velocity,\n\\[\nT(\\ddot{x}) = m\\mu_k - (u_i \\ddot{x} - T(t)) =  \\bigg(\\frac{m}{u_i}\\bigg)\\bigg(\\frac{(u_f - \\ddot{x})}{(T_i - x_i^2 - T_d)}\\bigg)\n\\]\nAfter a considerable amount of algebra, left as an exercise for the reader, we can solve this equation to find,\n\\[\nT(\\ddot{x}) = \\frac{M}{m} \\bigg(1 - \\bigg(\\frac{1}{L} \\bigg) \\mu_k (m g + N) \\bigg)\n\\]",
    "A.13 Rigid body with one fixed axis and gyroscopes\n\nA.13.1 Physical pendulum\n\nA.13.2 Rotating rod",
    "A.13.1 Physical pendulum\n\nA physical pendulum consists of a rod and a cylinder of a total mass $M$. The pendulum oscillates around a horizontal axis going through point $O$. Let $\\|OG\\| = L$ and the moment of inertia be $I_G$.\n\nHuygens-Steiner theorem:\n\\[ I_O = I_G + ML^2 \\quad \\text{(A.13.1)} \\]",
    "* Angular momentum theorem: $\\vec{L}_O = I_O \\vec{\\Omega}$\n\n$$\n\\vec{L}_{O\\text{rel}} = \\frac{d\\vec{L}_O}{dt} = I_O \\dot{\\vec{\\Omega}}\n$$\n\n$$\n\\vec{O}\\vec{G} \\times \\vec{P} + \\vec{O}\\vec{G} \\times \\vec{T} = I_O \\dot{\\vec{\\Omega}}\n$$\n\n$$\n\\Rightarrow L e_{\\psi} \\times M_g (\\cos \\phi \\vec{e}_r - \\sin \\phi \\vec{e}_{\\phi})\n$$\n\n$$\n= I_O \\ddot{\\phi} \\vec{e}_z = (I_G + M L^2 ) \\ddot{\\phi} \\vec{e}_z\n$$\n\nalong $\\vec{e}_t$ : $ -M_g L \\sin \\phi = (I_G + M L^2 ) \\ddot{\\phi}$\n\n$$\n\\Rightarrow \\ddot{\\phi} + \\frac{M_g L}{I_G + M L^2} \\sin \\phi = 0 \\quad \\text{(A.13.2)}\n$$",
    "Small angle approximation:\n\n$\\phi \\ll 1 \\implies \\sin\\phi \\approx \\phi$\n\n$(A.13.2) \\implies \\ddot{\\phi} + \\omega^2 \\phi = 0 \\quad (A.13.3)$\n\nwhere $\\omega = \\sqrt{\\frac{MgL}{I_G + ML^2}}$\n\nOscillation period:\n\n$T = \\frac{2\\pi}{\\omega} = 2\\pi \\sqrt{\\frac{I_G + ML^2}{MgL}} \\quad (A.14.4)$\n\nParticular case (mathematical pendulum):\n\n$I_G = 0 \\implies T = 2\\pi \\sqrt{\\frac{ML^2}{MgL}} = 2\\pi \\sqrt{\\frac{L}{g}}$",
    "A rod of length $l$, of negligible radius and of mass is rotating at constant angular velocity: $\\vec{\\Omega} = \\Omega (\\sin \\theta \\vec{e}_{1} - \\cos \\theta \\vec{e}_{3})$ around its end fixed at point O. The coordinate frame ($G, \\vec{e}_{1}, \\vec{e}_{2}, \\vec{e}_{3}$) is a principal axis frame. The moments of inertia of the thin rod are:\n\n$I_{G1} = I_{G3} \\equiv I_{G} = \\frac{1}{12} Ml^{2}; \\: I_{G2} = 0$",
    "- Centre of mass theorem:\n$\\vec{F}_{ext} = \\vec{P} + \\vec{T} = M\\vec{A}_G \\text{ (Centripetal acceleration)}$\nalong $\\vec{e}_{x_1}$: $T\\sin\\alpha = -\\frac{M}{2}\\sin\\theta \\Omega^2$\nalong $\\vec{e}_{x_2}$: $Mg - T\\cos\\alpha = 0$\n$(A.13.5) \\text{ and } (A.13.6)$\n\n- Angular momentum:\n$\\vec{L}_G = I_G \\vec{\\Omega}$\n$\\vec{\\Omega} = \\Omega_1 \\vec{e}_{x_1} + I_{G_2} \\Omega_2 \\vec{e}_{x_2} + I_{G_3} \\Omega_3 \\vec{e}_3$\nwhere $I_{G_1} = I_{G_3} = I_G$; $I_{G_2} = 0$\n$\\vec{e}_1 = R \\sin\\theta$; $\\Omega_2 = -\\Omega \\cos\\beta$; $\\Omega_3 = 0$\nThus, $\\vec{L}_G = I_G \\Omega \\sin\\theta \\vec{e}_1 \\quad (A.13.7)$",
    "- Poisson formula:\n$$\\dot{\\overrightarrow{e_1}} = \\overrightarrow{\\Omega} \\times \\overrightarrow{e_1} = \\Omega (\\sin \\alpha \\overrightarrow{e_3} - \\cos \\alpha \\overrightarrow{e_2}) \\times \\overrightarrow{e_1}$$\n$$ = \\Omega \\cos \\alpha \\overrightarrow{e_3}$$\n\n- Time derivative of the angular momentum:\n$$\\frac{d\\overrightarrow{L}}{dt} = IG \\Omega \\sin \\theta \\dot{\\overrightarrow{e_1}}$$\n$$ = IG \\Omega^2 \\sin \\theta \\cos \\theta \\overrightarrow{e_3} \\quad \\text{(A.13.8)}$$\n\n- External torque (tension):\n$$\\overrightarrow{T}^{\\text{ext}} = \\overrightarrow{G_0} \\times \\overrightarrow{r} = - \\frac{L}{2} \\overrightarrow{e_2} \\times T (\\sin (\\theta - \\alpha) \\overrightarrow{e_3} - \\cos (\\theta - \\alpha) \\overrightarrow{e_2})$$\n$$ = \\frac{1}{2} LT \\sin (\\theta - \\alpha) \\overrightarrow{e_3}$$\n$$ = - \\frac{1}{2} LT \\sin (\\alpha - \\theta) \\overrightarrow{e_3} \\quad \\text{(A.13.9)}$$",
    "- Angular momentum theorem:\n\\[\n\\vec{L}_{ext} = \\frac{d\\vec{L}_G}{dt}\n\\]\nalong $\\vec{e}_3$:\n\\[\n-\\frac{1}{2}TL\\sin\\alpha\\cos\\theta = I_G\\dot{\\Omega}_2\\sin\\theta\\cos\\theta\n\\]\n\\[\n\\Rightarrow TL(\\sin\\alpha\\cos\\theta - \\cos\\alpha\\sin\\theta)\n\\]\n\\[\n= -2 I_G \\dot{\\Omega}_2 \\sin\\theta \\cos\\theta \\quad \\text{(A.13.10)}\n\\]\n\n- Centre of mass theorem: (A.13.5) and (A.13.6)\n\\[\nT\\sin\\alpha = \\frac{1}{2}ML\\sin\\theta\\Omega^2 \\quad \\text{and} \\quad T\\cos\\alpha = Mg\n\\]\n\n- Thus, (A.13.10) becomes\n\\[\n\\frac{1}{2}ML^2\\sin\\theta\\cos\\theta\\dot{\\Omega}^2 - Mg L \\sin\\theta = -2 I_G \\dot{\\Omega}_2 \\sin\\theta \\cos\\theta \\quad \\text{(A.13.11)}\n\\]",
    "- Nutation angle : \\( \\frac{1}{\\sin \\theta} \\) (A.13.11)\n\n\\[ \\left( \\frac{1}{2} ML^2 + 2I_G \\right) \\Omega^2 \\cos \\theta = MgL \\quad \\text{(A.13.12)} \\]\n\n\\[\n\\Rightarrow \\cos \\theta = \\frac{MgL}{\\left( \\frac{1}{2} ML^2 + 2I_G \\right) \\Omega^2}\n\\]\n\nwhere \\( I_G = \\frac{1}{12} ML^2 \\).\n\nThus,\n\n\\[\n\\cos \\theta = \\frac{MgL}{\\frac{2}{3} ML^2 \\Omega^2} = \\frac{3}{2} \\frac{g}{L \\Omega^2}\n\\]\n\n\\[\n\\Rightarrow \\theta = \\arccos \\left( \\frac{3}{2} \\frac{g}{L \\Omega^2} \\right) \\quad \\text{(A.13.13)}\n\\]",
    "Chapter 4\n\nHARMONIC OSCILLATOR AND CIRCULAR MOTION",
    "4. Harmonic oscillator and circular motion\n\n4.1 Harmonic oscillator\n4.2 Damped harmonic oscillator\n4.3 Circular motion and angular velocity",
    "4.1 Harmonic oscillator\n\n- Universal vibration model (physics, chemistry, engineering)\n1) Quantum mechanics (atomic, molecular and solid vibrations, and quarks)\n2) Engineering (industrial applications: reduction of vibrations)\n3) Cosmology (fluctuation of matter density $\\Rightarrow$ formation of galaxies)\n4) Finance (fluctuation of the stock market)\n\nvibrations (phonons)",
    "4.1.1 Elastic force\n\nModel: In the elastic deformation regime, the elastic force is proportional to the deformation and it is opposed to the motion.\n\nHooke\u2019s law: $F_e = -kr \\quad \\text{where} \\quad k > 0 \\quad \\text{(4.1)}$\n\n$k$ = elastic constant\n\nExamples: object attached to a spring\natoms in a solid",
    "Experiment: measurement of the elastic force exerted on a spring.\n\n- The measurement is performed with a force and a displacement sensor by pulling on the spring.\n- In the elastic regime, the deformation is proportional to the applied force (Hooke's law).",
    "Experiment: Harmonic oscillator\n\n- In the air, the oscillation amplitude is constant during several oscillations.\n- In the water, the oscillation amplitude decreases quickly.",
    "4.1.2 Harmonic oscillatory law of motion\n\n- Elastic force: $F_e = -k r \\quad \\text{(4.1)}$\n- Negligible weight: $P \\ll F_e$\n- Negligible friction force: $F_f \\ll F_e$\n- Law of motion:\n  \\[\n  F_{\\text{ext}} = F_e = m a \\quad \\text{(4.2)}\n  \\]\n\n- $(4.1) \\implies (4.2) :$\n  \\[\n  m a = -k r \\quad \\text{(4.3)}\n  \\]\n\n- General case: oscillatory motion in plane\n- Particular case: zero initial velocity $\\implies$ linear oscillatory motion",
    "4.1.3 Harmonic oscillatory equation of motion\n\nHarmonic oscillatory law of motion:\n$$m a = -k r \\quad \\text{(4.3)}$$\n\nLinear harmonic oscillatory law of motion: (axis $Oe_x$)\n$$r = x e_x$$\n$$a = \\ddot{x} e_x$$\n\nHarmonic oscillatory equation of motion: (projection along the axis $Oe_x$)\n$$m \\ddot{x} = -k x \\quad \\text{(4.4)}$$\n\nPulsation (angular velocity): $\\omega \\equiv \\sqrt{\\frac{k}{m}} \\quad \\text{(4.5)}$\n\nEquation of motion:\n$$\\ddot{x} + \\omega^2 x = 0 \\quad \\text{(4.6)}$$",
    "- Harmonic oscillatory equation of motion\n\\[ \\ddot{x} + \\omega^2 x = 0 \\]\n\\[ \\ddot{x} = -\\omega^2 x \\]\n- Mathematical solutions \\((x(t) \\in \\mathbb{C})\\)\n\\[ x(t) = e^{\\pm i \\omega t} = e^{i \\omega t} \\]\n\\[ \\ddot{x} = (\\pm i \\omega)^2 e^{\\pm i \\omega t} = -\\omega^2 e^{\\pm i \\omega t} = -\\omega^2 x \\]\n\n- Mathematical solutions of unit modulus\n\\[ |e^{\\pm i \\omega t}|^2 = e^{i \\omega t} e^{-i \\omega t} = e^{+i \\omega t - i \\omega t} = e^0 = 1 \\]\n\n- Euler formula (graphical solutions)\n\\[ x(t) = e^{\\pm i \\omega t} = \\cos(\\omega t) \\pm i \\sin(\\omega t) \\]\n\n- Physical solutions \\((x(t) \\in \\mathbb{R})\\)\n1) \\[ x(t) = \\cos(\\omega t) = \\frac{e^{i \\omega t} + e^{-i \\omega t}}{2} \\]\n2) \\[ x(t) = \\sin(\\omega t) = \\frac{e^{i \\omega t} - e^{-i \\omega t}}{2i} \\]",
    "- General physical solution \\hspace{2cm} (linear combination of particular solutions)\n\\[ x(t) = A \\cos(\\omega t) + B \\sin(\\omega t) \\qquad (4.9) \\]\n\n- Change of variables: \\hspace{1cm} (A, B) \\rightarrow (C, \\varphi)\n\\[ A = C \\cos \\varphi \\]\n\\[ B = -C \\sin \\varphi \\]\n\\[ \\implies \\; x(t) = C (\\cos \\varphi \\cos(\\omega t) - \\sin \\varphi \\sin(\\omega t)) \\]\n\n- Trigonometric identity: \\hspace{1cm} \\cos(\\omega t + \\varphi) = \\cos(\\omega t) \\cos \\varphi - \\sin (\\omega t) \\sin \\varphi\n\n- General physical solution\n\\[ x(t) = C \\cos (\\omega t + \\varphi) \\qquad (4.10) \\]\n\n\\[ C = \\text{amplitude} \\; [m] \\]\n\\[ \\omega = \\text{pulsation} \\; [s^{-1}] \\]\n\\[ \\varphi = \\text{dephasing angle} \\]\n\\[ f = \\text{frequency} \\; [s^{-1}] \\]\n\\[ T = \\text{period} \\; [s] \\]\n\n\\[ \\omega = 2 \\pi f \\qquad (4.11) \\]\n\n\\[ \\omega = \\frac{2 \\pi}{T} \\qquad (4.12) \\]",
    "- Harmonic oscillator position equation:\n\\[ x(t) = C \\cos(\\omega t + \\varphi) \\quad (4.10) \\]\n\n- Harmonic oscillator velocity equation:\n\\[ \\dot{x}(t) = - \\omega C \\sin(\\omega t + \\varphi) \\quad (4.13) \\]\n\n- Harmonic oscillator acceleration equation:\n\\[ \\ddot{x}(t) = -\\omega^2 C \\cos(\\omega t + \\varphi) \\quad (4.14) \\]",
    "- Other general physical solution:\n\\[ x(t) = C \\sin (\\omega t + \\varphi') \\quad (4.15) \\]\n\\[ \\varphi' = \\varphi + \\frac{\\pi}{2} \\]\n\n- The constants \\((C, \\varphi)\\) or \\((C, \\varphi')\\) are determined by the initial conditions imposed on the position and the velocity.\n\n- Experiment: torsion pendulum.",
    "4.1.4 Initial conditions\n\n- Initial condition (position): $x(0) = x_0 \\quad (4.18)$\n- Initial condition (velocity): $\\dot{x}(0) = 0 \\quad (4.19)$\n- Position equations: $(4.10)$ or $(4.15)$\n\\[\nx(t) = C \\cos (\\omega t + \\varphi) \\quad \\text{or} \\quad x(t) = C \\sin (\\omega t + \\varphi')\n\\]\n- Velocity equations: $(4.13)$ or $(4.16)$\n\\[\n\\dot{x}(t) = - \\omega C \\sin (\\omega t + \\varphi) \\quad \\text{or} \\quad \\dot{x}(t) = \\omega C \\cos (\\omega t + \\varphi')\n\\]\n\n$(4.19) \\Rightarrow (4.13) \\quad \\text{and} \\quad (4.16): \\quad \\varphi = 0 \\quad \\text{and} \\quad \\varphi' =\\dfrac{\\pi}{2} \\quad (4.20)$\n\n$(4.18) \\Rightarrow (4.10) \\quad \\text{and} \\quad (4.15): \\quad C = x_0$\n\n- Particular solution:\n\\[\nx(t) = x_0 \\cos (\\omega t) = x_0 \\sin \\left( \\omega t + \\dfrac{\\pi}{2} \\right) \\quad (4.22)\n\\]",
    "4.2 Damped harmonic oscillator\n\n4.2.1 Damped harmonic oscillatory law of motion\n\n- Elastic force: $F_e = -kr \\quad (4.1)$\n- Viscous friction force: $F_f = -bv \\quad (3.3)$\n- Negligible weight: $P \\ll F_e$\n- Law of motion:\n\\[\n\\sum F_{\\text{ext}} = F_e + F_f = ma \\quad (4.23)\n\\]\n\\[\nma = -kr - bv \\quad (4.24)\n\\]\n\n- Three regimes:\n1) $||F_f|| \\ll ||F_e||$ weak damping\n2) $||F_f|| \\sim ||F_e||$ critical damping\n3) $||F_f|| \\gtrsim ||F_e||$ strong damping",
    "4.2.2 Damped harmonic oscillatory equation of motion\n\n- Damped harmonic oscillatory law of motion:\n\\[ ma = -kr - bv \\quad (4.24) \\]\n\n- Linear motion: (along the axis \\(Oe_x\\))\n\\[ r = xe_x \\quad v = \\dot{x}e_x \\quad a = \\ddot{x}e_x \\]\n\n- Damped harmonic oscillatory equation of motion: (projection along the axis \\(Oe_x\\))\n\\[ m\\ddot{x} = -b\\dot{x} - kx \\quad (4.25) \\]\n\n- Pulsation (without friction):\n\\[ \\omega_0 \\equiv \\sqrt{\\frac{k}{m}} > 0 \\quad (4.26) \\]\n\n- Damping factor:\n\\[ \\gamma \\equiv \\frac{b}{2m} > 0 \\quad (4.27) \\]\n\n- Equation of motion:\n\\[ \\ddot{x} + 2\\gamma \\dot{x} + \\omega_0^2 x = 0 \\quad (4.28) \\]",
    "- Equation of motion:\n$$\\ddot{x} + 2 \\gamma \\dot{x} + \\omega_0^2 x = 0 \\quad \\text{(4.28)}$$\n\n- Mathematical solution $ \\left( x(t) \\in \\mathbb{C} \\right) \\quad \\lambda \\in \\mathbb{C} $\n$$x(t) = e^{\\lambda t} = e^{(\\text{Re}(\\lambda) + i \\text{Im}(\\lambda))t} = e^{\\text{Re}(\\lambda)t} e^{i \\text{Im}(\\lambda)t} \\quad \\text{(4.29)}$$\n\n- Characteristic equation (4.29) $\\Rightarrow$ (4.28):\n$$e^{\\lambda t} \\left( \\lambda^2 + 2 \\gamma \\lambda + \\omega_0^2 \\right) = 0 \\quad \\Rightarrow \\quad \\lambda^2 + 2 \\gamma \\lambda + \\omega_0^2 = 0$$\n\n- Roots:\n$$\\lambda_1 = -\\gamma + \\sqrt{\\gamma^2 - \\omega_0^2} \\quad \\text{and} \\quad \\lambda_2 = -\\gamma - \\sqrt{\\gamma^2 - \\omega_0^2} \\quad \\lambda_1, \\lambda_2 \\in \\mathbb{C} \\quad \\text{(4.31)}$$",
    "Characteristic equation (4.29) \u21d2 (4.28):\n\\[ e^{\\lambda t} (\\lambda^2 + 2\\gamma \\lambda + \\omega_0^2) = 0 \\quad \\Rightarrow \\quad \\lambda^2 + 2\\gamma \\lambda + \\omega_0^2 = 0 \\]\n\nRoots:\n\\[ \\lambda_1 = -\\gamma + \\sqrt{\\gamma^2 - \\omega_0^2} \\quad \\text{and} \\quad \\lambda_2 = -\\gamma - \\sqrt{\\gamma^2 - \\omega_0^2} \\quad \\lambda_1, \\lambda_2 \\in \\mathbb{C} \\quad (4.31) \\]\n\nGeneral mathematical solution:\n\\[ x(t) = A_1 e^{\\lambda_1 t} + A_2 e^{\\lambda_2 t} \\quad A_1, A_2 \\in \\mathbb{C} \\quad (4.32) \\]\n\nThree regimes:\n1) \\(\\gamma < \\omega_0 \\quad \\Rightarrow \\quad \\text{weak damping}\\)\n2) \\(\\gamma = \\omega_0 \\quad \\Rightarrow \\quad \\text{critical damping}\\)\n3) \\(\\gamma > \\omega_0 \\quad \\Rightarrow \\quad \\text{strong damping}\\)",
    "4.2.3 Weak damping $(\\gamma < \\omega_0)$\n* General mathematical solution: $x(t) \\in \\mathbb{C}$\n$$ x(t) = A_1 e^{\\lambda_1 t} + A_2 e^{\\lambda_2 t} \\quad where \\quad A_1, A_2, \\lambda_1, \\lambda_2 \\in \\mathbb{C} \\tag{4.32} $$\n\n* Roots:\n$$ \\lambda_1 = -\\gamma + i \\omega; \\quad \\lambda_2 = -\\gamma - i \\omega = \\lambda_1^*; \\quad \\omega = \\sqrt{\\gamma^2 - \\omega_0^2} \\in \\mathbb{R}_+ \\tag{4.34} $$\n\n* Physical solution: $x(t) \\in \\mathbb{R} \\quad \\Rightarrow \\quad A_1 = A \\in \\mathbb{C}; \\quad A_2 = A^* \\in \\mathbb{C}$\n$$ x(t) = e^{-\\gamma t} \\left( A e^{i \\omega t} + A^* e^{-i \\omega t} \\right) \\quad and \\quad e^{i \\omega t} = \\cos(\\omega t) \\pm i \\sin(\\omega t)$$\n$$ x(t) = e^{-\\gamma t} \\left( \\frac{(A + A^*)}{2} \\cos(\\omega t) + \\frac{(A - A^*) i}{2 i} \\sin( \\omega t) \\right) \\tag{4.35} - \\tag{4.36} $$",
    "- Change of variables:\n$$(A + A^*) = C \\cos \\varphi \\quad \\ \\ \\ (A - A^*) i = -C \\sin \\varphi \\quad \\ (4.37)$$\n\n- General physical solution:\n$$x(t) = Ce^{-\\gamma t} (\\cos \\varphi \\cos (\\omega t) - \\sin \\varphi \\sin (\\omega t)) \\quad (4.38)$$\n\n- Trigonometric identity:\n$$\\cos (\\omega t + \\varphi) = \\cos \\varphi \\cos (\\omega t) - \\sin \\varphi \\sin (\\omega t) \\quad (4.39)$$\n\n- General physical solution:\n$$x(t) = Ce^{-\\gamma t} \\cos (\\omega t + \\varphi) \\quad (4.40)$$\n\nHarmonic oscillator where the amplitude $Ce^{-\\gamma t}$ decreases exponentially",
    "4.2.4 - 4.2.5 Strong and critical damping\n\nGeneral mathematical solution: $ x(t) \\in \\mathbb{C} $\n\n$x(t) = A_{1} e^{\\lambda_{1} t} + A_{2} e^{\\lambda_{2} t}$ (4.32)\n\n1. Strong damping $ \\gamma > \\omega $\n\nRoots: \n $\\lambda_{1} = -\\gamma + \\omega \\in \\mathbb{R}$\n $\\lambda_{2} = -\\gamma - \\omega \\in \\mathbb{R}$\n\nPhysical solution: $ x(t) \\in \\mathbb{R} \\Rightarrow A_{1}, A_{2} \\in \\mathbb{R} $ (4.43)\n\n$x(t) = A_{1} e^{\\frac{t}{\\tau_{1}}} + A_{2} e^{\\frac{t}{\\tau_{2}}}$\n\n$\\tau_{1} = \\frac{1}{\\gamma - \\omega} > 0\u00a0; \u00a0 \\tau_{2} = \\frac{1}{\\gamma + \\omega} > 0$\n\n2. Critical damping $ \\gamma = \\omega $ ($ \\omega = 0 ; \\lambda_{1} = \\lambda_{2} = -\\omega $)\n\nPhysical solution (2 indep. parameters/eq. of motion 2\\textsuperscript{nd} order)\n\n$x(t) = (A + Bt) e^{-\\omega t}$ (4.44)",
    "exponentially damped before oscillation\n\n$x(t) = (A + Bt) e^{-\\omega_0 t}$ \\hspace{2cm} (4.44)\n\n$x(t) = A_1 e^{-\\frac{t}{\\tau_1}} + A_2 e^{-\\frac{t}{\\tau_2}}$ \\hspace{2cm} (4.43)\n\n$x(t) = Ce^{-\\gamma t} cos(\\omega t + \\varphi)$ \\hspace{2cm} (4.40)\n\nexponential decrease of the oscillation amplitude $Ce^{-\\gamma t}$",
    "4.2.6 Initial conditions\n\nWeak damping\n- Position equation: $x(t) = Ce^{-\\gamma t} \\cos(\\omega t + \\varphi)$ (4.40)\n\n- Velocity equation:\n\\[\n\\dot{x}(t) = -Ce^{-\\gamma t} (\\gamma \\cos(\\omega t + \\varphi) + \\omega \\sin(\\omega t + \\varphi))\n\\] (4.46)\n\n- Initial conditions: \n\\[\nx(0) = x_0 \\quad \\text{and} \\quad \\dot{x}(0) = 0\n\\] (4.45)\n\n- (4.45b) $\\implies$ (4.46) $\\tan \\varphi = \\frac{\\gamma}{\\omega} \\implies \\varphi = \\arctan \\left( \\frac{\\gamma}{\\omega} \\right) \\] (4.47)\n\n- (4.45a) $\\implies$ (4.40) $\\implies x_0 = C \\cos \\varphi$ (4.48)\n\n- Trigonometric identity:\n\\[\n\\cos \\left( \\theta = \\arctan \\beta \\right) = \\frac{1}{\\sqrt{1 + \\beta ^2 }}\n\\] (4.49)\n\n- (4.49) $\\theta = \\frac{\\gamma}{\\omega} \\implies$ (4.48) \n\\[\nC = \\frac{x_0}{\\cos \\varphi} \\implies x_0 \\sqrt{1 + \\frac{\\gamma^2}{\\omega^2}} \\quad (4.50)\n\\]\n\n- Position equation:\n\\[\nx(t) = x_0 \\sqrt{1 + \\frac{\\gamma^2}{\\omega^2}} e^{-\\gamma t} \\cos \\left( \\omega t - \\arctan \\left( \\frac{\\gamma}{\\omega} \\right) \\right) \n\\] (4.51)",
    "Strong damping\n\n- Position equation: $x(t) = A_1 e^{-\\frac{t}{\\tau_1}} + A_2 e^{-\\frac{t}{\\tau_2}} \\quad (4.43)$\n- Velocity equation: $\\dot{x}(t) = -\\frac{A_1}{\\tau_1} e^{-\\frac{t}{\\tau_1}} - \\frac{A_2}{\\tau_2} e^{-\\frac{t}{\\tau_2}} \\quad (4.52)$\n- Initial conditions: $x(0) = x_0 \\quad \\text{and} \\quad \\dot{x}(0) = 0 \\quad (4.45)$\n- $(4.45a) \\Rightarrow (4.43)$ and $(4.45b) \\Rightarrow (4.52)$:\n  \\[\n  A_1 + A_2 = x_0 \\quad \\text{and} \\quad -\\frac{A_1}{\\tau_1} - \\frac{A_2}{\\tau_2} = 0 \\quad (4.53)\n  \\]\n  \\[\n  \\Rightarrow A_1 = \\frac{x_0 \\tau_2}{\\tau_1 - \\tau_2} \\quad \\text{and} \\quad A_2 = \\frac{x_0 \\tau_1}{\\tau_2 - \\tau_1} \\quad (4.54)\n  \\]\n  $(4.54) \\Rightarrow (4.43)$\n- Position equation: $x(t) = \\frac{x_0}{\\tau_1 - \\tau_2} \\left( \\tau_1 e^{-\\frac{t}{\\tau_1}} - \\tau_2 e^{-\\frac{t}{\\tau_2}} \\right)$",
    "Critical damping\n- Position equation: $x(t) = (A + Bt) e^{-\\omega_0 t}$ (4.44)\n- Velocity equation: $\\dot{x}(t) = (B - \\omega_0 (A + Bt)) e^{-\\omega_0 t}$ (4.56)\n- Initial conditions: $x(0) = x_0$ and $\\dot{x}(0) = 0$ (4.45)\n\n(4.45a) $\\Rightarrow$ (4.44) and (4.45b) $\\Rightarrow$ (4.56):\n$A = x_0$ and $B = A \\omega_0 = x_0 \\omega_0$ (4.57)\n\n(4.57) $\\Rightarrow$ (4.44)\n- Position equation:\n$x(t) = x_0 (1 + \\omega_0 t) e^{-\\omega_0 t}$ (4.58)\n\n- Experiment: Raw egg vs. cooked egg in torsion",
    "4.3 Circular motion and angular velocity\n\n4.3.1 Curvilinear abscissa\n\nCurvilinear abscissa: $s(t)$ distance traveled by a material point $P$ along a curve\n\nScalar velocity: time derivative of the curvilinear abscissa\n\n\\[ v(t) = \\frac{ds}{dt} \\tag{4.59} \\]",
    "4.3.2 Scalar angular velocity\n\nUniform circular motion (UCM) Motion along a circular trajectory of radius $R = \\text{const}$ at scalar velocity $v = \\text{const}$.\n\nCurvilinear abscissa:\n\\[ s(t) = R \\phi (t); \\quad R = \\text{const} \\tag{4.60} \\]\n\nScalar velocity:\n\\[ v = \\frac{ds}{dt} = R \\frac{d\\phi}{dt} = R \\dot{\\phi} \\tag{4.61} \\]\n\nScalar angular velocity:\n\\[ \\omega = \\dot{\\phi} = \\text{const} \\tag{4.62} \\]\n\\[ (4.61) \\quad \\Rightarrow \\quad v = R \\omega \\quad \\text{and} \\quad \\omega = \\frac{v}{R} \\tag{4.63} \\]\n\nIntegration of (4.62) w.r.t. time ($\\phi (0) = 0$)\n\\[ \\phi (t) = \\omega t \\tag{4.65} \\]",
    "4.3.3 Centripetal acceleration\n\n- Position\n  $x(t) = R \\cos(\\omega t) \\quad \\text{and} \\quad y(t) = R \\sin(\\omega t) \\quad (4.66)$\n- Velocity (time derivative of the position)\n  $\\dot{x}(t) = -R \\omega \\sin(\\omega t) \\quad \\text{and} \\quad  \\dot{y}(t) = R \\omega \\cos(\\omega t) \\quad (4.67)$\n- Acceleration (time derivative of the velocity)\n  $\\ddot{x}(t) = -R \\omega^2 \\cos(\\omega t) \\quad \\text{and} \\quad  \\ddot{y}(t) = -R \\omega^2 \\sin(\\omega t) \\quad (4.68)$\n- Position and acceleration vectors:\n  $$\n  \\mathbf{r}(t) = \\left( R \\cos(\\omega t), R \\sin(\\omega t), 0 \\right)\n  $$\n  $$\n  \\mathbf{a}(t) = \\left( -R \\omega^2 \\cos(\\omega t), -R \\omega^2 \\sin(\\omega t), 0 \\right)\n  $$\n  $$\n  \\Rightarrow \\quad \\mathbf{a}(t) = -\\omega^2 \\mathbf{r}(t) \\quad (4.69) \\quad \\Rightarrow \\text{radial acceleration directed towards the centre}\n  $$\n- Centripetal acceleration:\n  $$\n  \\|\\mathbf{a}\\| = R \\omega^2 \\left[ \\cos^2(\\omega t) + \\sin^2(\\omega t) \\right] = R \\omega^2 \\overset{(4.63)}{=} \\frac{v^2}{R} \\quad (4.70)\n  $$",
    "Experiments:\n1. Uniform circular motion:\n\n2. Harmonic oscillatory motion obtained by projection of a uniform circular motion",
    "4.3.4 Angular velocity vector\n\n- Position vector:\n  $$\n  \\mathbf{r} = (R \\cos (\\omega t), R \\sin (\\omega t), 0)\n  $$\n- Velocity vector:\n  $$\n  \\mathbf{v} = (-R\\omega \\sin (\\omega t), R\\omega \\cos (\\omega t), 0)\n  $$\n- Acceleration vector:\n  $$\n  \\mathbf{a} = (-R\\omega^2 \\cos (\\omega t), -R\\omega^2 \\sin (\\omega t), 0)\n  $$\n- Angular velocity vector:\n  $$\n  \\omega = (0, 0, \\omega) = \\text{const}\n  $$\n- Vectorial relations: $\\qquad$ where $||| \\omega ||| = \\omega = \\text{const}$\n  $$\n  \\mathbf{v} = \\dot{\\mathbf{r}} = \\omega \\times \\mathbf{r}\n  $$\n  $$\n  \\mathbf{a} = \\dot{\\mathbf{v}} = \\omega \\times \\mathbf{v} = \\omega \\times (\\omega \\times \\mathbf{r}) \\tag{4.71}\n  $$\n- Centripetal acceleration:\n  $$\n  \\mathbf{a} = \\omega \\times (\\omega \\times \\mathbf{r}) \\qquad \\mathbf{(\\omega \\cdot r)} \\mathbf{\\omega - (\\omega \\cdot \\omega) r} = -\\omega^2 r \\tag{4.72}\n  $$",
    "Chapter 9\n\nANGULAR MOMENTUM, TORQUE AND LAW OF GRAVITATION",
    "9. Angular momentum, torque and law of gravitation\n\n9.1 Angular momentum and torque\n9.2 Law of universal gravitation",
    "9.1 Angular momentum and torque\n\n9.1.1 Angular momentum\n\nAngular momentum: extensive and axial vectorial quantity $L_O$, defined with respect to a point $O$, associated to the rotational motion of a material point $P$ around $O$ (in plane).\n\n$ L_O = OP \\times p = r \\times p \\tag{9.1} $\n\n- Physical unit (SI): $\\left[ \\dfrac{\\text{kg} \\text{m}^2}{\\text{s}} \\right]$\n\nNewton introduced the concept of areal velocity but it is Bernoulli who first used a vectorial extensive quantity to characterise a rotational motion.",
    "9.1.2 Torque\n\nTorque: Extensive and axial vectorial quantity $\\tau_O$, defined with respect to a point $O$, associated to the action of a force $F$ on the rotational motion (in plane) of a material point $P$ around $O$.\n\n\\[\n\\tau_O = OP \\times F = r \\times F \\tag{9.2}\n\\]\n\nPhysical unit: $\\left[ \\dfrac{kg \\, m^2}{s^2} \\right]$\n\nQuantity introduced by James Thomson the brother of Lord Kelvin.",
    "9.1.3 Angular momentum theorem\n\nTheorem: The angular momentum theorem states that the time derivative of the angular momentum $L_O$ of a material point equals the sum of the external torques $\\tau_O^{ext}$ exerted on the material point by the external forces $F^{ext}$.\n\n\\[ \\sum \\tau_O^{ext} = \\frac{dL_O}{dt} \\tag{9.3} \\]\n\nDemonstration:\n\n\\[ \\frac{dL_O}{dt} \\ (9.1) = \\frac{d}{dt} (r \\times p) = \\frac{dr}{dt} \\times p + r \\times \\frac{dp}{dt} \\ (2.19) = u \\times m u + r \\times \\sum F^{ext} = \\sum r \\times F^{ext}= \\sum OP \\times F^{ext} = \\sum \\tau_O^{ext} \\tag{9.4} \\]\n\nThe angular momentum theorem is the rotational analog of Newton's 2nd law in translation.",
    "9.1.4 Uniform circular motion\n\nCentripetal acceleration:\n\\[ a = \\omega \\times (\\omega \\times r) = -\\omega^2 r \\quad (4.69) \\]\n\nNet external torque:\n\\[ \\sum \\tau_O^{\\text{ext}} = \\sum OP \\times F^{\\text{ext}} = r \\times \\sum F^{\\text{ext}} = r \\times ma = (4.69) - m \\omega^2 r \\times r = 0 \\quad (9.5) \\]\n\n\\[ \\Rightarrow \\sum \\tau_O^{\\text{ext}} = 0 \\]\n\nAngular momentum:\n\\[ \\sum \\tau_O^{\\text{ext}} = \\frac{dL_O}{dt} = 0 \\Rightarrow L_O = \\text{const} \\quad (9.6) \\]\n\nFor a circular motion around a vertical axis containing the point \\( O \\),\n\\[ \\sum \\tau_O^{\\text{ext}} = 0 \\] and \\[ L_O = \\text{const} = I_O \\omega \\] where \\[ I_O > 0 \\]",
    "**Experiment**: Smoke vortex\n\n- Pulling and releasing the membrane at the back of the cube, a smoke vortex can be created at the hole.\n- The rotation of the smoke in two opposite regions of the vortex (torus) occurs in opposite directions. Thus, the angular momenta $L_0$ and $L_0'$ are opposed and compensate each other such that the angular momentum of the vortex always cancels out.",
    "9.2 Law of universal gravitation\n\nKepler\u2019s laws: (celestial mechanics)\n\n1) Law of orbits: The planetary orbits are ellipses where the sun is located at a focal point.\n\n2) Law of areas: The area swept by the position vector, centered on the sun, per unit of time is a constant.\n\n3) Law of periods: The ratio of the orbital period squared divided by the semi-major axis of the ellipse cubed is a constant.",
    "**Experiment**: Central force and Kepler's 2nd law\n\nThe gravitation force, like the tension in the rope attached to the puck, is a central force directed at all times towards a fixed point, namely the sun. The areas swept during equal times are equal.\n\nChapter 9: Angular momentum, torque, and the law of gravitation",
    "- Planar motion of the earth in polar coordinates:\n- Position vector:\n$$\nr = \\rho e_{\\rho}\n$$\n(5.5)\n\n- Velocity vector:\n$$\nv = \\dot{\\rho} e_{\\rho} + \\rho \\dot{\\phi} e_{\\phi}\n$$\n(5.8)\n\n- Angular momentum:\n$$\nL_O = r \\times p = mr \\times v = m\\rho e_{\\rho} \\times (\\dot{\\rho} e_{\\rho} + \\rho \\dot{\\phi} e_{\\phi})= m\\rho^2 \\dot{\\phi} e_z\n$$\n(9.7)\n\n\u21d2 The angular momentum is orthogonal to the planar motion\n\n- Gravitational torque:\n$$\n\\tau_O = \\frac{dL_O}{dt} = m\\rho \\left(2 \\dot{\\rho} \\dot{\\phi} + \\rho \\ddot{\\phi}\\right) e_z\n$$\n(9.8)",
    "9.2.1 Kepler's 1st law\n\n- The motion of the earth in $P$ around the sun in $O$ is an ellipse of focal points $O$ and $O'$.\n- Ellipse: geometric locus of the points $P$ where the sum of the distances to the focal points is constant:\n- Ellipse in polar coordinates\n\n\\[\n\\rho + \\rho' = \\rho + \\sqrt{(\\rho \\sin \\phi')^2 + (2c + \\rho \\cos \\phi')^2} = 2a = \\text{const}\n\\]\n\n\\[\n\\Rightarrow \\rho = \\frac{a (1 - e^2)}{1 + e \\cos \\phi} \\quad \\text{(9.10)}\n\\]\n\nwhere $e = c / a$ is the eccentricity of the ellipse\n(circle: $e = 0$ and ellipse: $0 < e < 1$)",
    "9.2.2 Newton\u2019s 2nd law\n\n- Gravitational force $F_G$ oriented along the line connecting the two material points (attractive, $\\rho = \\rho(\\phi)$):\n\n$$F_G = -F_G(\\rho) \\, e_\\rho \\qquad \\text{where} \\quad F_G(\\rho) > 0 \\quad (9.11)$$\n\n- Law of motion:\n\n$$F_G = m a \\quad (9.12)$$\n\n- Acceleration (polar coordinates):\n\n$$a = (\\ddot{\\rho} - \\rho \\dot{\\phi}^2) \\, e_\\rho + (\\rho \\ddot{\\phi} + 2 \\dot{\\rho} \\dot{\\phi}) \\, e_\\phi \\quad (5.10)$$\n\n- Equations of motion:\n\nalong $e_\\rho$:\n\n$$-F_G(\\rho) = m (\\ddot{\\rho} - \\rho \\dot{\\phi}^2)$$\n\nalong $e_\\phi$:\n\n$$0 = m (\\rho \\ddot{\\phi} + 2 \\dot{\\rho} \\dot{\\phi}) \\quad (9.13)$$",
    "- Gravitational torque:\n\\[\n\\tau = mp(\\dot{\\rho} \\ddot{\\rho} + 2\\rho \\ddot{\\phi}) e_z \\Rightarrow \\tau = \\frac{dL_0}{dt} = 0\n\\]\n\n- Angular momentum:\n\\[\nL_0 = mp^2 \\dot{\\phi} e_z = \\text{const} \\Rightarrow L = mp^2 \\dot{\\phi} = \\text{const}\n\\]\n\n- The angular momentum of the gravitational motion is constant because there is no external torque with respect to the origin. This is due to the fact that the gravitational force $F_G = -F_G(\\rho)e_{\\rho}$ is collinear to the position vector $r = \\rho e_{\\rho}$.\n\n- Scalar angular velocity:\n\\[\n\\dot{\\phi} = \\frac{L}{mp^2}\n\\]",
    "- Radius and angular velocity:\n\\[ \\rho = \\frac{a \\left( 1 - e^2 \\right)}{1 + e \\cos \\phi} \\tag{9.10} \\]\n\\[ \\dot{\\phi} = \\frac{L}{m \\rho^2} \\tag{9.15} \\]\n\n- Radial velocity: time derivative of (9.10)\n\\[ \\dot{\\rho} = e \\dot{\\phi} \\sin \\phi \\quad \\frac{a \\left( 1 - e^2 \\right)}{\\left(1 + e \\cos \\phi \\right)^2} = \\frac{eL}{m a \\left( 1 - e^2 \\right)} \\sin \\phi \\tag{9.16} \\]\n\n- Radial acceleration: time derivative of (9.16)\n\\[ \\ddot{\\rho} = \\frac{eL}{m a \\left( 1 - e^2 \\right) } \\dot{\\phi} \\cos \\phi \\quad \\left(9.15 \\right) \\Rightarrow \\quad \\frac{e L^2}{m^2 a \\left(1 - e^2 \\right)^2 \\rho^2} \\cos \\phi \\tag{9.17} \\]\n\n- Gravitational force:\n\\[ F_G (\\rho) \\quad \\left(9.13 \\right) \\Rightarrow \\quad  m \\left( \\rho \\dot{\\phi}^2 - \\ddot{\\rho} \\right) \\quad \\left(9.10 \\right) \\Rightarrow \\quad \\frac{L^2}{m a \\left( 1 - e^2 \\right)^2 \\rho} \\left( \\frac{a \\left(1 - e^2 \\right)}{\\rho} - e \\cos \\phi \\right)  \\tag{9.18} \\]",
    "- Gravitational force:\n\n$F_G(\\rho) \\quad (9.13) \\quad m (\\ddot{\\rho} - \\dot{\\rho} \\dot{\\phi}) \\quad (9.15) \\quad (9.17) \\quad \\dfrac{L^2}{ma(1-e^2)\\rho^2} \\left( \\dfrac{a(1-e^2)}{\\rho} - \\cos \\phi \\right)$\n\n$\\dfrac{L^2}{ma(1-e^2)\\rho^2} \\quad (9.18)$\n\n$\\Rightarrow \\quad F_G(\\rho) = \\dfrac{K}{\\rho^2} \\quad \\text{where} \\quad K=\\dfrac{L^2}{ma(1-e^2)} = \\text{const} > 0 \\quad (9.19)$\n\n$\\Rightarrow \\quad F_G = - \\dfrac{K}{\\rho^2} e_{\\rho} \\quad (9.11)$",
    "9.2.3 Kepler\u2019s 3rd law\n\nInfinitesimal time interval:\n$$\n\\dot{\\phi} = \\frac{d\\phi}{dt} = \\frac{L}{m\\rho^2} \\quad \\Rightarrow \\quad dt = \\frac{m\\rho^2}{L} d\\phi \\quad (9.20)\n$$\n\nOrbital period: $\\phi \\in \\left[0, 2\\pi \\right) $  and $\\rho = \\rho (\\phi)$\n$$\nT = \\int_{0}^{T} dt = \\int_{0}^{2\\pi} \\frac{m\\rho^2}{L} d\\phi \\quad (9.10) \\quad ma^2 (1-e^2)^2 = \\int_{0}^{2 \\pi} \\frac{d\\phi}{(1+ e \\cos\\phi)^2} \\quad (9.21)\n$$\n\nIntegral computed with Mathematica ($u = \\tan (\\phi/2)$):\n$$\n\\int_{0}^{2\\pi} \\frac{d\\phi}{(1+e \\cos\\phi)^2} = \\frac{2\\pi}{(1-e^2)^{3/2}} \\quad (9.22)\n$$",
    "\u2022 Orbital period: (9.22) \u21d2 (9.21)\n\n\\[ T = \\frac{2 \\pi ma^2 (1 - e^2)^{1/2}}{L} \\]\n\n\u2022 Kepler\u2019s 3rd law:\n\n\\[ \\frac{T^2}{a^3} = \\text{const} \\ \\ \\ (9.23) \\]\n\n\\[ \\Rightarrow \\frac{T^2}{a^3} = \\frac{4 \\pi^2 m^2 a (1 - e^2)}{L^2} \\ (9.19) \\ \\frac{4 \\pi^2 m}{K} = \\text{const} \\ \\ \\Rightarrow \\ K \\propto m \\ \\ \\ (9.24) \\]",
    "- Constant: $K \\propto m$ where $m = \\text{mass of the earth}$\n\n- According to Newton's 3rd law, the gravitational force exerted by the sun on the earth $F_G$ is of equal norm and opposite orientation to the force exerted by the earth on the sun $-F_G$. According to Newton's 2nd law, the force is proportional to the mass of the material point. Thus, the force $-F_G$ exerted by the earth on the sun is proportional to the mass $M$ of the sun.\n\n- Constant: $K \\propto M$ where $M = \\text{mass of the sun}$\n\n$$\\Rightarrow  K = GMm \\quad (9.25) \\quad  G = \\text{universal gravitational constant}$$\n\n$$\\Rightarrow  F_G = -\\dfrac{K}{\\rho^2} e_\\rho = -\\dfrac{GMm}{\\rho^2} e_\\rho$$",
    "9.2.4 Law of universal gravitation\n\nLaw of universal gravitation:\nTwo massive material points are subjected to attractive gravitational forces that are equal and opposite, proportional to the product of the masses and inversely proportional to the square of the distance that separates them.\n\n\\[ F_G = - \\frac{GMm}{r^2} \\hat{r} \\quad \\text{where} \\quad \\hat{r} = \\frac{r}{r} \\] \n(9.26)\n\n- Universal gravitational constant\n\\[ G = 6.67 \\cdot 10^{-11} \\left[ \\frac{m^3}{kg \\; s^2} \\right] \\]",
    "Experiment: Measurement of the constant $G$\n\n1. Balance of Cavendish\n\nThe universal gravitational constant $G$ is measured using a torsion pendulum consisting of two small masses attached to a rod oscillating in a horizontal plane due to the attraction of the gravitational force generated by the two large masses.",
    "9.2.5 Constants of motion\n\n- Gravitational motion equation:\n\n$$\nm(\\ddot{\\rho} - \\rho \\dot{\\phi}^2) = -\\frac{K}{\\rho^2} \\quad \\text{where} \\quad \\dot{\\phi} = \\frac{L}{m\\rho^2} \\tag{9.15}\n$$\n\n$$\n\\Rightarrow m\\ddot{\\rho} - \\frac{L^2}{m\\rho^3} + \\frac{K}{\\rho^2} = 0 \\tag{9.27}\n$$\n\n- To integrate (9.27), we multiply by $\\dot{\\rho}$ :\n\n$$\nm\\ddot{\\rho}\\dot{\\rho} - \\frac{L^2}{m} \\frac{\\dot{\\rho}}{\\rho^3} + K \\frac{\\dot{\\rho}}{\\rho^2} = \\dot{\\rho} \\left( \\frac{1}{2} m \\dot{\\rho}^2 + \\frac{L^2}{2m \\rho^2} - \\frac{K}{\\rho} \\right) = 0 \\tag{9.28}\n$$\n\n- The integral of (9.28) is the mechanical energy (constant):\n\n$$\nE = \\frac{1}{2} m \\dot{\\rho}^2 + \\frac{L^2}{2m\\rho^2} - \\frac{K}{\\rho} \\tag{9.29}\n$$\n\n(no dissipative force)\n\n$$\n(9.15) \\Rightarrow E = \\frac{1}{2} m (\\dot{\\rho}^2 + \\dot{\\phi}^2 \\rho^2) - \\frac{K}{\\rho} = \\frac{1}{2} m v^2 - \\frac{K}{\\rho} = T + V_G \\tag{9.30}\n$$",
    "- The integral (9.28) is the mechanical energy (constant):\n\n$$E = \\frac{1}{2}m\\dot{\\rho}^2 + \\frac{L^2}{2m\\rho^2} - \\frac{K}{\\rho} \\quad (9.29) \\quad (\\text{no dissipative force})$$\n\n$$(9.15) \\Rightarrow E = \\frac{1}{2} m \\left(\\dot{\\rho}^2 + \\rho^2\\dot{\\phi}^2 \\right) - \\frac{K}{\\rho} = \\frac{1}{2} mv^2 - \\frac{K}{\\rho} = T + V_G \\quad (9.30)$$\n\n- Gravitational potential energy:\n\n$$V_G = -\\frac{K}{\\rho} = -\\frac{GMm}{\\rho} \\quad (9.31)$$",
    "Laplace - Runge - Lenz vector\n\n- Angular momentum:\n\\[\nL_O = r \\times p = mp e_\\rho \\times (\\dot{\\rho} e_\\rho + \\rho \\dot{e}_\\rho) = m\\rho^2 e_\\rho \\times \\dot{e}_\\rho \\quad (9.33)\n\\]\n\n- Acceleration vector:\n\\[\na = \\frac{F_G}{m} = -\\frac{K}{m\\rho^2} e_\\rho \\quad (9.32)\n\\]\n\n\\[\na = \\dot{T} \\Rightarrow L_O \\times a = -K (e_\\rho \\times \\dot{e}_\\rho) e_{\\rho} = -K \\dot{e}_{\\rho}  (9.34)\n\\]\n\n- Constants: $L_O$ and $K$ $L_O = 0 \\quad \\text{and} \\quad K = 0$ \n\\[\n\\frac{d}{dt} \\left(L_O \\times \\dot{r} + K e_{\\rho}\\right) = L_O \\times a + K\\dot{e}_{\\rho}  (9.34) \\Rightarrow 0  (9.35)\n\\]\n\n- Laplace \u2013 Runge-Lenz vector:\n\\[\nL_O \\times v + K e_{\\rho} = const.\n\\]\n\n- Eccentricity vector: (collinear to semi-major axis)\n\\[\ne = \\frac{1}{K} L_O \\times v + e_{\\rho} = const. \\quad (9.36) \\quad e = ||e||\n\\]",
    "9.2.6 Gravitational orbits\n\n- Mechanical energy:\n\\[\nE = \\frac{1}{2} m \\dot{\\rho}^2 + V_G^{\\text{eff}} \\tag{9.37}\n\\]\n\n- Effective potential energy:\n\\[\nV_G^{\\text{eff}} = \\frac{L^2}{2m\\rho^2} - \\frac{K}{\\rho} \\tag{9.38}\n\\]\n\n- Limits:\n1)\n\\[\n\\lim_{\\rho \\to \\infty} V_G^{\\text{eff}} = \\lim_{\\rho \\to \\infty} -\\frac{K}{\\rho} = 0\n\\]\n2)\n\\[\n\\lim_{\\rho \\to 0} V_G^{\\text{eff}} = \\lim_{\\rho \\to 0} \\frac{L^2}{2m\\rho^2} = +\\infty\n\\]",
    "Orbits:\n\nA) Circular orbit $(e = 0): \\quad E < 0; \\quad \\rho_{\\min} = \\rho = \\rho_{\\max}$\n\nB) Elliptic orbit $(0 < e < 1): \\quad E < 0; \\quad \\rho_{\\min} < \\rho < \\rho_{\\max}$\n\nC) Parabolic orbit $(e = 1): \\quad E = 0; \\quad \\rho_{\\min} < \\rho$\n\nD) Hyperbolic orbit $(e > 1): \\quad E > 0; \\quad \\rho_{\\min} < \\rho$",
    "Classical gravitation and general relativity\n\n1) Law of universal gravitation\n\nThe centripetal acceleration exerted by the gravitational force $F_G$ on the moon $\\Rightarrow$ elliptic orbit.\n\n2) General relativity theory\n\nThe curvature of the structure of space-time (membrane with squares) $\\Rightarrow$ elliptic orbit.\n\n1) Classical gravitation:\n\n- Force $F_G$ or potential energy $V_G$ $\\leftrightarrow$\n\n2) General relativity\n\n- Curvature of space-time",
    "Predictions of general relativity\n\n1 Gravitational lensing\nThe presence of the sun distorts the structure of space-time. The lights rays are deviated by this distortion. Their real positions are different from their apparent positions. The sun behaves as a \u00abgravitational\u00bb lens that deviates the beams of stellar light (1st experimental proof of general relativity: 1919)",
    "2) Black holes\n\nIf a mass $M$ is located inside a radius $R$ that is smaller than the Schwarzschild radius $R_s = 2GM/c^2$ then the structure of space-time gives rise to a singularity called black hole since nothing not even light can escape from that hole.",
    "3. Time dilatation\n\nTime does not pass at the same rate on the geostationary orbit as on the earth.\n\n1. A correction is needed for the use of GPS because of the satellites placed on the geostationary orbit.\n\n2. Time difference between sea level and the top of the Everest: 1.5 ms/year.",
    "Cosmology\n\n- Theory of general relativity applied to the universe as a whole.\n\n1) Geometry\n\n$\\Omega_0 > 1$\n\n$\\Omega_0 < 1$\n\n$\\Omega_0 = 1$\n\nMatter curves the universe in a regular manner at the scale of the cosmos.\n\n2) History (expansion)\n\nBig Bang accelerated expansion\n\n0 13.7 G years",
    "Chapter 10\n\nVARIABLE-MASS SYSTEM AND NON-INERTIAL FRAMES OF REFERENCE",
    "10. Variable-mass system and non-inertial frames of reference\n\n10.1 Variable-mass system   \n10.2 Non-inertial frames of reference   \n10.3 Relative motion   ",
    "10.1 Variable-mass system\n\nVariable-mass system \u2261 open system $(m = m(t))$\n\n1) Bath tub\n\n2) Chain\n\n3) Chariot with CO$_2$\n\n4) Rocket",
    "10.1.1 Thrust of a rocket\n\n- Time evolution of the mass of the rocket from $t$ to $t + dt$:\n  \\[m (t + dt) = m (t) + dm \\tag{10.1}\\]\n\n- with $dm < 0$ ejected gas mass\n\n- Momentum (system rocket + gas):\n  \\[p (t + dt) = \\left(m (t) + dm\\right) \\left(v (t) + dv\\right)\\]\n  \\[+ \\left(-dm\\right) \\left(v (t) + u\\right) \\tag{10.2}\\]\n  \n  \\[= m (t) v (t) + m (t) dv + 4mdvdt\\]\n  \\[ - dm u\\]\n\n\\[u\\] = relative ejection velocity of the gas\n\n\\[v\\] = velocity of the rocket",
    "Infinitesimal variation of $p$:\n\n$$dp = p(t+dt) - p(t) = m(t) dv - dm u$$\n\nNewton\u2019s 2\\textsuperscript{nd} law (2.19):\n\n$$\\sum F_{\\text{ext}} = \\frac{dp}{dt} = \\frac{m dv}{dt} - \\frac{dm}{dt} u \\quad (10.4)$$\n\n$$\\Rightarrow \\sum F_{\\text{ext}} + \\frac{dm}{dt} u = m a \\quad (10.5)$$\n\nNegligible friction $\\sum F_{\\text{ext}} = P$:\n\n$$P + \\frac{dm}{dt} u = m a \\quad (10.6)$$\n\nThrust:\n\n$$\\frac{dm}{dt} u \\quad \\text{where} \\quad \\frac{dm}{dt} < 0$$\n\n\n$\\Rightarrow$ The thrust is oriented upwards in the direction of motion because the relative velocity $u$ of the gas is oriented downwards.\n\nwhere: \n\n$u =$ relative ejection velocity of the gas \n\n$v =$ velocity of the rocket",
    "10.1.2 Takeoff condition and velocity\n\n* Law of motion:\n  \\[\n  P + \\frac{dm}{dt} u = ma \\quad (10.6)\n  \\]\n* Projections of vectorial quantities:\n  \\[\n  P = mg = - mg e_z; \\; u = - u e_z; \\; a = \\ddot{z} e_z\n  \\]\n* Equation of motion:\n  \\[\n  - mg - \\frac{dm}{dt} u = m \\ddot{z} \\quad (10.8)\n  \\]\n* Takeoff condition (at \\( t = 0 \\)):\n  \\[\n  \\ddot{z}(0) > 0 \\implies \\left| \\frac{dm}{dt} u \\right| > m(0) g \\quad (10.9)\n  \\]\n\nFor the rocket to takeoff (\\( i.e. \\; \\ddot{z}(0) > 0 \\)) the thrust \\(\\frac{dm}{dt} u \\) has to have a larger norm than the weight \\( P \\).",
    "Experiments:\n\n1. Air fueled rocket\n2. Water fueled rocket\n\nSince the time variation of the mass of water $dm/dt$ is much larger than the time variation of the mass of compressed air, the thrust with water as a \"fuel\" will be much larger than with compressed air\u2026",
    "Equation of motion:\n$$\n\\frac{dz(t)}{dt} = -g - \\frac{u}{m(t)} \\frac{dm(t)}{dt}\n$$\n$$\n\\Rightarrow \\frac{dz(t)}{dt} = -g dt - u \\frac{dm(t)}{m(t)}\n$$\n(10.10)\n\nIntegral of (10.10) with respect to time:\n$$\n\\int_{0}^{t} \\frac{dz(t')}{dt'} = -g \\int_{0}^{t} dt' - u \\int_{0}^{t} \\frac{dm(t')}{m(t')}\n$$\n(10.11)\n\nVelocity:\n$$\nv(t) = -gt - u \\ln \\left( \\frac{m(t)}{m(0)} \\right)\n$$\n(10.12)\n\nSince $m(t) < m(0)$ for $t > 0$,\n\n$$\n\\ln \\left( \\frac{m(t)}{m(0)} \\right) < 0 \\Rightarrow \n$$\nDuring a sufficiently small time interval the second term dominates and the velocity $v(t) > 0$.",
    "- Exponential decrease of mass: (particular model)\n$$\nm(t) = M + (m(0) - M) e^{-t/ \\tau} \\quad \\text{(10.13)}\n$$\n$$\n\\Rightarrow \\lim_{t \\rightarrow 0} m(t) = m(0); \\quad \\lim_{t \\rightarrow \\infty} m(t) = M \\quad \\text{(10.14)}\n$$\n\n- $M$ = mass of the empty rocket.\n\n$$u \\cdot v < 0$$\n\n$$u =$$ relative ejection velocity of the gas\n\n$$v =$$ velocity of the rocket",
    "Velocity\n\n$$v(t) = -gt - u \\ln \\left( \\frac{m(t)}{m(0)} \\right) \\quad (10.12)$$\n\nExponential decrease of mass:\n\n$$m(t) = M + (m(0) - M) e^{-t/\\tau} \\quad (10.13)$$\n\n(10.13) $\\Rightarrow$ (10.12)\n\n$$v(t) = -gt - u \\ln \\left( \\frac{M}{m(0)} + \\left( 1 - \\frac{M}{m(0)} \\right) e^{-t/\\tau} \\right) \\quad (10.15)$$\n\nWe did not take here into account the air friction.",
    "10.2 Non-inertial frames of reference\n\nFrame of reference that has a non zero acceleration with respect to an arbitrary inertial frame of reference.\n\nExample: Rotating frame of reference\n\nThe radial motion of water drops that exit the nozzle is filmed by a camera rotating with the nozzle. In the non-initial frame of the nozzle, the trajectory of the water jet is a fixed curve.",
    "10.2.1 Relative position\n\n- Absolute frame of reference: inertial frame of reference\nThe absolute frame $(O, \\hat{x}_1, \\hat{x}_2, \\hat{x}_3)$ is at rest with respect to the absolute frame of reference.\n- Relative frame of reference: non-inertial frame of reference\nThe relative frame $(A, \\hat{y}_1, \\hat{y}_2, \\hat{y}_3)$ is at rest with respect to the relative frame of reference.\n- Absolute and relative positions of the material point $P$:\n$$\n\\mathbf{r}_a(P) = OP = \\sum_{i=1}^{3} x_i \\, \\hat{x}_i \\quad (10.16) \\quad \\text{and} \\quad \\mathbf{r}_a(A) = OA\n$$\n$$\n\\mathbf{r}_r(P) = AP = \\sum_{i=1}^{3} y_i \\, \\hat{y}_i\n$$\n$$\nOP = OA + AP \\quad (10.16') \\quad \\mathbf{r}_a(P) = \\mathbf{r}_a(A) + \\mathbf{r}_r(P) \\quad (10.17)\n$$",
    "10.2.2 Relative velocity\n\nThe absolute frame $(O, \\hat{x}_1, \\hat{x}_2, \\hat{x}_3)$ is at rest and the relative frame $(A, \\hat{y}_1, \\hat{y}_2, \\hat{y}_3)$ is in translation and in rotation at angular velocity $\\Omega$ with respect to the absolute frame of reference.\n\nTime derivatives of basis vectors (Poisson (5.33)):\n$$ \\dot{\\hat{x}}_i = 0 \\quad \\text{and} \\quad \\dot{\\hat{y}}_i = \\Omega \\times \\hat{y}_i \\quad \\forall \\, i = 1, 2, 3 \\tag{10.18} $$\n\nTime derivative of the position (10.17):\n$$ \\dot{\\vec{r}} (P) = \\dot{\\vec{r}}_a (A) + \\dot{r}_r (P) \\tag{10.19} $$\n\n$$ (10.16) \\quad \\Rightarrow \\quad \\dot{\\vec{r}}_a (P) = \\sum_{i=1}^{3} \\dot{y}_i \\hat{y}_i \\quad \\text{and} \\quad \\dot{\\vec{r}}_r (P) = \\sum_{i=1}^{3} \\dot{y}_i \\hat{y}_i \\quad + \\sum_{i=1}^{3} y_i \\dot{\\hat{y}}_i \\tag{10.20} $$\n\nwhere\n$$ \\sum_{i=1}^{3} y_i \\dot{\\hat{y}}_i \\tag{10.18} $$\n\n$$ \\dot{\\vec{r}}_a (P) = \\sum_{i=1}^{3} \\Omega \\times \\hat{y}_i \\quad \\Rightarrow \\quad \\dot{\\vec{r}}_a (P) = \\Omega \\times \\vec{r}_r (P) $$\n\n$$ (10.16) \\quad \\Omega \\times \\vec{r}_r (P) \\quad \\Rightarrow \\quad \\dot{r}_r (P) = \\sum_{i=1}^{3} \\dot{y}_i \\hat{y}_i + \\Omega \\times \\vec{r}_r (P) $$\n\n$$ \\dot{\\vec{r}} (P) = \\dot{r}_a (P) + \\dot{r}_r (P) $$",
    "- Absolute and relative position of the material point $P$:\n  $$\\mathbf{r}_a(P) = \\sum_{i=1}^{3} x_{i} \\hat{\\mathbf{x}}_{i} \\quad \\text{and} \\quad \\mathbf{r}_r(P) = \\sum_{i=1}^{3} y_{i} \\hat{\\mathbf{y}}_{i} \\quad (10.16)$$\n\n- Time derivatives:\n  $$\\dot{\\mathbf{r}}_a(P) = \\sum_{i=1}^{3} \\dot{x}_{i} \\hat{\\mathbf{x}}_{i} \\quad \\text{and} \\quad \\dot{\\mathbf{r}}_r(P) = \\sum_{i=1}^{3} \\dot{y}_{i} \\hat{\\mathbf{y}}_{i} + \\Omega \\times \\mathbf{r}_r(P) \\quad (10.20)$$\n\n- Absolute and relative velocities:\n  $$\\mathbf{v}_a(P) = \\sum_{i=1}^{3} \\dot{x}_i \\hat{\\mathbf{y}}_i; \\quad \\mathbf{v}_r(P) = \\sum_{i=1}^{3} \\dot{y}_i \\hat{\\mathbf{y}}_i; \\quad \\mathbf{v}_a(A) = \\dot{\\mathbf{r}}_a(A) \\quad (10.22)$$\n  $$(10.19) \\quad \\dot{\\mathbf{r}}_a(P) = \\dot{\\mathbf{r}}_a(A) + \\dot{\\mathbf{r}}_r(P)$$\n  $$(10.20) (10.22) \\quad \\mathbf{v}_a(P) = \\mathbf{v}_a(A) + \\mathbf{v}_r(P) + \\Omega \\times \\mathbf{r}_r(P) \\quad (10.24)$$\n\n- Driving velocity:\n  $$\\mathbf{v}_d(P) = \\mathbf{v}_a(A) + \\Omega \\times \\mathbf{r}_r(P) \\quad (10.25)$$\n  $$(10.24) (10.22) \\quad \\mathbf{v}_a(P) = \\mathbf{v}_d(P) + \\mathbf{v}_r(P) \\quad (10.26)$$",
    "Theorem: The angular velocity $\\Omega$ is independent of the choice of origin $A$ (fixed point) of the relative frame, which is at rest with respect to the relative frame of reference.\n\nDemonstration: Let $B$ be a fixed point $\\Rightarrow \\mathbf{v}_r(B) = 0$\n$$\\mathbf{v}_a (P) = \\mathbf{v}_a (A) + \\mathbf{v}_r (P) + \\Omega \\times \\mathbf{AP} \\quad (10.27)$$\n$$\\mathbf{v}_a (B) = \\mathbf{v}_a (A) + \\Omega \\times \\mathbf{AB} \\Rightarrow \\mathbf{v}_a (A) = \\mathbf{v}_a (B) + \\Omega \\times \\mathbf{BA} \\quad (10.28)$$\n(10.28) $\\Rightarrow$ (10.27)\n$$\\mathbf{v}_a (P) = \\mathbf{v}_a (B) + \\mathbf{v}_r (P) + \\Omega \\times \\mathbf{AB} + \\Omega \\times \\mathbf{AP}$$\n$$= \\mathbf{v}_a (B) + \\mathbf{v}_r (P) + \\Omega \\times (\\mathbf{BA} + \\mathbf{AP}) \\quad (10.29)$$\n$$\\Rightarrow \\mathbf{v}_a (P) = \\mathbf{v}_a (B) + \\mathbf{v}_r (P) + \\Omega \\times \\mathbf{BP} \\quad (10.30)$$\nReplacing point $A$ by point $B$ in (10.27), we obtain (10.30) without changing $\\Omega$.",
    "10.2.3 Relative acceleration\n\nTime derivative of the absolute velocity (10.24):\n$\\dot{\\mathbf{v}}_{a} (P) = \\dot{\\mathbf{v}}_{a} (A) + \\dot{\\mathbf{v}}_{r} (P) + \\mathbf{\\Omega} \\times \\dot{\\mathbf{r}}_{r} (P) + \\dot{\\mathbf{\\Omega}} \\times \\mathbf{r}_{r} (P) \\quad $(10.31)\n\n(10.22) $\\Rightarrow \\mathbf{v}_{a} (P) = \\sum_{i=1}^{3} \\dot{x}_i \\hat{\\mathbf{x}}_i \\quad $ and $\\quad \\dot{\\mathbf{r}}_{r} (P) = \\sum_{i=1}^{3} \\dot{y}_i \\hat{\\mathbf{y}}_i$\n\\begin{equation*}\n\\text{where} \\quad \\sum_{i=1}^{3} \\dot{y}_i \\hat{\\mathbf{y}}_i (10.18) = \\sum_{i=1}^{3} \\dot{y}_i (\\mathbf{\\Omega} \\times \\hat{\\mathbf{y}}_i) = \\mathbf{\\Omega} \\times \\left( \\sum_{i=1}^{3} \\dot{y}_i \\hat{\\mathbf{y}}_i \\right)\n\\end{equation*}\n\n\\begin{equation*}\n\\Omega \\times \\mathbf{r}_{r} (P) \\quad(10.33)\n\\end{equation*}\n\nAbsolute and relative accelerations:\n$\\mathbf{a}_{a} (P) = \\sum_{i=1}^{3} \\ddot{x}_i \\hat{\\mathbf{x}}_i; \\quad \\mathbf{a}_{r} (P) = \\sum_{i=1}^{3} \\ddot{y}_i \\hat{\\mathbf{y}}_i ; \\quad \\mathbf{a}_{a} (A) = \\dot{\\mathbf{v}}_{a} (A) \\quad $(10.34)\n\n$\\mathbf{a}_{a} (P) = \\mathbf{a}_{a} (A) + \\mathbf{a}_{r} (P) + \\mathbf{\\Omega} \\times \\dot{\\mathbf{r}}_{r} (P) + \\mathbf{\\Omega} \\times \\dot{\\mathbf{r}}_{r} (P) + \\dot{\\mathbf{\\Omega}} \\times \\mathbf{r}_{r} (P)$",
    "- Absolute and relative acceleration:\n\n\\[ a_a(P) = a_a(A) + a_r(P) + \\Omega \\times v_r(P) + \\Omega \\times \\dot{r}_r(P) + \\dot{\\Omega} \\times r_r(P) \\]\n\n\\[ \\text{(10.20)} \\quad \\Rightarrow \\quad \\dot{r}_r(P) = v_r(P) + \\Omega \\times r_r(P) \\]\n\n\\[ \\Rightarrow \\quad a_a(P) = a_a(A) + a_r(P) + 2 \\Omega \\times v_r(P) \\]\n\n\\[ \\quad \\quad \\quad \\quad \\quad \\quad + \\Omega \\times \\left( \\Omega \\times r_r(P) \\right) + \\dot{\\Omega} \\times r_r(P) \\quad \\text{(10.37)} \\]",
    "Absolute acceleration:\n\\[ a_{a}(P) = a_{a}(A) + a_{r}(P) + 2\\Omega \\times v_{r}(P) + \\Omega \\times (\\Omega \\times r_{r}(P)) \\]\n\\[ \\quad \\quad \\quad \\quad \\quad \\ \\ \\ + \\dot{\\Omega} \\times r_{r}(P) \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ \\ \\ \\ \\ (10.37) \\]\n\nCoriolis acceleration:\n\\[ a_{C}(P) = 2\\Omega \\times v_{r}(P) \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ \\ (10.38) \\]\n\nCentripetal acceleration:\n\\[ a_{c}(P) = \\Omega \\times (\\Omega \\times r_{r}(P)) \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad (10.38) \\]\n\nEuler acceleration:\n\\[ a_{E}(P) = \\dot{\\Omega} \\times r_{r}(P) \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ \\ \\ \\ \\quad \\ (10.38) \\]\n\nDriving acceleration:\n\\[ a_{d}(P) = a_{a}(A) + a_{E}(P) \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\ (10.39) \\]\n\nThe driving acceleration is the acceleration that the material point \\( P \\) would have if it were fixed with respect to the relative frame of reference (i.e. \\( v_{r}(P) = 0 \\) and \\( a_{r}(P) = 0 \\))\n\\[ \\Rightarrow \\ \\quad a_{a}(P) = a_{d}(P) + a_{r}(P) + a_{C}(P) \\quad (10.40) \\]",
    "10.2.4 Inertial forces\n\n- Law of absolute motion of the material point $P$:\n\n\\[ \\sum F^{\\text{ext}} = m a_a (P) \\tag{10.41} \\]\n\n- Relation between the accelerations :\n\n\\[ a_a (P) = a_d (P) + a_r (P) + a_C (P) = a_a (A) + a_r (P) + a_C (P) + a_c (P) + a_E (P) \\tag{10.40} \\]\n\n- In view of (10.40), the law of absolute motion becomes :\n\n\\[ \\sum F^{\\text{ext}} = m \\left( a_a (A) + a_r (P) + a_C (P) + a_c (P) + a_E (P) \\right) \\tag{10.42} \\]\n\n- Law of relative motion of the material point $P$:\n\n\\[ \\sum F^{\\text{ext}} - m \\left( a_a (A) + a_C (P) + a_c (P) + a_E (P) \\right) = m a_r (P) \\tag{10.43} \\]",
    "Law of relative motion of the material point $P$:\n\\[\n\\sum F^{\\text{ext}} - m \\left( a_a(A) + a_C(P) + a_c(P) + a_E(P) \\right) = m a_r(P) \\quad (10.43)\n\\]\nTranslation force:\n\\[\nF_t = - m a_a(A) \\quad (10.44)\n\\]\nCoriolis force:\n\\[\nF_C = - m a_C(P) = - 2 m \\Omega \\times v_r(P) \\quad (10.44)\n\\]\nCentrifugal force:\n\\[\nF_c = - m a_c(P) = - m \\Omega \\times \\left( \\Omega \\times r_r(P) \\right) \\quad (10.44)\n\\]\nEuler force:\n\\[\nF_E = - m a_E(P) = - m \\dot{\\Omega} \\times r_r(P) \\quad (10.44)\n\\]\nDriving force:\n\\[\nF_d = - m a_d(P) = F_t + F_c + F_E \\quad (10.45)\n\\]",
    "- Law of relative motion:\n\\[\n\\sum F_{\\text{ext}} + F_t + F_C + F_c + F_E = m a_r (P) \\tag{10.46}\n\\]\n\n- Inertial forces $F_{\\text{in}}$:\n\\[\n\\sum F_{\\text{in}} = F_t + F_C + F_c + F_E \\tag{10.47}\n\\]\n\n- Law of relative motion:\n\\[\n\\sum F_{\\text{ext}} + \\sum F_{\\text{in}} = m a_r (P) \\tag{10.48}\n\\]",
    "10.3  Relative motion\n\n10.3.1  Pendulum in an accelerating train\n\n- Absolute frame of reference: rails \n  absolute frame $(O, \\hat{x}_1, \\hat{x}_2)$\n- Relative frame of reference: train \n  relative frame $(A, \\hat{y}_1, \\hat{y}_2)$\n- External forces: (pendulum) \n  weight $P = mg$ and tension $T$\n- Inertial force: $(\\Omega = 0)$ \n  translation force $F_t = - m a_a(A)$\n- Law of relative motion of the material point $P$: \n  \\[\n  \\sum F_{\\text{ext}} + \\sum F_{\\text{in}} = mg + T - m a_a(A) = m a_r (P)\n  \\quad (10.49)\n  \\]",
    "- Equilibrium: $a_r(P) = 0$\n- Law of relative motion: $mg + T - m a_a(A) = 0$\n- Projection of vectorial quantities:\n  $g = - g \\hat{y}_2$\n  $T = T \\sin \\theta \\hat{y}_1 + T \\cos \\theta \\hat{y}_2$\n  $a_a(A) = a \\hat{y}_1$\n- Equations of motion:\n  along $\\hat{y}_1$ : $T \\sin \\theta - ma = 0$\n  along $\\hat{y}_2$ : $- mg + T \\cos \\theta = 0$\n\n$(10.51) \\quad \\Rightarrow \\quad \\tan \\theta = \\frac{a}{g} \\quad (10.52)$",
    "10.3.2 Apparent weight\n\n- Absolute frame of reference: building absolute coordinate axis $ Ox_3 $\n- Relative frame of reference: elevator relative coordinate axis $ Ay_3 $\n- External forces:\n  weight $ P = mg $; tension $ T $\n- Inertial force: $ (\u03a9=0)$ translation force $F_t = -ma_a(A) $\n- Law of relative motion of the material point $P:$ \n$$ \\sum F^{ext} + \\sum F^{in} = mg + T - ma_a(A) = ma_r(P) \\quad (10.49) $$",
    "Equilibrium: $a_r(P) = 0$\n\nLaw of relative motion:\n$mg + T - m a_a(A) = 0$\n\nProjection of the vectorial quantities:\n$g = - g \\hat{y}_3 ; \\quad T = T \\hat{y}_3 ; \\quad a_a(A) = a = a \\hat{y}_3$\n\nEquation of motion:\n\n$-mg + T - ma = 0 \\Rightarrow T = m(g + a)$\n\nApparent weight:\n$P' + T = 0 \\Rightarrow P' = -T = -m(g + a) \\hat{y}_3$\n\n$\\Rightarrow \\quad \\begin{cases} \na > 0 \\quad \\Rightarrow \\quad \\|P' \\| > \\| P \\| \\text{ (UALM upwards)} \\\\\na < 0 \\quad \\Rightarrow \\quad \\|P' \\| < \\| P \\| \\text{ (UALM downwards)}\n\\end{cases}$",
    "10.3.3 Centrifuge\n\n- Absolute frame of reference: laboratory\nabsolute frame $(O, \\vec{x_1}, \\vec{x_2}, \\vec{x_3})$\n- Relative frame of reference: tube\nrelative frame $(O, \\vec{y_1}, \\vec{y_2}, \\vec{y_3})$\n- External forces:\nweight $P = mg$; normal reaction $N$\n- Inertial forces: $(\\hat{\\Omega} = 0; \\vec{a_{A}} = 0)$\ncentrifugal force $F_{c} = - m \\hat{\\Omega} \\times (\\hat{\\Omega} \\times \\vec{r}_{r} (P))$\nCoriolis force $F_{C} = -2m \\hat{\\Omega} \\times \\vec{v}_{r} (P)$\n- Law of relative motion of the material point $P$:\n$$\\sum \\vec{F}^{\\text{ext}} + \\sum \\vec{F}^{\\text{in}} = mg + N + F_{c} + F_{C} = m \\vec{a_{r}} (P) \\tag{10.56}$$",
    "- Law of relative motion:\n\\[ mg + N + F_c + F_C = m a_r (P) \\quad (10.56) \\]\n\n- Relative kinematical quantities:\n\\[ r_r (P) = y_i \\, \\hat{y}_i ; \\quad v_r (P) = \\dot{y}_i \\, \\hat{y}_i ; \\]\n\\[ a_r (P) = \\ddot{y}_i \\, \\hat{y}_i ; \\quad \\Omega = \\dot{\\Omega} \\, \\hat{y}_3 \\quad (10.57) \\]\n\n- External forces:\n\\[ P = mg = - mg \\, \\hat{y}_3 \\]\n\\[ N = N_2 \\hat{y}_2 + N_3 \\hat{y}_3\u00a0\\quad (10.58) \\]\n\n- Inertial forces:\n\\[ F_c = - m \\Omega \\times (\\Omega \\times r_r (P)) = - m \\Omega^2 y_i \\, \\hat{y}_3 \\times (\\hat{y}_3 \\times \\hat{y}_i) = m \\Omega^2 y_i \\, \\hat{y}_i \\] \n\\[ F_c = - 2 m \\Omega \\times v_r (P) = - 2 m \\Omega \\dot{y}_i \\, \\hat{y}_3 \\times \\hat{y}_i = - 2 m \\Omega \\dot{y}_i \\, \\hat{y}_2 \\quad (10.59) \\]",
    "Equations of relative motion:\n\nalong $\\hat{y_1}$: $m \\Omega^2 y_1 = m \\ddot{y_1}$\n\nalong $\\hat{y_2}$: $N_2 - 2m \\Omega \\dot{y_1} = 0$\n\nalong $\\hat{y_3}$: $-mg + N_3 = 0$\n\n(10.60)",
    "- Equation of relative motion along the axis Oy$_{1}$:\n$$\\ddot{y}_{1} - \\Omega^{2} y_{1} = 0 \\quad (10.61)$$\n\n- The other two equations yield the components of the normal reaction force:\n$$N_{2} = 2 m \\Omega \\dot{y}_{1}$$\n$$N_{3} = mg$$\n$$\\Rightarrow N = 2 m \\Omega \\dot{y}_{1} \\hat{y}_{2} + mg \\hat{y}_{3} = -F_{C} - P$$\n$$\\Rightarrow F_{C} = -(P + N)$$\n\nThe Coriolis force is opposed to the reaction force and weight. The centrifugal force determines the motion.\n\n- Position equation:\n$$y_{1}(t) = y_{1}(0) e^{\\Omega t} \\quad (10.62)$$",
    "10.3.4 Pendulum on a rotating door\n\nAbsolute frame of reference: earth  \nabsolute frame $(O, \\hat{x}_1, \\hat{x}_2, \\hat{x}_3)$\n\nRelative frame of reference: door  \nrelative frame $(A, \\hat{r}, \\hat{\\theta}, \\hat{\\phi})$\n\nExternal forces:  \nweight $P = mg$; normal reaction $N$ tension $T$  \n\nInertial forces: $\\hat{\\Omega} = 0$ and $a_a(A) = 0$  \ncentrifugal force $F_c = -m \\Omega \\times (\\Omega \\times r_r (P))$  \n\\[ F_c = -m \\Omega \\times (\\Omega \\times r_r (P)) \\tag{10.67}\\]\n\nCoriolis force $F_C = -2m \\Omega \\times v_r (P)$\n\nLaw of relative motion of the material point $P$:  \n$\\sum F^{ext} + \\sum F^{in} = mg + N + T + F_c + F_C = m a_r (P)$  \n\\[ \\sum F^{ext} + \\sum F^{in} = mg + N + T + F_c + F_C = m a_r (P) \\tag{10.63}\\]",
    "Law of relative motion:\n$$mg + N + T + F_c + F_e = m\\, a_r(P) \\tag{10.63}$$\n\nRelative kinematical quantities:\n$$r_r(P) = \\ell \\hat{r} ; \\quad v_r(P) = \\dot{\\ell} \\hat{r} + \\ell \\dot{\\theta} \\hat{\\theta}$$\n$$a_r(P) = -\\ell \\dot{\\theta}^2 \\hat{r} + \\ddot{\\ell} \\hat{r} + \\ell \\ddot{\\theta} \\hat{\\theta} \\tag{10.64}$$\n\nExternal forces:\n$$P = mg = mg (\\cos \\theta \\hat{r} - \\sin \\theta \\hat{\\theta})$$\n$$N = - N \\hat{\\Phi} \\quad et \\quad T = -T \\hat{r} \\tag{10.66}$$\n\nAngular velocity:\n$$\\Omega = - \\Omega \\cos \\theta \\, \\hat{r} + \\Omega \\sin \\theta \\, \\hat{\\theta} \\tag{10.65}$$",
    "\u2022 Law of relative motion:\n\\[ mg + R + T + F_c = m \\, a_r (P) \\]\n(10.63)\n\n\u2022 External forces:\n\\[ P = mg = mg (\\cos \\theta \\, \\hat{r} - \\sin \\theta \\, \\hat{\\theta}) \\]\n\\[ R = -R \\, \\hat{r} \\quad et \\quad T = -T \\, \\hat{r} \\]\n(10.66)\n\n\u2022 Inertial forces:\n\\[ F_c = -m \\, \\mathbf{\\Omega} \\times (\\mathbf{\\Omega} \\times r_r (P)) = -m \\, \\ell \\, \\Omega^2 (\\cos \\theta \\, \\hat{r} - \\sin \\theta \\, \\hat{\\theta}) \\times ((\\cos \\theta \\, \\hat{r} - \\sin \\theta \\, \\hat{\\theta}) \\times \\hat{\\phi}) \\]\n\\[ = m \\, \\ell \\, \\Omega^2 \\sin^2 \\theta \\, \\hat{r} + m \\, \\ell \\, \\Omega^2 \\sin \\theta \\cos \\theta \\, \\hat{\\theta} \\]\n(10.67)\n\\[ F_c = -2m \\, \\Omega \\, \\mathbf{\\nu}_r (P) = 2m \\, \\ell \\, \\Omega \\, \\dot{\\theta} (\\cos \\theta \\, \\hat{r} - \\sin \\theta \\, \\hat{\\theta}) \\times \\hat{\\phi} \\]\n\\[ = 2m \\, \\ell \\, \\dot{\\theta} \\cos \\phi \\, \\hat{\\phi} \\]\n\n\u2022 Relative kinematical quantities:\n\\[ r_r (P) = \\ell \\, \\hat{r} ; \\quad \\mathbf{\\nu}_r (P) = \\ell \\, \\dot{\\theta} \\, \\hat{\\theta} ; \\quad a_r (P) = -\\ell \\, \\ddot{\\theta} \\, \\hat{r} + \\ell \\, \\dot{\\theta}^2 \\, \\hat{\\phi}) \\]\n(10.64)",
    "Equations of motion:\n\nalong $\\hat{r}$: $mg \\cos \\theta - T + m \\ell \\Omega^2 \\sin^2 \\theta = - m \\ell \\ddot{\\theta}$\n\nalong $\\hat{\\theta}$: $- mg \\sin \\theta + m \\ell \\Omega^2 \\sin \\theta \\cos \\theta = m \\ell \\ddot{\\ell}$\n\nalong $\\hat{\\phi}$: $- N + 2m \\ell \\dot{\\ell} \\cos \\theta = 0 \\ \\ \\ \\ \\ \\ \\ \\ \\ (10.68)$",
    "- Equation of relative motion:\n\n$$\\ddot{\\theta}+\\left(\\frac{g}{\\ell}-\\Omega^{2}\\cos{\\theta}\\right)\\sin{\\theta}=0 \\tag{10.69}$$\n\nIt is the same equation of motion as for a ball in a ring of radius $\\ell$ rotating at angular velocity $\\Omega = \\text{const}$ around a vertical axis.\n\n- The two other equations yield the expression of the constraint forces:\n\n$$T = -m\\left(g\\cos{\\theta}+\\ell\\dot{\\theta}^{2}+\\ell\\Omega^{2}\\sin^{2}{\\theta}\\right)\\hat{r}$$\n$$N = -2m \\ell \\Omega \\dot{\\theta} \\cos{\\theta} \\hat{\\phi}$$",
    "Solutions to Problem Set 14\nRotation, translation, and rolling\nPHYS-101(en)\n\n1. Wheel pulled by a block\n\n1. Consider the system composed of the wheel and the block (i.e., the two objects in the problem that move and have mass). Since we are asked about the size of the system at a particular position ($x_w$), we enter about the system about a fixed distance $d_1$. It is useful to consider separately forces that are directed along the lines given by angles $\\theta_1$ and $\\theta_2$ when expressed in vectors. We thus know there is altered gravity arising from normal force from the table $N = N_1$ and the friction from the wire $T_x$. Additionally, we can tell that there must be a static friction force $f_x = f_{k1}$ and a retractive force $R = \\nu_1$. Therefore, the friction force in the system must satisfy $\\nu_1 = T \\sin(\\theta_T)$. The last relation appears to merely express the force constant $\\nu$ given in Eq. II of Lecture 13. Examining the different cases $x_w$ and $x_w'$ helps confirm whether $x_w$ is twice as large as the normal force $\\nu_N$ by as small as 10%. \n\nSince we are also asked about the work performed by several forces, the basic conservative-force $\\mathbf{T} = \\mathcal{F}$ (applying the sum of Eq. (34) in Section 8.2). The top surface $A$ across which the block slides and tests friction will bear it in the $\\psi$ position applied here. To this case, the magnitude $k_\\lambda$ is not always positive; henceforth it is applicable for all positions other than further action on basis of basis the problem Fig. $x_w$. Now compute the work done on the system:\n\n$$ \\mathcal{F} = \\oint \\mathbf{f} \\, d\\mathbf{r}$$\n\nThis is the usual derivative work of Eq. 2 by separating as a constant. Since throughout the circle on the inclined plane the area covered by the block is caused $< 3,4\\mathbf{r}$. Now if the newtonian angular transformation makes $\\theta_t$ small, the frictions are very slow work. This mechanical energy is conserved throughout the motion of the system.",
    "The total mechanical energy of the system is given by\n\\[ \nE_{\\text{mech}} = K_{\\text{rot}} + K_{\\text{trans}} + U_{\\text{g}} = \\frac{1}{2} I_{\\text{cm}} \\omega^2 + \\frac{1}{2} m v_{\\text{cm}}^2 + U_{\\text{g}} = \\frac{1}{2} m R^2 \\left( \\frac{m}{2} + \\frac{h^2}{R^2} \\right) \\omega^2 + \\frac{1}{2} m v_{\\text{cm}}^2 - mgh .\n\\]\n(1)\n\nwhere $K_{\\text{rot}}$ is the rotational kinetic energy of the wheel, $K_{\\text{trans}}$ is the translational kinetic energy of the wheel, $U_{\\text{g}}$ is the gravitational potential energy of the falling block, $I_{\\text{cm}}$ is the rotational inertia of the wheel \n\n\\[\nI_{\\text{cm}} = \\frac{1}{2} m R^2 + m h^2,\n\\]\n(2)\n\n $R$ is the radius, $m$ is the translational kinetic energy of the falling block, $h$ is the gravitational potential energy of the block.\n\n\\[\nU_{\\text{g}} = mgh \n\\]\n(3)\n\nIn the moment of inertia of the uniform wheel rotating about its center, it is also the expected potential energy of one end of the system of mass of the wheel, $kg$. Also, to keep the condition of the wheel ideal, a Cartesian coordinate system as shown in the figure above. Using the non-slip conditions, we also consider the speed of the center of the wheel to be\n\n\\[\nv_{\\text{cm}} = R \\omega\n\\]\n(4)\n\nSubstituting this into equation (2) gives us,\n\\[\nE_{\\text{mech}} = \\left( \\frac{1}{2} m \\left[ \\left( R^2 + h^2 \\right) R^2 \\right] \\omega^2 + \\frac{1}{2} m \\left( R \\omega \\right)^2 - m g h \\right)\n\\]\n(5)\n\nSince the wire is tension free, we have carefully defined an coordinate system that is instantaneously both fixed and has the applied torque of $T = R F$ of the system. Taking a difference in energy for the system, we have\n\n\\[\nU_{\\text{new}} = U_{\\text{int}} = 0 \\Rightarrow U_{\\text{pot}} = U_{\\text{elec}} \\Rightarrow\n\\]\n\nSubstituting these two relations into equation (5) \n\n\\[\nE_{\\text{mech}} = \\frac{1}{2} M_{\\text{mass}} R^2 \\omega^2\n\\]\n\nNow we can apply conservation of total energy between the initial state (when everything is at rest) and the final state (when the center of the wheel has moved by a distance y = \u00bd). Solving for v gives us\n\n\\[\nv_f^2 = g h\n\\]\n\nwhere we have solved for the potential energies for the total system and the speed of each object to their initial location. Solving for the final velocity corrected of the wheel gives\n\n\\[\nv_f = \\sqrt{g \\left( h - y \\right)}\n\\]\n\n2) For the wheel not to slip, the static friction force must not exceed its maximum magnitude of \n\n\\[\nf_{\\text{s max}} = \\mu_k .\n\\]\n\nDrawing a free body diagram for the wheel and looking at Newton\u2019s second law in the vertical direction shows that the normal force has a magnitude of $f = m v_f$. Thus, we find\n\n\\[\nF_T = \\left( 2 \\pi \\left( y - 2 \\right) \\right)\n\\]\n(11)",
    "By rearranging we find that the coefficient of static friction must be sufficiently high to satisfy\n\\[ \\mu_s \\geq \\frac{F_{t1}}{m_4 g - F_{n4}} \\] \notherwise the wheel will slip.\nTo be able to determine \\( F_{t1} \\), we must analyze the entire system. We can apply Newton's second law to the wheel of the equation\n\\[ \\sum F_{ext} = ma_r = (m_1 + m_2 + m_3 + m_4)g - T - F_{t1} = m_4 a_c \\]\nIn the horizontal direction, where \\( a_c \\) is the acceleration of the center of the wheel. Applying Newton's second law to the falling block and substituting, equation (13) gives\n\\[ \\sum F_{ext} = m_1 a_1 = m_1 g - T - F_{t1} = m_1 a_1 \\]\nFrom the constraint condition of equation, we find\n\\[ a_1 = \\frac{R}{I} (F_1 - T'_1) \\]\nLastly, applying Newton's second law for the rotational motion of the wheel about its center gives \n\\[ \\sum \\tau_{ext} = (L_f - L_i) = Ryk \\left( k(F_1 - F_2) \\right) \\]\nin the \\( \\hat{i} \\) direction, where \\( \\alpha_r \\) is the angular acceleration of the wheel (which is the derivative of its angular velocity), \\( k \\) is the radius of the wheel, and \\( r \\) the radius to the point of contact of the spring with the ground. Using the condition in equation, we find the angular velocity of the contact point of the wheel with the ground because the contact point is at rest relative to the ground. Substituting equation (14) into equation (15) and dividing both sides by \\( k \\), we find (after rearranging)\n\\[ \\frac{1}{R} \\left( \\frac{1}{m} \\sum_n a \\right) = (m_1 + m_3) \\]\nwhich can be rearranged to\n\\[ F_1 = \\mu_s a_c \\]\nSubstituting this into equation (12) reveals that the condition on the static coefficient of friction to be\n\\[ \\mu_s \\geq \\frac{m_2}{m_1} \\]\nThis is a fundamental solution in some sense, as it is independent of the mass and radius R. The main requirement for it to be applicable is that the wheel and block must have the same mass.",
    "2. Donkey cart\n\n1. Due to the symmetry of the system, the free body diagram for all of the wheels is identical and is shown above. There are four forces on the freely rotating disk: the weight of the wheel of mass $m$ (let $M_g$ be the center of the wheel), the normal force from the axis of the cart, the normal force from the ground, and the static friction force from the ground.\n\n2. To approach the problem, it is best to first think about which objects are rotating purely and then set up the translational and rotational force balance for the wheel and the cart together. Translationally, if we assume the translational motion of the surface of the wheels and the cart must be identical, thus the acceleration of the cart is given as\n\n$a_c = \\frac{F}{(M + 4m)}$,\n\nwhere $a$ is the acceleration of the cart as well as the centers of the wheels. Note that other forces like normal or internal forces within the two-body system play no role and should be balanced out as there are always balance forces for different parts of different bodies.\n\nNow let us look at the rotational motion. When the donkey is at rest and starts to pull the cart with a tensile force such that there is sufficient static friction, Newton\u2019s 2nd law for rotation states the angular momentum relative to the center of the wheel must be conserved. We thus have\n\n$\\sum{I\\ddot{\\theta}} = (RF_f + R_r N_f - \\frac{mR^2}{a}) = (M_g - N_f )R = M_g R N_f = F_r$. (1)\n\nIf we were to consider the force balance at the center of the wheel about its axis, it should also consider a net force of acceleration which also includes the pseudo inertial force of the rotating wheel.\n\nUsing the usual form of translational acceleration rotational equation, the angular acceleration for rolling without slipping (no translation)\n\n$a_c = M_fr - F_r = 0$,\n\nwhere $r$ is the translational velocity of the center of the wheel (and the wheel as a whole). Substituting this into equation (1) gives\n\n$N_f R = \\frac{m}{R} ( \\dot L_{\\theta} = \\ddot{\\theta})$. (2)\n\nSubstituting this into equation (1) allows us to find\n\n$F_f = \\frac{(M + 6m)a}{4} = F_r = \\frac{Ma}{6}\\\\\n\\dot{\\theta} = (M + 6m) = 0,\\\\\na_c = M_f = (a = 0).$\n\n4",
    "Since the acceleration is constant, it is straightforward to integrate this to find that the velocity is \n\\[ v(t) = \\frac{f}{m} t = \\frac{F_s}{m} t \\tag{6} \\]\n\nwhere the problem statement tells us that the initial velocity is $v_0 = 0$. Plugging in the numerical values suggests a total sledding time of $t = \\frac{0.61 \\text{ m/s}^2}{4.00 \\text{ m/s}^2} = 4.10 \\text{ s}$. \n\nTo calculate the required coefficient of static friction to enable rolling motion, we now need to calculate the magnitude of the static friction force. This can be found by substituting equation (5) into equation (4) to yield \n\\[ F_s = \\frac{f F_N}{mg} \\tag{7} \\]\n\nWe then require that this force be less than the maximum possible static friction force \n\\[ f_s \\leq \\mu_s F_N \\tag{8} \\]\n\nThe normal force can be found through the vertical component of Newton\u2019s second law for the entire cart-sled-earth system as \n\\[ \\sum F = 0 \\rightarrow N - mg = 0 \\Rightarrow F_N = mg \\tag{9} \\]\n\nso the acceleration in the $x$ direction is zero. Substituting this into equation (8) gives us \n\\[ F_s = \\frac{(4.00)(f \\sin (60^\\circ))}{(9.8) \\cos (30^\\circ)} \\Rightarrow f \\leq (0.38)f \\Rightarrow \\mu_s = 1 \\tag{10} \\]\n\nPlugging in the numerical values from the problem statement suggests a required coefficient of friction of \n\\[ \\mu_s = \\frac{0.61 \\text{ m/s}^2}{4.00 \\text{ m/s}^2} = 0.2 \\%, \\tag{11} \\]\n\nRemarkably, we see that the diameter of the wheel has no influence on the answer.\n\n3. The hanging spider\n\n1. We will choose to use a one-dimensional Cartesian coordinate system with the origin defined to be the location of the ceiling. If the spider were located at $x = 0$, the spring would have a length of zero.\n\n\\( x = 0 \\)\n\n\\( x = x_{eq} \\)\n\n\\( x = x_f  \\)\n\n\\( x_f \\) ",
    "Thus, the equilibrium position of the spring is at $x = L - a$. In fact this is different than the equilibrium position of the sphere (due to the presence of the gravitational force). We show the free body diagram below. Note that I am taking the center point either up or down depending on the position of the sphere. The equilibrium position of the sphere, i.e., for which the sum of the forces are equal to zero, can be written as $x = -x_{0}$. This is the definition of \u201cequilibrium\u201d. Using Newton\u2019s second law and the forces of the spring force,\n\n\\[F_s = k(L - x - x_0)\\]\n\nwe find\n\n\\[mg - F = 0 \\quad \\Rightarrow \\quad mg - k(L - x - x_0) = 0 \\quad \\Rightarrow \\quad -mg + k(L - x) = - kx_0 \\quad \\Rightarrow \\quad x_0 = \\frac{mg}{k}.\\] \\quad (1)\n\nWe now have that the equilibrium spring force must be pointing up to compensate gravity. Note that the center of mass moves from Newton second law, but the acting forces are rather pointing in negative $k$ direction (positive down because we set $x$ to be increasingly north). At any arbitrary time t, Newton's 2nd law tells us that the acceleration is\n\n\\[a = \\frac{d^2x}{dt^2} =  - \\omega^2\\left( x - L + a + x_0 \\right).\\] \\quad (2)\n\nThis is the equation of motion for the sphere.\n\n3. The problem statement tells us that the general solution to equation (3) has the form\n\n\\[x(t) = A\\cos(\\omega t + \\phi) + L - a - x_0. \\] \\quad (3)\n\nWe can find the values of the constants by substituting equation (3) into equation (2). We start by taking the first and second time derivative of equation (3):\n\n\\[\\frac{dx(t)}{dt} = - A\\omega\\sin(\\omega t + \\phi),\\] \\quad (4) \\[ \\frac{d^2x(t)}{dt^2} = - A\\omega^2\\cos(\\omega t + \\phi) \\] \\quad (5)\n\nrespectively. Substituting equation (4) and (5) into equation (2) gives us\n\n\\[- A\\omega^2\\cos(\\omega t + \\phi) = - \\omega^2\\left(A\\cos(\\omega t + \\phi) - L + a + x_0 \\right).\\] \\quad (6)\n\nTo solve this equation, we note that the motion function cancels out from both hand sides of the equations and we can solve for the remaining phase shifts:\n\n\\[x_0 + L - a \\Leftrightarrow x_0 + x_{eq} = x_0 = \\frac{mg}{k} - \\frac{k(L - a) + mg}{k\\omega^2} = 0.\\] \\quad (7)\n\nHere, since the initial position is the equilibrium position, we set $t = 0$ for both the potential energy and kinetic energy to zero as the motion starts. We find the initial conditions for the first and second derivatives of $t$ all time.\n\nHence, equation (3) now simplifies to\n\n\\[x(t) = L - a + A\\cos(\\omega t + \\phi). \\] \\quad (8)\n\nWe know from equation (3) that $x = x_0$. Thus we can substitute this result into equation (8) at any arbitrary time to get\n\n\\[Acos(\\phi) = L - a - x_0 \\Rightarrow x_0 + a = L - \\frac{mg}{k} - a = 0 \\Rightarrow A = L - a - \\frac{mg}{k} = 0. \\] \\quad (9)\n\nwhere\n\n\\[A(e) \\cos(\\phi + \\omega t) + a(\\omega + 1)T = \\sum_{n = 1} x_0^{-} a x  \\ t \\sum_{n=0}^{2}=A,\\]\n\n\\[A\\Rightarrow L - a = \\lim_{T\\rightarrow 0}T. \\left( 0 + \\frac{x}{k}\\right),\\] \\quad (10) \\[  \\sum_{n=0}^{T}(0)T+n\\rightarrow (\\tau)^{-p}(x_{eq}).\\}.\\] \\quad (11)\n\n\\[\\Rightarrow (\\sum_{n=2}^{T}. T^{e x\\alpha = p})\\left\\{x\\sum_{0}^{T}+ \\frac{\\left(\\Delta_{2}, x\\cos\\omega_{-\\alpha t}}}} \\right\\}.\\] \\quad (12)",
    "The problem states that at time $t_0$ the velocity of the spider is $\\dot x(t_0) = 0$ and the spring does not exert a force on the spider. We can use equation (8) to see that the first condition is equivalent to\n\n\\[\n0 = -A_1 \\omega_1 \\sin (\\omega_1 t_0) - A_2 \\omega_2 \\sin (\\omega_2 t_0)\n\\]\n\nand equation (9) to\n\n\\[\n0 = A_1 \\cos (\\omega_1 t_0) + A_2 \\cos (\\omega_2 t_0).\n\\]\n\nThe sine function vanishes to zero when its argument equals to an integer multiple of $\\pi$. We are free to arbitrarily choose any integer value of n as they all lead to the same value. This implies that\n\n\\[\n\\omega_1 t_0 = n\\pi \\quad \\rightarrow \\quad t_0 = \\frac{n\\pi}{\\omega_1}.\n\\]\n\nUsing equation (13) we can see that the second condition corresponds to\n\n\\[\nA_1 \\cos \\left( \\frac{n\\pi \\omega_2}{\\omega_1} \\right) = -A_2.\n\\]\n\nThe condition $\\dot x(t_0) = 0$ is always met. It is also stating that if the force exerted by the spring is zero at $t_0$, the spider must be starting at the equilibrium position of the spring, i.e. $x(t_0) = 0$. Using equations (10) and (14) we get\n\n\\[\n\\begin{aligned}\n0 &= A_1 \\cos \\left( -\\frac{n\\pi \\omega_2}{\\omega_1} \\right) - A_1\\cos \\left( \\frac{n\\pi \\omega_2}{\\omega_1} \\right) \\\\\n  &= A_1 \\left[ \\cos \\left( \\omega_2 (t + \\frac{n\\pi}{\\omega_1} \\right) \\right),\n\\end{aligned}\n\\]\n\nThis indicates that there are two possible values for $A_1$. However, we can disregard the non-trivial values of $n$ at the initial steps (corresponding to resonances with the specific system of equations) and choose the value of $n=0$ arbitrarily. This choice implies that $t_0 = \\frac{n\\pi}{\\omega_1} = 0$. No other choice will lead to a different solution since it was recognized that they are all equivalent. If we don\u2019t choose that, the above equations must be solved iteratively and numerically (non-trivial), so \u2013 let us check the case $n=0$:\n\n\\[\nA_1 = -A_2,\n\\]\n\nIn that sense we can determine the positions corresponding to $\\dot x (t)=0$ by\n\n\\[\nx (\\dot x = 0) = A_1 (\\cos (\\omega_1 t)) - \\cos (\\omega_2 t) = -2A_1 \\cos (\\omega_{\\pm} t) + 2).\n\\]\n\nThe analysis of the previous equation regarding $\\dot x = 0$ can be done using a trigonometric identity. Remember that $cos2a = 1-2\\sin^2 a$. We can use it to analyze the function $x (\\dot x = 0)$ in a similar way. Using a trigonometric identity to remove the negative signs in the front. The only difference between both expressions above (12) is the choice of the value in an arbitrary interval. Without loss of generality, we are free to choose any interval, thus equation (14) becomes\n\n\\[\nx (\\dot x) = - 2A_1 \\left[ 1 - \\frac{1}{2} \\left( ... \\right) \\right).\n\\]\n\nThe maximum speed of the spider can be found by substituting equation (22) into equation (25) to get\n\n\\[\n\\left( \\sqrt{\\frac{E_2 - E_1}{2k} \\right).\n\\]\n\nThe maximum of this function occurs at the time that max $\\left( d \\left( \\dot x \\right) 25t \\right).$ This leads to a maximum speed of\n\n\\[\nv_{max} = \\sqrt{\\frac{k}{m} \\left( \\frac{1}{2} - \\frac{1}{4} \\right)),\n\\]\n\nwhere we have used equation (12).",
    "6. We can substitute equations (4), (5), and (12) into the expression for \\(E\\) in the problem statement to find\n\n\\[ E = \\frac{1}{2} \\left( I_{A} \\cos^{2} ( \\phi + \\psi ) + m b^{2} \\right) \\ddot{\\phi} \\ddot{(\\phi + \\psi)} + \\left( \\frac{3}{2} m a \\sin( \\phi + \\psi ) \\right) \\ddot{\\psi} (25) \\]\n\n\\[ = \\frac{1}{2} m b^{2} \\cos \\phi (1 + \\cos (\\phi + \\psi )) \\ddot{\\phi} + 2 \\left( \\frac{I_{A}}{ 2 a^2 \\cos \\phi ( 1 - \\cos ( \\phi + \\psi ))} + \\frac{m}{2} \\right) \\ddot{(\\phi + \\psi )} (26) \\]\n\n\\[ = \\frac{1}{2} \\left( I_{A} \\cos^{2} ( \\phi + \\psi ) + m b^{2} \\right) \\ddot{\\phi} + m(b^{2} + a^{2}) \\ddot{\\phi} \\cos ( \\phi + \\psi ) \\] (27)\n\nusing the trigonometric identity \\(\\sin^{2} \\theta + \\cos^{2} \\theta = 1 \\). In this formula, \\(E\\) represents the total mechanical energy of the system, which is a constant as there are no nonconservative forces acting on the system.",
    "Solutions to Problem Set 11  \nRigid body rotation and static equilibrium  \nPHYS-101(en)  \n1. The leaning ladder  \nThe forces acting on the ladder are:  \n* its weight $F_g = -mg\\mathbf{j}$ applied at the ladder's center of mass,  \n* the normal force of the ground $N_1 = N_1\\mathbf{j}$ applied at the point of contact between the ladder and the ground,  \n* the normal force of the wall $N_2 = N_2\\mathbf{i}$ applied at the point of contact between the ladder and the wall,  \n* the friction force between the ladder and the ground $F_1 = -F_1\\mathbf{i}$ applied at the point of contact between the ladder and the ground.\n\nThere are shown in the figure below, where we have define a Cartesian coordinate system with its origin at the center of mass of the ladder.\n\nWe know that when $\\alpha = \\alpha_{\\text{lim}}$ the ladder is in equilibrium. In this case, Newton's second law (for the extended system composed of the entire ladder) can be written as:  \n$$\\sum \\mathbf{F} = m \\mathbf{a} = mg \\mathbf{j} + N_1 \\mathbf{j} + N_2 \\mathbf{i} + F_1 \\mathbf{i} = 0. \\qquad (1)$$",
    "Projecting this into the $x$ and $y$ directions gives\n\n\\[N_1 - F_f = 0 \\quad N_2 - F_f = 0 \\tag{2}\\]\n\nand\n\n\\[N_1 + N_2 - mg = 0 \\quad m\\vec{g} - m\\vec{g} = 0 \\tag{3}\\]\n\nrespectively.\n\nEquations (2) and (3) represent a system of two equations, but we have three unknowns: $N_1, N_2$, and $f_f$. For now (we leave the simulation until the end), we will not show that there is a proper solution. In order to solve this problem, we need to consider the torque on the ladder at the $x = 0$ point. If, on the right, the ladder does not start slipping, we have $N_2 \\geq 0$. We choose the direction N because it is the same direction as the ladder, meanwhile they enter their pivot points. Thus, we write down the sum of all the forces acting on the ladder as follows in the problem:\n\n\\[-\\sum_{i=1}^{n} \\left(\\frac{\\partial n}{\\partial x_i} y_i - x_i \\frac{\\partial n}{\\partial y_i} = \\sum_{i<\\partial x} \\left(\\frac{\\partial x}{\\partial x_i} - m y x_i \\left(\\frac{\\partial y}{\\partial x_i } \\Bigg|_{\\partial y} \\right) \\right) \\right) \\tag{4}\\]\n\nwhere point $O$ is the origin. We take this point to be the point of application of the net force (as shown in the above diagram). Given that the position vector for the gravitational force is\n\n\\[ \\sum n_i = \\sum_{i=1}^{n} N_ix_i + \\sum_{i}^{n} f_ix_i  \\]\n\nThe angular force resulting from line $f_j$ will always lie perpendicular to $\\vec{i}$ (due to the force equation from equation $\\vec{r}_{i} + \\vec{r}_{i\\mathrm{ln}} = x_{\\mathrm{i}} i + y_{\\mathrm{i}} j]$. Therefore, considering the torque relations, we will have $(F_fN`)_{peq} \\neq (F_{peq}) = 0$. Next, we determine the net forces due to a uniform resistive force $N_1$ and shown to be rigid i.e., $N_3 \\rightarrow 0$. Then the position of torques $ (A_i - N_j )\\frac{1}{2} N_{friction }i$ can be given as below:\n\n\\[ \\left[-\\sum\\left(\\frac{\\partial x_i}{\\partial y_i}\\right) \\vec{u}_{F_{f}} - u_{f} \\sum_i^{n} \\frac{\\partial x}{\\partial o } \\right]\\Bigg|_{i = N_1} \\leq \\vec {0} \\tag{5} \\]\n\nUsing the trigonometric identity that\n\n\\[\\sin \\left(\\frac{1}{2} y_i \\sin \\left(x_{i} = \\cos ^{\\frac{1}{2}} \\left( x_{i} = 0 \\right) \\tag{(}}_1 - mg = 0 \\right)\\]\n\nThis is the third equation that we need in order to solve our system of equations. Thus, we substitute equations (2) into the torque equation depending on $n_i$, as follows:\n\n\\[ \\frac{N_{1}}{mg} - \\frac{(\\sum N)1}{ \\cos(\\sum _)2} = \\cos y_i 0 \\]\n\n\\[\\sum_{X= N}^{\\[N_2=\\cos( \\phi_{0 }) + (\\sum, J_i)2]}\\]\n\nThe static friction will be taken to restrain the ladder in torque, as\n\n\\[ F_{l_s} = \\frac{1}{\\, \\frac{\\sum}{N}_{n}} - mg i = 0  \\cos { \\}\n\nwhere we need not work on the third force ${x_i}$ in motion;  eqautions (1,2) allows us to determine the\nminimum force required to stabilize the ladder.\n\nThe condition or contact will be,\n\n\\[f_x - N_{i_1} = 0 + (\\sin j)y+ \\cos_{ }} \\left( \\phi _{1} /{\\frac{N_{ x}{3}{(F_{2 \n\n\\section{P frictionless Imbalance}\n\nSince there are no frictionless/waves forces in the problem, we can impose conservation of mechanical energy on the entire system (i.e., non counterfactual, anguli peq)\\}\n\nThus, we have the work energies as below:\n\n\\[ \\begin{equation}\\right)\n N_{2_i} x }}= M {f_{f_{\\cos{ \\frac{N}}}\\almost failed }}_{N} + R{ \\sum N painted: depending\\}}\n \\tag{(6)}\\end  \\right)\\]\n\nConsider on all surface all velocities $c_{\\text{1}}$ which with full multiply the potential to collapse and/or correct use integrals i.e., respectively but the complications shown in those with comparable loss \\(\\cos_{} \\solver_{\\sum_ . Ireland in total.",
    "We will choose the reference point for the gravitational potential energy to be at the height of the center of the pulley, which we set as $z = 0$ and $y = 0$.\n\nThe total mechanical energy is the gravitational potential energy of the red and counterweight (as the center of mass of the pulley is at the reference level of the gravitational potential), that is,\n\n\\[E_{\\mathrm{mech}} = U_{\\mathrm{grav}} = m_2gz_2 - m_1gz_1~~~~(2)\\]\n\nwhere $z_i$ is the initial position of the counterweight and $z_f$ is the initial position of the car.\n\nAfter the car and counterweight are released, the mechanical energy converts to the translational kinetic energy of the car and counterweight, the translational kinetic energy of the red and counterweight, and the rotational kinetic energy of the pulley:\n\n\\[E_\\text{mech} = \\frac{1}{2}m_1v_1^2 + \\frac{1}{2}m_2v_2^2 + \\frac{1}{2}I\\omega^2 ~~~~~~~~~~~~(3)\\]\n\nwhere $v_1$ and $v_2$ are the velocities of the car and counterweight ($m_1$ and $m_2$) and $\\omega$ are the speeds of the car and counterweight at any moment, and $I$ is the moment of inertia of the pulley.\n\nSince there is no slipping, the energy is not lost. Thus, for the car and counterweight (assuming the counterweight is on the left rope) we have the equation of mass. This is the kinematic constraint, which is expressed as,\n\n\\[v_1 = -v_2 = R\\omega ~~~~~~~~~~~~(4)\\]\n\nSince the rope does not slip on the pulley, the points on the outer rim of the pulley move with a tangential speed $v_1,$ thus, we get\n\n\\[v_1 = R\\omega ~~~~~~~~~~~~(5)\\]\n\nThus, using equations (4) and (5), we can write equation (3) as,\n\n\\[E_\\text{mech} = \\frac{1}{2}m_1v_1^2 + \\frac{1}{2}m_2v_2^2 +\\frac {1}{2}\\left( \\frac{1}{2}MR^2 \\right) \\left(\\frac{v_1^2}{R^2}\\right) = \\frac{1}{2} \\left( m_1 + m_2 \\right)v_1^2 + \\frac{1}{4}M v_1^2 ~~~~~~~~~~~~(6)\\]\n\nSubstituting equations (2) and (6) into the conservation of mechanical energy given by equation (1) yields:\n\n\\[m_2gz_2 - m_1gz_1 = \\frac{1}{2} \\left( m_1 + m_2 \\right)v_1^2 + \\frac{1}{4}M v_1^2 ~~~~~~~~~~~~(7)\\]\n\nwhich reduces to\n\n\\[2g \\left( - m_1z_1 + m_2z_2 \\right) = \\left( m_1 + m_2 + \\right) v_1^2 ~~~~~~~~~~~~(8)\\]\n\nFrom the geometry of the problem and the fact that $h$ is the distance that the car travels down (we label downward positive and $z_i$ must be positive number), we see that\n\n\\[h = z_2 - z_1 ~~~~~~~~~~~~(9)\\]",
    "while\n\\[ d = p_2 - p_1, \\tag{10} \\]\n\nSubstituting these gives\n\\[ d = \\left( m_1 + m_2\\right) g = d \\left( \\frac {m_1 + m_2}{m_1 m_2} \\right) v^2. \\tag{11} \\]\n\nWe can now solve the for the speed as a function of the distance, which gives\n\\[ v(d) = \\sqrt {\\frac {d g \\left( m_1 + m_2\\right)}{m_1 m_2}} = \\sqrt {\\frac {d g M}{m_1 m_2}}. \\tag{12} \\]\n\nSince the problem statement tells us that $d = R_1 m_2/m_1$, we can also write this as\n\\[ v(d) = \\sqrt { \\frac {R_1 g m_2 \\left( m_1 + m_2 \\right)}{m_1^2 m_2}} = \\sqrt {\\frac {R_1 g}{m_1}}. \\tag{13} \\]\n\n3. Rotating cylinder\n\nWe will define the system to be the entirety of the cylinder and define a Cartesian coordinate system as shown below with the origin at the center of the cylinder (which is also the center of mass if the cylinder is uniform). Newton's first law for translation tells us that, for the center of the mass of the cylinder to remain at rest, the net force in both x- and y-direction must be zero.\n\nAnalogously Newton's first law for rotation tells us that, for the cylinder to rotate at a constant angular velocity, the net external torque must be zero :\n\\[ \\sum \\tau_o = I o_o = 0. \\tag{2} \\]\n\nTo apply these equations, we first draw a free body diagram for the system (shown above). We see that gravity\n\\[ F_{g} = -m g y c \\tag{3} \\]",
    "acts on the system. Additionally, at both points of contact with the V-groove there is a normal force\n\n\\[\nN_{1}\\hat{k} + N_{1}\\sin{\\theta} \\hat{i} + (\\mu_{s}N_{1}\\cos{\\theta}) \\hat{j}=0 \\tag{4}\n\\]\n\nand a kinetic friction force\n\n\\[\nN_{2}\\hat{k} + N_{2}\\sin{\\theta} \\hat{i} - F_{\\mathrm{p}}\\hat{i} + (\\mu_{s}N_{2}\\cos{\\theta}) \\hat{j}=0 \\tag{5}\n\\]\n\nThe external torque $\\tau$ does not appear. This is because a torque does exert its net translational force on the system. To solve the torque, a torque is needed for a few rules that impart internal torques that cancel out as work. A few tests of these rules are $F_{N} = Q(\\sin{\\theta})$ in the top groove and $F_{r}=\\cos{\\theta}$ toward the top groove. Comparing these two forces at the top grooves show subsisting $R_{1}$ in the above figure. This would enable the system to keep the same equilibrium. At this time, Angular friction force from equation (6) would then be\n\n\\[\nN_{1} = \\left\\{ \\begin{array}{ll} \n\\frac{N_{1}}{\\sin \\theta} = F_{N} \\cos \\theta \\, & \\text{ \\quad}\nN_{2} = \\left\\{ \\begin{array}{ll} \n\\frac{N_{2}}{\\sin \\theta} = \\cos \\theta \\, \n\\end{array}\\right. & \n\\end{array}\\right. 0\n \\tag{8}\n\\]\n\nin the $x$ direction and\n\n\\[\nN_{\\bot s}\\cos \\theta  - \\mu_sN_{2} \\cos \\theta + F_{\\tau} =0 \\tag{9}\n\\]\n\nin the $y$ direction. We can substitute the forms of the magnitude of the kinetic friction force $F_{fs}$ into the following equation:\n\n\\[\n\\left\\{ \\begin{array}{ll}\nN = \\mu_{s}N _{s}\\cos \\theta \\, \nN_{N}sin \\theta = \\cos \\theta (-\\frac{N_{2}}{\\mu_{s} + \\cot \\theta}) \n\\end{array}\\right. & \n\\begin{array}{ll} \nN_{2}\\sin{\\theta} = \\cos{\\theta} + \\frac{N_{2}}{\\cot{\\theta}}\n\\end{array}\\right. & \n\\begin{array}{ll} \nN_{\\parallel x} + \\cos \\theta N_{1} \\equiv 0 \n\\end{array}\\right.\n\\]\n\nRespectively, by allocating $N$ and others we note that the fact that $\\theta$ in such (which also can be introduced at any point in the problem). Equations (10) and (11) then gives\n\n\\[\nN_{1_{\\parallel \\theta}}= \\left\\{ \\begin{array}{ll} \n\\frac{N}{1+\\frac{2}{\\tan \\theta} + \\cos \\theta}\n\\end{array}\\right. & \n\\begin{array}{ll} \nN_{1\\bot \\theta}\n\\end{array}\\right. , -\n \\tan (\\theta \\sin^{-1}_{1} \\tan \\theta )\n\\]\n\nWe can substitute equation (12) into equation (13) to find\n\n\\[\n\\left( \\frac{\\tan \\phi}{\\tan \\theta} - 1 ) = ( \\frac{\\sin \\theta}{\\tan \\theta} = \\sqrt{ \\theta + \\tan^{-1} \\phi}) 2N_{1} = \\sqrt{6 \\alpha}`)\nThus, we have\n\n\\[\n\\sqrt{\\cos \\theta}. \n\\left\\{ \\begin {array}{ll}\n2N_{1}\\left( \\frac{-\\tan{ \\theta -1)}}{\\sqrt{2\\tan ^{-1 }\\theta}} =N_{1}.2(\\sqrt{\\tan -\\theta})\n2N[1}=4N_{\\parallel S}\n\\left\\{ \\begin{array}{ll} \n(\\frac{\\cos \\theta -1}{-1)} \\,\\cos (\\theta \\alpha \\sin} \\sin^{-1}={\\theta}\n\\end{array}\\right.\n \\tag{20}\n\\]\n\nwhich can be substituted into equation (12) to yield \n\nNote that the normal forces $N_{1}$ and $N_{2}$ are different. This is due to the rotation of the cylinder, and the curvature. This imparts an additional torque on the top and bottom grooves that act in opposition to the kinetic friction. Also, locally both of the kinetic frictions subtend its net forces. This also plays to the actions of the normal force in both systems. Limited to most circular-like shapes indeed remain what they are different.",
    "Finally, to find the externally applied torque $\\tau_f$, we must solve equation (9). We will choose the pivot point to be the axis of rotation of the cylinder. Then the torques are $\\tau_f + f_k R$, where $R$ denotes the radius of the cylinder. From equation (7), we also note that the tangential speed of the point S is equal to $v_{\\text{tr}} = - R \\omega$. Summing the forces in the $x$-axis to obtain the acceleration of the center-of-mass of the hoop gives\n\n\\[ \nm a_{\\text{cm}} = T_f - f_k = m R \\alpha,\n\\]\n\nwhere we have used the fact that $a_{\\text{cm}} = R \\alpha$. Summing the torques in the yz-plane and using $\\alpha = \\frac{\\alpha}{R}$ gives\n\n\\[ \n\\sum \\tau = I_{\\text{cm}} \\alpha = -f_k R + T_f R = f_k R + f_R R - f_{\\text{tr}} R = R (f_k + f_R - f_F) \n\\]\n\nCombining this equation with the expression for $a_{\\text{cm}}$ and the fact that these relationships are valid for a general torque and at the highest value of $v_{\\text{tr}}$, we can solve for the desired torque product. Substituting the form of the frictional torque and algebraic manipulations (13) and (14) give:\n\n\\[ \n\\tau_f = I_{\\text{cm}} \\left[ \\frac{I_{\\text{cm}} g \\mu_{\\text{k}} R - f_{\\text{tr}} R}{R^2} \\right] = I_{\\text{cm}} g \\frac{R^2 \\mu_{\\text{k}} - I_{\\text{cm}}}{R^2}. \n\\]\n\nwhere we also note that the distance to the point of application of the frictional force is $r_{\\text{fr}} = r_{\\text{cm}} = R$. Equation (15) thus requires torque applied to maintain the cylinder at a constant angular velocity.\u220e\n\n4. Pendulum and disk\n\n1. The total moment of inertia of a system about the axis of rotation P is defined to be\n\n\\[ \nI = \\int r^2 \\, \\text{d}m \n\\]\n\nwhere $r$ is the distance from the axis P. Using the Hald integrals, perform over the entire mass of the object, surface integrals if $f$ is one and $f$ transformations and surface divides the integral into two of the same shape, denoted for the two parts of the entire system as follows:\n\n\\[ \n\\iint_S \\mathbf{S} \\, dA = \\iint_S \\mathbf{S} \\, dA \n\\]\n\nwhere\n\n\\[ \nr_{\\text{sys}} = r_{\\text{sys}}, \n\\]\n\n\\[ \n\\frac{\\partial I_{\\text{sys}}}{\\partial m} = \\iint_S \\frac{\\partial I_{\\text{sys}}}{\\partial m} \\, dA,\n\\]\n\nWe will first calculate $r_{\\text{sys}}$ from the parallel axis theorem. We can relate the moment of inertia of the disk about point P to the moment of inertia about its center of mass, if we note that $I = m R^2$, according to Pappus.\n\nThe moment of inertia of a disk about its center of mass can be found from a table, which is perfectly acceptable. However, here we will also derive it from the definition if the moment of inertia:\n\n\\[ \nI = \\int_0^R r^2 \\, \\text{d}m \n\\]",
    "where \u03c1 is the distance from the center of mass of the disk. Since the disk is uniform, we know that its center of mass is at its geometric center and it has an areal density of \n$$\n\\sigma = \\frac{m}{A}\n$$\n(7)\nwhere $\\Delta A$ is a differential element of area. We can use \u03c3 to rewrite the integral over mass in equation \n(6) as an integral over area according to\n$$\nI_{CM} = \\int \\rho^2 \\, dm = \\sigma \\int \\rho^2 \\, dA\n$$\n(8)\n\nWhile the differential area $\\Delta A = dx \\, dy$ is Cartesian coordinates, we would like to use polar coordinates to reflect the geometry of the disk. In polar coordinates $r$ and $\\theta$, we can use symmetry to eliminate the $\\theta$ and use a differential element with a small central angle $d\\theta$ and length $r \\, dr$. We can write\n$$\ndA = r \\, dr \\, d\\theta\n$$\n(9)\nwhere we've chosen the bounds such that the integrals span the entire disk. Since the argument of the integral has no $\\theta$ dependence, we find\n$$\nI_{CM} = \\sigma \\int_0^{2\\pi} d\\theta \\int_0^R r^3 \\, dr\n$$\n(10)\n\nThe integral over $r$ is also straightforward, giving\n$$\nI_{CM} = 2\\pi\\sigma \\frac{R^4}{4} = \\frac{\\pi m R^4}{2\\pi R^2} = \\frac{1}{2} mR^2\n$$\n(11)\n\nwhere we have substituted in equation (7). Combining this with (6) gives the final expression\n$$\nI = I_{CM} + Mh^2 = \\frac{1}{2} mR^2 + Mh^2\n$$\n(12)\n\nTo calculate the moment of inertia of the rod, we can use the result from a table, which again is represented schematically in figure 6, and which you will also have to derive for a uniform rod by integrating directly:\n$$\nI_{CM} = \\frac{1}{12} mL^2\n$$\n(13)\n\nwhere $h$ is the distance from the axis of pendulum bob to the end of the rod. Since the rod is uniform, its center of mass is taken 1/2 of its length from the end:\n$$\nh = \\frac{L}{2}\n$$\n(14)\nwhere $\\Delta l$ is a linear differential element along the length of the rod. We can use $I_C$ to rewrite the integral over mass in equation (13) as an integral over length according to\n$$\nI_{CM} = \\sigma \\int_0^L \\left( x^2 \\, dm \\right)\n$$\n(15)\nThus, the integral over the rod is\n$$\nI_{CM} = \\sigma \\int_0^L dx \\int_{-(L/2)}^{L/2} l^2 \\, dl = \\sigma \\frac{L^3}{12}\n$$\n(16)\nSubstituting this and equation (12) into equation (1) we finally get the answer of\n$$\nI = \\frac{1}{2} mR^2 + m \\frac{L^2}{3} + 2 m \\left(\\frac{k}{2}\\right)^2\n$$\n(17)",
    "2. The center of mass of any system is given by:\n\\[ R_{\\text{CM}} = \\frac{\\sum_i m_i r_i}{\\sum_i m_i} \\]\n\nHere our system has two objects - the rod and the disk. Given that the rod is uniform, we know that its center of mass is at its midpoint, which is a distance \\( \\frac{L}{2} \\) from the pivot P. Similarly, since the disk is uniform its center of mass is at its geometric centre, which is also a distance \\(L\\) from the pivot P. The x-coordinates (as determined from the pivot) for these two objects are therefore (recall, x is the length of the rod). Plugging this information into equation (18) we get:\n\\[ R_{\\text{CM}} = \\frac{m_1 \\left(\\frac{L}{2}\\right) + m_2 L}{m_1 + m_2} = \\frac{m_1 \\frac{L}{2} + m_2 L}{m_1 + m_2} \\]\n\n3. As all of the forces acting on the pendulum system are conservative, we can impose conservation of mechanical energy\n\\[ \\Delta E = E_{\\text{final}} - E_{\\text{initial}} = 0 \\]\n\nThe potential energy of a system should be given by (where downwards is positive) and the final state of the pendulum is at the bottom of its swing (closest to the subject) P. The only force exerted is when the pendulum is stretched out to an angle \\( \\theta \\) given by the expression:\n\\[ U_{\\text{initial}} = -m_1 g \\left( -\\frac{L}{2} \\cos \\theta_{\\text{i}} \\right) + m_2 g ( -L \\cos \\theta_{\\text{i}} ) \\]\n\nThe gravitational potential energy is only dictated by the system when the pendulum is at angle \\(\\theta\\), that is perpendicular to the axis. The summary of the values for potential energy for the initial and final states include thought into consideration the work done by friction and air resistance, whereby energy values for initial and final potential states are given as:\n\n\\[\n-m_1 g \\left( -\\frac{L}{2} \\cos \\theta_{\\text{i}} \\right) + m_2 g ( -L \\cos \\theta_{\\text{i}} ) = 0.\n\\]\n\nwhere \\(\\Delta h\\) is the change in height of the rod and disk with pivot position to its initial position given by reducing height of rod as \\(\\frac{1}{2}\\):\n\\[\nR_{\\text{CM}} = \\frac{m_1 \\left(\\frac{L}{2}\\right) \\cos (\\theta_{\\text{1}}) + m_2 \\left(L\\right)\\cos( \\theta_{\\text{i}} )}{m_1 + m_2} = \\sqrt{2},\n\\]\nthen taking into the inherent reduction value by 4:\n\n\\[\n-m_1 \\frac{1}{2} g L \\cos \\theta_{\\text{i}} + m_2 g ( -L \\cos \\theta_{\\text{i}} ) = 0 \\\\\n\\cos(\\theta_{\\text{f}}) = 1 \n\\]\n\n\\[\n-m_1 g (-\\frac{L}{2}) + m_2 g (-L ) = m_2 g \\cos(\\theta _{\\text{i}}) - m_1 g \\frac{L}{2} \\cos \\theta_{\\text{i}}\n\\]",
    "5. Homework: The beam\n\nThe are three forces acting on the beam. The gravitational force (which acts at the beam's center of mass), the tension force from the rope (which acts at the point of connection between the rope and the beam), and the normal force from the wall (which acts at the point of contact between the wall and the beam). These are illustrated in the figure below.\n\nThe beam is in equilibrium when\n\\[ \\sum F = 0 \\]\nand\n\\[ \\sum \\tau = 0 \\]\nwhere we will choose to calculate the torque about an axis of rotation in the \\(\\hat{z}\\)-direction passing through the origin (i.e. the leftmost end of the beam). Given the forces in the problem, equation (1) gives\n\\[ F = T +mg +N = 0 \\]\nwhere\n\\[ T = T_x\\hat{i} + T_y\\hat{j} \\]\n\\[ T_x = -T\\cos{\\alpha}\\hat{i} + T\\sin{\\alpha}\\hat{j} \\]\n\nThus, the \\(x\\) component of equation (3)\n\\[ N-T\\cos{\\alpha} = 0 \\Rightarrow N = T\\cos{\\alpha} \\]\n(6)\n\nand the \\(y\\) component is\n\\[ T\\sin{\\alpha} - mg = 0 \\Rightarrow T\\sin{\\alpha} = mg \\]\n\nTo calculate the torques \\(\\tau = r \\times F\\) due to the forces in equation (2), we must consider the position vector \\(\\vec{r}\\) from the origin to the point of application where the force acts. As mentioned before, the torque \\(\\tau\\) is equal to zero if the force is applied at the origin. For the gravitational force thus \\(\\vec{r} = (L/ [2] \\hat{i} + 1/4\\) \\(\\hat{j}\\) as it acts at the center of mass.",
    "it is the middle (given that the beam is uniform). The point of application of the tension is known in the \nproblem statement to be $r = (f/4)\\hat{i}$. Thus, equation (8) becomes\n\n$$ \\sum r_k \\times F_k =(f \\sin \\beta - r_1) T \\hat{k} + \\left( \\frac{f}{2} - Mg f \\right) \\hat{k} = \\frac{f}{2}Mg \\hat{k} \\Rightarrow \\left( \\frac{f}{2} - r_1 \\right)(-T) \\hat{k} + \\left( \\frac{f}{2} - MG f \\right) \\hat{k} = 0, $$\n\nwhere we have used equations (5) and (6). Using the right-hand rule to simplify the cross products (e.g., \n$\\hat{i} \\times \\hat{j} = \\hat{k}$) gives\n\n$$ r_1 = \\frac{Mg \\cdot f}{2 T} \\quad \\text{and so} \\quad \\beta = \\sin^{-1} \\left( \\frac{Mg}{3 T} \\right). \\tag{10} $$\n\nPlugging this result into equation (9) gives\n\n$$ T_3 = \\frac{3 Mg}{4} = 3 \\left( \\frac{1 - \\cos \\theta}{a} \\right). \\tag{11} $$\n\nTo determine the normal force, we substitute equation (10) into equation (3) and (5) to find\n\n$$ N_L = Mg \\left( 1 - \\frac{r_1 - l}{f} \\right), \\tag{12} $$\n\n$$ N_R = Mg \\left( 1 - \\frac{r_1}{f} \\right). \\tag{13} $$\n\nFrom equation (4) we see that\n\n$$ N_0 = Mg \\left( \\frac{1}{2f} \\right) = \\frac{Mg}{st}. \\tag{14} $$\n\nThus, the vector expressions for the forces are given by equations (6), (11), and (13), while the points of \napplication are indicated in the above plot.",
    "A.10 Variable-mass system and non-inertial frame of reference\n\nA.10.1 Pendulum on a train in uniform circular motion\n\nA.10.2 Apparent weight of a falling chain",
    "A pendulum of mass $m$, of length $l$ is attached to the ceiling of a train wagon in uniform circular motion at angular velocity $\\vec{\\Omega} = \\Omega \\vec{e_z}$ (clockwise manner). A mechanism ensures that the pendulum oscillates in a plane orthogonal to the motion of the train.",
    "Absolute frame: rails  \nCoordinate frame $(0, \\vec{x_0}, \\vec{y_0}, \\vec{z_0})$\n\nRelative frame: train  \nCoordinate frame $(A, \\vec{x}, \\vec{y}, \\vec{z})$\n\nExternal forces:  \nWeight $\\vec{P} = m\\vec{g}$  \nNormal reaction: $\\vec{N}$  \nTension: $\\vec{T}$\n\nInertial forces:  \n$\\ddot{\\vec{r}}=\\vec{0}$\n\nDriving force: $\\vec{F_j} = -m\\vec{a_0}(A) - m \\vec{\\dot{\\Omega}} \\times (\\vec{\\Omega} \\times \\vec{r} (P))$\n\nCoriolis force: $\\vec{F_C} = - 2 m \\vec{\\Omega} \\times \\vec{v_r} (P)$",
    "* Law of relative motion:\n  $mg + \\vec{N} + \\vec{T} + \\vec{F_d} + \\vec{F_c} = m \\vec{a}_{r}(P)$ \\hspace{1em} (A.10.1)\n\n* Relative kinematic quantities:\n  $\\vec{r}_r(P) = L \\vec{F_r}$, $\\vec{V_r}(P) = L \\dot{\\theta} \\vec{\\theta}$\n  $\\vec{a_r}(P) = - L \\dot{\\theta}^2 \\vec{r} + L \\ddot{\\theta} \\vec{\\theta}$\n\n* External forces:\n  $\\vec{F} = mg \\vec{e}_z = mg(\\cos \\theta \\vec{F_r} - \\sin \\theta \\vec{\\theta})$\n  $\\vec{N} = N \\vec{\\theta}$, $\\vec{T} = -T \\vec{r}$\n\n* Angular velocity:\n  $\\vec{\\Omega} = \\Omega \\vec{e}_z = \\Omega \\cos \\theta \\vec{F_r} - \\Omega \\sin \\theta \\vec{\\theta}$",
    "- Law of relative motion:\n$$\nmg\\mathbf{\\hat{g}}+ \\mathbf{N} + \\mathbf{T} + \\mathbf{F}_{J} + \\mathbf{F}_{C} = m\\mathbf{a}_{r}(\\mathbf{P})\\quad (\\mathbf{A},10,1)\n$$\n\n- Relative kinematic quantities:\n$$\n\\mathbf{r}_{r}(\\mathbf{P}) = L \\mathbf{\\hat{e}}_{\\mathbf{\\theta}} \\quad ; \\quad \\mathbf{v}_{r}(\\mathbf{P}) = L \\dot{\\mathbf{\\theta}} \\mathbf{\\hat{e}}_{\\mathbf{\\theta}}\n$$\n$$\n\\mathbf{a}_{r}(\\mathbf{P}) = - L \\dot{\\mathbf{\\theta}}^2 \\mathbf{\\hat{e}}_{\\mathbf{r}} + L \\ddot{\\mathbf{\\theta}} \\mathbf{\\hat{e}}_{\\mathbf{\\theta}}\n$$\n\n- Inertial forces:\n$$\n\\mathbf{F}_{J} = - m \\mathbf{a}_{0}(\\mathbf{A}) - m \\mathbf{\\Omega} \\times (\\mathbf{\\Omega} \\times \\mathbf{r}_{r}(\\mathbf{P})) \n$$\n$$\n= m R \\mathbf{\\ddot{e}}_{\\mathbf{\\theta}} - m L \\mathbf{\\Omega}^2 \\mathbf{\\hat{e}}_{\\mathbf{r}} (\\sin \\mathbf{\\theta} \\mathbf{\\hat{i}} + \\cos \\mathbf{\\theta} \\mathbf{\\hat{j}})\n$$\n$$\n= m \\mathbf{\\Omega}^2 (R + L \\sin \\mathbf{\\theta}) [ \\sin \\mathbf{\\theta} \\mathbf{\\hat{i}} + \\cos \\mathbf{\\theta} \\mathbf{\\hat{j}}]\n$$\n$$\n\\mathbf{F}_{C} = -2 m \\mathbf{\\Omega} \\times \\mathbf{v}_{r}(\\mathbf{P}) = -2 m L \\mathbf{\\Omega} \\dot{\\mathbf{\\theta}} (\\cos \\mathbf{\\theta} \\mathbf{\\hat{j}} - \\sin \\mathbf{\\theta} \\mathbf{\\hat{i}})\n$$\n$$\n= -2 m L \\mathbf{\\Omega} \\dot{\\mathbf{\\theta}} \\cos \\mathbf{\\theta}\n$$",
    "- Law of relative motion:\n$$mg + \\vec{N} + \\vec{T} + \\vec{F}_d + \\vec{F}_C = m\\vec{a}_C (CP) \\quad (A.10.1)$$\n\n- Equations of motion:\n\nalong $\\vec{\\imath}'$: \n$$mg \\cos \\theta - T + m \\Omega^2 \\sin \\theta ( R + L \\sin \\theta ) = -m L \\ddot{\\theta} \\quad (A.10.2)$$\n\nalong $\\vec{\\theta}'$: \n$$-mg \\sin \\theta + m \\Omega^2 \\cos \\theta ( R + L \\sin \\theta ) = m L \\dot{\\theta}^2 \\quad (A.10.3)$$\n\nalong $\\vec{k}'$: \n$$N - 2 m L R \\dot{\\theta} \\cos \\theta = 0 \\quad (A.10.4)$$",
    "- Tension: (A.10.2)  \n  $T = mg \\cos \\theta + mL\\ddot{\\theta} + m(R + L\\sin\\theta)\\Omega^2 \\sin\\theta$ (A.10.5)\n\n- Normal reaction: (A.10.4)  \n  $N = 2mL\\Omega \\cos\\theta$ (A.10.6)\n\n- Equation of motion:  \n  $\\ddot{\\theta} + \\frac{g}{L}\\sin\\theta - \\frac{\\Omega^2}{L}\\cos\\theta(R + L\\sin\\theta) = 0$ (A.10.7)",
    "- Equation of motion: \n$$\n\\ddot{\\theta} + \\frac{g}{L} \\sin{\\theta} - \\frac{\\Omega^2}{L} \\cos{\\theta} (R + L \\sin{\\theta}) = 0 \\quad \\text{(A.10.7)}\n$$\n\n- Equilibrium positions: $(\\theta=\\theta_0); \\quad \\ddot{\\theta} = 0$\n$$\n\\tan{\\theta_0} = \\frac{\\Omega^2}{g}(R + L \\sin{\\theta_0}) \\quad \\text{(A.10.8)}\n$$\n\n- Approximation $(R \\gg L)$: \n$$\n\\tan{\\theta_0} = \\frac{R \\Omega^2}{g} \\quad \\text{(A.10.9)}\n$$\n\n$$\n\\ddot{\\theta} + \\frac{g}{L} \\sin{\\theta} - \\frac{R \\Omega^2}{L} \\cos{\\theta} = 0 \\quad \\text{(A.10.10)}\n$$",
    "A chain of mass \\( M \\) and of length \\( L \\) is falling at constant velocity \\( \\vec{u} = u \\vec{e}_{z} \\) into a cup that is connected to a force sensor that measures the net force \\( \\vec{F}_{\\text{net}}(t) = m(t) \\vec{a}(t) \\) corresponding to the apparent weight of the chain.\n\nMass:\n\\[ m(t) = \\frac{dm}{dt} \\cdot t = \\frac{M}{T} t \\quad \\text{(A.10.11)} \\]\n\\[ T = \\text{falling time} \\]",
    "- Law of motion (variable mass)\n\n$$ \\sum \\vec{F}_{\\text{ext}}(t) + \\frac{dm}{dt} \\vec{u} = m(t) \\vec{a}(t) = \\vec{F}_{\\text{net}}(t) \\quad \\text{(A.10.12)} $$\n\n- Weight:\n\n$$ \\sum \\vec{F}_{\\text{ext}}(t) = \\vec{P}(t) = m(t) \\vec{g} = Mg \\frac{t}{T} \\vec{e}_z $$\n\n- Relative falling velocity:\n\n$$ \\vec{u} = u \\vec{e}_z = \\frac{L}{T} \\vec{e}_z $$\n\n- Mass variation rate:\n\n$$ \\frac{dm}{dt} = \\frac{M}{T} $$\n\n- (A.10.12)\n\n$$ \\Rightarrow \\vec{F}_{\\text{net}}(t) = Mg \\frac{t}{T} + \\frac{ML}{T^2} \\quad \\text{(A.10.13)} $$",
    "Apparent weight $F_{net}$:\n\n$F_{net}$\n$Mg$\n$\\frac{ML}{T^2}$\n$0$\n$t$",
    "Chapter 3\n\nFRICTION AND BALLISTICS",
    "3. Friction and ballistics\n\n3.1 Friction force (dry and viscous)\n3.2 Ballistics without friction\n3.3 Ballistics with friction",
    "3.1 Friction forces\n\n3.1.1 Dry friction:\n\n- Dry friction force: friction force at the interface between two solids that is opposed to motion:\n\n1. Static friction force: (de Coulomb)\n$$\n||F_f|| \\leq \\mu_s ||N|| \\tag{3.1}\n$$\nwhere $\\mu_s$ static friction coefficient \n$N$ normal reaction force \n\n2. Kinetic friction force:\n$$\nF_f = - \\mu_c ||N|| \\hat{v} \\quad \\text{where} \\quad \\hat{v} = \\frac{v}{||v||} \\tag{3.2}\n$$\nwhere $\\mu_c$ kinetic friction coefficient",
    "Table 3.1  Dry friction coefficients\n\n| Materials            | Static $\\mu_s$ | Kinetic $\\mu_c$ |\n|----------------------|----------------|-----------------|\n| Rubber/Asphalt       | 1.0            | 0.8             |\n| Steel/Steel          | 0.74           | 0.57            |\n| Aluminium/Steel      | 0.61           | 0.47            |\n| Copper/Steel         | 0.53           | 0.36            |\n| Ice/Ice              | 0.1            | 0.03            |\n| Teflon/Teflon        | 0.04           | 0.03            |\n| Human articulation   | 0.01           | 0.003           |",
    "3.1.2 Viscous friction\n\n- **Viscous friction force**: friction force exerted on a solid in motion with respect to a fluid\n\n1. Stokes\u2019s law (laminary regime: slow velocity)\n\n\\[F_f = - k \\eta v = - b v \\] \n\\[ (3.3) \\]\n\n\\(\\eta\\) = viscosity \\[N.s/m^2\\]\n\\(k = 6 \\pi R\\) \\((R = \\text{ sphere radius})\\)\n\n2. Drag (turbulent regime: high velocity)\n\n\\[ F_f = - \\frac{1}{2} C_x A \\rho v^2 \\hat{v} \\] \n\\[ (3.4) \\]\n\n\\(C_x\\) = drag coefficient\n\n\\(A\\) = projected area \\(\\perp\\)\n\n\\(\\rho\\) = fluid density",
    "Viscosity\n\nTABLE 3.2 Viscosity at 25\u00b0 C\n\n| Substances | Viscosity \u03b7 [N \u00b7 s/m\u00b2] |\n|------------|------------------------|\n| Air        | 0.00002                |\n| Water      | 0.0009                 |\n| Blood      | 0.004                  |\n| Oil        | 0.2                    |\n| Honey      | 10                     |\n| Ketchup    | 100                    |\n| Glass      | 1000                   |\n\nDrag coefficient",
    "3.2 Ballistics without friction\n\n3.2.1 Problem solving\n\n1. Choice of frame of reference and geometric frame (here Cartesian frame).\n2. External forces expressed with respect to the frame (here weight).\n3. Initial conditions on position and velocity.\n4. Vectorial law of motion (Newton\u2019s 2nd law).\n5. Projection of the law of motion on the coordinate axes\n   $\\Rightarrow$ 3 differential equations of motion.\n7. Integration of the equations of motion to obtain the velocity equations and the position equations.\n8. Combination of the position equations to obtain the equation of the trajectory of the object.",
    "3.2.2 Weight\n\nModel: earth\u2019s gravitational attraction field $g \\, [m/s^2]$ is uniform, constant and directed downwards (approximation at the scale of motion).\n\nWeight: $P = mg$ of an object of mass $m$\n\nGravitational field:\n\n(altitude $h = 0 \\, [m]$; latitude $\\lambda = 45^\\circ$ )\n\n$||g|| = g = 9.81 \\, [m/s^2]$\n\nThe weight is an external force because the gravitational field $g$ is external to the object.",
    "3.2.3 Ballistic law of motion\n\n- Law of motion (2.33): \n\\[ F_{\\text{ext}} = P = ma \\quad \\text{(3.6)} \\]\n\n- Weight:\n\\[ P = mg \\quad \\text{(3.5)} \\]\n\n- Ballistic law of motion:\n\\[ a = g \\quad \\text{(3.7)} \\]\n\n- Law independent of mass (e.g. water drop, steel ball)\n\n- Torricelli experiment: (free fall of a feather and a lead mass in vacuum)",
    "3.2.4 Frame and initial conditions\n\nInitial position: $\\mathbf{r}(0) = \\mathbf{r}_0$\n(i)   $\\dot{x}(0) = x_0$\n(ii)  $\\dot{y}(0) = y_0$\n(iii) $\\dot{z}(0) = z_0$\n\nInitial velocity: $\\mathbf{v}(0) = \\mathbf{v}_0$\n(i)   $\\dot{x}(0) = v_{0x}$\n(ii)  $\\dot{y}(0) = v_{0y}$\n(iii) $\\dot{z}(0) = v_{0z}$",
    "3.2.5 Ballistic equations of motion\n\n- Ballistic law of motion:\n$$a = g \\quad \\text{where} \\quad a = (\\ddot{x}, \\ddot{y}, \\ddot{z}) \\quad \\text{and} \\quad g = (0, 0, -g)$$\n\n- Equations of motion:\n$$\\ddot{x} = 0 \\quad \\ddot{y} = 0 \\quad \\ddot{z} = -g = \\text{const} \\quad (3.10)$$\n\n- Velocity equations: (by integration + initial conditions)\n$$\\dot{x} = v_{0x} = \\text{const}$$\n$$\\dot{y} = v_{0y} = \\text{const}$$\n$$\\dot{z} = -gt + v_{0z} \\quad (3.11)$$\n\n- Position equations: (by integration + initial conditions)\n$$x(t) = v_{0x} t + x_{0} \\quad \\text{ULM}$$\n$$y(t) = v_{0y} t + y_{0} \\quad \\text{ULM}$$\n$$z(t) = -\\frac{1}{2} gt^{2} + v_{0z} t + z_{0} \\quad \\text{UALM} \\quad (3.12)$$",
    "3.2.6 Free fall\n\n- Vertical ballistic position equation\n\\[ z(t) = \\frac{1}{2} g t^2 + v_{0z} t + z_0 \\quad (3.12) \\]\n\n- Initial position: \\( z_0 = h \\) (falling height)\n\n- Initial velocity: \\( v_{0z} = 0 \\)\n\n- Falling time: \n\\[ t = t_c \\implies z(t_c) = 0 \\]\n\n\\[\n\\implies z(t_c) = \\frac{1}{2} g t_c^2 + h = 0 \\quad (3.13)\n\\]\n\n\\[\n\\implies t_c = \\sqrt{\\frac{2h}{g}} \\quad (3.14)\n\\]\n\n- Measuring \\( h \\) and \\( t_c \\), we can determine \\( g \\).",
    "3.2.7 Ballistic trajectory\n\n- Initial conditions (position and velocity)\n  $$\n  \\begin{align*}\n  x_0 & = 0 \\\\\n  y_0 & = 0 \\\\\n  z_0 & = 0 \\\\\n  v_{0x} & = v_0 \\cos \\alpha \\\\\n  v_{0y} & = 0 \\\\\n  v_{0z} & = v_0 \\sin \\alpha\n  \\end{align*}\n  $$\n\n- Position equations:\n  $$\n  \\begin{align*}\n  x(t) & = v_0 \\cos \\alpha \\, t \\quad \\Rightarrow \\quad t = \\frac{x}{v_0 \\cos \\alpha} \\\\\n  y(t) & = 0 \\\\\n  z(t) & = \\frac{1}{2} g t^2 + v_0 \\sin \\alpha \\, t \\tag{3.15}\n  \\end{align*}\n  $$\n\n- Parabolic trajectory (\\(O x z\\) plane):\n  $$\n  z(x) = - \\frac{1}{2} \\frac{g}{v_0^2 \\cos^2 \\alpha} x^2 + \\tan \\alpha \\, x \\tag{3.16}\n  $$",
    "Experiment\n\n1. Free fall and ballistic shot\n\n1. Ballistic shot on an air cushion table\n\n",
    "3.3 Ballistics with friction\n\n3.3.1 Ballistic law of motion\n\n- Ballistic law of motion with viscous friction\n\\[ \\sum F_{\\text{ext}} = P + F_f = m \\, a \\quad \\text{(3.17)} \\]\n- Weight: \n\\[ P = m \\, g \\quad \\text{(3.5)} \\]\n- Viscous friction force:\n\\[ F_f = -b \\, v \\quad \\text{where} \\quad b > 0 \\quad \\text{(3.3)} \\]\n(Stokes' law)\n- Law of motion\n\\[ m \\, g - b \\, v = m \\, a \\quad \\text{(3.18)} \\]\n\nThe law of motion depends on the mass $m$.",
    "3.3.2  Frame and initial conditions\n\nInitial position: $r(0) = 0$\n(i) $x(0) = 0$\n(ii) $y(0) = 0$\n(iii) $z(0) = 0$\n\nInitial velocity: $ v(0) = v_0$\n(i) $\\dot{x}(0) = v_{0x}$\n(ii) $\\dot{y}(0) = 0$\n(iii) $\\dot{z}(0) = v_{0z}$",
    "3.3.3  Ballistic equations of motion\n\n- Ballistic law of motion with friction\n  $m \\, a = m \\, g - b \\, v \\, ; \\quad g = (0, 0, -g) ; \\quad v = (\\dot{x}, \\dot{y}, \\dot{z}) ; \\quad a = (\\ddot{x}, \\ddot{y}, \\ddot{z})$\n- Equations of motion (projections along $Ox, \\, Oy, \\, Oz$):\n  $m \\ddot{x} = - b \\dot{x}$  \n  $m \\ddot{y} = - b \\dot{y}$  \n  $m \\ddot{z} = - mg - b \\dot{z}$\n\n  or  \n  $m \\ddot{x} = - b \\dot{x}$  \n  $m \\ddot{y} = - b \\dot{y}$  \n  $m \\ddot{z} = - mg - b \\dot{z}$  (3.21)\n\n- Damping time:\n  $\\tau = \\frac{m}{b}$  (3.22)\n\n- Equations of motion:\n  $\\dot{v}_x = \\frac{1}{\\tau} v_x$  \n  $\\dot{v}_y = \\frac{1}{\\tau} v_y$  \n  $\\dot{v}_z = - g - \\frac{1}{\\tau} v_z$  (3.23)",
    "3.3.4  Horizontal ballistic motion\n\nEquation of motion along the $x$-axis: $ \\dot{v}_{x} = dv_{x}/dt $\n\\[ \\dot{v}_x = - \\frac{1}{\\tau} v_x \\tag{3.23} \\quad \\Rightarrow \\quad \\frac{dv_{x}(t)}{v_{x}(t)} = - \\frac{dt}{\\tau} \\tag{3.24} \\]\n\nIntegration with respect to time from 0 to $t$:\n\\[ \\int_{v_{0x}}^{v_{x}(t)} \\frac{dv^{'}_{x}}{v^{'}_{x}} = - \\frac{1}{\\tau} \\int_{0}^{t} dt^{'} \\tag{3.25} \\]\n\n\\[ \\Rightarrow \\quad \\ln \\left( v_{x}(t) \\right) - \\ln \\left( v_{0x} \\right) = \\ln \\left( \\frac{v_{x}(t)}{v_{0x}} \\right) = - \\frac{t}{\\tau} \\tag{3.26} \\]\n\nVelocity equation along the $x$-axis:\n\\[ v_{x}(t) = v_{0x} \\exp \\left( - \\frac{t}{\\tau} \\right) \\tag{3.27} \\]",
    "- Velocity equation along the $x$-axis:\n  $$\\frac{dz(t)}{dt} = v_{0x} \\exp\\left(-\\frac{t}{\\tau}\\right) \\quad \\Rightarrow \\quad dz(t) = v_{0x} \\exp\\left(-\\frac{t}{\\tau}\\right) dt \\quad\\text{(3.28)}$$\n\n- Integration with respect to time from 0 to $t$: (n.b. $x(0) = 0$)\n  $$\\int_{0}^{x(t)} dx' (t') = v_{0x} \\int_{0}^{t} \\exp\\left(-\\frac{t'}{\\tau}\\right) dt' \\quad\\text{(3.29)}$$\n  $$\\Rightarrow \\quad x(t) = -v_{0x} \\tau \\exp\\left(-\\frac{t'}{\\tau}\\right) \\bigg|_{t'=0}^{t'=t} \\quad\\text{(3.30)}$$\n\n- Position equation along the $x$-axis:\n  $$x(t) = v_{0x} \\tau \\left(1 - \\exp\\left(-\\frac{t}{\\tau}\\right)\\right) \\quad \\text{(3.31)}$$",
    "- Position equation along the $x$\u2013axis:\n\\[ \nx(t) = v_0 x \\tau \\left( 1 - \\exp \\left( - \\frac{t}{\\tau} \\right) \\right)\n\\]\n(3.31)\n\n- Oblique asymptote:\n\\[ \nx(t) \\simeq v_0 x t \n\\]\nwhere \n\\[ \n\\exp \\left( - \\frac{t}{\\tau} \\right) \\simeq 1 - \\frac{t}{\\tau}\n\\]\n\n- Horizontal asymptote:\n\\[ \n\\lim_{t \\to \\infty} \\ x(t) = v_0 x \\tau \n\\]",
    "3.3.5 Vertical ballistic motion\n\n- Motion equation along the $z$-axis: (inhomogeneous equation)\n$$\\dot{v}_z = -g - \\frac{1}{\\tau} v_z \\quad (3.23 c)$$\n\n- Change of variable: (homogeneous equation)\n$$\\dot{u}_z = - \\frac{1}{\\tau} u_z \\quad (3.34) \\quad \\Rightarrow \\quad u_z (t) = v_z (t) + \\text{constant}$$\n$$\\dot{u}_z = \\frac{du_z}{dt} = \\frac{dt}{\\tau} \\quad \\Rightarrow \\quad u_z = du_z / dt \\quad (3.33) \\quad u_z (t) = v_z (t) + g \\tau \\quad (3.35) \\quad \\dot{u}_z = \\dot{v}_z$$\n$$\\quad (3.23 c) = (3.34)$$\n\n- Integration with respect to time from 0 to $t$:\n$$\\int_{u_z(0)}^{u_z(t)} \\frac{du_z(t')}{u_z(t')} = \\int_{v_{z_0}+g\\tau}^{v_z+g\\tau} \\frac{du_z(t')}{u_z(t')} = - \\frac{1}{\\tau} \\int_{0}^{t} dt' \\quad (3.36)$$\n$$\\Rightarrow \\quad \\ln (v_z(t) + g\\tau) - \\ln (v_{z0} + g\\tau) = \\ln \\left( \\frac{v_z(t) + g \\tau}{v_{z0} + g \\tau} \\right) = - \\frac{t}{\\tau} \\quad (3.37)$$\n\n- Velocity equation along the $z$-axis:\n$$v_z (t) = (v_{z0} + g \\tau) \\exp \\left( - \\frac{t}{\\tau} \\right) - g \\tau \\quad (3.38)$$",
    "- Velocity equation along the $z$-axis:\n  \\[\n  v_z(t) = (v_{0z} + g \\tau) \\exp \\left( - \\frac{t}{\\tau} \\right) - g \\tau \\quad (3.38)\n  \\]\n\n- Terminal velocity:\n  \\[\n  v_t = \\lim_{t \\to \\infty} v_z(t) = - g \\tau \\quad (3.39)\n  \\]\n  \\[\n  \\Rightarrow v_t \\quad (3.22) = \\frac{mg}{b} \\quad(3.3)=  - \\frac{mg}{k \\eta} \\quad \\Rightarrow \\tau= \\frac{m}{k \\eta}\n  \\]\n\n- The larger the viscosity $\\eta$ the smaller the damping time $\\tau$ (oil, glycerin, water).\n\n- The larger the viscosity $\\eta$ the smaller the terminal velocity $v_t$ (oil, glycerin, water).",
    "- Velocity equation along the \\( z \\)-axis:\n\\[\n\\frac{dz(t)}{dt} = (v_{0z} + g \\tau) \\exp \\left( - \\frac{t}{\\tau} \\right) - g \\tau\n\\]\n\\[\n\\Rightarrow \\quad dz(t) = (v_{0z} + g \\tau) \\exp \\left( - \\frac{t}{\\tau} \\right) dt - g \\tau \\, dt \\quad \\quad (3.40)\n\\]\n\n- Integration with respect to time from 0 to \\( t \\): (n.b. \\( z(0) = 0 \\))\n\\[\n\\int_0^{z(t)} dz'(t') = (v_{0z} + g \\tau) \\int_0^t \\exp \\left( - \\frac{t'}{\\tau} \\right) dt' - g \\tau \\int_0^t dt' \\quad \\quad (3.41)\n\\]\n\\[\n\\Rightarrow \\quad z(t) = - (v_{0z} + g \\tau^2) \\exp \\left( - \\frac{t'}{\\tau} \\right) \\Bigg|_{t'=0}^{t'=t} - g \\tau t \\Bigg|_{t'=0}^{t'=t} \\quad \\quad (3.42)\n\\]\n\n- Position equation along the \\( z \\)-axis:\n\\[\nz(t) = (v_{0z} \\tau + g \\tau^2) \\left( 1 - \\exp \\left( - \\frac{t}{\\tau} \\right) \\right) - g \\tau t \\quad \\quad (3.43)\n\\]",
    "3.3.6 Ballistic trajectory\n\n- Position equation along the horizontal axis:\n$$\nx(t) = v_{0x} \\tau \\left( 1 - \\exp \\left( - \\frac{t}{\\tau} \\right) \\right) \\tag{3.31}\n$$\n$\\Rightarrow \\quad t = - \\tau \\ln \\left( 1 - \\frac{x}{v_{0x} \\tau} \\right)$\n\n- Position equation along the vertical axis:\n$$\nz(t) = (v_{0z} + g\\tau) \\left( 1 - \\exp \\left( - \\frac{t}{\\tau} \\right) \\right) - g t \\tag{3.43}\n$$\n\n- Ballistic trajectory:\n$$\nz(x) = (v_{0z} + g\\tau) \\frac{x}{v_{0x} \\tau} + g\\tau^2 \\ln \\left( 1 - \\frac{x}{v_{0x} \\tau} \\right) \\tag{3.44}\n$$",
    "Chapter 13\n\nRIGID BODY WITH ONE FIXED AXIS AND GYROSCOPES",
    "13. Rigid body with one fixed axis and gyroscopes\n\n13.1 Moments of inertia  \n13.2 Rigid body with a fixed axis  \n13.3 Gyroscope and gyroscopic effects",
    "13.1 Moments of inertia\n\n- We assume that the material points $P_{\\alpha}$ of the rigid body are sufficiently close to each other to generate a continuum in a region of space that corresponds to the volume of the rigid body.\n- Continuum limit:\n  discrete sum $\\sum$ $\\rightarrow$ integral $\\int$\n- Moment of inertia $IG_{i}$ with respect to the axis $Ge_{i}$:\n  \\[\n  I_{G,i} = \\sum_{\\alpha} m_{\\alpha} r_{\\alpha, i}^{2} \\rightarrow I_{G,i} = \\int_{V} dm \\, r^{2}\n  \\]\n  where $m_{\\alpha}$ = mass of the material point $P_{\\alpha}$\n\n  $dm$ = mass of the infinitesimal volume element $dV$\n\n  $r_{\\alpha, i}$ = distance from the material point $P_{\\alpha}$ to the axis $Ge_{i}$\n\n  $r$ = distance from the infinitesimal volume element to the axis $Ge_{i}$\n\n  $V$ = volume of the rigid body",
    "13.1.1 Thin rod\n\n- Rod of mass $M$, of length $L$ and of thickness $e$, $e \\ll L$ oriented along $e_1$ in rotation around the axis $G e_3$.\n\n- Moment of inertia:\n\\[\nIG_{3}=\\int_{-L / 2}^{L / 2} d m \\ell^{2} \\tag{13.2}\n\\]\n\n- Linear density (homogeneous rod):\n\\[\n\\rho_{\\ell} = \\frac{M}{L} \\tag{13.3}\n\\]\n\n- Mass of an infinitesimal length element:\n\\[\nd m=\\rho_{\\ell} d \\ell=\\frac{M}{L} d \\ell \\tag{13.4}\n\\]\n\n- Moment of inertia:\n\\[\nIG_{3}=\\frac{M}{L} \\int_{-L / 2}^{L / 2} \\ell^{2} d \\ell=\\frac{M}{L}\\left[\\frac{\\ell^{3}}{3}\\right]_{-L / 2}^{L / 2}=\\frac{M}{L} \\frac{L^{3}}{12}=\\frac{1}{12} M L^{2} \\tag{13.5}\n\\]",
    "13.1.2 Hollow cylinder\n\n- Hollow cylinder of mass $M$, of height $L$, of radius $R$ and of negligible thickness $e$, i.e. $e \\ll R$, in rotation around the vertical symmetry axis $G e_3$.\n- Moment of inertia:\n\\[ \nI_{G,3} = \\int_{V} dm \\, R^2 \\quad (13.6)\n\\]\n- Infinitesimal volume element: \n\\[\ndV = R \\, L \\, e \\, d\\theta \\quad (13.7)\n\\]\n- Volumetric density (homogeneous): \n\\[\n\\rho = \\frac{M}{V} \\quad (13.8)\n\\]\n- Infinitesimal mass element:\n\\[\ndm = \\rho \\, dV = \\frac{M}{V} \\, R \\, L \\, e \\, d\\theta \\quad (13.9)\n\\]\n- Moment of inertia:\n\\[\nI_{G,3} = \\frac{M}{V} \\, R^3 \\, L \\, e \\int_{0}^{2\\pi} d\\theta = 2\\pi \\, \\frac{M}{V} \\, R^3 \\, L \\, e \\quad (13.10)\n\\]",
    "- Moment of inertia:\n  $I_{G,3} = 2 \\pi \\frac{M}{V} R^3 L e \\quad (13.10)$\n  \n- Volume:  $V = 2 \\pi R L e \\quad (13.11)$\n\n- Moment of inertia:  $I_{G,3} = M R^2 \\quad (13.12)$",
    "13.1.2 Full cylinder\n\n- Full cylinder of mass $M$, of height $L$, of radius $R$ in rotation around the vertical symmetry axis $G e_3$.\n- Moment of inertia:\n\\[ I_{G,3} = \\int_V dmr^2 \\]\n- Infinitesimal volume element: $dV = 2\\pi L r \\, dr$ \\hfill(13.13)\n- Volumetric density (homogeneous): $\\rho = \\frac{M}{V}$ \\hfill(13.8)\n- Infinitesimal mass element: $dm = \\rho dV = \\frac{M}{V} 2\\pi L r \\, dr$ \\hfill(13.14)\n- Moment of inertia:\n\\[ I_{G,3} = 2\\pi \\frac{M}{V} L \\int_0^R r^3 \\, dr = 2\\pi \\frac{M}{V} L \\left[ \\frac{1}{4} r^4 \\right]_0^R = \\frac{\\pi}{2} \\frac{M}{V} L R^4 \\hfill(13.15) \\]",
    "- Moment of inertia:\n\n\\[\nI_{G,3} = \\frac{\\pi}{2} \\frac{M}{V} L R^4 \\quad \\text{(13.15)}\n\\]\n\n- Volume: \n\n\\[\nV = \\pi R^2 L \\quad \\text{(13.16)}\n\\]\n\n- Moment of inertia:\n\n\\[\nI_{G,3} = \\frac{1}{2} M R^2 \\quad \\text{(13.17)}\n\\]",
    "Experiment: Cylinders rolling on an inclined plane\n\nThe of inertia of a full cylinder is smaller than the moment of inertia of a hollow cylinder of the same size and mass. If these cylinders are released at the same time of the same height, the full cylinder will reach the bottom of the inclined plane before the hollow cylinder.",
    "13.2  Rigid body with a fixed axis\n\n13.2.1  Huygens-Steiner theorem\n\nThe Huygens-Steiner theorem states that the moment of inertia $I_{A,i}$ of a rigid body of mass $M$ in rotation around a fixed axis $A e_i$, that is parallel to the principal axis $G e_i$ and orthogonal to the vector $A G$ is expressed in terms of the moment of inertia $I_{G,i}$ and of the distance \n$$d = ||AG|| = \\text{const as},$$\n$$I_{A,i} = I_{G,i} + M \\left( d \\right)^2$$ (13.18)",
    "Demonstration:\n- Angular momentum transfer theorem:\n  $(12.17) \\text{ for } O \\equiv A: \\quad \\mathbf{L}_A = \\mathbf{AG} \\times M \\mathbf{V}_G + \\mathbf{L}_G$ \\quad (13.19)\n- Identity between the velocities:\n  ($A = \\text{point of the axis}$)\n  $\\mathbf{V}_G = \\Omega \\times \\mathbf{AG}$ \\quad because \\quad $\\mathbf{V}_A = 0$ \\quad (13.20)\n  $(13.20) \\Rightarrow (13.19):$\n  $\\mathbf{L}_A = M \\mathbf{AG} \\times (\\Omega \\times \\mathbf{AG}) + \\mathbf{L}_G$ \\quad (13.21)\n  $(1.43) \\Rightarrow \\mathbf{AG} \\cdot \\Omega = 0 \\quad \\text{and} \\quad d^2 = \\mathbf{AG}^2:$\n  $\\mathbf{L}_A = M \\left(AG^2 \\Omega - (\\mathbf{AG} \\cdot \\Omega) \\mathbf{AG}\\right) + \\mathbf{L}_G = M d^2 \\Omega + \\mathbf{L}_G$ \\quad (13.23)\n- $\\mathbf{L}_A$ and $\\mathbf{L}_G$ are collinear to $\\Omega$:\n  $\\mathbf{L}_A = I_{A,i} \\Omega \\quad \\text{and} \\quad \\mathbf{L}_G = I_G,i \\Omega$ \\quad (13.24)\n  $(13.24) \\Rightarrow I_{A,i} \\Omega = (I_G,i + M d^2) \\Omega$ \\quad (13.25)\n  $(13.24) \\Rightarrow I_{A,i} = I_G,i + M d^2$ \\quad (13.26)",
    "13.2.2 Kinetic energy of a rigid body\n\n- Kinetic energy of a rigid body (set of material points):\n\n$$T = \\frac{1}{2} \\sum_\\alpha m_\\alpha v_\\alpha^2 \\quad (13.27)$$ \n\n- The relation between the velocities $v_\\alpha = v_G + v'_\\alpha$ (11.40) \n\n\\[\n\\Rightarrow \n\\]  \n\n$$T = \\frac{1}{2} \\sum_\\alpha m_\\alpha (v_G + v'_\\alpha)^2$$ \n\n$$= \\frac{1}{2} \\left( \\sum_\\alpha m_\\alpha \\right) v_G^2 + v_G \\left( \\sum_\\alpha m_\\alpha v'_\\alpha \\right) + \\frac{1}{2} \\sum_\\alpha m_\\alpha v'_\\alpha^2$$ \n\n$$= \\left( 0 \\right) + \\frac{1}{2} \\sum_\\alpha m_\\alpha v'_\\alpha^2 \\quad (13.28)$$  \n\n\\[\n\\Rightarrow\n\\] \n\n$$T = \\frac{1}{2} M v_G^2 + \\frac{1}{2} \\sum_\\alpha m_\\alpha v'_\\alpha^2 \\quad (13.29)$$",
    "- Kinetic energy:\n$$ T = \\frac{1}{2} MV_G^2 + \\frac{1}{2} \\sum_\\alpha m_\\alpha v^\\prime_\\alpha{}^2 \\quad (13.29) $$\n\n- Relative velocity:\n$$ v^\\prime_\\alpha = v_\\alpha - v_G^{(12.5)} = GP_\\alpha^{(11.39)} \\times \\Omega \\times r^\\prime_\\alpha \\quad (11.44) \\quad(13.30) $$\n$$ v^\\prime_\\alpha{}^2 = (\\Omega \\times r^\\prime_\\alpha) \\cdot (\\Omega \\times r^\\prime_\\alpha) = (r^\\prime_\\alpha \\times (\\Omega \\times r^\\prime_\\alpha)) \\cdot \\Omega \\quad (13.31) $$\n(13.31) $\\Rightarrow$ (13.29):\n$$ T = \\frac{1}{2} MV_G^2 + \\frac{1}{2} \\left( \\sum_\\alpha m_\\alpha r_\\alpha^\\prime \\times (\\Omega \\times r_\\alpha^\\prime) \\right) \\cdot \\Omega \\quad (13.32)$$",
    "Kinetic energy:\n\\[\nT = \\frac{1}{2} M V_G^2 + \\frac{1}{2} \\left( \\sum_\\alpha m_\\alpha \\mathbf{r}_\\alpha' \\times (\\mathbf{\\Omega} \\times \\mathbf{r}_\\alpha') \\right) \\cdot \\mathbf{\\Omega} \\tag{13.32}\n\\]\n\nAngular momentum (12.30):\n\\[\n\\mathbf{L}_G = \\sum_\\alpha m_\\alpha \\mathbf{r}_\\alpha' \\times (\\mathbf{\\Omega} \\times \\mathbf{r}_\\alpha') \\quad \\text{where} \\quad \\mathbf{r}_\\alpha' = G P_\\alpha \\tag{13.33}\n\\]\n\n(13.33) $\\rightarrow$ (13.32):\n\\[\nT = \\frac{1}{2} M V_G^2 + \\frac{1}{2} \\mathbf{L}_G \\cdot \\mathbf{\\Omega} \\tag{13.34}\n\\]\n\nPrincipal axis frame $(G, e_1, e_2, e_3)$ where $e_i \\cdot e_j = \\delta_{ij} \\quad \\forall i, j = 1, 2, 3$\n\\[\n\\mathbf{L}_G = \\sum_{j=1}^{3} I_{G,j} \\Omega_j e_j \\quad \\text{and} \\quad \\mathbf{\\Omega} = \\sum_{j=1}^{3} \\Omega_j e_j \\quad \\Rightarrow \\quad \\mathbf{L}_G \\cdot \\mathbf{\\Omega} = \\sum_{j=1}^{3} I_{G,j} \\Omega_j^2\n\\]\n\nKinetic energy of a rigid body:\n\\[\nT = \\frac{1}{2} M V_G^2 + \\frac{1}{2} \\sum_{j=1}^{3} I_{G,j} \\Omega_j^2 \\tag{13.35}\n\\]",
    "- Kinetic energy of a rigid body:\n\n\\[ T = \\frac{1}{2} MV_G^2 + \\frac{1}{2} \\sum_{j=1}^{3} I_{G,j} \\Omega_j^2 \\quad (13.35) \\]\n\n- Kinetic energy (fixed axis \\( G e_i \\Rightarrow \\Omega_j = \\Omega \\delta_{ij} \\))\n\n\\[ T = \\frac{1}{2} MV_G^2 + \\frac{1}{2} I_{G,i} \\Omega^2 \\quad \\text{ where } \\quad \\Omega = \\Omega e_i \\quad (13.36) \\]",
    "13.2.3 Kinetic energy theorem\n\nTheorem: The time derivative of the kinetic energy $T$ of the rigid body where the centre of mass $G$ has a velocity $V_G$ and that is rotating around the centre of mass $G$ at angular velocity $\\Omega$ is written as:\n\n$$\\frac{dT}{dt} = F^{ext} \\cdot V_G + \\tau_G^{ext} \\cdot \\Omega \\quad (13.37)$$\n\nwhere $F^{ext}$ = net external force\n\n$\\tau_G^{ext}$ = net external torque evaluated at $G$.\n\nFor the mechanics of a rigid body, the first law of thermodynamics reduces to the kinetic energy theorem.",
    "Demonstration:\n- Kinetic energy:\n$$ T = \\frac{1}{2} M V_{G}^{2} + \\frac{1}{2} \\sum_{j=1}^{3} I_{G,j}\\, \\Omega_{j}^{2} \\quad \\text{where} \\quad I_{G,j} = \\text{const} \\quad (13.38) $$\n\n- Time derivative of the kinetic energy:\n$$ \\frac{dT}{dt} = M \\frac{dV_{G}}{dt} \\cdot V_{G} + \\sum_{j=1}^{3} I_{G,j} \\frac{d \\Omega_{j}}{dt} \\Omega_{j} $$\n\n$$ = \\frac{d (M V_{G})}{dt} \\cdot V_{G} + \\sum_{j=1}^{3} (\\dot{I}_{G,j} \\Omega_{j}) \\cdot \\Omega_{j} \\quad (13.39) $$\n\n$$ P = M V_{G} \\quad \\text{and} \\quad L_{G} = \\sum_{j=1}^{3} I_{G,j} \\Omega_{j} e_{j} \\quad \\text{with} \\quad e_{j} \\cdot e_{i} = 1: $$\n\n$$ \\frac{dT}{dt} = \\frac{dP}{dt} \\cdot V_{G} + \\frac{d L_{G}}{dt} \\cdot \\Omega \\quad (13.40) $$",
    "- Time derivative of the kinetic energy:\n\n\\[\n\\frac{dT}{dt} = \\frac{d\\mathbf{P}}{dt} \\cdot \\mathbf{V}_G + \\frac{d\\mathbf{L}_G}{dt} \\cdot \\mathbf{\\Omega} \\tag{13.40}\n\\]\n\n\\[\n\\mathbf{F}^{\\text{ext}} = \\frac{d\\mathbf{P}}{dt} \\quad \\text{and} \\quad \\mathbf{\\tau}_G^{\\text{ext}} = \\frac{d\\mathbf{L}_G}{dt}\n\\]\n\n\\[\n\\frac{dT}{dt} = \\mathbf{F}^{\\text{ext}} \\cdot \\mathbf{V}_G + \\mathbf{\\tau}_G^{\\text{ext}} \\cdot \\mathbf{\\Omega} \\tag{13.41}\n\\]",
    "13.2.4 Unbalanced wheel\n\n- The principal axis $Ge_1$, $Ge_2$ and $Ge_3$ are at rest with respect to the frame of reference of the wheel.\n\n- The angular velocity vector is expressed in the principal axis frame as (at $t=0$, $e_1$ is a horizontal vector),\n\n\\[\n\\Omega_1 = \\Omega \\sin \\theta \\sin (\\Omega t)\n\\]\n\\[\n\\Omega_2 = \\Omega \\sin \\theta \\cos (\\Omega t)\n\\]\n\\[\n\\Omega_3 = \\Omega \\cos \\theta\n\\]\n\n- Time derivative of the relations (13.42):\n\n\\[\n\\dot{\\Omega}_1 = \\Omega^2 \\sin \\theta \\cos (\\Omega t)\n\\]\n\\[\n\\dot{\\Omega}_2 = - \\Omega^2 \\sin \\theta \\sin (\\Omega t)\n\\]\n\\[\n\\dot{\\Omega}_3 = 0\n\\]\n\n- Moments of inertia (cylinder):\n\n\\[\nIG_3 \\equiv IG_{\\parallel} ; \\quad IG_1 = IG_2 \\equiv IG_{\\perp}\n\\]",
    "- Angular velocity and acceleration:\n\n\\[\n\\begin{aligned}\n    \\Omega_1 &= \\Omega \\sin \\theta \\sin (\\Omega t) & ; \\quad \\dot{\\Omega}_1 = \\Omega^2 \\sin \\theta \\cos (\\Omega t) \\\\\n    \\Omega_2 &= \\Omega \\sin \\theta \\cos (\\Omega t) & ; \\quad \\dot{\\Omega}_2 = -\\Omega^2 \\sin \\theta \\sin (\\Omega t) \\\\\n    \\Omega_3 &= \\Omega \\cos \\theta & \\dot{\\Omega}_3 = 0\n\\end{aligned}\n\\] \n\n\\[\n(13.42) + (13.43)\n\\]\n\n- Euler equations (12.48) with (13.42) + (13.43):\n\n\\[\n\\begin{aligned}\n    \\tau_{G,1}^{\\text{ext}} &= I_{G, \\bot} \\Omega^2 \\sin \\theta \\cos (\\Omega t) + (I_{G, \\bot} - I_{G, \\|}) \\Omega^2 \\cos \\theta \\sin \\theta \\cos (\\Omega t)\\\\\n    \\tau_{G,2}^{\\text{ext}} &= -I_{G, \\bot} \\Omega^2 \\sin \\theta \\sin (\\Omega t) + (I_{G, \\bot} - I_{G, \\|}) \\Omega^2 \\cos \\theta \\sin \\theta \\sin (\\Omega t)\\\\\n    \\tau_{G,3}^{\\text{ext}} &= 0\n\\end{aligned}\n\\]\n\n\\[\n(13.44)\n\\]",
    "- External torque $\\tau^{\\text{ext}}_G$ exerted by the axis on the wheel: \n\\[\n\\tau^{\\text{ext}}_G = \\left( I_{G,\\perp} + (I_{G,\\parallel} - I_{G,\\perp}) \\cos \\theta \\right) \\Omega^2 \\sin \\theta \\cos (\\Omega t) \\, e_1 \n- \\left( I_{G,\\perp} + ((I_{G,\\parallel} - I_{G,\\perp}) \\cos \\theta \\right) \\Omega^2 \\sin \\theta \\sin (\\Omega t) \\, e_2 \\tag{13.45}\n\\]\n\n- The net external torque $\\tau^{\\text{ext}}_G$ is periodical \n\\[\n\\Rightarrow \\text{shakes! If } \\theta \\rightarrow 0 \\Rightarrow \\tau^{\\text{ext}}_G \\rightarrow 0\n\\]",
    "13.3 Gyroscope and gyroscopic effects\n\n- A gyroscope is a rotating wheel or disk where the rotation axis keeps a given orientation. When the wheel is rotating, the orientation of the axis is not modified by the rotation of the internal or external frame.\n\n- Gyroscopes are widely used in aeronautics.\n\n- The gyroscope was invented in 1852 by Leon Foucault as an alternative to the Foucault pendulum to demonstrate the earth\u2019s rotation; \u201cgyroscope\u201d = \"that enables to see the rotation of\" the earth.",
    "13.3.1 Gyroscopic effects\n\nBy analogy with the gyroscope, gyroscopic effects denote the dynamical behaviour of a rotating disk or wheel that resists any change of orientation of its rotation axis. These gyroscopic effects are related to the conservation law of angular momentum in the absence of an external torque.\n\n1. The wheel turns in a vertical plane $\\Rightarrow L_{z} = 0$\n2. The wheel turns in a horizontal plane $\\Rightarrow$ the person and the wheel turn in opposite directions such that $L_{z} = 0$",
    "Experiments: \u2460 Wheel held by hand\nWhen a rotating wheel is held by hand its weight $P=Mg$ generates a torque $\\tau^{\\text{ext}} = r \\times P$ on the wrist at $O$. The torque is orthogonal to the rotation axis.\n\nAccording to the angular momentum theorem, the variation of the angular momentum $d\\vec{L}_O$ is collinear to the external torque $\\vec{\\tau}^{\\text{ext}}_O$ and thus it is orthogonal to the rotation axis. This leads to a precession motion of the rotation axis. To keep the rotation axis fixed, the wrist needs to exert a torque of equal norm and opposite direction!",
    "2. Gyroscopic precession of a bike wheel\n\nWhen the rotating wheel is suspended to the extremity of its rotation axis, the torque due to its own weight generates the precession of the wheel around the rope, in agreement with the angular momentum theorem.",
    "13.3.2 Bike wheel\n\nLet us consider a bike wheel of mass $M$, of radius $R$ that is rolling without slipping. The centre of mass $G$ has a uniform circular motion of radius $\\rho = \\text{const}$ at angular velocity $\\dot{\\varphi} = \\dot{\\theta}_e = \\text{const}$.\n\nWe would like to determine the inclination angle $\\theta = \\text{const}$.\n\nPrincipal axis frame: $(G, e_1, e_2, e_3)$ where $e_1 = \\text{horizontal vector}$\n\n1. Kinematics: Angular velocity vector:\n\n$\\Omega = \\dot{\\varphi} + \\dot{\\psi} e_1 = \\dot{\\varphi} \\cos \\theta e_2 + (\\dot{\\theta} \\sin \\theta - \\dot{\\psi}) e_3$\n\nVelocity of the centre of mass (UCM + rolling without slipping):\n\n$V_G = V_C e_{\\varphi} = \\rho \\dot{\\varphi} e_{\\varphi}$\n\n$V_G = \\Omega \\times CG = (\\dot{\\varphi} \\cos \\theta e_2 + (\\dot{\\theta} \\sin \\theta - \\dot{\\psi}) e_3) \\times R e_2$\n\n$= -R (\\dot{\\theta} \\sin \\theta - \\dot{\\psi}) e_{\\varphi} = -R (\\dot{\\theta} \\sin \\theta - \\dot{\\psi}) e_{\\varphi}$ (13.48)",
    "- Angular velocity vector:\n\\[ \\Omega = \\dot{\\phi} \\cos \\theta \\, \\mathbf{e_2} + (\\dot{\\phi} \\sin \\theta - \\dot{\\psi}) \\, \\mathbf{e_3} \\tag{13.46} \\]\n\n- Velocity of the centre of mass:\n\\[ V_G = \\dot{\\phi} R \\, \\mathbf{e_b} \\quad \\text{and} \\quad V_G = -R (\\dot{\\phi} \\sin \\theta - \\dot{\\psi}) \\, \\mathbf{e_{\\phi}} \\]\n\n\\[ \\Rightarrow \\dot{\\phi} \\sin \\theta - \\dot{\\psi} = -\\frac{\\dot{R}}{R} \\dot{\\phi} \\tag{13.49} \\]\n\n\\[ \\Rightarrow \\Omega = \\dot{\\phi} \\cos \\theta \\, \\mathbf{e_2} - \\frac{\\dot{R}}{R} \\dot{\\phi} \\, \\mathbf{e_3} \\tag{13.50} \\]\n\n2. Dynamics\n\nWe evaluate the angular momentum theorem at the point of contact $C$ between the wheel and the ground, such that the torque due to the normal reaction $N$ vanishes. The only non vanishing torque is due to the weight $P$.\n\n\\[ \\text{External torque:} \\]\n\n\\[ \\mathbf{\\tau}^{\\text{ext}}_C = \\mathbf{CG} \\times \\mathbf{P} = \\mathbf{R e_2} \\times (-M g \\mathbf{e_3}) = -M R g \\sin \\theta \\, \\mathbf{e_2} \\times \\mathbf{e_3} \\]\n\\[ = -M R g \\sin \\theta \\, \\mathbf{e_1} = -M R g \\sin \\theta \\, \\mathbf{e_{\\theta}} \\tag{13.51} \\]",
    "- Angular momentum transfer theorem:\n\n\\[ L_C = L_G + CG \\times M \\, V_G \\]\n\\[ = L_G + (R e_2) \\times \\left( M \\rho \\dot{\\phi} e_1 \\right) \\]\n\\[ = L_G - MR \\rho \\dot{\\phi} e_3 \\]\n\\[ L_G = IG_1 \\, \\Omega_1 e_1 + IG_2 \\, \\Omega_2 e_2 + IG_3 \\, \\Omega_3 e_3 \\]\n\\[ = IG_2 \\dot{\\phi} \\cos \\theta \\, e_2 + IG_3 \\frac{\\rho}{R} \\dot{\\phi} e_3 \\]\n\n(13.52) \\\\\n(13.53)\n\n- Moments of inertia (hollow cylinder):\n\n\\[ IG_1 = IG_2 = \\frac{1}{2} MR^2 \\quad \\text{and} \\quad IG_3 = MR^2 \\]\n\n(13.54)\n\n- Angular momenta:\n\n\\[ L_G = \\frac{1}{2} MR^2 \\dot{\\phi} \\cos \\theta_2 - MR \\rho \\dot{\\phi} e_3 \\]\n\n(13.55)\n\n\\[ L_C = \\frac{1}{2} MR^2 \\dot{\\phi} \\cos e_2 - 2 MR \\rho \\dot{\\phi} e_3 \\]\n\n(13.56)",
    "- Angular momentum:\n\\[ L_C = \\frac{1}{2} MR^2 \\dot{\\phi} \\cos \\theta \\, \\mathbf{e}_2 - 2 MR \\dot{\\phi} \\mathbf{e}_3 \\] \n(13.56)\n\n- Basis vectors:\n\\[ \\mathbf{e}_2 = - \\sin \\theta \\, \\mathbf{e}_p + \\cos \\theta \\, \\mathbf{e}_z \\]\n\\[ \\mathbf{e}_3 = \\cos \\theta \\, \\mathbf{e}_p + \\sin \\theta \\, \\mathbf{e}_z \\]\n\n- Angular momentum:\n\\[ L_C = - \\left( \\frac{1}{2} MR^2 \\dot{\\phi} \\cos \\theta \\sin \\theta + 2 MR \\dot{\\phi} \\cos \\theta \\right) \\mathbf{e}_p + \\left( \\frac{1}{2} MR^2 \\dot{\\phi} \\cos^2 \\theta - 2 MR \\dot{\\phi} \\sin \\theta \\right) \\mathbf{e}_z \\]\n(13.58)\n\n- All the terms in brackets are constants. Moreover,\n\\[ \\dot{\\mathbf{e}}_p = \\dot{\\phi} \\mathbf{e}_h \\]\nand \n\\[ \\dot{\\mathbf{e}}_z = 0 \\]\n(5.6)",
    "- Angular momentum:\n\\[ L_C = -\\left(\\frac{1}{2} MR^2 \\dot{\\phi} \\cos \\theta \\sin \\theta + 2 MR \\rho \\dot{\\phi} \\cos \\theta \\right) e_\\varphi \\]\n\\[ + \\left(\\frac{1}{2} MR^2 \\dot{\\theta}^2 \\cos^2 \\theta - 2 MR \\rho \\dot{\\phi} \\sin \\theta \\right) e_z \\quad (13.58) \\]\n\n- All the terms in brackets are constants. Moreover,\n\\[ \\dot{e}_\\varphi = \\dot{\\phi} e_\\theta \\quad \\text{and} \\quad \\dot{e}_z = 0 \\quad (5.6) \\]\n\n- Time derivative of the angular momentum: \\((R \\ll \\rho)\\)\n\\[ \\frac{dL_C}{dt} = -\\left(\\frac{1}{2} MR^2 \\dot{\\phi} \\cos \\theta \\sin \\theta + 2 MR \\rho \\dot{\\phi} \\cos \\theta \\right) \\dot{e}_\\varphi \\]\n\\[ = -2 MR \\rho \\dot{\\phi} \\cos \\theta \\left( 1 + \\frac{R}{4 \\rho} \\sin \\theta \\right) e_\\varphi \\quad \\approx -2 MR \\rho \\dot{\\phi}^2 \\cos \\theta e_\\varphi \\]",
    "- Time derivative of the angular momentum:\n \\[\n\\frac{d\\vec{L}_C}{dt} = -2MR\\dot{\\phi}^2 \\cos \\theta \\, \\vec{e}_{\\phi} \\qquad (13.60)\n\\]\n\n- External torque:\n\\[\n\\vec{\\tau}^{\\text{ext}}_C = -MRg \\sin \\theta \\, \\vec{e}_{\\phi} \\qquad (13.51)\n\\]\n\n- Angular momentum theorem:\n\\[\n\\vec{\\tau}^{\\text{ext}}_C = \\frac{d\\vec{L}_C}{dt} \\quad \\text{where} \\quad V_C = 0 \\qquad (12.26)\n\\]\n\\[\n(13.51) \\quad (13.60) \\quad \\Rightarrow -2MR\\dot{\\phi}^2 \\cos \\theta = -MRg \\sin \\theta\n\\]\n\n\\[\n\\Rightarrow \\tan \\theta = \\frac{2 \\rho \\dot{\\phi}^2}{g} = \\frac{2V_G^2}{\\rho g} = \\frac{2AG}{g} \\qquad (13.62)\n\\]\n\nIf $V_G = \\text{const}$:\n\\[\n\\begin{cases}\n\\rho \\uparrow \\quad \\theta \\uparrow \\\\\n\\rho \\downarrow \\quad \\theta \\downarrow\n\\end{cases}\n\\]\n\nIf $p = \\text{const}$:\n\\[\n\\begin{cases}\nV_G \\uparrow \\quad \\theta \\uparrow \\\\\nV_G \\downarrow \\quad \\theta \\downarrow\n\\end{cases}\n\\]",
    "13.3.3 Spinning top\n\nLet us consider a spinning top of mass $M$ where the tip located at $O$ is fixed. Let $\\ell = |OG|$ be the distance between the tip and centre of mass.\nPrincipal axis frame $(G, e_1, e_2, e_3)$ where $e_1 =$ horizontal vector\n\n\u2460 Kinematics\nTotal angular velocity vector: \n$$\\Omega = \\dot{\\phi} + \\dot{\\psi} = \\dot{\\phi} e_3 + \\dot{\\psi} e_3 = \\dot{\\phi} e_1 + \\dot{\\phi} \\sin \\theta e_2 + \\left( \\dot{\\psi} + \\dot{\\theta} \\cos \\theta \\right) e_3$$ (13.63)\n\n\u2461 Dynamics\nExternal torque:\n$$\\tau_{ext} = OG \u00d7 P = (\\ell e_3) \u00d7 (- Mg e_z) = - Mg \\ell \\sin \\theta e_3 \u00d7 e_2 = Mg \\ell \\sin \\theta e_1 = Mg \\ell \\sin \\theta e_{\\phi}$$ (13.64)",
    "- Moments of inertia:\n\\[ I_{O,1} = I_{O,2} \\equiv I_{O,\\perp} \\quad \\text{and} \\quad I_{O,3} \\equiv I_{O,\\parallel} \\]\n\n- Angular momentum:\n\\[\n\\mathbf{L}_O = I_{O,1} \\Omega_1 e_1 + I_{O,2} \\Omega_2 e_2 + I_{O,3} \\Omega_3 e_3  \n= I_{O,\\perp} \\dot{\\theta} e_1 + I_{O,\\perp} \\dot{\\psi} \\sin \\theta e_2  \n+ I_{O,\\parallel} (\\dot{\\varphi} + \\dot{\\psi} \\cos \\theta) e_3  \n= I_{O,\\perp} \\dot{\\theta} \\hat{e}_{\\theta} - I_{O,\\perp} \\dot{\\psi} \\sin \\theta \\hat{e}_{r} + I_{O,\\parallel} (\\dot{\\varphi} + \\dot{\\psi} \\cos \\theta) \\hat{e}_{r} \\quad \\text{(3.65)}\n\\]\n\n- Time derivative of the angular momentum:\n\\[\n\\frac{d \\mathbf{L}_O}{dt} = I_{O,\\perp} \\ddot{\\theta} e_1 - I_{O,\\perp} (\\dot{\\psi} \\sin \\theta + \\ddot{\\varphi} \\cos \\theta) e_{\\theta}  \n+ I_{O,\\parallel} (\\ddot{\\varphi} + \\ddot{\\psi} \\cos \\theta - \\dot{\\psi} \\sin \\theta) e_r \\quad \\text{(3.66)}\n\\]\n\n- Time derivative of the basis vectors:\n\\[\n\\dot{e}_r = \\dot{\\theta} e_{\\theta} + (\\dot{\\varphi} + \\dot{\\psi} \\cos \\theta) e_{\\phi}, \\quad \\dot{e}_{\\theta} = -\\dot{\\theta} e_r + \\dot{\\psi} \\cos \\theta e_{\\phi}, \\quad \\dot{e}_{\\phi} = -\\dot{\\varphi} e_{r} - \\dot{\\psi} \\sin \\theta e_{\\theta} \\quad \\text{(5.16)}\n\\]",
    "- Time derivative of the angular momentum:\n\\[\n\\frac{d \\mathbf{L}_O}{dt} = I_{O, \\parallel} \\left( \\ddot{\\psi} + \\dot{\\phi} \\cos \\theta - \\dot{\\phi} \\sin \\theta \\right) \\mathbf{e}_r \\\\\n+ I_{O, \\parallel} \\left( \\dot{\\psi} + \\dot{\\phi} \\cos \\theta \\right) \\mathbf{e}_a \\\\\n+ I_{O, \\perp} \\left( \\ddot{\\phi} \\sin \\theta + 2 \\dot{\\phi} \\dot{\\theta} \\cos \\theta \\right) \\mathbf{e}_\\theta \\\\\n+ I_{O, \\parallel} \\ddot{\\phi} \\mathbf{e}_b + \\left( I_{O, \\parallel} - I_{O, \\perp} \\right) \\dot{\\phi} \\sin \\theta \\cos \\theta \\mathbf{e}_a \\\\\n+ I_{O, \\parallel} \\dot{\\psi} \\sin \\theta \\mathbf{e}_b\n\\]\n\n- External torque: $\\boldsymbol{\\tau}^{\\text{ext}} = Mg \\ell \\sin \\theta \\mathbf{e}_b$\n\n- Angular momentum theorem: $\\boldsymbol{\\tau}^{\\text{ext}} = \\frac{d \\mathbf{L}_O}{dt} \\quad \\text{(13.69)}$\n\n- Equations of motion (precession, nutation, intrinsic rotation):\n  along $\\mathbf{e}_r$: $I_{O, \\parallel} \\left( \\ddot{\\psi} + \\dot{\\phi} \\cos \\theta - \\dot{\\phi} \\sin \\theta \\right) = 0$\n  \n  along $\\mathbf{e}_a$: $I_{O, \\parallel} \\left( \\dot{\\psi} + \\dot{\\phi} \\cos \\theta \\right) - I_{O, \\perp} \\left( \\dot{\\psi} \\sin \\theta + \\dot{\\phi} \\cos \\theta + 2 \\dot{\\phi} \\cos \\theta \\right) = 0$\n  \n  along $\\mathbf{e}_\\theta$: $I_{O, \\perp} \\left( \\ddot{\\phi} \\sin \\theta + 2 \\dot{\\phi} \\dot{\\theta} \\cos \\theta \\right) + I_{O, \\perp} \\dot{\\psi} \\sin \\theta = Mg \\ell \\sin \\theta \\quad \\text{(13.70)}$",
    "- Particular case (negligible nutation):\n\n    $\\theta = \\text{const} \\quad \\Rightarrow \\quad \\dot{\\theta} = 0 \\quad \\text{and} \\quad \\ddot{\\theta} = 0$\n    \n- Equations of motion: (precession intrinsic rotation)\n\n    along $\\mathbf{e_r}$: $I_{O, \\perp} (\\dot{\\psi} \\dot{\\phi} + \\ddot{\\phi} \\cos \\theta) = 0$\n\n    along $\\mathbf{e_{\\phi}}$: $-I_{O, \\perp} \\dot{\\theta} \\sin \\theta = 0 \\quad (13.71)$\n\n    along $\\mathbf{e_{\\theta}}$: $(I_{O, \\perp} - I_{O, \\parallel}) \\dot{\\phi}^2 \\cos \\theta \\sin \\theta + I_{O, \\parallel} \\ddot{\\psi} \\dot{\\phi} \\sin \\theta = Mg \\ell \\sin \\theta$\n\n    $\\Rightarrow \\quad \\dot{\\phi} = 0 \\quad \\Rightarrow \\quad \\phi = \\text{const}$\n\n    $\\Rightarrow \\quad \\dot{\\psi} = \\dot{\\psi} = \\text{const}$\n\n- Approximation: slow precession with respect to the intrinsic rotation: $\\dot{\\phi} \\ll \\dot{\\psi}$\n\n    $\\Rightarrow \\quad I_{O, \\parallel} \\ddot{\\psi} = Mg \\ell \\quad \\Rightarrow \\quad \\dot{\\psi} = \\frac{Mg \\ell}{I_{O, \\parallel} \\dot{\\psi}} \\quad (13.72)$\n\n- Indeed, the precession angular velocity $\\dot{\\psi}$ is then inversely proportional to the intrinsic rotation angular velocity $\\dot{\\psi}$.",
    "Experiment: \u2460 Spinning top with a bike wheel\n\nSpinning top consisting of a bike wheel having an intrinsic rotation motion around its axis of symmetry, having a precession motion around the vertical axis and a nutation motion around the horizontal nodal axis.",
    "2 Rattleback\n\nThe rattleback is an ellipsoid cut along a plane that does not contain two axes of symmetry. When it is set in motion in the right direction, the rotation axis is a principal axis. When it is set in motion in the wrong direction, the rotation axis is not a principal axis which yields a yaw and roll - generated by the net external torque as for the unbalanced wheel - which increases over time and eventually stops the precession motion of the rattleback and sets it into a precession motion the other way around...\n\n- END -\n\nDr Sylvain Br\u00e9chet       Chapter 13: Rigid body with one fixed axis and gyroscopes                    37",
    "A.12 Rigid body kinematics and dynamics\n\nA.12.1 Dumbbell pulled by a string\n\nA.12.2 Yoyo",
    "A.12.1 Dumbbell pulled by a string\n\nA dumbbell of mass $M$ consists of a handle of radius $r$ and of two disks of radii $R$. It is pulled by a traction force $\\vec{T} = \\text{const.}$ It rolls without sliding on a horizontal plane. Its moment of inertia with respect to its axis of symmetry is $I_g$. The string does not slide with respect to the handle.",
    "- External forces:\n    - Weight: $\\vec{P} = \\vec{F_g} = Mg \\vec{e_y}$\n    - Normal reaction: $\\vec{N} = -N \\vec{e_y}$\n    - Traction: $\\vec{T} = -T \\vec{e}_t = T \\cos \\alpha \\vec{e_x} - T \\sin \\alpha \\vec{e_y}$\n    - Static friction: $\\vec{F_s} = F_s \\vec{e_x}$\n    where $F_s \\in \\mathbb{R}$\n\n- Centre of mass theorem:\n    $\\vec{F}_{\\text{ext}} = \\vec{P} + \\vec{N} + \\vec{T} + \\vec{F_s} = M \\vec{A}_G$\n\nalong $\\vec{e_x}$: $T \\cos \\alpha + F_s = M \\vec{a}_{Gx}$ \\hspace{1cm} (A.12.1)\n\nalong $\\vec{e_y}$: $Mg - N - T \\sin \\alpha = M \\vec{a}_{Gy} = 0$ \\hspace{1cm} (A.12.2)",
    "- Angular momentum theorem: $\\overrightarrow{T_{G}} = I_{G} \\dot{\\Omega}_{z}$\n$$\\overrightarrow{T_{G_{ext}}} = \\frac{d \\overrightarrow{L_{G}}}{dt} = I_{G} \\dot{\\Omega}_{z}$$\n$$\\overrightarrow{G_{C}} \\times \\overrightarrow{P_{C}} + \\overrightarrow{GC} \\times \\overrightarrow{N_{O}} + \\overrightarrow{GA} \\times \\overrightarrow{T} + \\overrightarrow{GC} \\times \\overrightarrow{F_{S}} = I_{G} \\dot{\\Omega}_{z}$$\n$$\\therefore \\overrightarrow{r_{0P}} \\times (\\overrightarrow{T} - T_{e_{x}} e_{x}) + \\overrightarrow{R_{e_{x}}} \\times F_{e_{x}} = I_{G} \\dot{\\Omega}_{z} e_{z}$$\nalong $e_{x}: \\quad r T - R F_{S} = I_{G} \\dot{\\Omega}_{z} e_{z}$ \\hspace{1cm} ($A.12.3$)\n\n- Link (rolling without sliding)\n$$\\overrightarrow{V_{G}} = \\overrightarrow{V_{C}} + \\overrightarrow{\\Omega_{z}} \\times \\overrightarrow{CG} \\quad \\text{where,} \\quad \\overrightarrow{V_{C}} = \\overrightarrow{0}$$\n$$\\therefore \\overrightarrow{V_{G}} = \\overrightarrow{\\Omega_{z}} \\times \\overrightarrow{CG} \\longrightarrow \\overrightarrow{\\dot{\\Omega}_{z}} \\quad \\text{where} \\quad \\overrightarrow{CG} = Const$$\n$$\\overrightarrow{A_{G}} = \\dot{\\Omega_{z}} \\times \\overrightarrow{CG} \\hspace{1cm} (A.12.4)$$",
    "$ \\vec{A}_G = \\ddot{x}_G \\vec{e}_x' \\; ; \\; \\vec{\\dot{\\Omega}} = \\ddot{\\Phi} \\vec{e}_z' \\; ; $\n\n$ \\vec{C}\\vec{G} = -R \\vec{e}_y' $\n\n$ (\\text{A.12.4}) \\Rightarrow \\quad \\ddot{x}_C \\vec{e}_x = \\ddot{\\Phi} \\vec{e}_x \\times (-R \\vec{e}_y') = R \\ddot{\\Phi} \\vec{e}_x' \\; \\text{along} \\; \\vec{e}_x' \\rightarrow \\ddot{x}_G = R \\ddot{\\Phi} $\n\n$ (\\text{A.12.5}) $\n\n$ (\\text{A.12.1}) \\Rightarrow $\n\n$ T \\cos \\alpha + F_5 = M \\ddot{x}_G \\; (\\text{A.12.6}) $\n\n$ -r T - R F_5 = I_G \\dot{\\Omega} \\; (\\text{A.12.3}) $\n\n$ \\cdot \\; R \\cdot (\\text{A.12.6}) - (\\text{A.12.3}) : $\n\n$ (R \\cos \\alpha - r) T = \\left(I_G + MR^2 \\right) \\frac{\\ddot{x}_G}{R} \\; (\\text{A.12.7}) $",
    "\\( (A.12.7) \\Rightarrow \\)\n\n\\[\n\\ddot{X}_G = \\frac{\\cos \\alpha - \\frac{r}{R}}{1 + \\frac{I_G}{MR^2}} \\frac{T}{M} \\quad (A.12.8)\n\\]\n\n\u2022 Physical interpretation:\n\nIf \\(\\cos \\alpha > \\frac{r}{R} \\Rightarrow \\ddot{X}_G > 0\\) (right)\n\nIf \\(\\cos \\alpha < \\frac{r}{R} \\Rightarrow \\ddot{X}_G < 0\\) (left)\n\nIf \\(\\cos \\alpha = \\frac{r}{R} \\Rightarrow \\ddot{X}_G = 0\\) (equilibrium)\n\nEquilibrium: \\(\\cos \\alpha = \\frac{r}{R}\\)",
    "- Motion of the centre of mass:\n\\[ T \\cos \\alpha + F_s = M \\ddot{X}_G \\quad \\text{(A.12.6)} \\]\n  \n- Static friction force:\n\\[ F_s = M \\ddot{X}_G - T \\cos \\alpha \\]\n\n- Acceleration of the centre of mass:\n\\[ \\ddot{X}_G = \\frac{\\cos \\alpha \\frac{r}{R}}{1 + \\frac{I_G}{MR^2}} \\frac{T}{M} \\]\n\n- Static friction force:\n\\[ F_s = - \\frac{\\frac{I_G}{MR^2} \\cos \\alpha + \\frac{r}{R}}{1 + \\frac{I_G}{MR^2}} T < 0 \\quad \\text{(A.12.9)} \\]\n\nThe static friction force is oriented towards the left.",
    "A.12.2 Yoyo\n\n- A yoyo consists of a cylinder of mass $M$, of radius $R$ with a string of negligible mass fixed on its surface. The string is attached to the ceiling. Its moment of inertia is $I_G$.\n- External forces:\n  - Weight $\\vec{P} = M\\vec{g} = Mg\\vec{e}_y$\n  - Tension $\\vec{T} = - T\\vec{e}_y$",
    "- Centre of mass theorem:\n$$\\vec{F}_{\\text{ext}} = \\vec{P} + \\vec{T} = M \\vec{A}_{\\vec{G}}$$\nalong $\\vec{e}_y$: \n$$Mg - T = M (-\\ddot{y}_{G}) \\quad (\\text{A.12.10})$$\n\n- Angular momentum theorem:\n$$\\vec{Z}_{\\vec{G}, \\text{ext}} = \\frac{d \\vec{L}_{\\vec{G}}}{dt} = I_{G} \\ddot{\\phi} \\quad \\text{where} \\quad \\vec{Z}_{\\vec{G}} = I_{G} \\ddot{\\Omega}$$\n$$\\vec{G} \\times \\vec{P} + \\vec{G} \\times \\vec{T} = I_{G} \\ddot{\\Omega}$$\n$$\\Rightarrow (-R \\vec{e}_{x}) \\times (-T \\vec{e}_y) = I_{G} \\ddot{\\phi} \\vec{e}_{z}$$\nalong $\\vec{e}_{z}$: \n$$RT = I_{G} \\ddot{\\phi} \\quad (\\text{A.12.11})$$\n\n- Link ($\\vec{V}_{\\vec{C}} = 0$):\n$$\\vec{V}_{\\vec{G}} = \\dot{y} \\vec{e}_{y} + \\dot{\\Omega} \\times \\vec{G} \\Rightarrow \\vec{A}_{\\vec{G}} = \\ddot{y} \\vec{e}_{y} + \\ddot{\\Omega} \\times \\vec{G} \\quad \\text{where} \\quad \\ddot{\\Omega} = \\vec{0}$$\n$$\\Rightarrow \\ddot{y} \\vec{e}_{y} = \\ddot{\\phi} R \\vec{e}_{x} \\Rightarrow \\ddot{y} = R \\ddot{\\phi} \\quad (\\text{A.12.12})$$",
    "\u2022 (A.12.10) and (A.12.12) => (A.12.11) :\n\\[\n\\begin{cases}\nMg - T = M \\ddot{y}_G \\quad \\text{(A.12.10)} \\\\\nR^2 T = I_G \\ddot{y}_G \\quad \\text{(A.12.11)}\n\\end{cases}\n\\]\n\n\u2022 \\( R^2 \\cdot \\text{(A.12.10)} + \\text{(A.12.11)} \\) :\n\\[\nM R^2 \\ddot{y}_G = (I_G + M R^2) \\ddot{y}_G\n\\]\n\n\u21d2 \n\\[\n\\ddot{y}_G = \\frac{M R^2}{I_G + M R^2} g \\quad \\text{(A.12.13)}\n\\]\n\n\u2022 \\( I_G \\cdot \\text{(A.12.10)} = M \\cdot \\text{(A.12.11)} \\)\n\n\\[\nMg I_G - I_G T = M R^2 T\n\\]\n\n\u21d2 \n\\[\nT = \\frac{I_G}{I_G + M R^2} Mg \\quad \\text{(A.12.14)}\n\\]",
    "- Full cylinder: $ I_G = \\frac{1}{2}MR^2 $\n\n$\\ddot{y}_G = \\frac{2}{3} g \\quad (A.12.15)$\n\n$ T = \\frac{1}{3} Mg \\quad (A.12.16)$\n\n- Hollow cylinder: $ I_G = MR^2 $\n\n$\\ddot{y}_G = \\frac{g}{2} \\quad (A.12.17)$\n\n$ T = \\frac{1}{2} Mg \\quad (A.12.18)$",
    "1. Balancing forces\n\n1. The forces exerted on the ball are the weight $W = mg$, the tension force exerted by the right cable $F_1$, and the tension force exerted by the left cable $F_2$.\n\n2. The forces in the $x$ direction are\n\n\\[ W_x = 0 \\]\n\\[ F_{1x} = F_1 \\sin \\theta \\]\n\\[ F_{2x} = -F_2 \\sin \\theta \\]\n\nand the forces in the $y$ direction are\n\n\\[ W_y = -W = -mg \\]\n\\[ F_{1y} = F_1 \\cos \\theta \\]\n\\[ F_{2y} = F_2 \\cos \\theta \\]\n\n3. The ball undergoes no acceleration, so Newton's second law in $\\Sigma F = 0$ and we have\n\n\\[ W_x + F_{1x} + F_{2x} = 0 \\]\n\nWe project this in the $x$ direction to get\n\n\\[ 0 + F_1 \\sin \\theta - F_2 \\sin \\theta = 0 \\]\n\nRearranging, we find\n\n\\[ F_1 \\sin \\theta = F_2 \\sin \\theta \\]  \\qquad (1)\n\nWe then project equation (1) in the $y$ direction to get\n\n\\[ F_1 \\cos \\theta + F_2 \\cos \\theta - mg = 0 \\]  \\qquad (2)\n\nFinally, we get\n\n\\[ F_1 \\cos \\theta + F_2 \\cos \\theta = mg \\]  \\qquad (3)",
    "Substituting (2) into (3) gives\n$$ mg \\sin \\theta + F \\cos \\theta = m g \\cos \\theta - F \\sin \\theta $$\n\nSolving for $F$, gives\n$$ mg \\sin \\theta + F \\cos \\theta = mg \\cos \\theta - F \\sin \\theta $$\n$$ F \\cos \\theta + F \\sin \\theta = mg (\\cos \\theta - \\sin \\theta) $$\n$$ F (\\cos \\theta + \\sin \\theta) = mg (\\cos \\theta - \\sin \\theta) $$\n$$ F = \\frac{mg (\\cos \\theta - \\sin \\theta)}{ (\\cos \\theta + \\sin \\theta)} $$\n\nwhere in the last step we have used the sine and cosine angle sum trigonometric identity. By substituting this into equation (2) we find the final answer for $f$:\n$$ f_B = mg - F \\cos \\theta = mg - \\frac{mg (\\cos \\theta - \\sin \\theta)}{ (\\cos \\theta + \\sin \\theta)} \\cos \\theta = \\frac{mg (1 - [\\cos^2 \\theta - \\sin \\theta \\cos \\theta)]}{ (\\cos \\theta + \\sin \\theta)} = \\frac{mg (1 - \\cos^2 \\theta + \\sin \\theta \\cos \\theta)]}{ (\\cos \\theta + \\sin \\theta)} = \\frac{mg (\\sin^2 \\theta + \\sin \\theta \\cos \\theta)}{ (\\cos \\theta + \\sin \\theta)} $$ \n\nFrom equation (3), we see that, if $ \\theta = 45$, then $ F_B = 0 $, as would be expected from the symmetry of the problem.\n\n2. Triangular trolley \n1. The free body diagrams for both trolleys are shown below. The forces on the small trolley are the weight mg and the normal force from the triangular trolley $f_1$. The forces on the triangular trolley are the weight $Mg$, the normal force from the small trolley $f_1$, the normal force from the ground $f_2$, and the external force $F$. \nAna (triangle)\nJohn (triangle)\n\n2. The forces on the small trolley are the weight mg and the normal force $f$ from the triangular trolley acting on the small trolley. Thus, from Newton\u2019s second law the acceleration of the small trolley is \n$$ mg \\sin \\theta = ma $$\n$$ a = g \\sin \\theta $$\n\nProjecting this in the $x$ (horizontal) direction gives us \n$$ a_x = g \\sin \\theta $$",
    "and\n\n\\[\na_{2} = \\frac{S \\sin \\theta}{m_{2}}\n\\]\n\nThe forces on the triangular trolley are the weight $M_{3} g$, the externally applied force $F$, the normal force $T$ from the ground acting on the triangular trolley and the normal force $S$ from the small trolley blocks on the triangular trolley.\n\nWe can recognize that $S$ and $G$ are action-reaction pairs. Thus, from Newton's third law we know that\n\n\\[\nG = S.\n\\]\n\nUsing this, Newton's second law for the triangular trolley becomes\n\n\\[\nM_{3} g + T + F + G = M_{3} a \\quad \\Rightarrow \\quad \\vec{M_{3} g} + \\vec{T} + \\vec{F} + \\vec{S} = M_{3} \\vec{a}\n\\]\n\nProjecting this in the x and y directions gives\n\n\\[\nA_{x} = \\frac{S \\sin \\theta}{M_{3}}\n\\]\n\nand\n\n\\[\nA_{y} = \\frac{S \\sin \\theta - Mg}{M_3}\n\\]\n\nwhere $F$ and $T$ are the norms of \\vec{F} and \\vec{T} respectively.\n\nSince the triangular trolley is not accelerating vertically, we can take $A_{y} = 0$ to show that\n\n\\[\nT = Mg + S \\cos \\theta.\n\\]\n\nWe want to find the force that leaves the small trolley immobile on the larger one, so we require\n\n\\[\n\\frac{s \\cos \\theta}{m_{1}} = \\frac{S \\cos \\theta}{m_{2}}\n\\]\n\nwhich corresponds to\n\n\\[\n\\frac{S}{m_{1}} = \\frac{S}{m_{2}}\n\\]\n\nrespectively. From the second equation we see that\n\n\\[\n\\frac{S}{m_{2}} = \\frac{g}{m_{1}}\n\\]\n\nwhich can be substituted into the first to find the final answer.\n\n\\[\nF = \\frac{(M + m_{1}) g}{\\tan \\theta}.\n\\]\n\n\\textbf{3. Force with friction}\n\nThe free body diagram for the block on the box is shown below, where we have the normal force of the table on the book $N_{A}$, the static friction force from the table on the book $f_{s}$, and the weight of the book $m_{B}$.",
    "There is no motion in the $y$ direction, so Newton\u2019s second law tells use that the weight is balanced by the normal force $N_s$ according to\n$$N_s - mg = 0 \\Rightarrow N_s = mg. \\tag{1}$$\n\nThe only horizontal force on the book is the static friction force $f_s$, which is equal to its maximum value $f_{s, \\text{max}} = \\mu_s N_s$ when Carl is applying the maximum force for which the book do not slide. By applying Newton\u2019s second law in the $x$ direction, we find\n$$f_s - F = 0 \\Rightarrow \\mu_s N_s = mg. \\tag{2}$$\n\nTherefore, using equation (1) we see that the acceleration is\n$$a = \\frac{F}{m} = g. \\tag{3}$$\n\nNow consider the table, where the free body diagram is shown below and includes a lot of forces. There is the upward normal force value $N_T$ from the support table of Carl, plus the kinetic friction force from the floor pulling the leg of the table group $f_k$ from the table leg, equal by Carl\u2019s leg. The static friction force $f_s$ due to the book on the table and that should be diagram is equal to support leg but reaction of static friction horizontal force $f_s$ and we have $f - F$ force of legs on the floor. We need to use as applied to magnitude and opposite in direction. \n\nNotice when the book slips the kinetic friction force, the table slips to as horizontal friction with small acceleration $a_{T}$ if the table leg imparts. The table and book is at rest friction horizontally. The kinetic friction force $f_s$ between the table and the floor is magnitude of $\\mu_k N_s$.\n\n$$N_s$$\n\nNow the table does not accelerate in the $y$ direction, Newton\u2019s second law gives\n$$N_s - Mg + f_s = 0 \\Rightarrow M_s - Mg + (f_s - F) = 0. \\tag{4}$$\n\nWhere we have used equation (2). In the $x$ direction, Newton\u2019s second law for the table is\n$$ f_s - f_k = m g - \\mu_k m a_T. \\tag{5}$$",
    "By substituting equations (i) through (iv) and the forms of the friction force $f_{\\parallel} = \\mu_t m_0 g$, and $f_{\\perp} = \\mu_n N_{50}$ from above, we obtain\n\n\\[\nf_{\\parallel} = f_{\\perp} = \\mu_t F_0 - \\mu_n M_{50}g = 0 \\Rightarrow F_0 = (\\mu_t + \\mu_n)g M_{50}\n\\]\n\nSolving for this equation for $F_0$ gives the final answer of\n\n\\[\nF_0 = \\frac{\\mu_t M_0 g}{\\mu_t + \\mu_n} g = (\\mu_t + \\mu_n)g M_{50}\n\\]\n\nand we can plug in numbers to find\n\n\\[\nF = 150 N.\n\\]\n\n4. Challenge: Rugby up-and-under play\n\nAs indicated in the title, this problem is challenging. We start by defining the coordinate system such that the upward direction is positive and $x$ is in the horizontal direction of the initial velocity of the ball. A player starts from rest at the location $y_0 > 0$ and is moving upward after the ball is kicked. In order to tackle the problem, we have the following set of equations:\n\n\\[\n\\mathbf{v} = \\mathbf{u} + \\mathbf{a}t\n\\]\n\nThe velocity vector $\\mathbf{v}$ and the acceleration vector $\\mathbf{a}$. The initial velocity $\\mathbf{u}$ is along the x direction and is to be used below. We start from the original set of equations for projectile motion along $x$ and $y$, which in this system is given by\n\n\\[\ny(t) = \\bigg( \\frac{v_0 t + v_1 t (v_{0z}/v_0) - \\frac{1}{2} at^2 + v_{1z}}{t} \\bigg) - \\frac{1}{2} a \\bigg( (\\frac{t-u_y}{g})^2 + \\frac{v_y}{u_y} \\bigg), \\quad (i)\n\\]\n\\[\nx(t) = \\bigg( -\\frac{1}{2} at^2 + \\frac{u_y}{g} \\bigg), \\quad (ii)\n\\]\n\n1. We want to find the distance at which the player catches the ball. To do so, we must first find the time $t_1$ at which the player catches the ball. At this moment, we have an equation for vertical displacement from which we obtain\n\n\\[\nv_y(t_0)(\\frac{t-u_y}{g})t_1 - \\frac{1}{2}at_{\\parallel)^2 = 0.\n\\]\n\nThis equation has two solutions, $t_1$, as follows (iii)\n\n\\[\nt_{\\parallel} = \\frac{2v_y}{g},\n\\]\n\\[\nt = \\frac{v_1 - v_2}{a}.\n\\]\n\nThe first solution corresponded to the first trip to the apex and the second correspond to the catch, to which the others have two possibilities to solve. Recall $\\mathbf{v}_0$ is initial velocity of the ball in the horizontal direction, respectively. By substitution, we get for time at which the ball needs to be\n\n\\[\nt_1 \\imp v_y = 0\n\\]\n\nNow we must analyze the player\u2019s motion. Since he runs at a constant velocity (that we will call $v_1$), and as we let $t_{\\parallel} = t - t^{-1}$.\n\nThus, at time $t_1$, let her position is\n\n\\[\ny(t_1) = Y_{Max} - \\frac{1}{2}\\bigg( x\\xi_{\\parallel}\\frac{t - u_y}{g} - g(\\phi^{-1})^2 + \\frac{v_x}{u_0} \\bigg)^2, \\quad (iv)\n\\]\n\n\\[\ny(t) \\sin at_1 = v_0 t_{\\parallel}, \\quad (v)\n = t(v - u_0), \n\\]",
    "where we have made use of equation (11).\n\nThe ball and the player must be at the same location for a catch to occur, which we will call $(-x_f/2+y_f\\cos{\\alpha},0)$. Then we require equations (12) and (14) to be equal, which allows us to determine the initial angle of the ball\n\n\\[\n\\cos{\\alpha} = \\frac{v_f^2-v_i^2}{2gx_f}\n\\]\n\n\\[\n\\Rightarrow \\alpha = \\cos^{-1} \\left( \\frac{v_f^2-v_i^2}{2gx_f} \\right) \\tag{15}\n\\]\n\nTo use this information to find a single expression for $\\alpha$, we can draw the triangle implied by this equation (shown below). After using the Pythagorean theorem to find that the length of the missing side is $\\sqrt{v_f^2-v_i^2}$, we see that\n\n\\[\n\\sin{\\alpha} = \\frac{\\sqrt{v_f^2-v_i^2}}{v_f}\n\\]\n\n\\[\n\\cos{\\alpha} = \\frac{v_i}{v_f}\n\\]\n\nSubstituting this result into equations (14) (or equation (12)) gives\n\n\\[\nt_f = \\frac{2v_f}{g} \\tag{17}\n\\]\n\nThis is the expression for the distance at which the ball lands, which we want to maximize. To do so, we must ascertain the rate we want to increase the initial velocity of the ball, which can be calculated by differentiating equation (14) with respect to $v_i$, which yields\n\n\\[\n\\frac{d t_f}{d v_i} = \\frac{2 (v_i+g t_f)}{g} \\tag{18}\n\\]\n\nThis is also intuitively obvious. The harder we kick the ball, the less time it will spend in the air. In other words, if we differentiate equation (16) with respect to $\\alpha$, we find that $t_f$ is maximized for a kickoff angle of $\\alpha = 45^\\circ$. Therefore the maximum range of the ball is given by inserting this into equation (12). We see that numerically the best results are obtained when $ t_f = \\frac{2v_f}{g}$ and $\\cos{\\alpha} = \\frac{v_f}{v_i}$, giving a value for our maximum range equal to $\\sqrt{\\frac{v_f \\cdot v_f}{g}}$. This yields similar conclusions to the previous exam problem. The maximum possible angle is 45\u00b0, for which we calculate:\n\n\\[\n\\frac{d}{d\\alpha} \\left[\\frac{v_i \\cdot (1-\\cos^2{\\alpha})}{g t_f}\\right] = 2 v_f \\cdot \\left[1 + \\cos{\\left(2 \\alpha\\right)} \\right]+\\frac{d}{d t_f}  g t_f)=2 v_f \\cdot \\cos{\\left(-\\alpha\\right)}+\\frac{t_0}{t_f}\n\\]\n\nUsing the chain rule and product rules. Simplifying this expression, we find that lower it's only extremes and it occurs at\n\n\\[\n\\frac{d t_f}{d v_i} \\sin{\\alpha} = \\frac{-g}{2v_i} \\cdot \\frac{-v_\\alpha}{t_f} (14)\n\\]",
    "Substituting this result into equation (17) and comparing with any other choice of \\(t_p\\) (e.g. \\(t_p = 0\\)), we can verify that this extremum is, in fact, a maxim (as opposed to a minima). Thus, this is the optimal spot that the player would ideally aim to hit. (This is typically near the optimal). Note: This is where the player should aim as possible to start. His ability to predict the response speed of \\(t_i\\). Therefore, we have to explicitly distinguish these two possibilities by writing:\n\\[\nv_f \\cos \\theta_i t_i = \\sqrt{R^2 + \\left( v_d t_i - d \\right)^2} = v_f t_f\n\\tag{21}\n\\]\n\nCombining equations (17), (18), and (21), we find that the maximum distance to catch the ball is\n\\[\nx_{\\text{max}} = \\sqrt{3} d = \\frac{v_f \\cos 45 ^\\circ}{\\left(\\sin 45 ^\\circ + \\sin \\theta \\right)}\n\\tag{22}\n\\]\nCombining equation (15), (18), (21), we find that ideal angle to kick the ball in\n\\[\n\\theta_i = 45 ^\\circ \\arccos \\left( \\frac{v_f \\cos 45 ^\\circ}{\\left(\\sin 45 ^\\circ + \\sin \\theta \\right)} \\cdot \\frac{1}{\\left(\\sin 45 ^\\circ + \\arccos \\left(  \\frac{\\sqrt{2}}{2} \\right)} \\right)}}\n\\]\n\nThe interpretation of these equations is that when the run sufficiently hard it will sufficiently impact the hit; just to make a direct effect as possible. In Bohr probabilities at least but quick to main the maxim value from start to the interception point of the ball. It is also very evident also by sight. To give some example at the max distance passed by the ball the air slower than \\( v_f \\). However, it is just near this value and the kicker already lost part of the kick motion that needed for the ball to intercept the maximum of its momentum at once. So at its peak, it makes an exact transverse angle when the ball is hit maximizing it on the axis \\( x_{\\max} \\). Ideally, we can calculate the kicking straightforward.\n\n9. The trajectory of the ball is given for equation (19). Using equations (19) and (10), we can write our equation for the \\( i - 1\\) th passed is given by \n\\[\nd(t) = x_{\\max} \\sin \\left( \\theta_i \\right) = \\left(g = \\vec{\\nabla} \\times \\delta \\vec{E} \\times \\vec{B}\\right) \n\\]\nSolving the x component of this equation (16). Therefore for \\( \\vec{d} = (- \\sin \\mathbf{i} \\delta g = v_f = g \\vec{\\nabla} \\times \\vec{u} ) - \\frac{d}{2 \\arccos \\delta^3}\\), which we can write as \n\\[\nx(t) = d + \\frac{1}{2}at^2 = \\frac{2 d \\vec{t} \\sqrt{g^2}}{\\cos \\theta} -\\tanh^{-1} \\sqrt{at^2}- at = \\sqrt{2 gh}\n\\]\n\nThis is the trajectory of free body that tends for the defensive player. So we need to determine at what point is intercepted the ball is just to stand that for the defense player's hand. Therefore we set \n\\[\nD = dx^2 + dy^2\n\\]\nwhich we want to solve as a quadratic equation, which we can solve by first computing the determinant \n\\[\n\\Delta = - \\sin^2 \\pi \\delta = \\pm \\frac{d^2}{at^3} = \\frac{\\sqrt{2}}{\\sin 2g}\n\\]\nand then the solution \n\\[\nx = - \\frac{b}{ac^2}+  \\left( \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\right)\n\\]",
    "We see there are 2 solutions \u2014 the shorter distance corresponds to the elevator just catching the ball on its way up, and the longer distance corresponds to catching it on the way down. We arrive at the final answer by subtracting equation (15) and (16) into the longer distance to get\n$$\nx = \\begin{cases}\n\\left( \\frac{(2u_0 - v_0)^2}{2g}\\left(\\sqrt{1 + \\frac{4gy_0}{(2u_0 - v_0)^2}} - 1\\right) - \\frac{vy_0}{g} \\right)^{1/2} & \\text{if } x < \\frac{v_0^2}{2g} - 2 \\sqrt{\\frac{4y_0v_0}{g}} \\\\\\\n\\left( \\frac{u_0^2}{2g} - y_0\\right)^{1/2} & \\text{otherwise}\n\\end{cases}\n$$\n\n5. Homework: Elevator\n\n1. The acceleration, velocity, and position as a function of time are plotted below.\n\n2. There are three stages of motion given in the problem and we see that the problem is one-dimensional. The first and third stages are at constant acceleration and the second stage is at constant velocity. Note that we have plotted the first and second stage with positive $a(t)$ and the third stage with the same $a(t)$ but in the negative direction. Therefore, we only need to consider the correct $a(t)$ to any time for the problem. For the third stage at $t_5$, we initiate negative $a(t)$ until that first stage and the position is at the end of the second stage is the initial position for the third stage.\n\n3. One can intuitively write the general solution for the acceleration, velocity, and position during any constant acceleration is\n$$\na(t) = a + tg\n$$",
    "$x(t)=\\frac{1}{2}a_{1}t^{2}+v_{i}t+y_{i}$ \n\nrespectively. During the first stage the acceleration is $+a_{1}$. Thus, after a time interval $t_{1}$, the elevator has an upward speed and displacement\n\\[\nv_{1} = v(t_1) = a_{1}t_1 + v_i\n\\]\n\\[\n\\Delta y_1 = y(t_1) - y_i = \\frac{1}{2} a_{1} t_{1}^{2} + v_{i} t_{1}\n\\]\nrespectively, where we must remember that the acceleration $a_{1}$ is positive and unknown. \n\nDuring the second stage, the elevator has a constant acceleration $a = 0$, so the upward speed and displacement are\n\\[\nv(t) = v_{1} = a_{1} t_{1} + v_i\n\\]\n\\[\n y(t) = v_{1}(t - t_{1}) + y(t_{1}) \n\\]\nwhere we use that there is no further lift-induced stage time basis. Thus, after a time interval $t_{2}$ the elevator has a velocity and displacement of\n\\[\nv_{2} = v(t_{1} + t_{2}) = a_{1}t_{1} + v_{i}\n\\]\n\\[\n\\Delta y_{2} = y(t_{1} + t_{2}) - y(t_{1})= v_{1}t_{2}\n\\]\nDuring the third stage, we have constant acceleration $a= -a_{2}$, so the upward speed and displacement are \n\\[\nv(t)= -a_{2}(t - t_{1} - t_{2}) + v_2\n\\]\nAfter a time interval $t_3$, the upward speed and displacement are\n\\[\n v_{3} = v(t_{1} + t_{2} + t_{3})= -a_{2}t_{3} + a_{1}t_{1} + v_{i}\n\\] \n\\[\n\\Delta y_{3}= y(t_{1} + t_{2} + t_{3}) - y(t_{1} + t_{2}) = -\\frac{1}{2} a_{2} t_{3}^{2} + v_{2} t_{3}\n\\]\n\nThus, the total distance traveled is the sum of the displacements in the three stages and is also equal to the height $\\Delta y$ of the building, so\n\\[\n\\Delta y = \\frac{1}{2} a_{1} t_{1}^{2} + \\{ a_{1} t_{1} + v_{i} \\} t_{2} + \\left[- \\frac{1}{2} a_{2} t_{3}^{2} + \\{ a_{1} t_{1}+ v_{i} \\} t_{3} \\right]\n\\]\n\nSolving this equation for the acceleration gives the solution of\n\n4. Let's assume that the sixth floor is about $h = 25 m$ above the ground. This happens to be a slow elevator, which makes approximately $t_3 = 10s$ to reach the sixth floor. Therefore, the acceleration is \n\\[\na_{1} =\\frac{2h}{t_{3}^{2}} =\\frac{2 (25 m)}{(10s)^{2}} =\\frac{50 m}{100 s^{2}} =0.5 \\frac{m}{s^{2}}\n\\]\n\nThis number reveals that it is around 20\\% of the gravitational acceleration. In a slow elevator, one hardly senses that the elevator is accelerating.",
    "Chapter 8\nLAW OF ACTION-REACTION, COLLISIONS",
    "8. Law of action-reaction, collisions\n\n8.1 Law of action-reaction\n8.2 Collisions\n8.3 Two-body problem",
    "8.1 Law of action-reaction\n\nNewton's 3rd law (Principia mathematica):\nTo every action there is always opposed an equal reaction: or the mutual actions of two bodies upon each other are always equal, and directed to contrary parts.\n\nIn more modern words:\nA material point 1 exerting a force $F^{1 \\rightarrow 2}$ on a material point 2 is subjected to a reaction force $F^{2 \\rightarrow 1}$ of equal norm but opposite direction exerted by the material point 2.\n\n$F^{1 \\rightarrow 2} + F^{2 \\rightarrow 1} = 0 \\quad (8.1)$",
    "8.1.2 Internal and external forces\n\n- Newton\u2019s 3rd law: (no net force; action-reaction) \n$$F^{1 \\rightarrow 2} + F^{2 \\rightarrow 1} = 0$$\n- Internal forces: (tensions in the rope)\n$$F^{1 \\rightarrow 2} \\ \\text{and} \\ F^{2 \\rightarrow 1}$$\n- External forces: (weight of the masses)\n$$P_1 \\ \\text{and} \\ P_2$$",
    "8.1.3 Momentum conservation\n\n- Isolated system: system of material points (\u22652) that has no interaction with the exterior.\n- We consider an isolated system consisting of 2 material points. Each material point is a subsystem.\n- Newton\u2019s 2nd law: (applied to each subsystem)\n\n$$ F^{2 \\rightarrow 1} = \\frac{dp_1}{dt} \\quad \\text{and} \\quad F^{1 \\rightarrow 2} = \\frac{dp_2}{dt} \\quad (8.2) $$\n\n- Newton\u2019s 3rd law:\n\n$$ F^{1 \\rightarrow 2} + F^{2 \\rightarrow 1} = 0 \\quad (8.1) $$\n\n- Newton\u2019s 2nd law: (applied to the system)\n\n$$ \\frac{dp}{dt} = \\frac{d (p_1 + p_2)}{dt} = \\frac{dp_1}{dt} + \\frac{dp_2}{dt} \\quad (8.2) + (8.1) \\longrightarrow 0 $$\n\n$$ \\Rightarrow \\quad p = p_1 + p_2 = \\text{const} \\quad (8.3) $$\n\nFor an isolated system, the total momentum $ p $ is conserved.",
    "Examples: Conservation of total momentum.\n\n\u2460 System (chariot + person)\n\nWhen a person moves on the chariot, the chariot moves in the opposite direction to conserve the total momentum.",
    "2) Chariot with a water tank\n\nThe chariot moves in the opposite direction to the water flow in the absence of a wagon. If the water flows into the receiver wagon attached to the chariot, the whole stays at rest to conserve the total momentum.",
    "8.2 Collisions\n\nCollision model:\nVery short impact between two material points with conservation of the total momentum $p$.\n\n1. Elastic collision:\n    The total kinetic energy $T$ is conserved during the impact.\n\n2. Inelastic collision:\n    The total kinetic energy $T$ is not conserved during the impact.",
    "**Experiment:** Measurement of the length of a collision\n\nThe anvil or the lead block are hit by the hammer. The result of the impact is observed on the oscilloscope. The length of the impact is longer with the lead block (less elastic impact).",
    "8.2.1 Impulse\n\nThe impulse $I$ is defined as the variation of momentum $dp$ due to the action of the force $F$ during the impact,\n\\[ I = dp = F \\, dt \\tag{8.4} \\]\n\nIsolated system consisting of two material points:\n\\[ I_1 = dp_1 = F^{2 \\to 1} \\, dt \\quad \\text{and} \\quad I_2 = dp_2 = F^{1 \\to 2} \\, dt \\tag{8.5} \\]\n\nThe total impulse vanishes:\n\\[ I = I_1 + I_2 = \\left( F^{2 \\to 1} + F^{1 \\to 2} \\right) \\, dt \\tag{8.1, 8.5} = 0 \\tag{8.6} \\]\n\nIsolated system:\n\\[ p = \\text{const} \\quad \\text{and} \\quad I = 0 \\quad \\text{during a collision} \\]",
    "Examples: Conservation of momentum\n\n1. Gun bullet\n\nDuring the impact of a gun bullet, an impulse is transferred to the wood, which makes the target oscillate, contrary to the glass that breaks.\n\n2. Slider with projectile\n\nDuring the explosion of the fuel ($H_2$) the glider undergoes a recoil for the total impulse to vanish.",
    "8.2.2 Elastic collision\n\nWe consider an elastic collision between two material points.\n\n- Isolated system: $p = p_1 + p_2 = \\text{const}$ (8.3)\n\n- Elastic collision: $T = T_1 + T_2 = \\text{const}$\n\n- The material point 2 is initially at rest:\n  $v_{2i} = 0 \\implies p_{2i} = 0 \\quad \\text{and} \\quad T_{2i} = 0$\n\n- Momentum balance: (i = initial and f = final)\n  $p_{1i} + p_{2i} = p_{1f} + p_{2f} \\quad \\text{where} \\quad p_{2i} = 0$ (8.7)\n\n- Kinetic energy balance:\n  $T_{1i} + T_{2i} = T_{1f} + T_{2f} \\quad \\text{where} \\quad T_{2i} = 0$ (8.8)",
    "Momentum conservation: (projections)\n\nalong $x$: $p_{1i} = p_{1f} \\cos \\theta_1 + p_{2f} \\cos \\theta_2$  \\hfill (8.9)\n\nalong $y$: $0 = p_{1f} \\sin \\theta_1 - p_{2f} \\sin \\theta_2$\n\n$(8.9)^2 \\Rightarrow (p_{1i} - p_{1f} \\cos \\theta_1)^2 = p_{2f}^2 \\cos^2 \\theta_2$  \\hfill (8.10)\n\n$p_{1f}^2 \\sin^2 \\theta_1 = p_{2f}^2 \\sin^2 \\theta_2$  \\hfill (8.10)\n\n(8.10 a) + (8.10 b) \n\n$\\Rightarrow (p_{1i} - p_{1f} \\cos \\theta_1)^2 + p_{1f}^2 \\sin^2 \\theta_1 = p_{2f}^2$  \\hfill (8.11)",
    "- Kinetic energy conservation: $T = \\frac{1}{2}mv^2 = \\frac{p^2}{2m}$\n\n$$\\frac{p_{1i}^2}{2m_1} = \\frac{p_{1f}^2}{2m_1} + \\frac{p_{2f}^2}{2m_2} \\implies \\frac{p_{2f}^2}{2} = \\frac{m_2}{m_1}(p_{1i}^2 - p_{1f}^2) \\tag{8.12}$$\n\n- Momentum conservation:\n\n$$p_{2f}^2 = (p_{1i} - p_{1f}\\cos\\theta_1)^2 + p_{1f}^2\\sin^2\\theta_1 \\tag{8.10}$$\n\n(8.10) = (8.12):\n\n$$\\left(1 + \\frac{m_2}{m_1}\\right)p_{1f}^2 - 2p_{1i}p_{1f}\\cos\\theta_1 + \\left(1 - \\frac{m_2}{m_1}\\right)p_{1i}^2 = 0 \\tag{8.13}$$\n\n$$\\implies \\left(\\frac{p_{1f}}{p_{1i}}\\right)^2 - \\frac{2m_1}{m_1 + m_2}\\cos\\theta_1 \\cdot \\frac{p_{1f}}{p_{1i}} + \\frac{m_1 - m_2}{m_1 + m_2} = 0$$\n\n$$\\implies \\frac{p_{1f}}{p_{1i}} = \\frac{m_1v_{1f}}{m_1v_{1i}} = \\frac{v_{1f}}{v_{1i}} = \\frac{m_1}{m_1 +m_2}\\left(\\cos\\theta_1 \\pm \\cos\\theta_1 - \\left(1 - \\frac{m_2^2}{m_1^2}\\right)\\right)^{\\frac{1}{2}} \\tag{8.14}$$",
    "1. Equal masses: $(m_1 = m_2)$\n- Conservation of $p \\Rightarrow v_{1i} = v_{1f} + v_{2f}$ (8.15)\n- Conservation of $T \\Rightarrow v_{1i}^2 = v_{1f}^2 + v_{2f}^2$ (8.16)\n- $(8.15)^2 \\Rightarrow v_{1i}^2 = v_{1f}^2 + 2v_{1f} \\cdot v_{2f} + v_{2f}^2$ (8.17)\n- (8.17) - (8.16) $\\Rightarrow$\n$$\nv_{1f} \\cdot v_{2f} = 0 \\Rightarrow \\left\\{\n\\begin{array}{ll}\nv_{1f} \\neq 0 \\text{ and } v_{2f} \\neq 0 \\Rightarrow \\theta_1 + \\theta_2 = \\frac{\\pi}{2} \\\\\nv_{1f} = 0 \\Rightarrow v_{2f} = v_{1i} \\text{ (8.15)}\n\\end{array}\n\\right.\n$$\n(8.18)\n\nThe blue puck is thrown from the left and hits the white puck that is initially at rest. After the collision, the angle between the trajectories of the two pucks is slightly inferior to $90^\\circ$.",
    "\u2461 Linear collision:\n\n\u2022 General collision:\n\\[\n\\frac{v_{1f}}{v_{1i}} = \\frac{m_1}{m_1 + m_2}\\left(\\cos \\theta_1 \\pm \\sqrt{\\cos^2 \\theta_1 - \\left(1 - \\frac{m_2^2}{m_1^2}\\right)}\\right) \\quad (8.14)\n\\]\n\n\u2022 Linear collision: $\\theta_1 = \\theta_2 = 0$\n\\[\n(8.14) \\quad \\Rightarrow \\quad \\frac{v_{1f}}{v_{1i}} = \\frac{m_1}{m_1 + m_2}\\left(1 \\pm \\sqrt{1 - \\left(1 - \\frac{m_2^2}{m_1^2}\\right)}\\right) = \\frac{m_1 \\pm m_2}{m_1 + m_2} \\quad (8.19)\n\\]\n\n\u2022 reject $\\pm$ sign: absence of collision (\"virtual\" mass $m_2$)\n\\[\n(8.19) \\quad \\Rightarrow \\quad \\frac{v_{1f}}{v_{1i}} = \\frac{m_1 - m_2}{m_1 + m_2} v_{1i} \\quad (8.20)\n\\]",
    "- Conservation of momentum:\n\\[\nv_{1f} = \\frac{m_1 - m_2}{m_1 + m_2} v_{1i} \\quad (8.20)\n\\]\n\n- Kinetic energy conservation:\n\\[\n\\frac{1}{2} m_1 v_{1i}^2 = \\frac{1}{2} m_1 v_{1f}^2 + \\frac{1}{2} m_2 v_{2f}^2 \\quad \\Rightarrow \\quad v_{2f}^2 = \\frac{m_1}{m_2} \\left( v_{1i}^2 - v_{1f}^2 \\right) \\quad (8.21)\n\\]\n\\[\n(8.20) \\quad \\Rightarrow \\quad (8.21): \\quad v_{2f}^2 = \\frac{4 m_1^2}{(m_1 + m_2)^2} v_{1i}^2 \\quad \\Rightarrow \\quad v_{2f} = \\frac{2 m_1}{m_1 + m_2} v_{1i} \\quad (8.22)\n\\]\n\n- Final velocities:\n\\[\nv_{1f} = \\frac{m_1 - m_2}{m_1 + m_2} v_{1i} \\quad (8.20)\n\\]\n\\[\nv_{2f} = \\frac{2 m_1}{m_1 + m_2} v_{1i} \\quad (8.22)\n\\]",
    "Final velocities:\n$$v_{1f} = \\frac{m_1 - m_2}{m_1 + m_2} v_{1i} \\quad (8.20)$$\n$$v_{2f} = \\frac{2 m_1}{m_1 + m_2} v_{1i} \\quad (8.22)$$\n\n2 particular cases:\n1) equal masses: $m_1 = m_2 \\Rightarrow v_{1f} = 0$ and $v_{2f} = v_{1i}$ (pool balls, linear elastic collision of balls)\n2) infinite mass: $m_1 / m_2 \\rightarrow 0 \\Rightarrow v_{2f} = 0$ and $v_{1f} = -v_{1i}$ (bounce of a ball, collision of a molecule against a wall)",
    "8.2.3 Perfectly inelastic collision\n\nPerfectly inelastic collision: collision between two material points where the two material points remain attached to one another after the collision.\n\nMomentum conservation:\n\\[ p_1 + p_2 = p_f \\quad \\text{where} \\quad p_2 = 0 \\quad \\Rightarrow \\quad p_1 = p_f \\tag{8.23} \\]\n\\[ \\Rightarrow \\quad m_1 v_1 = (m_1 + m_2) v_f \\quad \\Rightarrow \\quad v_f = \\frac{m_1}{m_1 + m_2} v_1 \\tag{8.25} \\]\n\nKinetic energy variation: (dissipation)\n\\[ T_1 = \\frac{1}{2} m_1 v_1^2 \\quad \\text{and} \\quad T_f = \\frac{1}{2} (m_1 + m_2) v_f^2 \\tag{8.26} \\]\n\\[ \\Delta T = T_f - T_1 \\quad \\Rightarrow \\quad \\Delta T = \\frac{1}{2} \\frac{m_1^2}{m_1 + m_2} v_1^2 - \\frac{1}{2} m_1 v_1^2 = -\\frac{1}{2} \\frac{m_1 m_2}{m_1 + m_2} v_1^2 < 0 \\tag{8.27} \\]",
    "8.2.4 Coefficient of restitution\n\nCoefficient $e$ that measures the elasticity of a collision against an object of infinite mass.\n\\[ e = \\frac{v_f}{v_i} \\]\nThree types of collisions or impacts:\n1) elastic: $e = 1$\n2) inelastic: $0 < e < 1$\n3) perfectly inelastic: $e = 0$\n\nThe harder the material is, the smaller will be the deformation during the collision and thus the larger the coefficient of restitution will be.",
    "8.3 Two-body problem\n\n8.3.1 Reduced law of motion\n\n- Laws of motion (2 material points)\n$$\n\\mathbf{F}^{2\\rightarrow 1} = m_1 \\mathbf{\\ddot{r}}_1 \\quad \\text{and} \\quad \\mathbf{F}^{1\\rightarrow 2} = m_2 \\mathbf{\\ddot{r}}_2 \\quad (8.29)\n$$\n\n- Position vector of the centre of mass:\n$$\n\\mathbf{R}_G = \\frac{m_1}{M} \\mathbf{r}_1 + \\frac{m_2}{M} \\mathbf{r}_2 \\quad \\text{where} \\quad M = m_1 + m_2 \\quad (8.30\\, a)\n$$\n\n- Relative position vector:\n$$\n\\mathbf{r} = \\mathbf{r}_1 - \\mathbf{r}_2 \\quad (8.30\\, b)\n$$",
    "- Position vectors:\n  \\[\n  \\mathbf{R}_G = \\frac{m_1}{M} \\mathbf{r}_1 + \\frac{m_2}{M} \\mathbf{r}_2 \n  \\tag{8.30}\n  \\]\n  \\[\n  \\mathbf{r} = \\mathbf{r}_1 - \\mathbf{r}_2\n  \\]\n- Second order time derivatives:\n  \\[\n  M \\mathbf{\\ddot{R}}_G = m_1 \\mathbf{\\ddot{r}}_1 + m_2 \\mathbf{\\ddot{r}}_2 \n  \\]\n  and\n  \\[\n  \\mathbf{\\ddot{r}} = \\mathbf{\\ddot{r}}_1 - \\mathbf{\\ddot{r}}_2\n  \\tag{8.31}\n  \\]\n- Laws of motion:\n  \\[\n  \\mathbf{F}^{2 \\to 1} = m_1 \\mathbf{\\ddot{r}}_1 \n  \\]\n  and\n  \\[\n  \\mathbf{F}^{1 \\to 2} = m_2 \\mathbf{\\ddot{r}}_2 \n  \\tag{8.29}\n  \\]\n  \\[\n  \\tag{8.29}\n  \\Rightarrow \\mathbf{F}^{2 \\to 1} + \\mathbf{F}^{1 \\to 2} = m_1 \\mathbf{\\ddot{r}}_1 + m_2 \\mathbf{\\ddot{r}}_2 \n  \\]\n  \\[\n  \\tag{8.31}\n  \\Rightarrow M \\mathbf{\\ddot{R}}_G\n  \\]\n- Newton\u2019s 3rd law:\n  \\[\n  \\mathbf{F}^{2 \\to 1} + \\mathbf{F}^{1 \\to 2} = 0 \\Rightarrow \\mathbf{\\ddot{R}}_G = 0 \\Rightarrow \\mathbf{V}_G = \\mathbf{R}_G = \\text{const} \n  \\tag{8.33}\n  \\]\n  The centre of mass has a uniform linear motion.",
    "- Law of motion:\n$$F^{2 \\to 1} = m_1 \\ddot{\\mathbf{r}}_1 \\quad \\text{and} \\quad F^{1 \\to 2} = m_2 \\ddot{\\mathbf{r}}_2 \\quad (8.29)$$\n\n- Reduced mass:\n$$\\mu = \\frac{m_1 m_2}{M} = \\frac{1}{\\frac{1}{m_1} + \\frac{1}{m_2}} \\quad (8.35)$$\n\n$$(8.29) + (8.35) \\Rightarrow m_2 F^{2 \\to 1} - m_1 F^{1 \\to 2} = m_1 m_2 (\\ddot{\\mathbf{r}}_1 - \\ddot{\\mathbf{r}}_2) = \\frac{(8.35)}{(8.31)} M \\mu \\ddot{\\mathbf{r}} \\quad (8.34)$$\n\n- Newton's 3rd law:\n$$m_2 F^{2 \\to 1} - m_1 F^{1 \\to 2} = (m_2 + m_1) F^{2 \\to 1} = M F^{2 \\to 1} \\quad (8.34 \\text{ bis})$$\n\n$$(8.34) \\equiv (8.34 \\text{ bis}) \\Rightarrow \\text{Reduced law of motion: } F^{2 \\to 1} = \\mu \\ddot{\\mathbf{r}} \\quad (8.36)$$\n\nThe motion of the two-body problem reduces to the uniform linear motion of the centre of mass and the reduced motion of an object of reduced mass $\\mu$.",
    "8.3.2 Momentum and kinetic energy\n\n- Total momentum $p$ and total kinetic energy $T$:\n$$p = m_1 v_1 + m_2 v_2 \\quad (8.37) \\quad T = \\frac{1}{2} m_1 v_1^2 + \\frac{1}{2} m_2 v_2^2 \\quad (8.38)$$\n\n- Position vectors:\n$$R_G = \\frac{m_1}{M} r_1 + \\frac{m_2}{M} r_2 \\quad \\text{and} \\quad r = r_1 - r_2 \\quad (8.30)$$\n\n- We inverse $(8.30)$: $\\mu = m_1 m_2 / M$\n$$\\Rightarrow r_1 = R_G + \\frac{\\mu}{m_1} r \\quad \\text{and} \\quad r_2 = R_G - \\frac{\\mu}{m_2} r \\quad (8.39)$$\n\n- Time derivative of $(8.39)$\n$$v_1 = V_G + \\frac{\\mu}{m_1} v \\quad \\text{and} \\quad v_2 = V_G - \\frac{\\mu}{m_2} v \\quad (8.40)$$\n\n- Momentum: $(8.40) \\Rightarrow (8.37)$\n$$p = m_1 v_1 + m_2 v_2 = (m_1 + m_2) V_G = MV_G$$\n\nThe total momentum is the momentum of the centre of mass.",
    "- Expression of the velocities:\n  $v_1 = V_G + \\frac{\\mu}{m_1}v$ and $v_2 = V_G - \\frac{\\mu}{m_2}v$\n\n- Kinetic energy:\n  \\[\n  T = \\frac{1}{2} m_1 \\left( V_G + \\frac{\\mu}{m_1} v \\right)^2 + \\frac{1}{2} m_2 \\left( V_G - \\frac{\\mu}{m_2} v \\right)^2\n  \\]\n  \\[\n  = \\frac{1}{2} \\left( m_1 + m_2 \\right) V_G^2 + \\frac{1}{2} \\left( \\frac{1}{m_1} + \\frac{1}{m_2} \\right) \\mu^2 v^2\n  \\]\n  \\[\n  = \\frac{1}{2} M V_G^2 + \\frac{1}{2} \\mu v^2 \\quad (8.43)\n  \\]\n\nThe total kinetic energy is equal to the kinetic energy of the centre of mass plus the reduced kinetic energy.",
    "8.3.3 Centre of mass frame of reference\n\n- Relative positions: (with respect to the frame of reference of C.M.)\n\\[ r'_1 = r_1 - RG = \\frac{\\mu}{m_1} r \\quad \\text{and} \\quad r'_2 = r_2 - RG = -\\frac{\\mu}{m_2} r \\]\n- Time derivatives of (8.44):\n\\[ v'_1 = \\frac{\\mu}{m_1} v \\quad \\text{and} \\quad v'_2 = -\\frac{\\mu}{m_2} v \\]\n- Relative momentum:\n\\[ p' = m_1 v'_1 + m_2 v'_2 = 0 \\]\n- Relative total kinetic energy:\n\\[ T' = \\frac{1}{2} m_1 v'_1^2 + \\frac{1}{2} m_2 v'_2^2 = \\frac{1}{2} \\left( \\frac{1}{m_1} + \\frac{1}{m_2} \\right) \\mu^2 v^2 = \\frac{1}{2} \\mu v^2 \\]",
    "Solutions to Problem Set 12\nAngular momentum\nPHYS-101(en)\n\n1. Planetary survey\n\nAfter the instrument is launched, the only force it will experience is its gravitational attraction to the planet. This force is given by\n\n\\[ \\mathbf{F_G} = -G\\frac{m_i m_p}{r^2} \\hat{r} \\]\n\n(1)\n\nwhere $r$ is the distance between the instrument and the center of the planet, $r$ is the radial unit vector pointing from the center of the planet towards the instrument, $G$ is the universal gravitational constant. Since this is the only force acting on the instrument, it experiences a total central torque about the center of the planet of \n\n\\[ \\sum \\mathbf{N_c} = \\mathbf{r} \\times \\mathbf{F_G} = \\mathbf{r} \\times \\left(- G\\frac{m_i m_p}{r^2} \\hat{r}\\right) = 0 \\]\n\n(2)\n\nwhere we have used equation (1) and the fact that the cross product of parallel vectors is zero. Thus, since the total central torque on the instrument about the center of the planet is zero, its angular momentum about the planet must be conserved:\n\n\\[ \\mathbf{L} = \\mathbf{r} \\times \\mathbf{p} = \\text{ constant} \\]\n\n(3)\n\nor\n\n\\[ L_p = L_f \\]\n\n(4)\n\nwhere the angular momentum is\n\n\\[ \\mathbf{L} = \\mathbf{r} \\times \\mathbf{p} = m_i(\\mathbf{r} \\times \\mathbf{v}) \\]\n\n(5)\n\nHere $r_f$ and $v_f$ represent the final values of the instrument's position and velocity. It is natural to define a twofold coordinate system with its origin at the center of the planet. The initial velocity can be found considering the equations of motion, so we have\n\n\\[ \\mathbf{r_0} = r_0 \\hat{r} \\quad \\text{and} \\quad \\mathbf{v_0} = v_0 \\hat{t} \\]\n\n(6)\n\nSubstituting this and the initial position of the instrument into equations (4) gives\n\n\\[ m_i \\mathbf{r_0} \\times \\mathbf{v_0} = m_i \\mathbf{r_f} \\times \\mathbf{v_f} \\]\n\n(7)\n\nThus, this results in \n\n\\[ r_0 v_0 \\sin(\\theta_0) = r_f v_f \\sin(\\theta_f) \\]\n\n(8)\n\nWe will consider the final state to occur when the instrument just grazes the surface of the planet. At this instant, the optimum angle of launch and the final velocity $v_f$ is up to the effective escape tanget to the surface. Thus, the radial and tangential unit can be written as \n\n\\[ v_f = v_0 \\frac{r_0}{R_p} \\sin(\\theta_0) \\]\n\n(9)",
    "Plugging equations (6) and (7) into equation (3) yields\n\n\\[\n\\tau_{\\text{instr}, \\parallel} - \\tau_g^\\parallel = r_f F_f\n\\]\n\nHowever, this equation still has two unknowns $r_f$ and $F_f$ so we require another condition.\n\nTo determine the final velocity of the instrument, we can think about the situation physically. We realize that\nthe instrument will be released and fall faster than the gravitational potential reference bar. There may be some\nfrictional force on the instrument. (An analysis of mechanical energy loss assumes there are no nonconservative\nforces acting on the instrument). Thus, we have\n\n\\[\n\\tau_{\\text{instr}} = \\tau_{\\text{instr}, \\parallel} = I_{\\text{instr}, f} \\alpha + K_f r_f, \\quad (\\alpha = g = 0)\n\\]\n\nIn previous problem sets, we've found the universal gravitational potential (with a reference point infinitely\nfar away) to be\n\n\\[\nU_g = -\\alpha \\frac{GM_{\\oplus}}{r_{\\oplus}}\n\\]\n\nPlugging this and the form of the kinetic energy of the moon $\\left( \\frac{1}{2} m_{\\text{instr}, f} v_{\\text{instr}, f}^2 \\right)$ gives\n\n\\[\n\\frac{1}{2} m_{\\text{instr}, f} v_{\\text{instr}, f}^2 = G \\frac{M_{\\oplus}}{r_{\\oplus}}\n\\]\n\nSubstituting equations (8) allows us to find the final answer of\n\n\\[\n\\frac{1}{2} m v_{\\text{instr}, f}^2 = G \\frac{M_{\\oplus}}{r_{\\oplus}} - \\frac{M_{\\text{instr}}}{r_f} - \\frac{G {M_{\\text{instr}}}^2}{M_{\\oplus}}\n\\]\n\nwhere\n\n\\[\nv_f = \\sqrt{G \\left( \\frac{M_{\\oplus}}{r_{\\oplus}} - \\frac{M_{\\text{instr}}}{r_f} - \\frac{G {M_{\\text{instr}}}^2}{M_{\\oplus}} \\right)}\n\\]\n\n2. Toy locomotive\n\nWe begin by defining our system to consist of the locomotive and the track. Because there are no external\ntorques acting on the system, the angular momentum of one system must remain constant about\ntotal axis:\n\n\\[\nL_{\\text{initial}} = L_{\\text{final}}\n\\]\n\nbecause both the locomotive and the track are at rest. The final angular momentum will be composed of\nthe angular momentum of the locomotive and the track revolving. \n\n\\[\nL_{\\text{final}} = L_{\\text{friction}} + L_{\\text{track}}\n\\]\n\nwhere the subscripts $L$ and $T$ refer to the locomotive and track respectively.\n\nThe final angular momentum due to the sliding friction (which we have found to be a point mass) is given by\n\n\\[\nL_{\\text{friction}} = m_{\\text{loc}} v_{\\text{loc}} r_{\\text{loc}}\n\\]\n\nwhere $r_{\\text{loc}}$ is the position vector from the center of mass of the track to the center of mass of the\nlocomotive. This will also be equal and opposite to the track's angular momentum about the center\nof the ground. From the figure we see that for the track moving only, to be in direction, we obtain\n\n\\[\nL_{\\text{friction}} = - m_{\\text{track}} r_{\\text{track}} v_{\\text{track}}\n\\]\n\nand thus\n\n\\[\nL_{\\text{friction}} = m_{\\text{loc}} v_{\\text{loc}} r_{\\text{loc}} = \\frac{v_{\\text{loc}}}{v_{\\text{track}}}\n\\]",
    "(where $v_f$ is the final speed relative to the floor that we are trying to determine). Plugging this into equation (4) produces\n\n$$ L_{f} = R m_f v_f \\hat{i} + m_f R^2 \\omega_f \\hat{k} = R m_i v_{\\text{iya}} \\hat{i} $$\n\nwhere the $\\hat{k}$ vector points counter-clockwise (when viewed from above) and the $\\hat{i}$ unit vector points upwards.\n\nThus we must determine the final angular momentum of the truck (which is a continuous system). We will write the vector sum of inertia of a disk as follows, where $\\delta m$ asks passing through its center is\n\n$$ I_{\\text{cm}} = m R^2 \\hat{i} \\ \\ \\ \\ \\ \\ \\ (6) $$\n\nThis can also be calculated from the definition of the moment of inertia according to\n\nInt$(I_{\\text{cm}} = \\sum \\delta m_i R^2_i = 0 \\ P_i(\\rho) d \\theta_0 \\ R (\\delta m_i g_l - \\dfrac{ 1 }{2} \\dfrac{R}{\\theta}) = \\delta m_i \\dfrac{ R_o }{\\hat{i}} ) \\rightarrow \\ d \\theta= \\dfrac{ R }{\\ i^2 } = \\delta m_i R_{t} $  \\ \\ \\ \\ \\ \\ \\ \\ (7)$\n\nUsing the linear mass density $\\lambda = m = P_i \\dfrac{\\theta_i}{i_o}$ and, the arc length of the truck in $t \\rightarrow f$, and ($\\R_i^2_p$ the definition of the angular momentum of a continuous system, we know that the final angular momentum $L_f$ is\n\n$$ L_f = R \\int_{0}^{2t} m_s v_0 d\\theta_i = m_s v_t(\\dfrac{ f^2 }{a_t})  $$\n\nwhere $v_f$ is the angular velocity of the truck. The angular velocity can be related to the tangential velocity $v$ at any point on the truck through\n\n$$ w_f = \\dot{\\varkappa} R_g = R_o(\\theta_{m_g}, \\dot{\\theta_1}) \\Bigg[\\dfrac{ v }{g_{e}} \\cdot S  \\bigg] \\ \\ \\ \\ \\ \\ \\ \\ (8) $$\n\nwhere $v_f$ is the final tangential speed of the truck relative to the ground and we have derived this distance from the linear mass density, where we can use the limits: $w_s R \\rightarrow = T_s r_1 v_1 = \\dfrac{v_{\\text{lya}}}{R^2}$. Substituting equation (8) into equation (7) implies that the final angular momentum of a truck is\n\n$$ w_f L_\\varphi \\beta_i \\Bigg[ R^2_T\\cdot (R T = \\dfrac{ \\delta v_{r_0} }{ R } )v_f  \\Bigg ]  \\rightarrow  \\ \\ \\ \\ \\ \\ \\ \\ (10) $$\n\nUnfortunately, we are left with some uncertainty about the energy required (since we have no way to calculate). To determine it, we go to another variable. Specifically, we need the force of the linear collision in the final state above i.e. The formula below will be used to verify the definitions of the required force. Rewriting from equation (6), we have\n\n$$ R g\\Bigg[ \\beta \\cdot \\dot{g2} + \\dfrac{v} \\Bigg]_{0}^{f^2} \\bigg [ \\C{v}{r}^2 + \\dfrac{T}{v}  \\cdot S d\\theta_f^a (m q_i/o) \\Bigg]  = 2\\pi\\beta S \\Big( \\dfrac{\\delta m_f \\cdot \\hat{i}(\\nabla w_r G_q)}{\\delta m_i} \\Bigg\\lvert_{\\ d\\theta\\delta R^2}^{\\theta_{sf}} \\cdot \\Bigg]  $$\\ \\ \\ \\ \\ \\ \\ \\ (11)\n\nwhere $L_f$ is the final angular momentum of the truck and $m_f L_i$ is the mass of the speed, $T = v_s^i$, the turns for initial velocity as per unit angle of measure. We know the initial states for energy. Therefore, are given by\n\n$$ \\omega_s^d  \\Bigg( \\dfrac{P^*}{g_s} = \\Big(  m_f \\Bigg  (\\dfrac{s_{in}}{ t^2} )^{  Q 2^2_0  \\rightarrow \\  \\ \\ \\ \\ \\ \\ \\ \\ (12)}$$\n\nWhich is not confined exactly in relation to the final angular speed $11Sp_a f^2$ that we are trying to find q by. Finally, we can substitute equations (2), (3), (4), and (12) into equation (7) to find the final angular state:\n\n$$ \\omega_i/k = w_o  = R, m v^{2}_f/I_s  = i \\Big[ p v_{m_f} g_s) \\rightarrow  => p = m_s g_a \\lvert {\\dfrac{\\ v}{m_w - R_{o}| }^{2}} \\Long g \\Big]$$",
    "3. Particle-rod collision revisited\n\n1. The motion of any rigid body can be represented as the motion of the center of mass, plus a rotation about the center of mass. In problem Set 6, we found the position of the center of mass after the collision to be\n$$\n\\vec {R}_{\\text{cm}} (t) = \\frac{1}{M+m} \\left( m\\vec {R} + M\\vec {R}_\\text {cm} \\right)\n$$\nHowever, to completely specify the motion of the particle-rode system, we must also calculate the angular velocity or rotation of the system bout the center of mass.\n\n2. Now, in order to analyze the collision for the instance before and after the collision, we will use the conservation of angular momentum about the center of mass (as there are no external torques acting on the particle-rod system). This is expressed as,\n$$\n\\vec {L}_{\\text{cm}}(t) = \\vec {L}_{\\text{cm}}(t - \\epsilon)\n$$\nwhere the subscript \"$\\epsilon$\" indicates that the quantity is evaluated just before the collision and the subscript \"$-\\epsilon$\" indicates that immediately before the collision, all the angular momentum is due to the velocity of the mass in the linear motion. This implies that in such a condition,\n$$\n\\vec {L}_{\\text{cm}} = \\sum_i ( \\vec {r}_i - \\vec {R}_{\\text{cm}}) \\times m_i \\vec {V}_i + I_{\\text{cm}} \\vec {\\omega_{\\text{r}} } \\\\\nI_{\\text{cm}}\\vec{\\omega}_\\text{r} = \\sum_i (\\vec{r}_i - \\vec{R}_{\\text{cm}}) \\times m_i \\vec{V}_i\n$$\nwhere the subscript \"$r_{\\text{r}}$\" indicates the particle. Note that there are no contributions to the angular momentum due to linear motion. Here therefore, we do not include any cross product of the velocity of particle velocities as\n$$\n\\vec {r}_i = \\vec{v}_i\n$$\nsince they are just prior to the collision, the particle and the rod masses are considered.\n\nBefore the collision, the rod and particle form the combined component system: a rigid object with its angular momentum described as (8) and just after collision, the system must continue to be conserved as (9).\n\n$$\n\\vec{L}_{\\text{cm}}=\\vec{L}_{\\text{cm}final}\n$$\nAfter the collision, the rod and particle form a combined object that rotates at a common angle, $\\omega_{\\text{rot}}$, about their axis. The angular momentum of such a rotating combined subject is\n$$\n\\vec{L}_{\\text{rot}}=I_{\\text{cm}}\\omega_{\\text{rot}}\n$$\nwhere $I_{\\text{cm}}$ accounts for the inertia of both the particle-rod system about its center of mass. Substituting this as an equation (4) into equation (5) as given by\n$$\nmy_{\\text{cm}}^2{\\omega_{\\text{rot}}} = I_{\\text{cm}}a_{\\text{cm}} \\over I_{\\text{cm}} \\Rightarrow(a_{\\text{cm}} = \\sum_i (\\mathfrak{D}) \\\\\nI_{\\text{cm}} = I_{\\text{cm}}) \\\\\n\\implies \\text{Now the dominance is lost. Instead we use{x_{\\cm}} \\left(m\\above m_{5cm}\\)\n$$\n4. The amount that angular momentum is lost, but we don't know $I_{\\text{cm}}. $ To calculate $I_{\\text{cm}}$ from the definition of the center of mass,\n$$\nI_{\\text{cm}} = \\int (\\mathbb{T} I_{\\text{cm}}, molI_{\\text{cm}})dm\n$$\nwhere the integral is taken over the entire mass of the combined object. Because integrals are just defined for systems parts individually and later combined, we can rewrite it as the contributions to:\n$$\nI_{\\text{cm}} = \\int_{\\text{rod}} r_{\\bot}^2 dm_{\\text{rod}} + \\int_{\\text{particle}} r_{\\bot}^2 dm_{\\text{particle}}\n$$",
    "Since the particle is well represented by a point mass, all of its mass is located at the same distance $r = l/4$ from the center of mass. Thus,\n\n\\[\nT_{\\text{CM}} = \\frac{1}{2} M R^2 \\left( \\frac{d \\theta_0}{d t} \\right)^2 + \\left( \\int_0^{M/2} \\frac{l}{4} \\mathop{\\mathrm{sign}}(x) \\frac{d \\theta_0}{d t} \\delta m \\right) \\frac{d \\theta_0}{d t}.\n\\]\n\nThere are two ways to solve this: (i) assuming the total moment of inertia from the point. The first is simpler and uses the parallel axis theorem. From the table of moments of inertia provided in lecture, however, we start with the moment of inertia of a rod of mass $M/2$ and length $l$ about the center of mass parallel to it, such that $I_{\\text{rod}} = \\frac{1}{12} M l^2$. However, we are interested in the moment about the center of mass of a mass $M = M/2 = 2M$. Noting the center of mass is located a distance $l/4$ from the center of inertia, we have\n\n\\[\nI_{\\text{total}} = \\frac{1}{12} M l^2 + M \\left( \\frac{l}{4} \\right)^2 = \\frac{1}{12} M l^2 + \\frac{1}{16} M l^2 = \\frac{1}{48} M l^2 \\left( 3 + 4 \\right) = \\frac{7}{48} M l^2.\n\\]\n\nNow, since the parallel axis theorem states that the moment of inertia of a point mass $m$ at a perpendicular distance $r$ from an axis is $mr^2$, we will have\n\n\\[\nI_{\\text{CM}} = \\left( \\frac{MR^2}{12} + MR^2 \\left( \\frac{l}{4} \\right)^2 \\right) \\left( \\frac{7}{48} M l^2 + \\frac{1}{16} M l^2 \\right) = \\frac{1}{48} M l^2 (4 + 3) = \\frac{7}{48} M l^2.\n\\]\n\nThe second way to find the moment of inertia is the more accurate way; i.e., integrate the integral in equation (9). This approach is more challenging, but applies to a wider variety of situations. To convert from $(x,y)$ axes to the $(u,t)$ coordinate system, we notice that $f$ and $M$ are both functions formed from the same finite-only structure as well as the same $\\delta m$ integration variables. Rewriting,\n\n\\[\nI_{\\text{CM}} = \\int_0^r r^2 \\delta m = \\frac{M}{l^2} \\int_0^r \\left( \\frac{l}{4} \\right)^2 dx = \\frac{M l^2}{16} = 7 M \\left( \\frac{l}{4} \\right)^2.\n\\]\n\nTo determine the locus of the integration, we must think about the geometry of the problem. For this reason, we imagine isolating the rod at $0$ and the part of the rod $0 < x$. Assuming in the direction original $x \\rightarrow 0$, we can more easily see the part of the rod above and below it to be the radial, normalized body elements. We should remember that the local axes can be handled by splitting the ends of above figures as $\\int_0^r$\n\nEvaluating this equation is straightforward and yields\n\n\\[\nI_{\\text{CM}} = \\frac{M}{l^2} \\int_0^{\\frac{1}{4} T} \\left( \\frac{l}{4} \\right)^2 dx = \\frac{M l^2}{16} \\int_0^{\\frac{1}{4} l} x^2 dx = \\frac{M l^2}{48} \\left( 4 + 3 \\right) = \\frac{7}{48} M l^2,\n\\]\n\nwhich is identical to the solution using the parallel axis theorem (i.e., equation (10)). Substituting equation (9) into (10) equations (6) give the total moment of inertia of the particle-system suspended like in terms of\n\n\\[\nI_{\\text{total}} = \\frac{7}{48} M l^2.\n\\]\n\nSubstituting this into equation (6) gives the final answer as\n\n\\[\n\\frac{d \\theta_{0}}{d t} = \\sqrt{\\frac{3 M g \\left(\\frac{l}{2}\\right)}{\\frac{7}{48} M l^2}} = \\left( \\frac{144 g}{7 l} \\right) = 0.3154.\n\\]\n\nNote that, since there are no additional forces acting at a later time, we have conservation of angular momentum. Thus, the angular velocity of the particle/rod system remains the same at all times if $z_0$.",
    "2. We know that the particle-rigid system moves based on the combination of two types of motion. Its center of mass translates, which has been calculated in question (b). Additionally, in the center of mass reference frame, each point in the system rotates about the center of mass with velocity $\\vec{r}$ at an angular velocity of $\\vec{\\omega} = \\dot{\\theta} \\hat{k}$. This rotation is where circular motion comes in, the angular velocity corresponds to a velocity of\n\\[\n\\vec{v} = \\vec{\\omega} \\times \\vec{r} = \\dot{\\theta} \\hat{k} \\times r \\hat{e}_y = r\\dot{\\theta}\\hat{e}_x.\n\\]\nWe asked about the position of the particle, which is located at a distance $r = l/6$ away from the center of mass. Thus, it has a velocity of\n\\[\n\\vec{v} = \\frac{l}{6} \\dot{\\theta} \\hat{e}_x\n\\]\nafter the collision. Note that if we substitute the value for $\\dot{\\theta}$ we found $\\dot{\\theta} = 6\\dot{v}/l$, which shows that the particle's velocity is substantially as a result of the collision.\nThus, combining both translational velocity in Cartesian coordinates, we will convert the cylindrical value of v according to\n\\[\n\\begin{aligned}\nv_x & = v - \\frac{l}{6}\\dot{\\theta}\\cos{\\theta} \\\\\nv_y & = -\\frac{l}{6}\\dot{\\theta}\\sin{\\theta}.\n\\end{aligned}\n\\]\nGiven that v is constant, we can integrate the definition of the angular speed $\\omega = \\dot{\\theta} = 6v/l$ to find\n\\[\n\\theta = \\frac{6v}{l} t.\n\\]\nSo, plugging in this value of $\\theta$ into the equations of the x-axis and the y-axis interactions terms, we will have\n\\[\n\\begin{aligned}\nv_x & = v\\left[ 1- \\cos{(\\frac{6vt}{l})} \\right] \\\\\nv_y & = -v \\sin{ \\left( \\frac{6vt}{l} \\right)}.\n\\end{aligned}\n\\]\nSubstituting x and y coordinates $(19)$ and $(20)$ into the final coordinates, we find that $\\vec{r} = x \\hat{e}_x + y \\hat{e}_y$, is\n\\[\n\\vec{r} = l \\left\\lbrace \\frac{t}{t_c}-\\frac{l}{6v}\\sin{ \\left[ \\frac{6vt}{l} \\right]} \\hat{e}_x - \\frac{l}{6v}\\sin{ \\left[ \\frac{6vt}{l} \\right]} \\right\\rbrace.\n\\]\nWe also see that we have used trigonometric identities for sine and cosine. These trigonometric expressions come in handy to the simplified version of the particle-rigid body system, about the origin.\nTo find if we substitute, we simply integrate\n\\[\n\\int_{}^{} dt = t \\rightarrow \\int_{}^{}d \\left(\\frac{- \\cos{(\\frac{6vt}{l})}}{36}\\right)  = \\int_{}^{}dx\n\\]\nand for the specific case, we have\n\\[\n-\\cos \\left( \\frac{6vt}{l} \\right) = \\cos(\\theta).\n\\]\nHowever, we note that taking $6v/l$ and integrating the previous final frame moving with the center of mass of the particle system. Thus we cannot change back to the reference frame given in the previous calculation $\\dot{\\theta} \\neq 6v/l$. This helps lead to the solution.\n\\[\n\\vec{E}_{xy} \\theta = \\vec{R_{\\theta}}*(6\\dot{\\theta}) = (-6\\dot{\\theta}^2 (\\vec{e_x}) + 6\\dot{\\theta}\\vec{e_y})\n\\]\n\n4. Former exam question: The ringmaster\n\na. If points P in the vertical direction, the ring experiences only gravity and the normal force and does not accelerate. Thus, the vertical components of Newton's second law for the ring tells us that -\n\\[\nN - mg = 0 \\rightarrow N=mg.\n\\]",
    "In the horizontal direction, kinetic friction causes a force\n$$\nf_{k}=- \\mu_{k}m g \\hat{i}, \\tag{2}\n$$\nwhere we have defined the direction of motion of the ring to be the $\\hat{i}$ direction. Since this is the only horizontal force on the ring, Newton's second law in the $\\hat{i}$ direction tells us that the corresponding acceleration is a constant $a_{h}$, and has a value of\n$$\na_{h}=- \\mu_{k}g. \\tag{3}\n$$\nAccording to the work-kinetic energy theorem, the change in kinetic energy is equal to the work done by the forces. Since the disk starts out with kinetic energy $K_{i}$, we may write\n$$\n\\Delta K=K_{f}-K_{i}=\\int_{t_{i}}^{t_{f}}\\mathbf{F} \\cdot \\mathbf{v} d t=\\int_{0}^{t}(- \\mu_{k} m g) v_{h} d t\n\\quad-\\frac{1}{2}I \\frac{v_{r}^{2}}{R^{2}}, \\tag{4}\n$$\nwhere $v_{h}$ is the final distance traveled by the ring and we have replaced $v$ with $v_{h}$, the tangential velocity of the ring under constant acceleration, so we can immediately write the velocity as\n$$\nv_{h}=a_{h}t. \\tag{5}\n$$\nWe have now used equations (3), (5). We can also talk the time $t_{s}$ at which the ring will stop, which gives\n$$\nt_{s}=\\frac{v_{i}}{\\mu_{k}g}. \\tag{6}\n$$\nTo calculate the initial velocity, we can use the formula for the translational kinetic energy and find\n$$\nK_{i} = E_{i} = \\frac{1}{2} m v_{i}^{2}\\rightarrow v_{i} = \\sqrt{\\frac{2 E_{i}}{m}}. \\tag{7}\n$$\nSubstituting this into equation (6) gives the final answer of\n$$\nt_{s}=\\frac{\\sqrt{2 m E_{i}}}{\\mu_{k}g}. \\tag{8}\n$$\n$$ Alternative \\ solution: \\ $$\nKinetic friction does a horizontal force, which will slow the motion of the rotation of the ring. Let the initial tangential velocity, $v_{i}$, of the ring be directed along the horizontal axis. The initial momentum at the centre of the mass of the disc is\n$$\n\\mathbf{L}_{c_{m}} = m v_{i} R, \n$$\nrespectively. Solving equation (10) for $v$ and plugging it into equation (9) gives\n$$\nv = \\int_{0}^{t} \\frac{\\mathbf{h}}{\\mu_{k}gR}\n$$\nThe only net horizontal force on the ring arises from kinetic friction, which is given by equation (2), which we repeat here for easy reference. Thus, the generalization of Newton's second law for a ring, with linear and\n$$\nF = - f_{k} \\widehat{i}+m\\sqrt{(\\ddot{x})^{2}}, \n$$",
    "using equations (2) and (13). From this we can find the time at which the ring comes to rest to be\n\n$$\nt(\\xi)=0-\\left(-\\omega_{p,i}+\\sqrt{W_{i}}\\right) \\cos \\xi=\\frac{1}{2} \\pi \\frac{\\ell}{e},\n$$\n\nwhich is consistent with equation (8).\n\n2. (a) In parts (a) and (b) of this problem, we use a cylindrical coordinate system $\\left(3 \\pi / 6\\right.$ with its origin $O$\nat the center of the ring, with the angular directions pointing outward. Here, we assume cylindrical symmetry. We define the reduced angular momentum of the ring in the intermediate mass frame. We then calculate the total angular momentum and then find the strength of the torque to determine the angular velocity at the initial state.\n\n(b) Suppose that at first the initial angular velocity which is denoted by $\\omega_{b}$ does not change. We define the initial angular momentum about point $O$ as follows:\n\n$$\nL_{b} = \\tau_{b} L_{i}\n$$\n\nwhere $L_{i}$ is the moment of inertia of the ring. The initial kinetic energy of the ring is its initial\nkinetic energy minus the energy to find the initial angular velocity to be\n\n$$\nI_{\\mathrm{rot}} = \\frac{1}{2} I_{r} e^{2}\n$$\n\n(15)\n\nHere we have used the fact that $I$ and $e$ denote the magnitude of $I$ in front of the square root. We can now calculate (19) from equation (10) as follows:\n\n$$\n\\left(\\frac{d I_{\\mathrm{rot}}}{d t}\\right)_{\\text {comlinear }\\left(\\partial_{t} e\\right)=I_{\\mathrm{tot}} \\sqrt{\\frac{W_{\\mu}}{\\omega_{\\mathrm{tot}}}}\n$$\n\nGiven that the moment of inertia of a thin horizontal ring about the z-axis, this then becomes\n\n(16)\n\nTo calculate the torque exerted by the kinetic friction force on the ring, we integrate and approximate the energy exchange per ring per period. We first express the potential of the energy separating the two components as follows:\n\n$$\n{\\text {U_{ring}}=\\frac{1}{2}\\left(\\partial_{t} e\\right)L_{v s}},\n$$\n\n(19)\n\nwhere $\\partial_{t} k$ is the infinitesimal work done due to linear and angular kinetic friction and $i$ in $(i, j)$ are quantities of each component of the force in the tangential direction. The expression of $m$, $h$, and $k$ for any $k$ presented in equation (13) from the equation (14). The energy variably due to angular momentum is then expressed in terms of the initial energy difference as follows:\n\n$$\n\\partial_{t} k A_{\\mathit{i}} A_{\\mathit{j}}\n$$\nIn the tangential directions, the differential normal will experience a kinetic frictional force given by\n\n$$\n\\left(\\partial_t^2\\right(A_{\\mathit{i}} A_{\\mathit{j}}))-g_{i_{x j_{y} (N_{\\mathrm{tot}} x_{i, j)}}\\right)\n\\right)\n$$\n\n(18)\n\n(18)\n\nwhich is used to calculate the leading order term overpower and also in Eq. 18, the frictional force expression must apply in the infinitesimal ($\\mathit{k}$), of the initial angular state to be denoted as $T$ to be denoted at rank $i$ and $j$, and $\\Delta$ represents the Moller $\\varepsilon_{\\mathit{i}}$.\n\nThe frictional force arises due to the rates of $b$ at the work done by shear stress force, so the resulting $i \\mathrm{~th}$ dependence denoted as the forward direction for $n-1$.\n\nTo find the initial energy difference $K$ in the system, we apply the contributions from every differential element. This we derived as\n\n$$\nf(\\mathit{k} t_{i j})=\\begin{cases}\\frac{\\left(\\partial_{t} k, k_t\\right)}{\\cos \\phi k\\sin \\phi k}=\\pm \\left(\\frac{\\partial i}{8} y_p /\\left[k_x x_y\\right], \\partial t_{i j}\\right)-2(\\partial_{s_{i x j_y}} \\phi),\\\\ \\frac{\\partial_{t} A_{j} A_{\\mathit{i}} n j}{B_{\\mathrm{s} k}}=\\partial_{(}-\\mathit{\\omega_{i j}}=-\\frac{k_{x} x_y}{n_{yi}} \\cos \\pi n\\left(\\begin{array}{c}A_{\\mathit{i}} A_{\\mathit{j}}\\end{array}\\right) \\sin \\mathit{\\phi}\\end{cases} \\sqrt{\\frac{\\sum_{r}-b^{2}}{A_{\\mathit{i}}}} \\\\\n\\text { and }\n\\left(1+A_{\\mathit{i}} A_{\\mathit{j}}+\\tau_{y i} \\partial_{i j} \\omega_{i j}\\right)\n$$",
    "Given that the integral of $l$ over the entire mass of the object is just the total mass m, we find\n\\[ \\tau = R \\omega_0 m \\frac{\\eta}{2}. \\]\n\nWe see that this torque is in the direction opposite to the ring\u2019s angular velocity as is intuitive. Since this torque is constant, integrating the formula $\\frac{dl}{dt} = \\tau$ in time shows that\n\\[ l(t) = l_0 + \\tau t. \\]\n\nPlugging in equations (17) and (22) gives\n\\[ l(t) = Rm \\omega_0 t' = R \\sqrt{\\frac{mE_i}{2}} = \\left( \\frac{\\sqrt{mE_i} \\eta t}{2} \\right). \\]\n\nThis can be used to calculate the time $t'$ at which the ring stops spinning according to\n\\[ l(t') = 0 = \\omega_0 \\left( \\frac{\\sqrt{mE_i}}{\\eta} = l_0 \\left( l_0 (t'_s) \\right). \\]\n\nDividing this by equation (8) shows that the ratio $t' / t_s = \\sqrt{2}$. \n\nAlternative solution:\nAssuming that friction depends on the surface area, we can consider the torque due to the friction of the ring at rest equal to the torque from a single point mass at the same radius\n\\[ \\tau = \\bigg( \\frac{\\delta^2 E_{k,i}}{\\delta t^2} \\bigg) = \\bigg( \\omega_f^2 r \\bigg). \\]\n\nIf we replace $\\omega_0 \\cdot e_R$ with $R \\omega$ in this formula, this approach allows us to apply Newton\u2019s second law for rotational motion in the r direction and substitute equation (20) to find\n\\[ \\bigg( \\frac{dE_k}{dt} \\bigg) = R_1 ) 2 \\eta (r - o ^2) = m \\eta \\bigg( V_{f_m} \\bigg). \\]\n\nWhen there is no moment of inertia of the ring around the z-axis and add the rest of torque to form\n\\[ E_{int} = E_\\phi (tqr) M R_1 \\upsilon \\bigg( \\frac{1}{2} m \\upsilon^2_1. \\bigg) \\]\n\nRe-inserting $l$, the first equation becomes $l = m R (\\frac{E_k}{V_f^2})$\n\nnow where is the initial angular velocity which we can substitute equation (15) and\n\\[ m (E_{fi})^2 = m \\upsilon_{c,\\phi} = m \\eta t (E \\kappa - \\omega_0^2 ) = mv \\omega_f^2 - \\kappa. \\]\n\nThis is consistent with (22) if it sounds\n\n3. (1 point) The calculation of the time $t_s$ stops because, for practical motions, the object is moving by some external force when it starts to be at rest or begins to rotate in the same plane. Equation (18) shows us that a simple system has already rotated by 60 degrees before stopping the ring. This error cannot be zero but can be kept small if we sample this time at a much smaller rate than the torque exerted by an external motive force. Solving the integral (20), more practically shows us why the ratio scales to show the system stopped:\n\n\\[\nE_f(\\omega_i \\upsilon_0) = \\tau_sp int(\\frac{m_E}{V_f}) \\Bigg( \\frac{\\eta^2 t_s ( \\sqrt{\\omega_0 - m_0(\\upsilon_M - \\upsilon_0}) - \\upsilon_0\\sqrt{m})}{dER_t f_k} - mV_0 \\omega_o_1 + qV_i^2.)^2\n\\]",
    "where we must remember that we've defined $\\mathbf{e}_s$ to point clockwise and $\\mathbf{e}_s$ to point down. To find the overall torque on the ring, if we add up the contributions from every differential element, which, in the limit of $\\Delta m_i \\to 0$, becomes the integral\n\\[\n\\mathbf{N}_{\\mathrm{net}} = \\sum_i \\mathbf{r}_i \\times \\frac{d\\mathbf{p}_i}{dt} = \\sum_{i=1}^N r_i \\hat{r}_i \\times m_i \\frac{d^2 r_i (t)}{dt^2}\\hat{r}_i = \\int_0^{2\\pi}R(\\cos\\theta\\mathbf{e}_x + \\sin\\theta\\mathbf{e}_y) R\\left(-\\omega^2\\cos\\theta \\mathbf{e}_x -\\omega^2\\sin\\theta\\mathbf{e}_y \\right) d\\theta.\n\\]\nGiven that the disk is uniform, we can use the areal density to show\n\\[\n\\sigma = \\frac{dm}{dA} = \\frac{M}{\\pi R^2} \\implies dm = \\sigma dA = \\frac{M}{\\pi R^2}rdrd\\theta\n\\]\nwhere $dA$ is the differential element of area. In polar coordinates, it is expressed as $dA = rdrd\\theta$. Substituting this and equation (32) into equation (31) gives\n\\[\n\\mathbf{N}_{net} = \\int_0^{2\\pi} \\int_0^R r \\mathbf{e}_s \\times \\sigma rdr \\frac{d^2s}{dt^2} d\\theta\n\\]\nEvaluating the integral in $\\theta$ gives\n\\[\n\\mathbf{N}_{net} = \\int_0^r R \\mathbf{e}_s \\times \\sigma rdr \\left( -\\omega^2 r \\right) d\\theta = \\int_0^r r \\mathbf{e}_s (-\\omega^2 \\sigma ) r dr \\left( x \\mathbf{e}_s \\right) = -\\omega^2 \\sigma R^4 \\int_0^r r dr \\frac{1}{2R} (-R^2 \\mathbf{e}_x + 2 x_{\\mathbf{e}_y})) = - \\frac {\\omega^2M }{2}\n\\]\nEvaluating the integral in $r$ gives\n\\[\nL_{\\mathrm{net}} = I \\omega = \\sigma \\frac{\\int_0^R r dr \\left ( x_{\\mathbf{e}_x} \\right)}{3}\n\\]\nWe see that this torque $T$ is in the direction opposite to the ring's angular velocity as is intuitive. Since we know that angular impulse is the time integral of torque, we have $\\int \\mathbf{T} dt = \\Delta \\mathbf{L}$. As $\\Delta \\mathbf{L} = \\mathbf{L}f - \\mathbf{L}i$ and for a thin ring, $\\mathbf{L} = I \\omega$, the above can be rewritten as\n\\[\n-\\frac{\\omega M}{2} = (0 - I \\omega)\n\\]\nTo calculate $\\omega_f$, we can use my equation (36) from part 2 set to zero time the moment of inertia of a disk, $I = \\frac{MR^2 }{2}$ (rather than a ring). This gives\n\\[\n\\frac{1}{2} MR^2 \\omega_0^3 = 0\n\\]\nPlugging in this and equation (35) into equation (30) gives\n\\[\n0 = \\int_0^{T_{\\mathrm{stop}}}I(0 - \\omega) d\\omega dt = \\omega_i\n\\]\nThis can be used to calculate the time $\\tau_f$ at which the ring stops spinning according to\n\\[\n0 = \\omega_i = -\\int_0^{r = R} \\frac{\\omega^2 M}{2}\n\\]\nDividing this by equation (8) shows that the ring stops spinning according to\n\\[\n\\tau_f = \\frac{3}{8} \\sqrt{\\pi} R\n\\]",
    "5. Optional: Elliptic Orbit\n\n1. As in the problem 1, the motion of the satellite will conserve both angular momentum and mechanical energy according to\n$$\n\\begin{aligned}\nL &= L_{0}, \\\\\nE_{e l l} &= E_{0}.\n\\end{aligned}\n$$\n(1)\n\nWe will choose to evaluate angular momentum about the center of the planet and take the reference energy for the gravitational potential energy to be infinitely far away. Thus, conservation of angular momentum and mechanical energy become\n$$\n\\begin{aligned}\nL_{0} &= m v_{\\perp} r=m v \\sin \\theta r, \\\\\nK_{0}+U &=\\frac{1}{2} m v^{2}-\\frac{G M m}{r}=E_{0},\n\\end{aligned}\n$$\n(3)\nrespectively. Taking a cylindrical coordinate system and substituting the forms of the kinetic and gravitational potential energy gives\n$$\n\\begin{aligned}\nK &=\\frac{1}{2} m\\left(v_{\\perp}^{2}+v_{\\|}^{2}\\right)=\\frac{1}{2} m\\left(r^{2} \\dot{\\theta}^{2}+\\dot{r}^{2}\\right), & \\quad U=-\\frac{G M m}{r}.\n\\end{aligned}\n$$\n(4)\n\nSubstituting the expression for $L_{0}$ into $v_{\\perp}$ we obtain\n$$\n\\begin{aligned}\nK &=\\frac{1}{2} m\\left(\\frac{L_{0}^{2}}{m^{2} r^{2}}+\\dot{r}^{2}\\right)=\\frac{L_{0}^{2}}{2 m r^{2}}+\\frac{1}{2} m \\dot{r}^{2}, & \\quad U=-\\frac{G M m}{r}.\n\\end{aligned}\n$$\n(5)\n\nSubstituting the expressions for $K$ and $U$ into the energy relation and solving for $\\dot{r}$ gives\n$$\n\\begin{aligned}\nE_{0} &=\\frac{L_{0}^{2}}{2 m r^{2}}+\\frac{1}{2} m \\dot{r}^{2}-\\frac{G M m}{r}=\\frac{L_{0}^{2}}{2 m r^{2}}+\\frac{1}{2} m \\dot{r}^{2}-\\frac{G M m}{r} \\\\\n\\frac{1}{2} m \\dot{r}^{2} &=E_{0}-\\frac{L_{0}^{2}}{2 m r^{2}}+\\frac{G M m}{r} \\\\\n\\dot{r} &=\\sqrt{\\frac{2}{m}}\\left(E_{0}+\\frac{G M m}{r}-\\frac{L_{0}^{2}}{2 m r^{2}}\\right)^{\\frac{1}{2}}\n\\end{aligned}\n$$\n(6)\n\n2. Since the satellite is not burning any fuel, the gravitational attraction to the planet must be causing the acceleration and hence acting like a time-like circular guide. This condition is represented by centripetal acceleration which is given by $\\ddot{r}=0$.\n$$\n\\begin{aligned}\n\\ddot{r} &=\\frac{d}{d t} \\dot{r}=\\frac{d \\dot{r}}{d r} \\dot{r}=\\frac{d \\dot{r}}{d r} \\sqrt{\\frac{2}{m}}\\left(E_{0}+\\frac{G M m}{r}-\\frac{L_{0}^{2}}{2 m r^{2}}\\right)^{\\frac{1}{2}}\n\\end{aligned}\n$$\n\nThe centripetal acceleration is given by $\\ddot{r}=\\frac{v_{\\perp}^{2}}{r}=\\frac{L_{0}^{2}}{m^{2} r^{3}}$. In order to evaluate the remaining term we take the time derivative of $\\dot{r}$ to be zero, giving the orbit equation\n$$\n\\begin{aligned}\n0 &=\\frac{d}{d r} \\dot{r}=\\sqrt{\\frac{2}{m}} \\frac{d}{d r}\\left(E_{0}+\\frac{G M m}{r}-\\frac{L_{0}^{2}}{2 m r^{2}}\\right)^{\\frac{1}{2}} \\\\\n0 &=\\frac{d}{d r} \\sqrt{\\frac{2}{m}}\\left(\\frac{-G M m}{r^{2}}+\\frac{L_{0}^{2}}{m r^{3}}\\right)^{\\frac{1}{2}} \\\\\n0 &=\\frac{1}{2}\\left(-\\frac{G M}{r^{2}}+\\frac{L_{0}^{2}}{m r^{3}}\\right)=r_{0}=\\frac{L_{0}^{2}}{G M m^{2}}\n\\end{aligned}\n$$\n(8)\n\nThis solution can be understood better if it is translated as an orbit about a focus. If we let $r$ vary, the angular variation $\\sin \\theta=\\frac{L_{0}}{m v r}$. For conservation of angular momentum we have $\\dot{\\theta}=\\frac{L_{0}}{m r^{2}}, \\theta=\\left(\\frac{1}{r_{0}}-\\frac{1}{r}\\right)$. Thus\n$$\n\\begin{aligned}\n\\sin \\theta &=\\frac{L_{0}}{m v r}\n\\end{aligned}\n$$\n(11)\n\nwhere $v$ is maintained because the energy conservation, becomes the average separation $a$. If at some point we want to eliminate the velocity $v$ using the previous lens, the average separation is",
    "We substitute this into equation (7) to get \n\n\\[\n\\frac{2GM_{m_s}}{r_c} = \\frac{x2GM_{m_s}}{{r_p}{r_c}} - \\frac{2GM_{m_s}}{r_p}\n\\]\n\nor\n\n\\[\n\\frac{2GM_{m_s}}{r_c} = \\frac{2GM_{m_s}}{r_p} \\left( \\frac{r_p}{r_c} \\right) - \\frac{2GM_{m_s}}{r_p}\n\\quad \\Rightarrow \\quad \\frac{2GM_{m_s}}{r_c} = \\frac{2GM_{m_s}}{r_p} \\left( \\frac{r_c - r_p}{r_c} \\right)\n\\quad \\Rightarrow \\quad \\frac{r_c}{r_p} = \\frac{2 + \\left( \\frac{{\\partial{r_c}}/{r_c}}{}\\right) \\times {2r_p}}{r_c}\n\\]\n\nWe can now evaluate equation (10) at $r_c = r_p$ to get \n\n\\[\n\\left(\\frac{\\partial{r_c}}{r_c}\\right)_p^2 \\frac{1}{{r_c}} = \\left( \\frac{\\partial{r_c}}{r_c} \\right)_p \\times ,1.\n\\]\n\nand compare with equation (12). Since $r_p < r_c$, we know that $\\sqrt{\\frac{1}{r_c/r_p-1}}>1$. Thus. we find that\n\n\\[\nr_c \\geq r_p\n\\]\n\nand the speed throughout the circular orbit is less than the speed at the point of closest approach in an elliptical orbit.",
    "Chapter 12\n\nRIGID BODY KINEMATICS AND DYNAMICS",
    "12.  Rigid body kinematics and dynamics\n\n12.1  Rigid body kinematics\n12.2  Rigid body dynamics\n12.3  Inertia tensor and Euler equations",
    "12.1 Rigid body kinematics\n\n12.1.1 Rigid body\n\nA rigid body is a closed system consisting of a set of material points where the distances between the points are constant. The volume or the shape of the rigid body does not change, only its spatial orientation changes.\n\nExamples: frame of reference, cube\n\n- Rotational motion of the centre of mass.\n\n- Rotational motion of the centre of mass + intrinsic rotational motion around the centre of mass.",
    "Theorem: 6 coordinates are necessary to determine entirely the position (3 coordinates) and orientation (3 coordinates) of a rigid body of arbitrary shape with respect to a given frame of reference.\n\nDemonstration: Rigid body = frame of reference (4 material points A, B, C, D).\n\nLet \\(ABCD\\) be a regular tetrahedron of edge \"r\" and of orientation \\((AB \\times AC) \\cdot AD > 0\\).\n\n- Position of point A (3 Cartesian coordinates)\n- Position of point B (2 angles on a sphere of radius r centered at A)\n- Position of point C (1 angle on a circle defined by the intersection of two spheres of radius r centered at A and B)\n- Position of point D (point entirely determined by the intersection of three spheres of radius r centered at A, B, and C and by the orientation condition); \\(3 + 2 + 1 = 6\\)",
    "12.1.2 Euler angles\n\nThe orientation of a rigid body, around the origin $O$, can be determined by particular angles called \"Euler angles\" ($\\phi, \\theta, \\psi$)\n- Absolute frame $(O, \\hat{x}_1, \\hat{x}_2, \\hat{x}_3)$ associated to the inertial frame of reference\n- Relative frame $(O, \\hat{y}_1, \\hat{y}_2, \\hat{y}_3)$ associated to the rigid body\n- Transformation: $(O, \\hat{x}_1, \\hat{x}_2, \\hat{x}_3) \\xrightarrow{(\\phi, \\theta, \\psi)} (O, \\hat{y}_1, \\hat{y}_2, \\hat{y}_3)$\n\n1. Rotation of angle $\\phi$ around the vertical axis $O z_3$: $O x_1 \\rightarrow O u$ precession\n2. Rotation of angle $\\theta$ around the nodal axis $O u$: $O x_3 \\rightarrow O y_3$ nutation\n3. Rotation of angle $\\psi$ around the intrinsic rotation axis $O y_3$: $O u \\rightarrow O y_1$ intrinsic rotation",
    "Since there are 3 Euler angles ($\\phi, \\theta, \\psi$), there are 3 specific rotational motions of a rigid body that are characterised by an angular velocity vector.\n\n1. Precession: around the vertical axis $O x_{3}$\nAngular velocity: $\\dot{\\phi} = \\dot{\\phi} \\hat{z_{3}}$\n\n2. Nutation: around the nodal axis $O u$\nAngular velocity: $\\dot{\\theta} = \\dot{\\theta} \\hat{u}$\n\n3. Intrinsic rotation: around the intrinsic rotation axis $O y_{3}$\nAngular velocity: $\\dot{\\psi} = \\dot{\\psi} \\hat{y_{3}}$\n\nTotal angular velocity:\n$$\\Omega = \\dot{\\phi} \\hat{z_{3}} + \\dot{\\theta} \\hat{u} + \\dot{\\psi} \\hat{y_{3}}$$",
    "Experiments: \u25c9 Gyroscope with a sphere on an air cushion\n\nThe precession is the rotational motion of the axis of the gyroscope around the vertical symmetry axis.\n\nThe nutation is the rotational motion of the axis of the gyroscope in a vertical plane.\n\nThe intrinsic rotation is the rotational motion of the colored disk around the axis of the gyroscope.",
    "2) Chinese spinning tops\n\nThe particular geometry of the Chinese spinning tops enables them to undergo a nutation of 180\u00b0 which makes them turn around and stand on their axis.\n\n3) Euler disk\n\nThe precession motion of the point of contact of the Euler disk gives it its characteristic noise. The nutation motion, that brings progressively the plane of the disk to a horizontal position, increases the rotation angular velocity of the point of contact.",
    "The Tait-Bryan angles are a variation of the Euler angles.\n\n1. Precession \u2192 Yaw\n2. Nutation \u2192 Pitch\n3. Intrinsic rotation \u2192 Roll\n\nExample: Aeronautics (airplane)\n\nPitch axis       \nYaw axis  (1)\n    \nRoll axis  (3)",
    "12.1.3 Velocity and acceleration of a rigid body\n\n- Absolute frame of reference: inertial frame of reference\n  Absolute frame $(O, \\hat{x}_1, \\hat{x}_2, \\hat{x}_3)$\n\n- Relative frame of reference: accelerated frame of reference of the rigid body in translation and rotation at angular velocity $\\Omega$ with respect to the absolute frame of reference.\n  Relative frame $(A, \\hat{y}_1, \\hat{y}_2, \\hat{y}_3)$\n\n- The material point $P$ belongs to the rigid body:\n  $$v_r (P) = 0 \\quad \\text{and} \\quad a_r (P) = 0 \\tag{12.2}$$\n\n- Simpler notation (rigid body):\n  $$r_r (P) \\equiv AP; \\quad v_a (A) \\equiv VA; \\quad v_a (P) \\equiv VP;$$\n  $$a_a (A) \\equiv AA; \\quad a_a (P) \\equiv AP \\tag{12.3}$$",
    "Relation between the velocities of 2 material points of the rigid body:\n\n$(10.24) \\quad \\left(\\text{12.2}\\right) \\quad \\left(\\text{12.3}\\right) \\quad V_P = V_A + \\Omega \\times AP \\quad \\left(12.4\\right)$\n\nTheorem: The velocities $V_P$ and $V_Q$ of arbitrary material points that belong to the rigid body satisfy the rotation:\n$V_Q = V_P + \\Omega \\times PQ \\quad (12.5)$\n\nDemonstration:\n\n$(12.4) \\quad \\text{with} \\quad P \\equiv Q \\quad \\Rightarrow \\quad V_Q = V_A + \\Omega \\times AQ \\quad (12.6)$\n\n$(12.6) - (12.4) \\quad \\Rightarrow \\quad V_Q - V_P = \\Omega \\times \\left( AQ - AP \\right) = \\Omega \\times PQ \\quad (12.7)$",
    "\u2022 Relation between the accelerations of 2 points of the rigid body:\n\n$(10.37) \\quad (12.2) \\quad (12.3) \\quad a_P = a_A + \\Omega \\times (\\Omega \\times AP) + \\dot{\\Omega} \\times AP \\qquad (12.8)$\n\n**Theorem:** The accelerations $a_P$ and $a_Q$ of arbitrary material points that belong to the rigid body satisfy the relation:\n\n$a_Q = a_P + \\Omega \\times (\\Omega \\times PQ) + \\dot{\\Omega} \\times PQ \\qquad (12.9)$\n\n**Demonstration:**\n\n(12.8) with $P \\equiv Q \\quad \\Rightarrow \\quad a_Q = a_A + \\Omega \\times (\\Omega \\times AQ) + \\dot{\\Omega} \\times AQ \\quad \\qquad (12.10)$\n\n$(12.9) - (12.8) \\quad \\Rightarrow \\quad a_Q - a_P = \\Omega \\times (\\Omega \\times (AQ - AP)) + \\dot{\\Omega} \\times (AQ - AP)$\n$$= \\Omega \\times (\\Omega \\times PQ) + \\dot{\\Omega} \\times PQ \\quad \\qquad (12.11) \\text{ \u25a0}$$",
    "12.1.4 Rolling without slipping\n\nGeneral relation between velocities\n$V_G = V_C + \\Omega \\times CG$\n\n- Slipping (translation)\n- Rolling (intrinsic rotation)\n\n1) Slipping without rolling\n$V_G = V_C$\ntranslation of the point of contact $C$ without intrinsic rotation of the rigid body around $G$ (i.e. $\\Omega = 0$).\n\n2) Rolling without slipping\n$V_G = \\Omega \\times CG$ because $V_C = 0$\nIntrinsic rotation of the rigid body around $G$ without translation of the point of contact $C$ (i.e. $V_C = 0$).\n\n$V_G = $ velocity of the centre of mass\n$V_C = $ velocity of the point contact\n\nIn rolling without slipping the point of contact changes over time, but at each time its translational velocity with respect to the ground vanishes (i.e. $V_C = 0$).",
    "12.2 Rigid body dynamics\n\nSince a rigid body is a closed system of material points where the distances between the points are fixed, the momentum theorem and the angular momentum theorem are the same as for a system of material points.\n\nMomentum theorem\n$$\\mathbf{F}^{\\text{ext}} = \\frac{d\\mathbf{P}}{dt} = M \\mathbf{A}_G \\ \\text{because} \\ M = \\text{const} \\ (12.13)$$\n\nAngular momentum theorem\n$$\\mathbf{\\tau}^{\\text{ext}} = \\frac{d\\mathbf{L}_O}{dt} \\ (12.14)$$",
    "12.2.1 Angular momentum transfer theorem and first Koenig theorem\n\nTheorem: Let $O$ be a fixed point of the inertial frame of reference and $P$ a point of the rigid body. The angular momentum transfer theorem states:\n$$\nL_P = PO \\times M VG + L_O \\tag{12.15}\n$$\n\nDemonstration:\n$$\nL_P \\sum_\\alpha P P_\\alpha \\times p_\\alpha = \\sum_\\alpha (PO + OP_\\alpha) \\times p_\\alpha \\tag{12.16}\n$$\n$$\n=: PO \\times M V + \\sum_\\alpha OP_\\alpha \\times p_\\alpha = PO \\times M V_G + L_O \\tag{11.59}{11.52}\n$$\n\nFor $P \\equiv G$, the angular momentum transfer theorem is called the first Koenig theorem.\n$$\nL_O = OG \\times M V_G + L_C \\tag{12.17}\n$$",
    "Theorem: Let $P$ be a point of the rigid body and $G$ its centre of mass. The angular momentum transfer theorem states:\n\\[L_P = PG \\times M V_G + L_G \\quad (12.18)\\]\n\nDemonstration: \n\\[ L_P = PO \\times M V_G + L_O \\quad (12.15) \\]\n\\[ L_O = OG \\times M V_G + L_G \\quad (12.17) \\]\n\\[\\implies L_P = (PO + OG) \\times M V_G + L_G \\]\n\\[= PG \\times M V_G + L_G \\quad (12.19) \\]",
    "12.2.2 Torque transfer theorem\n\nTheorem: Let $O$ be a fixed point of the inertial frame of reference and $P$ a point of the rigid body. The torque transfer theorem states:\n$$ \\boldsymbol{\\tau}_P^{\\text{ext}} = \\mathbf{PO} \\times M \\mathbf{a}_G + \\boldsymbol{\\tau}_O^{\\text{ext}} \\quad \\text{(12.20)} $$\n\nDemonstration:\n$$ \\boldsymbol{\\tau}_P^{\\text{ext}} = \\sum_\\alpha \\mathbf{PP}_\\alpha \\times \\mathbf{F}_\\alpha^{\\text{ext}} = \\sum_\\alpha (\\mathbf{PO} + \\mathbf{OP}_\\alpha) \\times \\mathbf{F}_\\alpha^{\\text{ext}} $$\n$$ \\mathbf{PO} \\times \\mathbf{F}_\\alpha^{\\text{ext}} + \\sum_\\alpha \\mathbf{OP}_\\alpha \\times \\mathbf{F}_\\alpha^{\\text{ext}} $$\n$$ \\boldsymbol{\\tau}_P^{\\text{ext}} = \\mathbf{PO} \\times M \\mathbf{a}_G + \\boldsymbol{\\tau}_O^{\\text{ext}} \\quad \\square $$\n\nFor $P \\equiv G$, the external torque transfer theorem states:\n$$ \\boldsymbol{\\tau}_O^{\\text{ext}} = \\mathbf{OG} \\times M \\mathbf{a}_G + \\boldsymbol{\\tau}_G^{\\text{ext}} \\quad \\text{(12.22)} $$",
    "Theorem: Let $P$ be a point of the rigid body and $G$ its centre of mass. The external torque transfer theorem states:\n$$\n\\tau_P^{ext} = \\mathbf{PG} \\times M\\mathbf{A}_G + \\tau_G^{ext} \\qquad (12.23)\n$$\n\nDemonstration:\n$$\n\\tau_P^{ext} = \\mathbf{PO} \\times M \\mathbf{A}_G + \\tau_O^{ext} \\qquad (12.20)\n$$\n$$\n\\tau_O^{ext} = \\mathbf{OG} \\times M \\mathbf{A}_G + \\tau_G^{ext} \\qquad (12.22)\n$$\n$$\n\\Rightarrow \\tau_P^{ext} = (\\mathbf{PO} + \\mathbf{OG}) \\times M \\mathbf{A}_G + \\tau_G^{ext}\n$$\n$$\n= \\mathbf{PG} \\times M \\mathbf{A}_G + \\tau_G^{ext} \\qquad (12.24)\n$$",
    "12.2.3 Angular momentum theorem with respect to a point\n\n- Angular momentum transfer theorem:\n$$L_P = PO \\times M VG + L_O \\quad (12.15)$$\n\n- Time derivative of (12.15):\n$$ \n\\frac{dL_P}{dt} = - \\frac{dOP}{dt} \\times M VG + PO \\times M \\frac{dVG}{dt} + \\frac{dL_O}{dt} \n$$\n$$ \n= - V_P \\times M VG + PO \\times M A_G + \\frac{dL_O}{dt} \\quad (12.25) \n$$\n\n- Torque transfer theorem:\n$$\n\\tau^{ext}_P = PO \\times M A_G + \\tau^{ext}_O \\quad (12.20) \n$$\n\n- (12.20) - (12.25):\n$$\n\\tau^{ext}_P - \\frac{dL_P}{dt} = V_P \\times M VG + \\tau^{ext}_O - \\frac{dL_O}{dt} \\quad (12.20 a) \n$$",
    "- Vectorial relation:\n$$\\tau_{P}^{\\text{ext}} = \\frac{dL_{P}}{dt} + V_{P} \\times MV_{G} + \\tau_{O}^{\\text{ext}} - \\frac{dL_{O}}{dt} \\quad \\text{(12.20 b)}$$\n\n- Angular momentum theorem:\n$$\\tau_{O}^{\\text{ext}} = \\frac{dL_{O}}{dt} \\quad \\text{(12.14)}$$\n\n- (12.14) $\\Rightarrow$ (12.20 b) Angular momentum theorem:\n$$\\tau_{P}^{\\text{ext}} = \\frac{dL_{P}}{dt} + V_{P} \\times MV_{G} \\quad \\text{(12.26)}$$\n\n- Angular momentum theorem (12.26) for $P \\equiv G$:\n$$\\tau_{G}^{\\text{ext}} = \\frac{dL_{G}}{dt} \\quad \\text{(12.27)}$$",
    "12.3 Inertia tensor and Euler equations\n\nMomentum of a rigid body:\n$$P = M V_G \\quad (12.28)$$\n\nAngular momentum of the rigid body evaluated with respect to its centre of mass $G$.\n$$L_G = I_G \\Omega \\quad (12.29)$$\n\nwhere $I_G$ is a linear application called the inertia tensor and represented by a 3 x 3 matrix.\n\n1) $P$ is always collinear to $V_G$\n   $$\\Rightarrow M \\text{ is a scalar}$$\n2) $L_G$ is not always collinear to $\\Omega$\n   $$\\Rightarrow I_G \\text{ is a linear application}$$",
    "Theorem: The angular momentum of the rigid body $L_G$, evaluated with respect its centre of mass $G$, can be recast as\n$$\nL_G = \\sum_\\alpha m_\\alpha GPA_\\alpha \\times (\\Omega \\times GPA_\\alpha) \\tag{12.30}\n$$\n\nDemonstration:\n- Identity of the velocities (12.5) for a material point $P_\\alpha$ of the rigid body:\n$$\nv_\\alpha = V_G + \\Omega \\times GPA_\\alpha\\tag{12.31}\n$$\n- Angular momentum:\n$$\nL_G = \\sum_\\alpha GPA_\\alpha \\times p_\\alpha = \\sum_\\alpha GPA_\\alpha \\times m_\\alpha v_\\alpha\n$$\n$$\n= \\sum_\\alpha GPA_\\alpha \\times m_\\alpha (V_G + \\Omega \\times GPA_\\alpha)\n$$\n$$\n= m_\\alpha \\sum_\\alpha r_\\alpha \\times V_G + \\sum_\\alpha m_\\alpha GPA_\\alpha \\times (\\Omega \\times GPA_\\alpha) = 0\n$$\n$$\n= \\sum_\\alpha m_\\alpha GPA_\\alpha \\times (\\Omega \\times GPA_\\alpha) \\tag{12.32}\n$$",
    "12.3.1 Inertia tensor\n\n- Angular momentum: $L_G = \\sum_{\\alpha} m_{\\alpha} G P_{\\alpha} \\times (\\Omega \\times G P_{\\alpha})$ (12.30)\n\n(1.43) \\[\n\\Rightarrow L_G = \\sum_{\\alpha} m_{\\alpha} \\left( G P_{\\alpha}^2 \\Omega - (G P_{\\alpha} \\cdot \\Omega ) G P_{\\alpha} \\right) \\] (12.33)\n\n- Angular velocity with respect to the basis $(\\hat{y}_1, \\hat{y}_2, \\hat{y}_3 )$ of the rigid body:\n\\[\n\\Omega = \\sum_{j=1}^{3} \\left( \\Omega \\cdot \\hat{y}_j \\right) \\hat{y}_j \\quad (12.34)",
    "- Angular momentum: $L_G = \\sum_{\\alpha} m_{\\alpha} (GP_{\\alpha}^2 \\mathbf{\\Omega} - (GP_{\\alpha} \\cdot \\mathbf{\\Omega}) GP_{\\alpha})$ (12.33)\n\n- Angular velocity: $\\mathbf{\\Omega} = \\sum_{j=1}^{3} (\\mathbf{\\dot{y}}_j \\mathbf{\\hat{y}}_j)$ (12.34)\n\n- Component of $L_G$ along $\\mathbf{\\dot{y}}_i$ (12.33) $\\Rightarrow$\n$$L_G \\cdot \\mathbf{\\dot{y}}_i = \\sum_{\\alpha} m_{\\alpha} (GP_{\\alpha}^2 \\mathbf{\\Omega} - (GP_{\\alpha} \\cdot \\mathbf{\\Omega}) GP_{\\alpha}) \\cdot \\mathbf{\\dot{y}}_i$$\n$$= \\sum_{j=1}^{3} \\sum_{\\alpha} m_{\\alpha} (GP_{\\alpha}^2 ( \\mathbf{\\dot{y}}_j \\mathbf{\\hat{y}}_j ) - (GP_{\\alpha} \\cdot (\\mathbf{\\dot{y}}_j \\mathbf{\\hat{y}}_j)) GP_{\\alpha}) \\cdot \\mathbf{\\dot{y}}_i$$\n$$= \\sum_{j=1}^{3} \\left( \\sum_{\\alpha} m_{\\alpha} (GP_{\\alpha}^2 \\mathbf{1} - GP_{\\alpha} \\otimes GP_{\\alpha}) \\mathbf{\\hat{y}}_j \\right) \\cdot \\mathbf{\\dot{y}}_i$$\n$$= \\sum_{j=1}^{3} (I_{G} \\mathbf{\\Omega}_j ) \\cdot \\mathbf{\\dot{y}}_i$$",
    "- Inertia tensor associated to the centre of mass $G$:\n  (linear application represented by a $3 \\times 3$ matrix)\n  \n  \\[\n  \\mathbf{I_G} = \\sum_{\\alpha} m_{\\alpha} \\left(GP_{\\alpha}^{2} \\mathbf{1} - GP_{\\alpha} \\otimes GP_{\\alpha}\\right) \\qquad (12.36)\n  \\]\n\n- The relation (12.35) is expressed in components with respect to the basis ($\\hat{y}_1, \\hat{y}_2, \\hat{y}_3$)\n\n\\[\nLG_i = \\sum_{j=1}^{3} I_{G,ij} Q_j \\qquad (12.37)\n\\]\n\n  where the components of the inertia tensor are written as:\n\n\\[\nI_{G,ij} = \\sum_{\\alpha} m_{\\alpha} \\left( \\sum_{k=1}^{3} GP_{\\alpha,k}^{2} \\delta_{ij} - GP_{\\alpha,i} GP_{\\alpha,j}\\right) \\qquad (12.38)\n\\]",
    "The components of the inertia tensor are written as:\n\n\\[\nIG_{\\alpha,ij} = \\sum_{\\alpha} m_{\\alpha} \\left( \\sum_{k=1}^{3} GP_{\\alpha,k}^{2} \\delta_{ij} - GP_{\\alpha,i} GP_{\\alpha,j} \\right) \\quad (12.38)\n\\]\n\nThe diagonal components of $I_G$:\n\n\\[\nIG_{1,11} = \\sum_{\\alpha} m_{\\alpha} (GP_{\\alpha,2}^{2} + GP_{\\alpha,3}^{2}) \\equiv \\sum_{\\alpha} m_{\\alpha} r_{\\alpha,23}^{2}\n\\]\n\n\\[\nIG_{2,22} = \\sum_{\\alpha} m_{\\alpha} (GP_{\\alpha,3}^{2} + GP_{\\alpha,1}^{2}) \\equiv \\sum_{\\alpha} m_{\\alpha} r_{\\alpha,31}^{2}\n\\]\n\n\\[\nIG_{3,33} = \\sum_{\\alpha} m_{\\alpha} (GP_{\\alpha,1}^{2} + GP_{\\alpha,2}^{2}) \\equiv \\sum_{\\alpha} m_{\\alpha} r_{\\alpha,12}^{2}\n\\]\n\nwhere\n\n\\[\nr_{\\alpha,23} = \\text{distance to the axis} \\quad Gy_{1}\n\\]\n\n\\[\nr_{\\alpha,31} = \\text{distance to the axis} \\quad Gy_{2}\n\\]\n\n\\[\nr_{\\alpha,12} = \\text{distance to the axis} \\quad Gy_{3}\n\\]",
    "12.3.2 Moments of inertia and principal axes\n\n- The inertia tensor $I_G$ is represented by a real and symmetric $3 \\times 3$ matrix, i.e. $I_{G,ij} = I_{G,ji} \\in \\mathbb{R}$\n\n- The spectral theorem of linear algebra implies that there exists a vector basis $(e_1, e_2, e_3)$ associated to the rigid body with respect to which the inertia tensor is represented by a diagonal matrix.\n\n- Geometric frame $(G, e_1, e_2, e_3)$ : principal axis frame\n\n- Axes $Ge_1, Ge_2, Ge_3$: principal axes (symmetry axes) (12.29): expressed with respect to the principal axis frame\n\n\\[ \n\\begin{pmatrix}\nL_{G,1} \\\\\nL_{G,2} \\\\\nL_{G,3}\n\\end{pmatrix} = \n\\begin{pmatrix}\nI_{G,1} & 0 & 0 \\\\\n0 & I_{G,2} & 0 \\\\\n0 & 0 & I_{G,3}\n\\end{pmatrix}\n\\begin{pmatrix}\n\\Omega_1 \\\\\n\\Omega_2 \\\\\n\\Omega_3\n\\end{pmatrix} \n\\tag{12.40}\n\\]",
    "Relation expressed with respect to the principal axis (diagonal matrix)\n\n$$\n\\begin{pmatrix}\nLG_{,1} \\\\\nLG_{,2} \\\\\nLG_{,3}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nIG_1 & 0 & 0 \\\\\n0 & IG_2 & 0 \\\\\n0 & 0 & IG_3\n\\end{pmatrix}\n\\begin{pmatrix}\n\\Omega_1 \\\\\n\\Omega_2 \\\\\n\\Omega_3\n\\end{pmatrix}\n\\quad \\text{(12.40)}\n$$\n\nRelation (12.40) is written vectorially as:\n\n$$\nLG = \\sum_{i=1}^{3} IG_i \\Omega_i e_i = IG_1 \\Omega_1 e_1 + IG_2 \\Omega_2 e_2 + IG_3 \\Omega_3 e_3 \\quad \\text{(12.41)}\n$$\n\nThe eigenvalues $IG_1$, $IG_2$, and $IG_3$ of the inertia tensor $IG$ are called the moments of inertia of the rigid body with respect to a rotation around the principal axes $Ge_1$, $Ge_2$, and $Ge_3$.\n\n$$\nIG_1 = \\sum_{\\alpha} m_{\\alpha} r_{\\alpha 2}^2 \\; ; \\; IG_2 = \\sum_{\\alpha} m_{\\alpha} r_{\\alpha 1}^2 \\; ; \\; IG_3 = \\sum_{\\alpha} m_{\\alpha} r_{\\alpha 3}^2 \\quad \\text{(12.42)}\n$$\n\nwhere $r_{\\alpha, i}$ = distance of the material point $P_{\\alpha}$ to the axis $Ge_i$ $\\forall i = 1, 2, 3",
    "- Three types of regular rigid bodies:\n1. Ellipsoid\nThree different moments of inertia\n $I_{G,1} \\neq I_{G,2} ; \\quad I_{G,2} \\neq I_{G,3}$\n $I_{G,3} \\neq I_{G,1}$\n \n2. Cylinder\nTwo equal moments of inertia\n $I_{G,2} = I_{G,3} \\equiv I_{G,\\perp}$\n $I_{G,1} \\equiv I_{G,\\parallel} \\neq I_{G,\\perp}$\n\n3. Sphere\nThree equal moments of inertia\n $I_{G,1} = I_{G,2} = I_{G,3} \\equiv I_{G}$",
    "Experiment: Man with dumbbells on a rotating stool.\nIn the absence of an external torque $\\boldsymbol{\\tau}_{G}^{ext}$ = 0, the angular momentum is conserved: $L_{G} = I_{G,3} \\Omega_3 e_3 = \\text{const}$. By bringing the dumbbells back towards the body, the moment of inertia $I_{G,3}$ decreases, which increases the angular velocity $\\Omega_3$ in order to keep the angular momentum $L_G$ constant.\n\n$\\Omega = \\Omega_3 e_3$\n$L_G = I_{G,3} \\Omega_3 e_3 = \\text{const}$\n\n$I_{G,3}$ large\n$\\Rightarrow \\Omega_3$ slow\n\n$I_{G,3}$ small\n$\\Rightarrow \\Omega_3$ fast",
    "12.3.3 Euler equations\n\n- Time derivatives of the basis vectors of the principal axis frame:\n\\[ \\dot{e}_i = \\Omega \\times e_i \\quad \\forall \\; i = 1, 2, 3 \\quad \\text{(12.43)} \\]\n\n- Angular momentum: \n\\[ \\mathbf{L}_G = \\sum_{i=1}^{3} I_{G,i} \\, \\Omega_i \\, e_i \\quad \\text{(12.41)} \\]\n\n- Rigid body: \n\\[ I_{G,i} = \\text{const} \\quad \\forall \\; i = 1, 2, 3 \\]\n\n- Time derivative of the angular momentum:\n\\[ \\frac{d \\mathbf{L}_G}{dt} = \\sum_{i=1}^{3} I_{G,i} \\, \\dot{\\Omega}_i \\, e_i + \\sum_{i=1}^{3} I_{G,i} \\, \\Omega_i \\, \\dot{e}_i \\]\n\n\\[ \\sum_{i=1}^{3} I_{G,i} \\, \\dot{\\Omega}_i \\, e_i + \\Omega \\times \\left( \\sum_{i=1}^{3} I_{G,i} \\, \\Omega_i \\, e_i \\right) \\quad \\text{(12.44)} \\]\n\n\\[ = \\frac{d \\mathbf{L}_G}{dt} = \\dot{\\mathbf{L}}_G  \\]\n\n- Particular case: \n\\[ \\dot{\\Omega}_1 = \\dot{\\Omega}_2 = \\dot{\\Omega}_3 = 0 \\]\n\n\\[ \\dot{\\mathbf{L}}_G = \\Omega \\times \\mathbf{L}_G \\quad \\text{(12.45)} \\]",
    "\u2022 General case:\n\\[\n\\frac{d \\mathbf{L}_G}{dt} = I_{G,1} \\dot{\\Omega}_1 e_1 + I_{G,2} \\dot{\\Omega}_2 e_2 + I_{G,3} \\dot{\\Omega}_3 e_3\n\\]\n\\[\n+ (\\Omega_1 e_1 + \\Omega_2 e_2 + \\Omega_3 e_3) \\times (I_{G,1} \\Omega_1 e_1 + I_{G,2} \\Omega_2 e_2 + I_{G,3} \\Omega_3 e_3)\n\\]\n\\[\n= I_{G,1} \\dot{\\Omega}_1 e_1 + I_{G,2} \\dot{\\Omega}_2 e_2 + I_{G,3} \\dot{\\Omega}_3 e_3 + (\\Omega_1 e_1 + \\Omega_2 e_2 + \\Omega_3 e_3) \\times (I_{G,3} \\Omega_3 e_2 - I_{G,2} \\Omega_2 e_1) + (I_{G,1} - I_{G,3}) \\Omega_1 \\Omega_3 e_2 + (I_{G,2} - I_{G,1}) \\Omega_2 \\Omega_1 e_3 \\quad \\text{(12.46)}\n\\]\n\n\u2022 Net external torque:\n\\[\n\\tau^{\\text{ext}}_G = \\tau^{\\text{ext}}_{G,1} e_1 + \\tau^{\\text{ext}}_{G,2} e_2 + \\tau^{\\text{ext}}_{G,3} e_3 \\quad \\text{(12.47)}\n\\]",
    "- Time derivative of angular momentum:\n\\[\n\\frac{d \\mathbf{L}_G}{dt} = I_{G,1} \\dot{\\Omega}_1 \\mathbf{e}_1 + I_{G,2} \\dot{\\Omega}_2 \\mathbf{e}_2 + I_{G,3} \\dot{\\Omega}_3 \\mathbf{e}_3 + (I_{G,3} - I_{G,2}) \\Omega_2 \\Omega_3 \\mathbf{e}_1 + (I_{G,1} - I_{G,3}) \\Omega_1 \\Omega_3 \\mathbf{e}_2 + (I_{G,2} - I_{G,1}) \\Omega_1 \\Omega_2 \\mathbf{e}_3\n\\]\n(12.46)\n\n- Net external torque:\n\\[\n\\boldsymbol{\\tau}_G^{\\text{ext}} = \\tau_{G,1}^{\\text{ext}} \\mathbf{e}_1 + \\tau_{G,2}^{\\text{ext}} \\mathbf{e}_2 + \\tau_{G,3}^{\\text{ext}} \\mathbf{e}_3\n\\]\n(12.47)\n\n- Angular momentum theorem:\n\\[\n\\boldsymbol{\\tau}_G^{\\text{ext}} = \\frac{d \\mathbf{L}_G}{dt}\n\\]\n(12.27)\n\n- Euler equations:\n\\[\n\\tau_{G,1}^{\\text{ext}} = I_{G,1} \\dot{\\Omega}_1 + (I_{G,3} - I_{G,2}) \\Omega_2 \\Omega_3\n\\]\n\\[\n\\tau_{G,2}^{\\text{ext}} = I_{G,2} \\dot{\\Omega}_2 + (I_{G,1} - I_{G,3}) \\Omega_1 \\Omega_3\n\\]\n\\[\n\\tau_{G,3}^{\\text{ext}} = I_{G,3} \\dot{\\Omega}_3 + (I_{G,2} - I_{G,1}) \\Omega_1 \\Omega_2\n\\]\n(12.48)",
    "Solutions to Problem Set 10\nCollisions\nPHYS-101(en)\n\n1. A collision\n\nIn an elastic collision, both the mechanical energy and momentum are conserved. Conservation of momentum in one dimension is\n\n$$m_1 v_{1i} + m_2 v_{2i} = m_1 v_{1f} + m_2 v_{2f}$$\n$(1)$\n\nwhere the subscripts $i$ and $f$ indicate the state just before and just after the collision respectively and the subscripts $1$ and $2$ indicate the first or second ball respectively. Since the first ball has an initial speed of $v_{1i} = v$ and the second ball starts at rest $v_{2i} = 0$, equation $(1)$ becomes\n\n$$m_1 v = m_1 v_{1f} + m_2 v_{2f}$$\n$(2)$\n\nSolving this equation for the final velocity of the first ball gives\n\n$$v_{1f} = \\frac{m_1 v - m_2 v_{2f}}{m_1}$$\n$(3)$\n\nWe chose to solve for $v_{1f}$ rather than $v_{2f}$ because we are searching for $v_{2f}$ and substituting equation $(3)$ into the conservation of energy equation will allow us to eliminate $v_{1f}$. \n\nSince the collision is elastic, making it conservative, we consider the collision and we can write\n\n$$\\frac{1}{2} m_1 v_{1i}^2 + \\frac{1}{2} m_2 v_{2i}^2 = \\frac{1}{2} m_1 v_{1f}^2 + \\frac{1}{2} m_2 v_{2f}^2$$\n$(4)$\n\nGiven the initial velocities of the balls, this becomes\n\n$$\\frac{1}{2} m_1 v^2 = \\frac{1}{2} m_1 v_{1f}^2 + \\frac{1}{2} m_2 v_{2f}^2$$\n$(5)$\n\nSubstituting equation $(3)$ into equation $(5)$ allows us to eliminate $v_{1f}$ and gives\n\n$$\\frac{1}{2} m_1 v^2 = \\frac{1}{2} m_1 \\left( \\frac{m_1 v - m_2 v_{2f}}{m_1} \\right)^2 + \\frac{1}{2} m_2 v_{2f}^2$$\n$$\\frac{1}{2} m_1 v^2 = \\frac{1}{2 m_1} \\left( m_1^2 v^2 - 2 m_1 m_2 v v_{2f} + m_2^2 v_{2f}^2 \\right) + \\frac{1}{2} m_2 v_{2f}^2$$\n$$m_1 v^2 = \\frac{1}{m_1} \\left( m_1^2 v^2 - 2 m_1 m_2 v v_{2f} + m_2^2 v_{2f}^2 \\right) + m_2 v_{2f}^2$$\n$$m_1 v^2 = m_1 v^2 - 2 m_2 v v_{2f} + \\frac{m_2^2 v_{2f}^2}{m_1} + m_2 v_{2f}^2$$\n$$0 = -2 m_2 v v_{2f} + \\frac{m_2^2 v_{2f}^2}{m_1} + m_2 v_{2f}^2$$\n$$0 = -2 m_2 v v_{2f} + v_{2f}^2 \\left( \\frac{m_2^2}{m_1} + m_2 \\right)$$\n$$2 m_2 v v_{2f} = v_{2f}^2 \\left( \\frac{m_2^2 + m_1 m_2}{m_1} \\right)$$\n$$2 m_1 m_2 v = v_{2f} \\left( m_2^2 + m_1 m_2 \\right)$$\n$$ v_{2f} = \\frac{2 m_1 m_2 v}{m_2 (m_2 + m_1)} $$\n$$v_{2f} = \\frac{2 m_1 v}{m_1 + m_2}$$\n$(11)$\n\n$$ \\boxed{}$$",
    "To calculate the maximum height attained by the second ball after the collision, we can use conservation of mechanical energy. Since there are no non-conservative forces acting on it, we have\n\n\\[ K_{e,f} + U_{f} = K_{e,max} + U_{max} \\tag{12} \\]\n\nwhere \\( K_{e,max} \\) and \\( U_{max} \\) are the kinetic and gravitational potential energies at the maximum height. Given that it is at the maximum height, we note that \\( K_{e,max} = 0 \\). Additionally, let\u2019s take the bottom of the hill as the gravitational potential to be 0 for the height of the collision. Thus, the right side of equation (12) reduces to \\( U_{max} \\):\n\n\\[ K_{e,f} + 0 = 0 + U_{max} \\quad \\Rightarrow \\quad K_{e,f} = U_{max} \\tag{13} \\]\n\nSubstituting equations (11) plus (8),\n\n\\[ U_{max} = \\frac{1}{2} \\frac{m_1^2}{(m_1+m_2)} g r = m_2 g h_{\\text{max}} \\quad \\Rightarrow \\quad h_{\\text{max}} = \\frac{m_1^2}{2 (m_1 + m_2)^2} r \\tag{14} \\]\n\nPlugging in numbers, we find that\n\n\\[ h_{\\text{max}} = \\frac{(2)^2}{2 (2 + 1)^2} (3) = \\frac{4}{2 \\cdot 9}(3) = \\frac{4}{18}(3) = \\frac{2}{3} = 0.22 \\, \\text{m} \\tag{15} \\]\n\nIt is clear that momentum is not conserved, but mechanical energy is not lost. Thus, equation (12) still holds. Here, we need to also take into account the energy before the collision. We know that\n\n\\[ K_{i_1} = \\frac{1}{2} m_1 v_{i}^{2} + \\frac{1}{2} m_2 v_{i}^{2} = \\frac{1}{2} m_1 v_{i}^{2} \\]\n\nwhere the kinetic energy is converted wholly by the collision (due to the new conservative frictional forces) into rotational energy (and height, therefore it is separately obtained).\n\nWe then have\n\n\\[ K_{i_1} = U_{\\text{max}} = \\frac{1}{2} m_1 v_{i}^{2} = \\left(m_1 g h_{\\text{max}} \\right) \\quad h_{\\text{max}} = \\frac{1}{2} \\frac{m_1}{(m_1 + m_2)} r \\tag{16} \\]\n\nLet the combined object with mass \\( m_i \\) be the ball before hit. We define the reference point as \\( z_0 \\) rather than \\( U_{\\max} \\) on the bottom.\n\n\\[ K_i + U_0 = U_{\\max} \\]\n\n\\[ K_i = \\frac{1}{2} m_1 v_i^2 \\quad U_{\\max} = U_{\\max} \\]\n\nSubstituting equations (10) powering,\n\n\\[ h_{\\text{max}} = \\frac{1}{2} \\frac{m_1}{(m_1 + m_2)} r \\tag{19} \\]\n\nPlugging in numbers,\n\n\\[ h_{\\text{max}} = 0.56 \\, \\text{m} \\tag{20} \\]\n\nwhich is a factor of 4 lower than the first instance collision. This is due to the negative work that occurs between forces on the system during the isolated collision. Ultimately, this lost energy becomes heat.",
    "2. Bouncing balls\n\nFor this problem, we will decompose the situation into four successive parts: the projectile motion of the descent, then the collision between ball 1 and the ground, then the collision between ball 1 and ball 2, and finally the projectile motion of the ascent.\n\n1.a) Projectile motion of the descent. Before the first collision, both balls experience projectile motion. By conservation of mechanical energy during the entire fall, we have \n\\[\nm v_1 = 0 = m g \\left( h + H \\right) \\quad \\Rightarrow \\quad v_{1,0} = \\sqrt{2 g \\left( h + H \\right) }\n\\]\n(1)\nin\nv_{2,0} = \\sqrt{2 g h}\n(2)\n\nwhere we will define \\( y = 0 \\) to be the ground and \\( h \\) to point upwards, as shown in the problem statement. Solving both equations (1) and (2) for the velocity just before impact with the ground, \nv_{1,0} = \\sqrt{2g(h+H) }\nv_{2,0} = \\sqrt{2 g h}\nremark that it is the same for both balls (which is expected as we know that objects fall the same rate in a vacuum). We have also provided the expressions in a more compact form using an implicit understanding of y = 0 as the starting point for the reference for \\( y \\). Note here that ball 2 is initially dropped from rest and ball 1 is initially launched upward with some initial velocity before experiencing projectile motion. We have the initial state so that the initial quantities v_0 and H are incoming data with a result of collision. Labelling this point as the fixed initial system, we speed up by writing situation as a combination of potential as well as a beautiful engraving where potential U moving kinetic terms are states from here,\n\nwe choose the starting E defines on v_0 which means our linear up Figure which never takes a laboratory preferred system; however, on the other form the value of energy out. system is a final velocity of these terms where a periodic image of action console types\n\nSince the collision is elastic, we thus have conservation of mechanical energy\n\\[\n\\frac{m}{2} v_1^2 + m g y_1 = M g \\eta_1 + \\frac{M \\eta_1^2}{2} + \\frac{m \\eta_2^2}{2}\n\\]\n(4) \n\n\\[( m v_{1,1}^2 ) + 2 m = 2M g_{1 f}^2 = M_r (v_{sub}\\cdot r)^2\n\\]\n\n Substituting equation (3) shows that\n\\[\n\\eta_1 = \n\t\\frac{2 m^2 + M - m \\left( {h + \\eta_1} \n\\]\n(5)\nsince \n\t\\frac{4}{3} + \\sqrt{m \\left( \\eta_1 + r_1 \\cdots m_{-1}} {h}\n\\]\n Hence the ratio is simply that since takes the rest substitution we have\n\t\\right) } }\nFinally note that the right side of Eq. (5) contains the same constants as Eq. (5) , but the left-hand side does not. Set the variable to these constants; the final ratio shows\n\nAfter substituting Eq. (3), we have the two next equations (7) and the previous as indices that are with the same approximation in angle. The other equation can be seen to be\n\\[\nh = H \\left( m_{sup_2} + \\cdot r_1 \\left( g + H - r\\right) \n\\]\n\nCollision between ball 1 and ball 2: Now we have both balls colliding just after the first descent. We derived the general formula for the velocities that result from an elastic collision between two balls. We derived the general formula for the velocities that result from an elastic collision between two balls:\n\n",
    "objects in our discussion. This derivation was streamlined to minimize the math, but was not intuitive. You are free to simply use this formula we found. Here we present a more intuitive derivation that, as\na result, is considerably more messy (even for the case considered here of identical initial speeds). Enforcing conservation of momentum and using the final velocities from the previous part gives\n$$\nm_1 v_{1i} + m_2 v_{2i} = m_1 v_{1f} y + m_2 v_{2f y}\n$$\n$$\nm_1 v_{1i} + m_2 v_{2i} = m_1 v_{1f x} + m_2 v_{2f x}\n$$\nSince the collision is elastic, we enforce conservation of mechanical energy\n$$\n\\frac{1}{2} m_1 v_{1i x}^2 + \\frac{1}{2} m_1 v_{1i y}^2 + \\frac{1}{2} m_2 v_{2i x}^2 + \\frac{1}{2} m_2 v_{2i y}^2 = \\frac{1}{2} m_1 v_{1f y}^2 + \\frac{1}{2} m_1 v_{1f x}^2 + \\frac{1}{2} m_2 v_{2f x}^2 + \\frac{1}{2} m_2 v_{2f y}^2\n$$\nSubstituting equations (8) and simplifying produces\n$$\n\\frac{1}{2} m_1 v_{1i x}^2 = \\frac{1}{2} m_1 v_{1f y}^2 + \\frac{1}{2} m_2 v_{2f y}^2\n$$\n$$\n\\frac{1}{2} m_1 v_{1i y}^2 + \\frac{1}{2} m_2 v_{2i y}^2 = \\frac{1}{2} m_1 v_{1f y}^2 + \\frac{1}{2} m_2 v_{2f y}^2\n$$\nCombining these equations with\n$$\nv_{2f x} = \\frac{m_1}{m_1 + m_2} v_{1i y} + (1 - \\frac{m_1}{m_1 + m_2} m_{2i x}) = \\frac{m_1}{m_1 + m_2} v_{1i x}\n$$\nand\n$$\nv_{2f y} = \\frac{m_1}{m_1 + m_2} v_{1i y} + (1 - \\frac{m_1}{m_1 + m_2} m_{2i y}) = \\frac{m_1}{m_1 + m_2} v_{1i y}\n$$\nin more compact notation, these equations give\n$$\nv_{2i y} = v_{1i y} = 0\n$$\nApplying the quadratic formula gives\n$$\nv_{1fy} = \\pm \\left(\\sqrt{(m_1 - m_2)^2(4 m_1 m_2)} = (4 m_1 m_2 v_{1i x})(v_{1i y} - v_{2i y})\\sqrt{\\left(\\frac{m_1}{m_1 + m_2} v_{1iy}}\n$$\nWe see that for symmetrical mass we have \\( m_1 = m_2) with initial relative velocity of\n$$\nv_{1i y} = 0 \\rightarrow v_{1f y} = \\left(\\pm \\frac{v_{1i x}}{4 m_1m_2 \\sqrt{(m_1- m_2)^2}} =0 \\right) v_{1i y}\n$$\nso that ball 1 continues on completely unaffected, while ball 2 ends up with all of particle 1's initial speed, in the \\( y \\) direction:\nLetting this result be played with, noting that since \\(v_{2i} = 0 \\)\n$$\nv_{1fy} = 0 = \\left(\\frac{m_1}{m_1i - m_2^{2 i}) y \\left = v_{1ix}} - v_{1iy} y^{i}\n$$\nin other words $v_{1fy},_{\\left(\\sqrt{(m_1 - m_2)^2}\\right)}^4 =  = (m_1 - m_2) y = v_{1i y})$\n$$\nv_{1fy x = \\sqrt{\\pm m_1 v_{1i} - \\left(\\frac{m_2 \\sqrt{4 m_1 m_2My) (m_1 P^2}{m_1)}}\n$$\n$$\n\\therefore \\rightarrow y \\left(v_1X = \\frac{m_1 y = V_{1i}}- v_{1iy}\\right(\\frac{(M1)  y_i( \\frac{v_{1i}}{2}=)\n$$\nusing equation (7):\n$$\nV_{2f x y} = \\left(\\frac{m_1^{2 v_1}}{m_1}m{\\right)} ( v_{1i}  ={2}) = v_{1i-y} \\rightarrow\n$$\nIn order for both balls to bounce off the ground upwards we require that\n$$\n vfj >0  and y_2}>0 = (21)\n$$",
    "Using equations (17) and (20), this gives the conditions that \n\n\\[ m_1 > 3m_2 \\quad \\text{and} \\quad 3m_2 > m_3 \\tag{22} \\]\n\nrespectively. If the first is satisfied, the second will also be. For all three balls to bounce upwards we require that\n\n\\[ m_1 > 3m_3. \\tag{23} \\]\n\n1.c) Ball 1 will fly again to its max-height on the ground if \\( V_1 > 0 \\). From equation (20), we have that \n\n\\[ m_1 > 3m_2. \\]\n\nIf \\( m_1 > 3m_2 \\), the first ball will travel downwards and collide with the ground again.\n\n1.d) Projectile motion of the ascent: After the balls collide, they have vertical velocities of \\( v_1 \\), \\( v_2 \\), \\( v_3 \\) as before. But from eq. equations (17), these values are\n\n\\[ V_1 = \\frac{2m_2(g)}{m_1} = \\frac{2m_3(g)}{m_2(m_1)}. \\]\n\nThere are no non-conservative forces, so we can apply conservation of mechanical energy. In simplifying notation, we'll have to factor since and we can define the reference point for the gravitational potential energy to be on the ground, hence\n\n\\[ E = E_{\\text{pot}} + E_{\\text{kinetic}} = \\frac{1}{2}mU_y^2 + mgh. \\tag{25} \\]\n\nSubstituting equations (2) and (23) gives the final measure of\n\n\\[ h = \\frac{(2m_2U_y)}{m_1h_{\\text{system}}}. \\]\n\n2.a) The projectile motion of the descent and the collision between ball 1 and the ground remains constant.\nCollision between ball 1 and ball 2: The difference only arises when the system is subjected to external forces. We have symmetric collision: energy and momentum.\nProjectile motion of the first ball: We define \\( m_1U^{\\perp} \\equiv 2m_2(2y \\cdot ay) = V_y, \\)\nWhere we only have the final terms that work together. \\( \\vec{p} = \\vec{p}_{1\\perp y} = \\vec{p} = mv + mv'[2], \\)\nHence, a simple substitution:\n\n\\[ \\beta = \\frac{q}{m_1 + m_2 \\cdot \\gamma_v}. \\]\n\nSubstituting equations \\((1/2)\\) gives the final answer of:\n\n\\[ q_y = \\frac{m_1 v_s}{m_{\\text{system}}}, \\cdot d_y. \\]\n\n2.b) For the two balls to go upwards, the final velocity \\( v > 0 \\) must be positive. Using equation \\((28)\\), we need\n\n\\[ m_1 \\left( m_3 > 2m_2 \\right). \\]\n\nFor this \"\\(\\phi \\)\" must hold, on the grounds of \\( \\left[ \\frac{\\perp}{2m_2} \\right] \\). From equation \\((29)\\), we see that the third will acquire atmosphere. Newton's third law,\n\n\\[ q_y \\neq q + r - E_{y1}(E_{\\text{balls}} \\cdot l_y). \\]\n\nSince the two balls undergo projectile motion after the collision, we can apply conservation of energy by factoring the up and down multiplier. The conserv. momentum:\n\n\\[ p_{\\text{final}} = (m_1 + m_2) \\eq_{y + 2U} \\]\n\n\\[ u_t(l) = 0. \\]\n\n\\[ q_y t - \\beta - d_y(l + m_3) = (1 \\cdot m_3h_{\\text{system}}). \\tag{30} \\]",
    "Substituting equation (29) gives the final answer of \n\\[ \\frac{v_1}{v_2} = \\frac{m_2}{m_1}. \\tag{31} \\]\n\n3. Damped cannon\n\nAs a result of the explosion, the entire cannon moves backwards and the spring compresses. The energy of this system is composed of kinetic $E_k$ and spring potential energy $E_p$. We will ignore any small drag in the movement of the cannon, thereby neglecting the gravitational potential energy $E_g$. Given that energy is always conserved, we have\n\\[ K_{t_i} + U_{t_i} = K_{t_f} + U_{t_f} \\tag{1} \\]\nWe will take the initial state to be just before the damage caused by the explosion, when the cannon is moving at maximum speed $V_0$ to the left, the spring is still in its equilibrium position, for the final state, we take a hypothetical condition in which the spring is maximum displaced and the cannon has temporarily come to rest. The equation (1) then becomes\n\\[ M \\frac{V_0^2}{2} + 0 = 0 + \\frac{K A^2}{2} \\Rightarrow A^2 = \\frac{MV_0^2}{K}. \\tag{2} \\]\nUnfortunately, we need to know the initial speed of the cannon $V_0$. To find this, we must use the information given in the problem statement about the dynamics of the cannonball. To relate the speed $V_0$ of the cannon to that of the cannonball, we consider the conservation of linear momentum p and consider the initial system to consist of the cannon and a cannonball of mass $m$, moving together with speed $V_i$ and total system mass $M + m$. Then,\n\\[ (M + m) V_i = MV_0 + mV_E \\Rightarrow V_0 = \\frac{(M + m) V_i - mV_E}{M}. \\tag{3} \\]\nwhere $V_i$ is the initial velocity of the cannonball and the direction is defined in the diagram above. Substituting this into equation (2) yields\n\\[ A^2 = \\frac{M}{K} \\left( \\frac{(M + m) V_i - mV_E}{M} \\right)^2. \\tag{4} \\]",
    "To find the velocity $v_0$, we can use the equations of projectile motion\n\n\\[\nx(t) = t v_0 \\cos \\theta\n\\]\n\\[\ny(t) = -\\frac{1}{2}gt^2 + t v_0 \\sin \\theta + y_0\n\\]\n\nwhere we have defined a Cartesian coordinate system as shown in the diagram above. We will define the origin of the coordinate system to be the cannon, such that the cannonball is at $x=0$ and $y=0$ when $t=0$, and thus $y_0=0$. Given the coordinate system and the problem statement, we know that $x_C = v_0 \\cos \\theta$ and $y_C = v_0 \\sin \\theta$. Thus, equations (5) and (6) become\n\n\\[\nx(t) = tv_0 \\cos \\theta\n\\]\n\\[\ny(t) = -\\frac{1}{2}gt^2 + tv_0 \\sin \\theta\n\\]\n\nAt some time $t=t_f$, we know that the cannonball will land at the location\n\n\\[\nx(t_f) = \\frac{D}{2} = t_f v_0 \\cos \\theta\n\\]\n\\[\ny(t_f) = 0 = t_f v_0 \\sin \\theta - \\frac{1}{2}gt_f^2\n\\]\n\nEquating equations (9) and (10) gives\n\n\\[\nt_f = \\frac{D}{2 v_0 \\cos \\theta}\n\\]\n\nSubstituting this into equation (10) gives\n\n\\[\n0 = \\frac{D}{2} \\tan \\theta - \\frac{g}{2} \\left( \\frac{D}{2 v_0 \\cos \\theta} \\right)^2\n\\]\n\nwhich simplifies to\n\n\\[\nv_0 = \\sqrt{ \\frac{gD}{2 \\cos^2 \\theta \\tan \\theta} } = \\sqrt{ \\frac{gD}{2 \\sin \\theta \\cos \\theta} } = \\sqrt{ \\frac{gD}{2 \\sin 2\\theta} }\n\\]\n\nPlugging in the numerical values from the problem statement gives\n\n\\[\nv_0 = \\sqrt{ \\frac{(10 \\, m/s^2)(1000 \\, m)}{2 \\sin 45^\\circ} } = \\sqrt{ \\frac{10000}{2 \\cdot \\frac{\\sqrt{2}}{2}} } = 100 \\, m/s\n\\]\n\nwhere we used that $M = 10 \\, tons = 10^4 \\, kg$.\n\n2. The total energy delivered by the explosion will be the energy imparted to the cannon and the cannonball such that the velocity of the cannonball is twice the velocity of the cannon. By conservation of momentum, the cannonball is moving with speed $2v$ and mass $M=10^4 \\, kg$, while the cannon is moving with speed $v$ and mass $2M$. The total energy is then\n\n\\[\nK_{total} = \\frac{1}{2} 2M v^2 + \\frac{1}{2} \\left( M \\left( 2v \\right)^2 \\right) = 2Mv^2\n\\]\n\nPlugging in numerical values (including equation (13)) gives\n\n\\[\nK_{total} = 2 \\times 10^7 \\, J\n\\]",
    "1. The initial speed of the projectile is equal to the magnitude of its escape velocity. Given the definition of escape velocity, this can be found from the condition that\n\n\\[ K_i + U_i = 0, \\]\n\nwhere the subscript $i$ indicates the initial value and $U_i$ indicates the general gravitational potential which is distinct from the gravitational potential between two small objects. We can calculate $U(r)$ from the form of the gravitational force field (in spherical form) $F(r)$:\n\n\\[ F(r) = - \\frac{GMm}{r^2}. \\]\n\nChoosing to use a spherical coordinate system, the change in the potential energy $r \\to \u221e$ due to the force $F(r)$ is \n\n\\[ \\Delta U = U(r \\rightarrow \\infty) - U(r) = \\int_{r}^{\\infty} F(r') \\, dr' = - \\int_{r}^{\\infty} \\frac{GMm}{r'^2} \\, dr' = \\left[ \\frac{GMm}{r'} \\right]_{r}^{\\infty} = - \\left(\\frac{GMm}{\\infty} - \\frac{GMm}{r} \\right) = - \\left( 0 - \\frac{GMm}{r} \\right) = \\frac{GMm}{r} \\]\n\nwhere the integration path $r' \\; dr'$ may path from $r$ to $r = \\infty$. However, we see that, in fact, the force is purely radial, only the change in radius counts. Thus, we can write\n\n\\[ \\Delta U = \\frac{GMm}{r}. \\]\n\nTaking the integral gives a potential energy difference of\n\n\\[ \\Delta U = U(\\infty) - U(r) = 0 - \\left( - \\frac{GMm}{r} \\right) = \\frac{GMm}{r}. \\]\n\nSince the reference point for the potential energy is $U_r = 0$, we define the potential energy such that $U(r) = 0$, the potential energy (5) becomes\n\n\\[ U(r) = -\\frac{GMm}{r}. \\]\n\nSubstituting this into equation (1) allows us to find the initial speed of the projectile when it is launched from\n\n\\[ K_i = -U_i \\rightarrow \\frac{1}{2} m v_{esc}^2 = \\frac{GMm}{R} \\rightarrow v_{esc} = \\sqrt{\\frac{2GM}{R}} \\]\n\nwhere $R = R_e$ is the initial position.\n\n2. Since all the forces are conservative, mechanical energy is conserved and we can have\n\n\\[ \\Delta K + U = K_{after} + \\Delta U = 0, \\quad K_{before} + U_{before} = 0. \\]\n\nwhere kinetic energy is zero right before the collision. Therefore, we can use equation (1) to obtain \n\n\\[ 0 + U_{before} = K_{before} + \\Delta U  \\rightarrow -\\frac{GMm}{R} = 0 + \\Delta U \\rightarrow \\Delta U = -\\frac{GMm}{R}. \\]\n\nIn this position, the final kinetic energy conservation equation is\n\n\\[ \\Delta K + \\Delta U = 0 \\rightarrow K + \\Delta U = \\frac{1}{2} m v_{after}^2 - \\frac{GM m}{2 R} = 0 \\rightarrow v_{after} = v_{esc} / 2. \\]\n\nat the location just before the collision $R = 2 R_e$.",
    "3. Drawing a free body diagram for the satellite and using the gravitational force is given by equation (2), we see that Newton's second law in the r direction is\n\n$$ \\frac{mv^2}{R_h} = \\frac{GMm}{R_h^2} $$\n\n(10)\n\nwhere we have used the form of the centripetal acceleration and v_h is the speed of the satellite. Solving this equation for the speed gives\n\n$$ v_h = \\sqrt{\\frac{GM}{R_h}} = \\sqrt{\\frac{gR_E^2}{R_h}} $$\n\n(11)\n\n4. Given the the collision happens quickly, we can use the impulse approximation to ignore the effect of gravity during the collision. Momentum is conserved in the r direction as\n\n$$ m_iv_{r,i} + m_e 0 = (m_i + m_e)v_{r,f} \\quad \\Rightarrow \\quad v_{r,f} = \\frac{m_iv_{r,i}}{m_i + m_e}, $$\n\n(12)\n\nwhere the subscript i indicates the projectile, the subscript e indicates the satellite, the subscript r indicates the radial component of the velocity, and the subscripts i and f indicate times before and after the collision. Since the satellite is very massive and the objects stick together, the final transverse component of the velocity changes the least, so we can say $v_{T,f} \\approx v_{T,i}$.\n\nWe will adopt a polar coordinate system, such that the projectile is moving in the r direction before the collision. This tells us that $v_{r,i} = v_p$, $v_{T,i} = 0$. After the collision:\n$$ v_{r,f} = \\frac{m_iv_p}{m_i + m_e}, \\quad v_{T,f} = v_h $$\nWe assume a perfectly inelastic collision and an infinitesimally small projectile which leads us to $m_i \\ll m_e$. Using the binomial approximation and equation (13) to write an expression for the final velocity of the satellite and projectile after the collision\n\n$$ v_f = \\sqrt{v_{r,f}^2 + v_{T,f}^2} = \\sqrt{\\left( \\frac{m_i}{m_i + m_e}v_p \\right)^2 + v_h^2} \\approx \\sqrt{\\left( \\frac{m_i}{m_e}v_p\\right)^2 + v_h^2}. $$\n\nTo get the speed, we simply take the magnitude according to\n\n$$ v_f = \\sqrt{ v_h^2 \\left(1 + \\left( \\frac{m_iv_p}{m_ev_h}\\right)^2} = v_h\\sqrt{1 + \\frac{m_i^2v_p^2}{m_e^2}\\frac{R_h}{GM}} \\approx v_h \\left( 1 + \\frac{1}{2} \\left( \\frac{m_iv_p}{m_ev_h}\\right)^2\\right)\n = \\sqrt{\\frac{GM}{R_h}} = \\sqrt{\\frac{gR_E^2}{R_h}} \\left(1 + \\frac{1}{2}\\frac{m_ix^2}{GM} \\right). $$\n\n5. Stream bouncing off a wall\n\nWe start by considering a single particle as it collides with the surface. The change in its momentum due to the collision is\n\n$$ \\Delta \\vec{p} = \\vec{p}_{\\text {after}} - \\vec{p}_{\\text {before}} = - p_x \\hat{i} - p_y \\hat{j} - (p_x \\hat{i} - p_y \\hat{j} ) = - 2p_x \\hat{i} $$\n\nwhere we have defined the x direction to point into the wall. This change in momentum is related to the force of the wall on the particle F_wall through the impulse relationship:\n\n$$\n\n\\Delta \\vec{p} = \\int_{t_i}^{t_f} \\vec{F}_{\\text {wall}} dt. $$",
    "Since we only care about the average force (and not the details about how it changes with time), we can model the impulse as an average force applied over the same time interval according to\n\n\\[\nI = \\int_{t_{i}}^{t+f} F_{x}(t')dt' = \\overline{F_{x}} \\Delta t\n\\]\n\nwhere the time interval $\\Delta t = t_f - t_i$ is the time between successive particles hitting the wall. This time interval $\\Delta t$ is straightforward to calculate as the particles are a distance d apart and travel at a constant velocity of $\\vec{v}$. This immediately also gives us $n$, the time before the next one hits will be equal to the time it takes a particle to travel a distance $d$. This gives\n\n\\[\n\\Delta t = \\frac{d}{v} \\quad \\Rightarrow \\quad v = \\frac{d}{\\Delta t}\n\\]\n\nSubstituting equations (1), (3), and (4) into equation (2) gives\n\n\\[\n-\\frac{2mv}{\\Delta t} = \\overline{F_{x}} \\quad \\Rightarrow \\quad \\overline{F_{x}} = \\frac{-2mv}{\\Delta t}\n\\]\n\nBy Newton's third law, the force exerted by the wall on the particles has the same magnitude as the force of the particles on the wall. Thus, we find that\n\n\\[\nF_{wall} = \\frac{2mv}{\\Delta t}\n\\]",
    "Queries with For\n\nPrinciples of Functional Programming",
    "The for notation is essentially equivalent to the common operations of query languages for databases.\n\nExample: Suppose that we have a database books, represented as a list of books.\n\n\\[\n\\text{case class Book(title: String, authors: List[String])}\n\\]",
    "val books: List[Book] = List(\n  Book(title = \"Structure and Interpretation of Computer Programs\",\n    authors = List(\"Abelson, Harold\", \"Sussman, Gerald J.\")),\n  Book(title = \"Introduction to Functional Programming\",\n    authors = List(\"Bird, Richard\", \"Wadler, Phil\")),\n  Book(title = \"Effective Java\",\n    authors = List(\"Bloch, Joshua\")),\n  Book(title = \"Java Puzzlers\",\n    authors = List(\"Bloch, Joshua\", \"Gafter, Neal\")),\n  Book(title = \"Programming in Scala\",\n    authors = List(\"Odersky, Martin\", \"Spoon, Lex\", \"Venners, Bill\")))",
    "Some Queries\n\nTo find the titles of books whose author's name is \u201cBird\u201d:\n\nfor\n    b <- books\n    a <- b.authors\n    if a.startsWith(\"Bird,\")\nyield b.title\n\nTo find all the books which have the word \"Program\" in the title:\n\nfor b <- books if b.title.indexOf(\"Program\") >= 0\nyield b.title",
    "Another Query\n\nTo find the names of all authors who have written at least two books present in the database.\n\nfor\n    b1 <- books\n    b2 <- books\n    if b1 != b2\n        a1 <- b1.authors\n        a2 <- b2.authors\n        if a1 == a2\n            yield a1\n\nWhy do solutions show up twice?\n\nHow can we avoid this?",
    "To find the names of all authors who have written at least two books present in the database.\n\nfor\n  b1 <- books\n  b2 <- books\n  if b1.title < b2.title        impose lexicographical comparison of titles.\n  a1 <- b1.authors\n  a2 <- b2.authors\n  if a1 == a2\n  yield a1",
    "Problem\n\nWhat happens if an author has published three books?\n\n0 The author is printed once\n0 The author is printed twice\nX The author is printed three times\n0 The author is not printed at all",
    "Solution: We must remove duplicate authors who are in the results list twice.\n\nThis is achieved using the distinct method on sequences:\n\nval repeated =\n  for\n    b1 <- books\n    b2 <- books\n    if b1.title < b2.title\n      a1 <- b1.authors\n      a2 <- b2.authors\n      if a1 == a2\n  yield a1\nrepeated.distinct",
    "Better alternative: Compute with sets instead of sequences:\n\n\\[\\text{val bookSet = books.toSet}\\]\n\n\\[\\text{for}\\]\n\\[\\quad b1 \\leftarrow \\text{bookSet}\\]\n\\[\\quad b2 \\leftarrow \\text{bookSet}\\]\n\\[\\text{if}\\ b1 \\neq b2\\]\n\\[\\quad a1 \\leftarrow b1.authors\\]\n\\[\\quad a2 \\leftarrow b2.authors\\]\n\\[\\text{if}\\ a1 == a2\\]\n\\[\\quad \\text{yield}\\ a1\\]",
    "Exercise Session 10\n\nQUESTION 1\nFor this exercise, you are given the following ASTs representing an expression $expr$\n\n\\begin{lstlisting}\nenum BinOp:\n  case Plus\n  case Minus\n  case Times\n  case Div\n\nenum Expr:\n  case Cst(n: Int)\n  case Var(x: String) \n  case BinOp(op: BinOp, arg1: Expr, arg2: Expr)\n  case Let(x: String, aexpr: Expr, body: Expr)\n  case Cond(bcond: Boolean, arg1: Expr, arg2: Expr)\n\\end{lstlisting}\n\n\\begin{lstlisting}\n/* Environment context */\ntype Env = Map[String, Int]\n/* Reference Storage */\ntype Store = Map[String, Int]\n\n/* The Global Environment */\ntype GlobEnv = List[Expr]\n\\end{lstlisting}\n\n\\begin{lstlisting}\n/* Function call */\ndef FunCall(f: Expr, arg: Expr): Expr\n/* Function definition */\ndef FunDef(x: String, body: Expr): Expr\n\\end{lstlisting}\n\n\\begin{lstlisting}\ntype Value = Int\n\\end{lstlisting}\n\nOne has to implement a valid primitive operations that includes:\n\n\\begin{lstlisting}\ndef BinOp(op: BinOp, e1: Expr, e2: Expr): Expr = op match {\n  case Plus => BinOp(Plus, e1, e2)\n  case Minus => BinOp(Minus, e1, e2)\n  case Times => BinOp(Times, e1, e2)\n  case Div => BinOp(Div, e1, e2)\n}\n\\end{lstlisting}\n\nThe global environment is a sequence of \"name\" definition tuples of type $(String, Expr)$\n\nAll definitions can reference all names in the global environment.\n\nWhere for example one could define a division function div$ as follows:\n\n\\begin{lstlisting}\nval div = FunDef(\"x\",\n  FunDef(\"y\",\n    BinOp(Div,\n      FunPar(\"x\"),\n      FunPar(\"y\"))))\n\nval GlobEnv = Map(\"\" -> FunCall(\"div\", Name(\"x\")),\n  (\"\", FunCall(\"div\",\"y\"))\n\\end{lstlisting}\n\nYour task is to implement the greatest common divisor $gcd$ function in $expr$.\n\nHence in Scala the $gcd$ can be implemented as:\n\n\\begin{lstlisting}\ndef gcd(x: Int, y: Int) : Int = {\n  if (y == 0) x else gcd(y, x % y)\n}\n\\end{lstlisting}\n\nQUESTION 2\nFor this exercise, we will add lists to our language:\n\n\\begin{lstlisting}\nenum Expr:\n  case Var(x: String)\n  case CstI(n: Int)\n  case CstB(b: Boolean)\n  case CstL(lst: List[Expr])\n  case Add(e1: Expr, e2: Expr)\n  case If(e1: Expr, e2: Expr, e3: Expr)\n  case Let(x: String, e1: Expr, e2: Expr)\n  case Get(lst: Expr, idx: Expr)\n  case Cons(e1: Expr, e2: Expr)\n\\end{lstlisting}\n\nFor example, the following Scala program:\n\n\\begin{lstlisting}\nval x = Nil \nval y = List(1,2,3)\nval z = 5 :: x \n\\end{lstlisting}\n\nwould translate as:\n\n\\begin{lstlisting}\nLet(\"x\", CstL(Nil),\n  Let(\"y\", CstL(List(CstI(1), \n    CstI(2), CstI(3))),\n    Cons(CstI(5), Var(\"x\"))))",
    "Question 2.1: map\n\nYour task is to implement the map function in Expr.\n\nHint:\n\ndef map(l: List[E])(f: E => E): List[E] = \n  l match {\n    case Nil => Nil\n    case h :: t => f(h) :: map(t)(f)\n  }\n\nQuestion 2.2: foldLeft\n\nYour task is to implement the foldLeft function in Expr.\n\nHint:\n\ndef foldLeft(l: List[E])(z: E)(f: (E, E) => E): E = \n  l match {\n    case Nil => z\n    case h :: t => foldLeft(t)(f(z, h))(f)\n  }\n\nYour task is to implement the greatest common divisor (gcd) function in Expr.\n\n** TODO exercice 4b\n\nHint: in Scala the gcd can be implemented as\n\ndef gcd(a: Int, b: Int): Int =\n  if (b == 0) a else gcd(b, a%b)\n\nQUESTION 3\n\nFor this exercise, we will add writable cells to our language. Assume we have a global array of memory that can be indexed by int.\n\n``` expr\n# To read from position `i`\nreadMem: Int => Int\n\n# To write the value `x` in position `i` and then\n# return unit\nwriteMem: Int => Int => Unit  # or:\nwriteMem: Int => (Int => Unit)\n```\nYour task is to implement the CAS (compare and swap) function.\n\n``` expr\n# type definition:\nDef ArrayCell = 3  # 3 corresponds to `Expr`\n\ndef CAS(index: Int), (expected: Expr), (new: Expr): Int =\n  Def old: ArrayCell = readMem(index) in\n  Def b: Int =\n    if (Eq[old, expected])\n      writeMem(index, new)\uff1b 1\n    else\n      0\n  in b\n  #end\n```",
    "Question 2.1: map\n\nYour task is to implement the map function in Expr.\n\nHint:\n\n```\ndef map(f: List[Int] => Int => Int): List[Int] = \n  case Nil => Nil\n  case x :: xs => f(x) :: map(f)(xs)\n```\n\n```\nmap => Fun(\"f\", \n  Fun(\"e\", \n    Match(Name(\"e\"), \n      EmptyList, \n      rhs, \n      Call(Name(\"f\"), Name(\"x\")), \n      Call(Name(\"map\"), \n        Name(\"f\")\n        Name(\"xs\")\n        NewCons(\n          Call(Name(\"f\"), \n          Name(\"x\")),\n          Call(Name(\"map\")\n            Name(\"f\"), \n            Name(\"xs\"))))))\n    )  \n  )\n)\n```\n\nQuestion 2.2: foldleft\n\nYour task is to implement the foldleft function in Expr.\n\nHint:\n\n```\ndef foldleft(ls: List[Int])(acc: Int)(f: Int, Int) => Int): Int = \n  ls => acc match\n      case Nil => acc\n      case x :: xs => foldleft(xs)(f(acc, x))(f)\n```\n\n```\nfoldleft => Fun(\"ls\",\n  Fun(\"acc\",\n    Fun(\"f\",\n      Match(Name(\"xs\"),\n        EmptyList, \n        Name(\"acc\"), \n        Cons(Name(\"x\"), \n          Name(\"xs\")),\n          Call(Call(Name(\"f\"\n            Name(\"acc\")\n            Name(\"x\")))))))\n)\n```",
    "QUESTION 3\n\nFor this exercise, we will add writable cells to our language. Assume we have a global array of memory that can be accessed by index.\n\n$$Expr ::= \\dots$$\n$$\\vert\\ \\text{Read } Expr$$\n$$\\vert\\ \\text{Write } Expr \\text{ to position } idx \\text{ and then } Expr$$\n\nYour task is to implement the CAS (compare and swap) function in Expr.\n\nHint:\n\n$$cas:B??$$\n$$cas:Array[Id] = ??$$\n$$IdxGuess \\text{ IntId : Index IntId : Int : Int} = $$\n\n$f(idx)=idx$\n$$Id = Id$$",
    ")))",
    "Lists\n\nPrinciples of Functional Programming",
    "Lists\n\nThe list is a fundamental data structure in functional programming.\n\nA list having $x_1, \\dots, x_n$ as elements is written $List(x_1, \\dots, x_n)$\n\nExample\n\n```\nval fruit = List(\"apples\", \"oranges\", \"pears\")\nval nums = List(1, 2, 3, 4)\nval diag3 = List(List(1, 0, 0), List(0, 1, 0), List(0, 0, 1))\nval empty = List()\n```\n\nThere are two important differences between lists and arrays.\n\n- Lists are immutable --- the elements of a list cannot be changed.\n- Lists are recursive, while arrays are flat.",
    "Lists\n\n```\nval fruit = List(\"apples\", \"oranges\", \"pears\")\nval diag3 = List(List(1, 0, 0), List(0, 1, 0), List(0, 0, 1))\n```",
    "The List Type\n\nLike arrays, lists are homogeneous: the elements of a list must all have the same type.\n\nThe type of a list with elements of type T is written scala.List[T] or shorter just List[T]\n\nExample\n\nval fruit: List[String]    = List(\u201capples\u201d, \u201coranges\u201d, \u201cpears\u201d)\nval nums: List[Int]        = List(1, 2, 3, 4)\nval diag3: List[List[Int]] = List(List(1, 0, 0), List(0, 1, 0), List(0, 0, 1))\nval empty: List[Nothing]   = List()\n\nlist of list of ints.",
    "Constructors of Lists\n\nAll lists are constructed from:\n\n- the empty list $Nil$, and\n- the construction operation $::$ (pronounced cons):\n  $x :: xs$ gives a new list with the first element $x$, followed by the elements of $xs$.\n\nFor example:\n``` \nfruit = \"apples\" :: (\"oranges\" :: (\"pears\" :: Nil))\nnums = 1 :: (2 :: (3 :: (4 :: Nil)))\nempty = Nil\n```",
    "Right Associativity\n\nConvention: Operators ending in \"::\" associate to the right.\n\n$A :: B :: C$ is interpreted as $A :: (B :: C)$.\n\nWe can thus omit the parentheses in the definition above.\n\nExample\n\nval nums = 1 :: 2 :: 3 :: 4 :: Nil",
    "Operations on Lists\n\nAll operations on lists can be expressed in terms of the following three:\n- $head$: the first element of the list\n- $tail$: the list composed of all the elements except the first.\n- $isEmpty$: 'true' if the list is empty, 'false' otherwise.\n\nThese operations are defined as methods of objects of type $List$. For example:\n\nfruit.head == \"apples\"\nfruit.tail.head == \"oranges\"\ndiag3.head == $List(1, 0, 0)$\nempty.head == throw $NoSuchElementException(\"head of empty list\")$",
    "List Patterns\n\nIt is also possible to decompose lists with pattern matching.\nNil The Nil constant\np :: ps A pattern that matches a list with a head matching p and a tail matching ps.\nList(pl, ..., pn) same as pl :: ... :: pn :: Nil\n\nExample\n1 :: 2 :: xs Lists of that start with 1 and then 2\nx :: Nil Lists of length 1\nList(x) Same as x :: Nil\nList() The empty list, same as Nil\nList(2 :: xs) A list that contains as only element another list that starts with 2.",
    "Exercise\n\nConsider the pattern $x :: y :: \\text{List}(xs, ys) :: zs$.\n\nWhat is the condition that describes most accurately the length $L$ of the lists it matches?\n\n\\[\n\\begin{align*}\n0 & \\quad L == 3 \\\\\n0 & \\quad L == 4 \\\\\n0 & \\quad L == 5 \\\\\n0 & \\quad L >= 3 \\\\\n0 & \\quad L >= 4 \\\\\n0 & \\quad L >= 5 \\\\\n\\end{align*}\n\\]",
    "Exercise\n\nConsider the pattern $x :: y :: List(xs, ys) :: zs$. \n\nWhat is the condition that describes most accurately the length $L$ of the lists it matches?\n\n0 $ \\quad L == 3$  \n0 $ \\quad L == 4$  \n0 $ \\quad L == 5$  \nX $ \\quad L >= 3$  \n0 $ \\quad L >= 4$  \n0 $ \\quad L >= 5$",
    "Suppose we want to sort a list of numbers in ascending order:\n- One way to sort the list List(7, 3, 9, 2) is to sort the tail List(3, 9, 2) to obtain List(2, 3, 9). \n- The next step is to insert the head 7 in the right place to obtain the result List(2, 3, 7, 9).\n\nThis idea describes Insertion Sort:\n\\[ \n\\text{def isort(xs: List[Int]): List[Int] = xs match} \\\\\n\\quad \\text{case List() => List()} \\\\\n\\quad \\text{case y :: ys => insert(y, isort(ys))}\n\\]",
    "Complete the definition insertion sort by filling in the ???s in the definition below:\n\n```scala\ndef insert(x: Int, xs: List[Int]): List[Int] = xs match\n    case List() => ??? List(x)\n    case y :: ys => ??? if x <= y then x :: xs else y :: insert(x, ys)\n```\n\nWhat is the worst-case complexity of insertion sort relative to the length of the input list N?\n\n- [ ] the sort takes constant time\n- [ ] proportional to N\n- [ ] proportional to N log(N)\n- [x] proportional to N * N",
    "Combinatorial Search Example\n\nPrinciples of Functional Programming",
    "Sets\n\nSets are another basic abstraction in the Scala collections.\n\nA set is written analogously to a sequence:\n\n```\nval fruit = Set(\"apple\", \"banana\", \"pear\")\nval s = (1 to 6).toSet\n```\n\nMost operations on sequences are also available on sets:\n\n```\ns.map(_ + 2)\nfruit.filter(_.startsWith(\"app\"))\ns.nonEmpty\n```\n\n(see Scaladoc for scala.Set for a list of all supported operations)",
    "Sets vs Sequences\n\nThe principal differences between sets and sequences are:\n\n1. Sets are unordered; the elements of a set do not have a predefined order in which they appear in the set\n2. sets do not have duplicate elements: \n\ns.map(_ / 2) // Set(2, 0, 3, 1)\n\n3. The fundamental operation on sets is contains:\n\ns.contains(5) // true",
    "Example: N-Queens\n\nThe eight queens problem is to place eight queens on a chessboard so that no queen is threatened by another.\n\nIn other words, there can\u2019t be two queens in the same row, column, or diagonal.\n\nWe now develop a solution for a chessboard of any size, not just 8.\n\nOne way to solve the problem is to place a queen on each row.\n\nOnce we have placed \\( k - 1 \\) queens, one must place the kth queen in a column where it\u2019s not \u201cin check\u201d with any other queen on the board.",
    "Algorithm\n\nWe can solve this problem with a recursive algorithm:\n\n\u25ba Suppose that we have already generated all the solutions consisting of placing k-1 queens on a board of size n.\n\u25ba Each solution is represented by a list (of length k-1) containing the numbers of columns (between 0 and n-1).\n\u25ba The column number of the queen in the k-1th row comes first in the list, followed by the column number of the queen in row k-2, etc.\n\u25ba The solution set is thus represented as a set of lists, with one element for each solution.\n\u25ba Now, to place the kth queen, we generate all possible extensions of each solution preceded by a new queen:",
    "Implementation\n\ndef queens(n: Int) =\n  def placeQueens(k: Int): Set[List[Int]] =\n    if k == 0 then Set(List())\n    else\n      for \n        queens <- placeQueens(k - 1)\n        col <- 0 until n\n        if isSafe(col, queens)\n      yield col :: queens\n  placeQueens(n)",
    "Write a function \n\n```scala\ndef isSafe(col: Int, queens: List[Int]): Boolean\n```\n\nwhich tests if a queen placed in an indicated column col is secure amongst the other placed queens.\n\nIt is assumed that the new queen is placed in the next available row after the other placed queens (in other words: in row queens.length).",
    "Exercise\n\n```scala\ndef isSafe(col: Int, queens: List[Int]): Boolean =\n  !checks(col, 1, queens)\n\nwhere the checks predicate takes in an additional second parameter delta \nthe distance in rows between the first row of queens and the row where \nthe current queen is placed. checks is defined as follows:\n\ndef checks(col: Int, delta: Int, queens: List[Int]): Boolean = queens match\n  case qcol :: others =>\n    qcol == col                       // vertical check\n    || (qcol - col).abs == delta      // diagonal check\n    || checks(col, delta + 1, others)\n  case Nil =>\n    false\n```",
    "Example: Finding Fixed Points\n\nPrinciples of Functional Programming",
    "Finding a fixed point of a function\n\nA number $x$ is called a fixed point of a function $f$ if\n$$f(x) = x$$\n\nFor some functions $f$ we can locate the fixed points by starting with an initial estimate and then by applying $f$ in a repetitive way,\n\n$$x, \\; f(x), \\; f(f(x)), \\; f(f(f(x))), \\; \\ldots$$\n\nuntil the value does not vary anymore (or the change is sufficiently small).",
    "This leads to the following function for finding a fixed point:\n\n```scala\nval tolerance = 0.0001\n\ndef isCloseEnough(x: Double, y: Double) = {\n    abs((x - y) / x) < tolerance    // correct for small and large numbers.\n}\n\ndef fixedPoint(f: Double => Double)(firstGuess: Double): Double = {\n    def iterate(guess: Double): Double = {\n        val next = f(guess)\n        if isCloseEnough(guess, next) then next\n        else iterate(next)\n    }\n    iterate(firstGuess)\n}\n```",
    "Return to Square Roots\n\nHere is a specification of the sqrt function:\n\n$$\n\\sqrt(x) = \\text{the number y such that } y * y = x.\n$$\n\nOr, by dividing both sides of the equation with y:\n\n$$\n\\sqrt(x) = \\text{the number y such that } y = x / y.\n$$\n\nConsequently, sqrt(x) is a fixed point of the function (y => x / y).",
    "This suggests to calculate sqrt(x) by iteration towards a fixed point:\n\n```\ndef sqrt(x: Double) =\n  fixedPoint(y => x / y)(1.0)\n```\n\nUnfortunately, this does not converge.\n\nLet's add a println instruction to the function fixedPoint so we can follow the current value of guess:",
    "First Attempt (2)\n\ndef fixedPoint(f: Double => Double)(firstGuess: Double) =\n\ndef iterate(guess: Double): Double =\nval next = f(guess)\nprintln(next)\nif isCloseEnough(guess, next) then next\nelse iterate(next)\n\niterate(firstGuess)\n\nsqrt(2) then produces:\n2.0\n1.0\n2.0\n1.0\n...\n\n",
    "Average Damping\n\nOne way to control such oscillations is to prevent the estimation from varying too much. This is done by averaging successive values of the original sequence:\n\n```scala\ndef sqrt(x: Double) = fixedPoint(y => (y + x / y) / 2)(1.0)\n```\n\nThis produces:\n1.5\n1.4166666666666665\n1.4142156862745097\n1.4142135623746899\n1.4142135623746899\n\nIn fact, if we expand the fixed point function `fixedPoint` we find a similar square root function to what we developed last week.",
    "Functions as Return Values\n\nThe previous examples have shown that the expressive power of a language is greatly increased if we can pass function arguments.\n\nThe following example shows that functions that return functions can also be very useful.\n\nConsider again iteration towards a fixed point.\n\nWe begin by observing that $\\sqrt{x}$ is a fixed point of the function $y => x / y$.\n\nThen, the iteration converges by averaging successive values.\n\nThis technique of stabilizing by averaging is general enough to merit being abstracted into its own function.\n\n```scala\ndef averageDamp(f: Double => Double)(x: Double): Double = \n  (x + f(x)) / 2\n```",
    "Exercise:\n\nWrite a square root function using fixedPoint and averageDamp.",
    "Final Formulation of Square Root\n\n```scala\ndef sqrt(x: Double) = fixedPoint(averageDamp(y => x/y))(1.0)\n```\n\nThis expresses the elements of the algorithm as clearly as possible.",
    "Summary\n\nWe saw last week that functions are essential abstractions because they allow us to introduce general methods to perform computations as explicit and named elements in our programming language.\n\nThis week, we've seen that these abstractions can be combined with higher-order functions to create new abstractions.\n\nAs a programmer, one must look for opportunities to abstract and reuse.\n\nThe highest level of abstraction is not always the best, but it is important to know the techniques of abstraction, so as to use them when appropriate.",
    "Type Classes\n\nPrinciples of Functional Programming\nMartin Odersky and Julien Richard-Foy",
    "Type Classes\n\nIn the previous lectures we have seen a particular pattern of code:\n\ntrait Ordering[A]:\n  def compare(x: A, y: A): Int\n\nobject Ordering:\n  given Ordering[Int] with\n    def compare(x: Int, y: Int) =\n      if x < y then -1 else if x > y then 1 else 0\n  given Ordering[String] with\n    def compare(s: String, t: String) = s.compareTo(t)",
    "We say that Ordering is a type class.\n\nIn Scala, a type class is a generic trait that comes with given instances for type instances of that trait.\n\nE.g., in the Ordering example, we have given instances for Ordering[Int] and Ordering[String]\n\nType classes provide yet another form of polymorphism:\n\nThe sort method can be called with lists containing elements of any type A for which there is a given instance of type Ordering[A].\n\n\\[\n\\text{def sort[A: Ordering](xs: List[A]): List[A] = ...}\n\\]\n\nAt compilation-time, the compiler resolves the specific Ordering implementation that matches the type of the list elements.",
    "Exercise\n\nImplement an instance of the Ordering typeclass for the Rational type.\n\ncase class Rational(num: Int, denom: Int)\n\nReminder:\n\nlet $q = \\frac{num_q}{denom_q}, \\, r = \\frac{num_r}{denom_r}$\n\n$q < r \\Leftrightarrow \\frac{num_q}{denom_q} < \\frac{num_r}{denom_r} \\Leftrightarrow num_q \\times denom_r < num_r \\times denom_q$\n\ndef compare(x: Rational, y: Rational) =\n\nval xNum = x.num \u00d7 y.denom\nval yNum = y.num \u00d7 x.denom\n\nif xNum < yNum then -1 else if xNum > yNum then 1 else 0",
    "Digression: Retroactive Extension\n\nIt is worth noting that we were able to implement the Ordering[Rational] instance without changing the Rational class definition.\n\nType classes support retroactive extension: the ability to extend a data type with new operations without changing the original definition of the data type.\n\nIn this example, we have added the capability of comparing Rational numbers.",
    "Conditional Instances\n\n**Question:** How do we define an Ordering instance for lists?\n\n**Observation:** This can be done only if the list elements have an ordering.\n\n```scala\ngiven listOrdering[A](using ord: Ordering[A]): Ordering[List[A]] with\n\n  def compare(xs: List[A], ys: List[A]) = (xs, ys) match\n    case (Nil, Nil) => 0\n    case (Nil, _) => -1\n    case (_, Nil) => 1\n    case (x :: xs1, y :: ys1) =>\n      val c = ord.compare(x, y)\n      if c != 0 then c else compare(xs1, ys1)\n```\n\nThe given instance listOrdering takes type parameters and implicit parameters.",
    "Conditional Instances\n\nGiven instances such as listOrdering that take implicit parameters are conditional:\n\n- An ordering for lists with elements of type T exists only if there is an ordering for T.\n\nThis sort of conditional behavior is best implemented with type classes.\n\n- Normal subtyping and inheritance cannot express this: a class either inherits a trait or doesn\u2019t.",
    "Recursive Implicit Resolution\n\nGiven instances with implicit parameters are resolved recursively:\n\nA given instance for the outer type is constructed first and then its implicit parameters are filled in in turn.\n\nExample:\n\n```scala\ndef sort[A](xs: List[A])(using Ordering[A]): List[A] = ...\nval xss: List[List[Int]] = ...\n\nsort(xss) // We just write this.\n```",
    "Recursive Implicit Resolution\n\nGiven instances with implicit parameters are resolved recursively:\n\nA given instance for the outer type is constructed first and then its implicit \nparameters are filled in in turn.\n\nExample:\n\ndef sort[A](xs: List[A])(using Ordering[A]): List[A] = ...\nval xss: List[List[Int]] = ...\n\nsort[List[Int]](xss)",
    "Recursive Implicit Resolution\n\nGiven instances with implicit parameters are resolved recursively:\n\nA given instance for the outer type is constructed first and then its implicit parameters are filled in in turn.\n\nExample:\n```\ndef sort[A](xs: List[A])(using Ordering[A]): List[A] = ...\nval xss: List[List[Int]] = ...\n\nsort[List[Int]](xss)(using listOrdering)\n```",
    "Recursive Implicit Resolution\n\nGiven instances with implicit parameters are resolved recursively:\nA given instance for the outer type is constructed first and then its implicit parameters are filled in in turn.\n\nExample:\n\n```scala\ndef sort[A](xs: List[A])(using Ordering[A]): List[A] = ...\nval xss: List[List[Int]] = ...\n\nsort[List[Int]](xss)(using listOrdering(using Ordering.Int))\n```\n\ncopiles adds the missing pieces.",
    "Exercise\n\nImplement an instance of the Ordering typeclass for pairs of type (A, B), where A, B have Ordering instances defined on them.\n\nExample use case: Consider a program for managing an address book. We would like to sort the addresses by zip codes first and then by street name. Two addresses with different zip codes are ordered according to their zip code, otherwise (when the zip codes are the same) the addresses are sorted by street name. E.g.\n\ntype Address = (Int, String) // Zipcode, Street Name\nval xs: List[Address] = ...\nsort(xs)",
    "Exercise\n\nImplement an instance of the Ordering typeclass for pairs of type (A, B), where A, B have Ordering instances defined on them.\n\ngiven pairOrdering[A, B](using orda: Ordering[A], ordb: Ordering[B])\n  : Ordering[(A, B)] with\n    def compare(x: (A, B), y: (A, B)) =\n      val c = orda.compare(x._1, y._1)\n      if c != 0 then c else ordb.compare(x._2, y._2)",
    "Type Classes and Extension Methods\n\nLike any trait, a type class trait may define extension methods.\n\nFor instance, the Ordering trait would usually contain comparison methods like this:\n\ntrait Ordering [A]:\n  def compare(x: A, y: A): Int\n\nextension (x: A)\n  def < (y: A): Boolean = compare(x, y) < 0\n  def <= (y: A): Boolean = compare(x, y) <= 0\n  def > (y: A): Boolean = compare(x, y) > 0\n  def >= (y: A): Boolean = compare(x, y) >= 0",
    "Visibility of Extension Methods\n\nExtension methods on a type class trait are visible whenever a given instance for the trait is available.\n\nFor instance one can write:\n\n```scala\ndef merge[T: Ordering](xs: List[T], ys: List[T]): Boolean = (xs, ys) match\n  case (Nil, _) => ys\n  case (_, Nil) => xs\n  case (x :: xs1, y :: ys1) =>\n    if x < y then x :: merge(xs1, ys)\n    else y :: merge(xs, ys1)\n```\n\n\u25ba There's no need to name and import the Ordering instance to get access to the extension method < on operands of type T.\n\n\u25ba We have an Ordering[T] instance in scope, that's where the extension method comes from.",
    "Summary\n\nType classes provide a way to turn types into values.\n\nUnlike class extension, type classes\n\n- can be defined at any time without changing existing code,\n- can be conditional.\n\nIn Scala, type classes are constructed from parameterized traits and given instances.\n\nType classes give rise to a new kind of polymorphism, which is sometimes called *ad-hoc* polymorphism.\n\nThis means that a type $TC[A]$ has different implementations for different types $A$.",
    "Recap from Weeks 1 - 6\n\nPrinciples of Functional Programming\nMartin Odersky",
    "Recap: Case Classes\n\nCase classes are Scala\u2019s preferred way to define complex data.\nExample: Representing JSON (JavaScript Object Notation)\n\n{\n  \"firstName\": \"John\",\n  \"lastName\": \"Smith\",\n  \"address\": {\n    \"streetAddress\": \"21 2nd Street\",\n    \"state\": \"NY\",\n    \"postalCode\": 10021\n  },\n  \"phoneNumbers\": [\n    { \"type\": \"home\", \"number\": \"212 555-1234\" },\n    { \"type\": \"fax\", \"number\": \"646 555-4567\" }\n  ]\n}",
    "abstract class JSON\nobject JSON:\n  case class Seq (elems: List[JSON])                   extends JSON\n  case class Obj (bindings: Map[String, JSON])         extends JSON\n  case class Num (num: Double)                         extends JSON\n  case class Str (str: String)                         extends JSON\n  case class Bool (b: Boolean)                         extends JSON\n  case object Null                                     extends JSON",
    "Representation of JSON with Enums\n\nCase class hierarchies can be represented more concisely as enums:\n\n```scala\nenum JSON:\n  case Seq (elems: List[JSON])\n  case Obj (bindings: Map[String, JSON])\n  case Num (num: Double)\n  case Str (str: String)\n  case Bool (b: Boolean)\n  case Null\n```",
    "val jsData = JSON.Obj(Map(\n  \"firstName\" -> JSON.Str(\"John\"),\n  \"lastName\" -> JSON.Str(\"Smith\"),\n  \"address\" -> JSON.Obj(Map(\n    \"streetAddress\" -> JSON.Str(\"21 2nd Street\"),\n    \"state\" -> JSON.Str(\"NY\"),\n    \"postalCode\" -> JSON.Num(10021)\n  )),\n  \"phoneNumbers\" -> JSON.Seq(List(\n    JSON.Obj(Map(\n      \"type\" -> JSON.Str(\"home\"), \"number\" -> JSON.Str(\"212 555-1234\")\n    )),\n    JSON.Obj(Map(\n      \"type\" -> JSON.Str(\"fax\"), \"number\" -> JSON.Str(\"646 555-4567\")\n    ))\n  ))\n))",
    "Pattern Matching\n\nHere's a method that returns the string representation of JSON data:\n\n```scala\ndef show(json: JSON): String = json match\n  case JSON.Seq(elems) =>\n    elems.map(show).mkString(\"[\", \", \", \"]\")\n  case JSON.Obj(bindings) =>\n    val assocs = bindings.map {\n      case (key, value) => s\"${inQuotes(key)}: ${show(value)}\"\n    }\n    assocs.mkString(\"{\", \",\\n\", \"}\")\n  case JSON.Num(num) => num.toString\n  case JSON.Str(str) => inQuotes(str)\n  case JSON.Bool(b) => b.toString\n  case JSON.Null => \"null\"\n\ndef inQuotes(str: String): String = \"\\\"\" + str + \"\\\"\"\n```",
    "Recap: Collections\n\nScala has a rich hierarchy of collection classes.",
    "Recap: Collection Methods\n\nAll collection types share a common set of general methods.\n\nCore methods:\n\nmap\nflatMap\nfilter\n\nand also\n\nfoldLeft\nfoldRight",
    "Idealized Implementation of map on Lists\n\nextension [T](xs: List[T])\n    def map[U](f: T => U): List[U] = xs match\n        case x :: xs1 => f(x) :: xs1.map(f)\n        case Nil => Nil",
    "Idealized Implementation of flatMap on Lists\n\n```scala\nextension [T](xs: List[T])\n  def flatMap[U](f: T => List[U]): List[U] = xs match\n    case x :: xsl => f(x) ++ xsl.flatMap(f)\n    case Nil => Nil\n```",
    "Idealized Implementation of filter on Lists\n\nextension [T](xs: List[T])\n  def filter(p: T => Boolean): List[T] = xs match {\n    case x :: xsl =>\n      if p(x) then x :: xsl.filter(p) else xsl.filter(p)\n    case Nil => Nil\n\nIn practice, the implementation and type of these methods are different in order to\n\u25ba make them apply to arbitrary collections, not just lists,\n\u25ba make them tail-recursive on lists.",
    "For-Expressions\n\nSimplify combinations of core methods `map`, `flatMap`, `filter`.\n\nInstead of:\n\n$(1\\ until\\ n)(i\\ =>\n\\quad(1\\ until\\ i)\\ filter\\ (j\\ =>\\ isPrime(i\\ +\\ j))\\ map\n\\quad(j\\ =>\\ (i,\\ j)))$\n\none can write:\n\nfor\n\n$j\\ \\leftarrow\\ 1\\ until\\ n$\n\n${\\color{red}{\\text{what includes 1 but excludes n}}}$\n\n$i\\ \\leftarrow\\ 1\\ until\\ i$\n\nif $isPrime(i + j)$\n\nyield $(i, j)$",
    "For-expressions and Pattern Matching\n\nThe left-hand side of a generator may also be a pattern:\n\n```\ndef bindings(x: JSON): List[(String, JSON)] = x match\n  case JSON.Obj(bindings) => bindings.toList\n  case _ => Nil\n```\n\nFor case (\"phoneNumbers\", JSON.Seq(numberInfos)) <- bindings(jsData) numberInfo <- numberInfos case (\"number\", JSON.Str(number)) <- bindings(numberInfo) if number.startsWith(\"212\") yield number\n\nIf the pattern starts with case, the sequence is filtered so that only elements matching the pattern are retained.",
    "Tail Recursion - a form of recursion which acts as a loop\n\nPrinciples of Functional Programming",
    "Review: Evaluating a Function Application\n\nOne simple rule: One evaluates a function application $f(e_1, ..., e_n)$\n\n- by evaluating the expressions $e_1, ..., e_n$ resulting in the values $v_1, ..., v_n$, then\n- by replacing the application with the body of the function $f$, in which the actual parameters $v_1, ..., v_n$ replace the formal parameters of $f$.",
    "Application **Rewriting Rule**\n\nThis can be *formalized as a rewriting of the program itself*:\n\n$$\n\\text{def } f(x_1, \\dots, x_n) = B; \\quad \\dots f(v_1, \\dots, v_n)\n$$\n\n$$\n\\Rightarrow \\text{def } f(x_1, \\dots, x_n) = B; \\quad B[v_1/x_1, \\dots, v_n/x_n]\n$$\n\nHere, $[v_1 / x_1, \\dots, v_n / x_n] B$ means:\n\nThe expression $B$ in which all occurrences of $x_i$ have been replaced by $v_i$.\n\n$[v_1 / x_1, \\dots, v_n / x_n]$ is called a *substitution*.\n\n**Note:** $v_i / x_i \\ne v_i = x_i$\n\n$v_i / x_i$ means $x_i \\leftarrow V_i$",
    "Rewriting example:\n\nConsider gcd, the function that computes the greatest common divisor of two numbers.\n\nHere's an implementation of gcd using Euclid's algorithm.\n\ndef gcd(a: Int, b: Int): Int =\n  if b == 0 then a else gcd(b, a % b)\n\nNote: a replaced by a % b, and b replaced by a or b.\n\nmodules (%): returns remainder of division.\n\n$$\\frac{11}{4} = 2 + \\frac{3}{4}$$",
    "Rewriting example:\n\n$$\n\\gcd(14, 21) \\text{ is evaluated as follows:}\n$$\n\n$$\n\\gcd(14, 21)\n$$\n$$\n\\Rightarrow \\text{if } 21 \\equiv 0 \\text{ then } 14 \\text{ else } \\gcd(21, 14 \\% 21)\n$$\n$$\n\\Rightarrow \\text{if false then } 14 \\text{ else } \\gcd(21, 14 \\% 21)\n$$\n$$\n\\Rightarrow \\gcd(21, 14 \\% 21)\n$$\n$$\n\\Rightarrow \\gcd(21, 14)\n$$\n$$\n\\Rightarrow \\text{if } 14 \\equiv 0 \\text{ then } 21 \\text{ else } \\gcd(14, 21 \\% 14)\n$$\n$$\n\\Rightarrow \\gcd(14, 7) \\Rightarrow \\text{if 7} \\equiv 0 \\text{ then } 14 \\text{ else } \\gcd(7, 14 \\% 7)\n$$\n$$\n\\Rightarrow \\gcd(7, 0)\n$$\n$$\n\\Rightarrow \\text{if 0} \\equiv 0 \\text{ then } 7 \\text{ else } \\gcd(0, 7 \\% 0)\n$$\n$$\n\\Rightarrow 7\n$$",
    "Another rewriting example:\n\nConsider factorial:\n\ndef factorial(n: Int): Int =\n    if n == 0 then 1 else n * factorial(n - 1)\n\nfactorial(4)\n\n\u21d2 if 4 == 0 then 1 else 4 * factorial(4 - 1) \u21d2 3\u21d2 4 * factorial(3)\n\n\u21d2 4 * (3 * factorial(2))\n\n\u21d2 4 * (3 * (2 * factorial(1)))\n\n\u21d2 4 * (3 * (2 * (1 * factorial(0)))\n\n\u21d2 4 * (3 * (2 * (1 * 1)))\n\n\u21d2 24\n\nWhat are the differences between the two sequences?",
    "Tail Recursion\n\nImplementation Consideration:\nIf a function calls itself as its last action, the function\u2019s stack frame can be reused. This is called tail recursion.\n\n\u21d2 Tail recursive functions are iterative processes.\n\nIn general, if the last action of a function consists of calling a function (which may be the same), one stack frame would be sufficient for both functions. Such calls are called tail-calls.",
    "Tail Recursion in Scala\n\nIn Scala, only directly recursive calls to the current function are optimized.\n\nOne can require that a function is tail-recursive using a @tailrec annotation:\n\nimport scala.annotation.tailrec\n\n@tailrec\ndef gcd(a: Int, b: Int): Int = ...\n\nIf the annotation is given, and the implementation of gcd were not tail recursive, an error would be issued.",
    "Exercise: Tail recursion\n\nDesign a tail recursive version of factorial.",
    "Exercise Session 7\n\nQUESTION 1\n\nConsider the following series:\n1\n1 1\n2 1\n1 2 1 1\n1 1 1 2 2 1\n3 1 2 2 1 1\n???\n\n1. Find the next element in the sequence above.\n\nNow, let us encode an element of the sequence above as a List[Int].\n\n2. Write a function to compute the next element.\n\ndef nextLine(currentLine: List[Int]): List[Int] = ???\n\n3. Implement a lazy List funSeq which constructs this sequence. Recall: to construct a lazy list, you can use LazyList.cons(A, a). Also: a #::: LazyList(a):\n\nlazy val funSeq: LazyList[List[Int]] = ???\n\nQUESTION 2\n\n1. Write a lazy list of squares of integers \u2265 1. You may use LazyList.from(i: Int).\n\nval squares: LazyList[Int] = ???\n\n2. Write a lazy list of all non-empty strings using the characters \"0\" and \"1\" and the concatenation operator ++. In other words, every non-empty string composed of \"0\" and \"1\" should be reached at some point in time.\n\nlazy val codes: LazyList[String] = ???\n\n3. Using codes, write a lazy list of all possible non-empty palindromes of \"0\" and \"1\". You may use the .reverse function defined on strings.\n\nlazy val palCodes: LazyList[String] = ???\n\n4. Can you do the same without filtering? The palindromes need not be in the same order.\n",
    "5. Given another lazy list otherCodes, possibly finite or infinite, you don't know at first:\n\n```swift\nval otherCodes: LazyList[String] = ??? // some external source\n```\n\nBuild a lazy list allCodes that interleaves palCodes and otherCodes.  \n\nConsider the following series:\n\n\\[ \\begin{align*}\n1 & \\rightarrow 1 \\\\\n2 & \\rightarrow 11 \\\\\n3 & \\rightarrow 21 \\\\\n4 & \\rightarrow 1211 \\\\\n5 & \\rightarrow 111221 \\\\\n6 & \\rightarrow 312211 \\\\\n\\end{align*} \\]\n\nFind the next element in the sequence above, so: 312211 \\(\\rightarrow\\) 13112221\n\nNow, let us encode an element of the sequence above as a List(text).\n\n1. Look at the first element in the sequence.\n2. Compute the run length of previous element in the sequence.\n\n```scala\nex: List(1, 2, 21).runLengthEncode() returns\nList(13112221, 111221, 312211)\n```\n\n```scala\nval palCodes: LazyList[String] =\nLazyList.iterate(List(1))(nextElement).map(_.mkString)\n```\n\n```scala\nLazyList.iterate(312211)(runLengthEncode).take(1) \n```\n\n```scala\nval allCodes: LazyList[String] = ??? \n```\n\n1.4.1) \\[ 13112221 \\]\n\n1.4.2) computing the next line:\n\nwe read the following pattern:\n- count digits for which we are counting the number of successive appearances\n- count read as long as we read a new digit\n- next to 1 whereas we see a new digit.\n\n- output = output list we are building.",
    "Whenever we see new list, we update output list with:\n\n$(\\text{curs} \\ldots \\text{curt}) : \\text{output}$\n\n=> We must reverse the list at end.\n\nThis can be implemented with foldRight and pattern matching:\n\n\\[\n\\text{def nextLine} (\\text{cumsum } : \\text{List[Int]}) : \\text{List[Int]} = \\{ \\\\\n\\quad \\text{cumsum.foldRight} ((\\text{List.empty[Int]},0)) \\{ \\\\\n\\qquad (\\text{x,} \\, (\\text{acc,next})) \\Rightarrow \\\\\n\\qquad\\quad \\text{val y} = \\text{cum:} \\\\\n\\qquad\\quad \\text{curt = y.curt: curt} \\Rightarrow \\text{x: (\\text{curs} \\ldots \\text{curt + 1}): curt} \\\\\n\\qquad\\quad \\text{case _ => x::acc } \\\\\n\\quad\\} \\\\\n\\}.\\text{reverse}\n\\]\n\n1.3) We must now construct LazyList implementation of whole sequence as a LazyList[List[Int]]\n\n\\[\n\\text{lazy val finalSeq: LazyList[List[Int]]} = \\\\ \n\\text{LazyList.cons} (1, \\text{finalSeq.map(nextLine)})\n\\]\n\n\\#\\# This is an infinite recursive call",
    "QUESTION 2\n\ndef from(n: Int): LazyList[Int] = n #:: from(n+1)\n \n1. Write a lazy list of squares of integers \u2265 1. You may use LazyList.from(i: Int)\n\nval squares: LazyList[Int] =\u00a0LazyList.from(1).map (x => x x x)\n\n2. Write a lazy list of all non-empty strings using the characters \"0\" and \"1\" and the concatenation operation +. In other words, every non-empty string composed of \"0\" and \"1\" should be reached at some point. \n\nlazy\u00a0ros: def cat[Stng] = (os Stng) ((s + os + ( .. ), (s ... ((\"))): Choices as -> :[]): LazyList.empty{Sting]}\n\n3. Using code, write a lazy list of all possible non-empty palindromes of \"0\" and \"1\". You may use the helper functions defined as stings. \n\ndef isPalindrome (x:Sting) = x x.reverse == x\n\nval palcodes: LazyList[Sting] = codes. {filter (isPalindrome)}",
    "4. Can you do the same without filtering? The palindromes need not be in the same order.\n\n  Generate lists in such a way that when s is:\n  - we add \"o\" to front, we also add \"o\" to back.\n  - we add \"1\" to front we also add \"1\" to back.\n  \n  val palCodes: LazyList[String] = \"o\" #::\n                                   \"1\" #::\n                                   palCodes.flatMap {\n                                     s: String => (\"o\" + s + \"o\") #::\n                                                  (\"1\" + s + \"1\") #::\n                                                  LazyList.empty\n                                   }\n\n5. Given another lazy list otherCodes, possibly finite or infinite, you don't know at first:\n\n  val otherCodes: LazyList[String] = ???\n  \n  Build a lazy list allCodes that interleaves palCodes and otherCodes.\n\n  def interleave(xs: LazyList[A], ys: LazyList[A]): LazyList[A] = \n    (xs, ys) match {\n      case (x #:: x1, y #:: y1) => x #::\n                                  y #::\n                                  interleave(xs,x1)\n      case (xs, LazyList.empty) => xs\n      case (LazyList.empty, ys) => ys\n  }\n\n  val allCodes = interleave(palCodes, otherCodes).",
    "Functions as Objects\n\nPrinciples of Functional Programming",
    "Functions as Objects\n\nWe have seen that Scala's numeric types and the Boolean type can be implemented like normal classes.\n\nBut what about functions?\n\nIn fact function values are treated as objects in Scala.\n\nThe function type $A => B$ is just an abbreviation for the class $scala.Function1[A, B],$ which is defined as follows.\n\n\\[\n\\text{package scala}\n\\]\n\\[\n\\text{trait Function1[A, B]:}\n\\]\n\\[\n\\text{\\ \\ \\ \\ def apply(x: A): B}\n\\]\n\nSo functions are objects with apply methods.\n\nThere are also traits Function2, Function3, ... for functions which take more parameters.",
    "Expansion of Function Values\n\nAn anonymous function such as\n\n$(x: \\text{Int}) => x * x$\n\nis expanded to:\n\n$new \\text{Function}[\\text{Int}, \\text{Int}]:$\n$ \\quad \\text{def apply}(x: \\text{Int}) = x * x$\n\nThis anonymous class can itself be thought of as a block that defines and instantiates a local class:\n\n$ \\{\\ \\text{class} \\$\\text{anonfun}\\{1\\} \\text{extends Function}[\\text{Int}, \\text{Int}]:$\n$ \\quad \\text{def apply}(x: \\text{Int}) = x * x$\n$ \\quad \\$\\text{anonfun}\\{1\\}()$\n$ \\}$",
    "Expansion of Function Calls\n\nA function call, such as $f(a, b)$, where $f$ is a value of some class type, is expanded to\n\n$$f.apply(a, b)$$\n\nSo the OO-translation of\n\n$$\\text{val } f = (x: \\text{Int}) => x * x$$\n$$f(7)$$\n\nwould be\n\n$$\\text{val } f = \\text{new Function1}[\\text{Int, Int}]:$$\n$$\\ \\ \\ \\text{def apply(x: \\text{Int}) = x * x}$$\n\n$$f.apply(7)$$",
    "Note that a method such as\n\n    def f(x: Int): Boolean = ...\n\nis not itself a function value.\n\nBut if f is used in a place where a Function type is expected, it is converted automatically to the function value\n\n    (x: Int) => f(x)\n\nor, expanded:\n\n    new Function1[Int, Boolean]:\n        def apply(x: Int) = f(x)",
    "In package week3, define an\n\nobject IntSet:\n    ...\n\nwith 3 functions in it so that users can create IntSets of lengths 0-2 using syntax\n\nIntSet()        // the empty set\nIntSet(1)       // the set with single element 1\nIntSet(2, 3)    // the set with elements 2 and 3.",
    "Object IntSet :\n  def apply(): IntSet = Empty\n  def apply(x: Int): IntSet = Empty.incl(x)\n  def apply(x: Int, y: Int): IntSet = Empty.incl(x).incl(y)",
    "We have seen an interpreter for a language with nested recursive definitions:\n\n```\nenum Expr\ncase C(c: BigInt)\ncase N(name: String)\ncase IfNonzero(cond: Expr, trueE: Expr, falseE: Expr)\ncase Call(function: Expr, arg: Expr)\ncase Fun(param: String, body: Expr)\ncase Defs(defs: List[(String, Expr)], rest: Expr)\n```\n\nWe now make language smaller, but without losing expressive power!",
    "We have seen an interpreter for a language with nested recursive definitions:\n\n\\[\n\\text{enum} \\ \\text{Expr} \\\\\n\\text{case} \\ \\text{C(c: BigInt)} \\\\\n\\text{case} \\ \\text{N(name: String)} \\\\\n\\text{case} \\ \\text{IfNonzero(cond: Expr, trueE: Expr, falseE: Expr)} \\\\\n\\text{case} \\ \\text{Call(function: Expr, arg: Expr)} \\\\\n\\text{case} \\ \\text{Fun(param: String, body: Expr)} \\\\\n\\text{case} \\ \\text{Defs(defs: List((String, Expr)), rest: Expr)}\n\\]\n\nWe now make language smaller, but without losing expressive power! We show that we only need these three constructs:\n\n\\[\n\\text{enum} \\ \\text{Expr} \\\\\n\\text{case} \\ \\text{N(name: String)} \\\\\n\\text{case} \\ \\text{Call(function: Expr, arg: Expr)} \\\\\n\\text{case} \\ \\text{Fun(param: String, body: Expr)}\n\\]\n\nThe higher-order language with only these three constructs is called lambda calculus.",
    "Encoding Recursion: Extra Parameter\n\nWe show that recursion can be encoded using higher-order functions. Consider a recursive factorial function definition:\n```\n(def fact = (n =>\n                if n then * n (fact( - n 1)) else 1)\n fact 10)\n```\nLet us add an extra parameter called to factorial which we will call 'self'. It initially serves no purpose because we just propagate it without ever using it:\n```\n(def factGen = (self => n =>\n                       if n then * n (factGen self( - n 1)) else 1)\n factGen factGen 10)\n```\nIt does not matter what we give as the self argument to fact, as it is not used. Let us use factGen as the first argument. Clearly, factGen factGen 10 computes the same thing as fact 10.",
    "Starting from:  \n(def factGen = (self => n =>  \n&nbsp;&nbsp;&nbsp;&nbsp;if n then * n (factGen self (- n 1)) else 1)  \n\n&nbsp;&nbsp;&nbsp;&nbsp;factGen factGen 10)  \n\nlet us assume that factGen will always be called with itself as the first argument.  \nThen factGen and self are interchangeable, so let us use self in the body:  \n(def factGen = (self => n =>  \n&nbsp;&nbsp;&nbsp;&nbsp;if n then * n (self self (- n 1)) else 1)  \n\n&nbsp;&nbsp;&nbsp;&nbsp;factGen factGen 10)  \n\nNow factGen is not recursive any more, it uses higher-order functions instead.  \nThus our interpreter does not need support for recursive definitions.",
    "Non-Recursive Definitions Using Anonymous Functions\n\nWe can always substitute away definitions, instead of: \n```lisp\n(def factGen = (self => n => \n                if n then * n (self self (- n 1)) else 1)\nfactGen factGen 10)\n```\nwe can write directly:\n```lisp\n(self => n => if n then * n (self self (- n 1)) else 1) // factGen\n(self => n => if n then * n (self self (- n 1)) else 1) // factGen 10\n```",
    "Non-Recursive Definitions Using Anonymous Functions\n\nWe can always substitute away definitions, instead of:\n```scheme\n(def factGen = (self => n =>\n                if n then * n (self self (- n 1)) else 1)\n factGen factGen 10)\n```\nwe can write directly:\n```scheme\n(self => n => if n then * n (self self (- n 1)) else 1)  // factGen\n (self => n => if n then * n (self self (- n 1)) else 1)  // factGen\n 10\n```\nWe can also express this by turning `factGen` into a parameter:\n```scheme\n(factGen => factGen factGen 10)\n (self => n => if n then * n (self self (- n 1)) else 1)\n```\nthat expression reduces to the previous one after one function application.",
    "First-Class Functions Subsume Recursion\n\nThis encoding works in environment based-interpreter. (Not much slower.)\n\nIt also works in substitution-based interpreter, which is instructive to follow.\n\nIt also works in Scala, we just need to define the recursive type for self:\n\n```scala\ncase class T(f: T => BigInt => BigInt)\n\nval factGen: T = T(\n    (self:T) =>\n        (n:BigInt) =>\n            if n != 0 then n * self.f(self)(n - 1)\n            else 1\n)\ndef factOf10: BigInt = factGen.f(factGen)(10) // factGen factGen 10\ndef fact(m: BigInt): BigInt = factGen.f(factGen)(m)\n```",
    "Towards a General Form\n\nThere is nothing special about the constant 10 in\n$$(self => n => if n then * n (self self (- n 1)) else 1)$$\n$$(self => n => if n then * n (self self (- n 1)) else 1) 10$$\n\nIf we take arbitrary m, the expression\n$$(self => n => if n then * n (self self (- n 1)) else 1)$$\n$$(self => n => if n then * n (self self (- n 1)) else 1) m$$\n\ncomputes the factorial of m. Thus,\n$$(self => n => if n then * n (self self (- n 1)) else 1)$$\n$$(self => n => if n then * n (self self (- n 1)) else 1)$$\n\nis the factorial function. Note that it is of the form\n$$(self => body1) (self => body1)$$\n\nwhere body1 is the body of the original factorial function but with self self instead of the recursive call.",
    "Automating Recursive Function Encoding\n\ndef mkRecursive(recCallName: String, body: Expr): Expr =\n  val body1 = subst(body, recCallName, Call(N(\"self\"), N(\"self\")))\n  val selfToBody1 = Fun(\"self\", body1)\n  Call(selfToBody1, selfToBody1)\n\nFor example, if we define the term factBody as:\nn => if n then n * (myself (\u2212 n 1)) else 1\n\nthen evaluating the term\nCall(mkRecursive(\"myself\", factBody), C(6))\n\ngives 720, as desired. We could thus use desugaring to support recursive constructs instead of having a support in the interpreter.",
    "Exercise Session 2\n(with solutions)\n\nThis week we will work on playing with functions as values.\n\nQUESTION 1\n\nDefine the function flip. It takes a function and returns the same function, but with the arguments flipped.\n\n```\ndef flip(f: (Double, Int) => Boolean): (Int, Double) => Boolean = ???\n```\n\nQUESTION 2\n\nQuestion 2.1\n\nDefine the identity function for integers, which, given an Int, returns it.\n\n```\nval id: Int => Int = ???\n```\n\nQuestion 2.2\n\nDefine the compose function, that, given 2 functions f, g, returns a function that composes them, i.e., f * g.\n\n```\ndef compose(f: Int => Int, g: Int => Int): Int => Int = ???\n```\n\nWhat does composed(id, f)(x) evaluate to for some function f and integer x?\n\nQuestion 2.3\n\nDefine the function repeated, which takes a function and repeatedly applies it n times (n > 0).\n\n```\ndef repeated(f: Int => Int, n: Int): Int => Int = ???\n```\n\nHint: What values should be returned by repeated(x => x + 1, 0) and repeated(x => x + 1, 3)?\n\nQUESTION 3\n\nQuestion 3.1\n\nDefine the function curry2, that curries a two arguments function. That is, curry2(f) = g such that f(x, y) = g(x)(y)\n\n```\ndef curry2(f):\ng(x)(y)\n```",
    "def curry2(f: (Double, Int) => Boolean): Double => (Int => Boolean) = ???\n\nHint: what should curry2((x, y) => x < y)(1.0)(0) return?\n\nQuestion 3.2\n\nDefine the function uncurry2. It takes a curried function, and creates a two-argument function.\n\ndef uncurry2(f: Double => (Int => Boolean)): (Double, Int) => Boolean = ???\n\nQuestion 4\n\nWrite a function fixedPoint with the following signature:\n\ndef fixedPoint(f: Int => Int): Int => Int\n\nThe function takes a function f and returns a function that maps an integer into the fixed point of f that is obtained by iterating f some finite number of times starting from the initial value.\n\nA value x is a fixed point of f if f(x) == x.\n\nFor each of the following expressions, indicate whether it terminates, and if so, what is the value returned:\u00a0\n\nfixedPoint(x => x/2)(15)\nfixedPoint(x+1)(123456)\nfixedPoint(x => x-1)(10)\nfixedPoint(x => if (x > 0) x else x * 3)(3)\nfixedPoint(x:int => if (x == 0) x + 2 else x - 1)(20)\n\nQuestion 5\n\nQuestion 5.1\n\nWrite the sum function with the following signature:\n\ndef sum(f: Int => Int)(a: Int, b: Int): Int = ???\n\nWhich returns the sum of applying f to the integers from a to b.\n\nBonus part: Can your implementation be tail recursive?\n\nQuestion 5.2\n\nWrite the quadratic function with the following signature:\n\ndef quadratic(c: Int): Int => Int = ???",
    "Which returns a function that takes an integer x as argument and returns \\( (x - c)^2 \\).\n\nQuestion 5.3\n\nUsing the above functions, define the function quad3Integrate which, given two integers a and b, computes the sum of \\( (i - 3)^2 \\) where i ranges from a to b.\n\nval quad3Integrate: (Int, Int) => Int = ???\n\nDefine the function f:flip to take a function and returns the same function, but with the arguments flipped.\n\n2)\n\ndefine func f(x1,x2:Z2:u[double X (o]] = g(X1, Xd)\n\nLet's define a test function: \nlet's define a test function:\ntest_function (x1:double, x2:Int): Boolean =\n  x1 = 1.00 /\\\n  x2 = 10  \n\n\\(g(x1=1.00, x2=22 ==> \\text{is even } x2c\\)\n\n_no empty cells_\n\nstep1: \\(test_function(1.2,0)\\) = \nstep2: \\(test_function(1.0,22)\\)\n\nDefine the identity function for integers, which, given an Int, returns it.\n\n2.1) \\(Identity: Int\u2192 Int \\)\n\n\"Identity\": \nlet identity = (x: Int) => x\n\n2.2) \n\\(f(x\\rightarrow f(\\text{identity(Bc)})) = Bc \\text{(int)}\\)\n\\(f(x\\rightarrow x) = g(Bc:int)\\) ",
    "2.3) Define the function repeat, which takes a function and repeatedly applies it n times $(n > 0)$.\n\nHint: What values should be returned when $n = 0$ and when $n = 1$? \n\n$$\n\\text{If} \\quad n = 0 \\quad \\text{then identity} \n$$\nalso compose $(g, \\quad \\text{repeat}(f,n-1))$\n\n$$\nrepeat(f,n)= \\begin{cases} \n  \\text{id} & n = 0 \\\\ \n  compose(f,\\text{repeat}(f,n-1))  & n > 1 \n\\end{cases} \n$$\n\n3.7) Define the function curry2 that curries a two-argument function. That is, curry2(f) is such that\n\n$$\n\\text{curry2} ( (\\lambda (x1,x2) \\to e)) \\to (\\lambda (x1) ) \\to ((\\lambda (x2)) \\to e)\n$$\n\n$$\n(\\lambda x1:Doub) \\to ((x:Int) \\to B(x1,x2))\n$$\n\n$$\n\\text{curry2} (\\lambda(x1,x2) \\to B(x1,x2)) \\to ((\\lambda (x1)) \\to ((\\lambda (x2)) \\to B(x1,x2))\n$$\n\n3.2) Define the function uncurry2. It takes a curried function, and creates a two-argument function.\n\n$$\n(\\lambda(x1) \\to \\lambda(x2) \\to e(x1,x2)) \\to (\\lambda(x1,x2) \\to e(x1,x2))\n$$\n\n$$\n(\\lambda (x1:Doub) \\to x:(Int) \\to ) B(x1,x2))\n$$\n\n4) Write a function $\\text{fact}$ that uses the following:\n\ni. an outer function returning an inner function that maps an integer into the final result (of that factorial computation),\n\nii. looping within the inner function until the result is derived.\n\n$$\nval \\  \\text{fact}: Int \\to Int=\\lambda n =\n\n\\lambda  i= n, \\quad \\text{res =one}  \\to\n\nwhile (i \\ > 0) res = res * i --then val,\n\ni = i -1 ... do Loop (\\mathbf{G}(res), res+i,\n\n(\\lambda(x:Int) \\to i+1)\n$$\n\n$$\n(x:Int) \\to (\\lambda(x) \\to x+1)\n$$",
    "Alternative solution \u2013 currying:\n\n```scala\ndef fisapositursy (f: Int => Int => Int)(a: Int): Int = \n   val image = f(a)(a)\n   if image == f(image)(image)\n      if image == 0 image\n      else fisapositursy(f)(image)\nexample:\nfisapositursy(x = x * x)(4) -- retum 0.\n  8 gives crucial input.\n```\n\n5.1\t\n\tWrite the sum function with the following signature:\n```scala\ndef sum(f: Int => Int)(a: Int, b: Int): Int = ???\n```\nWhich returns the sum of f(i) where i ranges from a to b.\n\n**Bonus point Can your implementation be tail recursive?**\n```scala\ndef loop(acc: Int, i: Int): Int = \n  if i > b then acc\n  else loop(acc + f(i), i +1)\nloop(0, a)\n```\n\n5.2 \nWrite the quadratic function with the following signature:\n```scala\ndef quadratic(a: Int, b: Int, c: Int)(x: Int): Int =\n\t a * x * x + b *x + c\nval qf = quadratic(3,2,1) -- (x - 1) * (x - 1)\n```\n5.3\t\nUsing the above definitions, define the function  quadrintegrate which, given two integers a and b computes this function:\n```scala\n(a: Int, b: Int) => sum( quadratic(3)(a,b), b)\n```\n",
    "Lab 3 - Merging\n  \n1) $[4,3,5,6,1]$\n   $left\\_filter(left, right\\_filter)$\n   $filter(p, acc)$\n   \n         4\n       /   \\\n      3     5\n     / \\     \\\n    2   3     6\n   /\n   1\n   \n   $right\\_filter(p, acc)$\n\n   $left\\_filter(p, right\\_filter)$\n\n   $right\\_filter(p, acc)$\n \n2) \n\n$try\\_lhs,\\ then\\ we\\ include\\ dom\\ that:$\n\n$left\\_min \\left(left\\_min(left\\_incl(dom))\\ in\\ that\\ left \\right)$\n\n$right\\_min \\left(left\\_min(left\\_incl(dom))\\ in\\ that\\ left \\right)$\n\n$Note:$\n\n$Look\\ at\\ function\\ \\text {Insert},\\ we\\ don't\\ have\\ access\\ to\\ dom,\\ right,\\ left\\ from\\ that.$",
    "def union (left: TreeSet, right: TreeSet) -> TreeSet =\n  right.union (left .union (left, include(elem)))\n\n8 left =           6 right =                1\n (                  2      4)                       (     1           2        )\n\nright.union (left .union (left, include (elem)))\n\n \\displaystyle {\\textstyle \\bigcup _{}^{}{\\left\\{{1,2}\\right\\},}}\\displaystyle {\\textstyle \n\nright.union (left, 3)\n\n unions \"les petits\"\n\nleft.union (left, 2)\n\n \\displaystyle \\textstyle \\bigcup _{}^{{right,\\  elem(3)}} \\displaystyle =\n\n \\displaystyle \\bigcup _{}^{}{\\left\\{{1,2,3,4}\\right\\}}.\n\nleft.union (left, 2)\n\n unions \"petits\"\n\nleft.union (left, 2 )\n\nright.union (left.union (left, 2, include elem)),\nright.union ({left .union (left, include elem)} )\n\nleft.union ({right_3 })\n= \\displaystyle \\textstyle {left .union (left*, 1)} (include elem)\n\nle \n\n=right.union (right.union({3}), 4)=\nleft.union (left, 4)\n\nfinal union\n\nright.union ({right_union (left, 4 )}) =\n\n({left.union (left, right)\n\nleft.union (left, 4 }) \\textstyle\n\nright.union (include elem=)\n\nleft.union final (right_goal",
    "$ \\text{left\\_min(left\\_5)} = 5 $ \n\n$ \\text{right\\_min(right\\_6)} = \\text{right\\_min(right\\_5 \\text{ and } right\\_1)} $ \n\n$ \\text{right\\_min(left\\_6)} = 6 $ \n\n\u0e2b\u0e32!!\n\n$3) \\text{Find next networked element from tree:}$ \n\n\\begin{verbatim}\ntree: \n        2\n       / \\\n      /   \\\n     3     4\n    / \\     \\\n   5   3     1\n\\end{verbatim}\n\n\n$ \\text{def nextnetworked (tree):} $ \n$ \\text{def comparetwos(t1: \\text{Tree}, t2: \\text{Tree}): \\text{Tree}} = $ \n$       \\text{if  t1. subnets + t2. subnets then t1 else t2} $ \n\n$ \\text{if  left.isEmpty \\& \\& right.isEmpty.team elem} $ \n\n$ \\text{else if right.empty then comparetwos(left,nextnetworked,elem)} $ \n\n$ \\text{else if left.isEmpty then comparetwos(right,nextnetworked,elem)} $ ",
    "tree\n\n$C := \\text{compareTrees} \\left(\\text{right}, \\text{notRetained}, \\text{compareTrees}(\\text{left}, \\text{notRetained}, \\text{done})\\right)$\n\n$\\text{tree:}$\n$1$\n $2$\n $ \\text{elan}$\n\n$\\text{right:}$\n\n$(cite, notRetained:)$\n$C := \\text{compareTrees} \\left(\\text{right}, \\text{notRetained}, \\text{compareTrees}(\\text{left}, \\text{notRetained}, \\text{done})\\right)$\n\n$= 5$\n\n$\\leftarrow \\text{notRetained:}\\right)$\n$\\text{case: Done})$ \n$C := \\text{compareTrees} \\left(\\text{right}, \\text{notRetained}, \\text{compareTrees}(\\text{left}, \\text{notRetained}, \\text{done})\\right)$ \n\n$= 5$\n\n$(cite \\quad notRetained:)$\n\n$\\text{case: Done})$ \n\n$C := \\text{compareTrees} \\left(\\text{right}, \\text{notRetained}, \\text{compareTrees}(\\text{left}, \\text{notRetained}, \\text{done})\\right)$\n$= 5$\n\n$cite$\n$\\text{move}$\n$= 5$\n\n$\\text{case 1:}\\text{elan}=2$\n\n$(cite \\quad notRetained:)$\n$= 5$\n\n$\\text{move(Done)}$\n\n$\\cite \\leftarrow notRetained:)$\n\n$\\text{case 1:}\\text{elan}=5$",
    "EPFL\n\nPutting the Pieces Together\n\nPrinciples of Functional Programming",
    "Once upon a time, before smartphones, phone keys had mnemonics assigned to them.\n\n```scala\nval mnemonics = Map(\n  '2' -> \"ABC\", '3' -> \"DEF\", '4' -> \"GHI\", '5' -> \"JKL\",\n  '6' -> \"MNO\", '7' -> \"PQRS\", '8' -> \"TUV\", '9' -> \"WXYZ\")\n```\n\nAssume you are given a dictionary words as a list of words.\n\n**Design a method encode such that**\n\n```scala\nencode(phoneNumber)\n```\n\nproduces all phrases of words that can serve as mnemonics for the phone number.\n\nExample: The phone number \"7225247386\" should have the mnemonic _Scala is fun_ as one element of the set of solution phrases.",
    "class Coder(words: List[String]):\n  val mnemonics = Map(...)\n\n/** Maps a letter to the digit it represents */\nprivate val charCode: Map[Char, Char] = ???\n\n/** Maps a word to the digit string it can represent */\nprivate def wordCode(word: String): String = ???\n\n/** Maps a digit string to all words in the dictionary that represent it */\nprivate val wordsForNum: Map[String, List[String]] = ???\n\n/** All ways to encode a number as a list of words */\ndef encode(number: String): Set[List[String]] = ???",
    "Implementation (1)\n\nclass Coder(words: List[String]):\n  val mnemonics = Map(...)\n\n  /** Maps a letter to the digit it represents */\n  private val charCode: Map[Char, Char] =\n    for\n      (digit, str) <- mnemonics\n      ltr <- str\n    yield ltr -> digit",
    "Implementation (1)\n\nclass Coder(words: List[String]):\n  val mnemonics = Map(...)\n\n  /** Maps a letter to the digit it represents */\n  private val charCode: Map[Char, Char] =\n    for (digit, str) <- mnemonics; ltr <- str yield ltr -> digit\n\n  /** Maps a word to the digit string it can represent */\n  private def wordCode(word: String): String = \n    word.toUpperCase.map(charCode)",
    "Implementation (1)\n\nclass Coder(words: List[String]):\n  val mnemonics = Map(...)\n\n/** Maps a letter to the digit it represents */\nprivate val charCode: Map[Char, Char] =\n  for (digit, str) <- mnemonics; ltr <- str yield ltr -> digit\n\n/** Maps a word to the digit string it can represent */\nprivate def wordCode(word: String): String = word.toUpperCase.map(charCode)\n\n/** Maps a digit string to all words in the dictionary that represent it */\nprivate val wordsForNum: Map[String, List[String]] =\n  words.groupBy(wordCode).withDefaultValue(Nil)",
    "/** All ways to encode a number as a list of words */\n\ndef encode(number: String): Set[List[String]] =\n\nIdea: use divide and conquer",
    "/** All ways to encode a number as a list of words */\n\ndef encode(number: String): Set[List[String]] =\n  if number.isEmpty then Set(Nil)\n  else\n    for\n      splitPoint <- (1 to number.length).toSet\n      word <- wordsForNum(number.take(splitPoint))\n      rest <- encode(number.drop(splitPoint))\n    yield word :: rest",
    "Testing It\n\nA test program:\n\n@main def code(number: String) =\n  val coder = Coder(List(\n    \"Scala\", \"Python\", \"Ruby\", \"C\",\n    \"rocks\", \"socks\", \"sucks\", \"works\", \"pack\"))\n  coder.encode(number).map(_.mkString(\" \"))\n\nA sample run:\n\n> scala code \"7225276257\"\nHashSet(Scala rocks, pack C rocks, pack C socks, Scala socks)",
    "Background\n\nThis example was taken from:\n    Lutz Prechelt: An Empirical Comparison of Seven Programming\n    Languages. IEEE Computer 33(10): 23-29 (2000)\n\nTested with Tcl, Python, Perl, Rexx, Java, C++, C.\n\nCode size medians:\n    - 100 loc for scripting languages\n    - 200-300 loc for the others",
    "Benefits\n\nScala's immutable collections are:\n\n\u25ba easy to use: few steps to do the job.\n\u25ba concise: one word replaces a whole loop.\n\u25ba safe: type checker is really good at catching errors.\n\u25ba fast: collection ops are tuned, can be parallelized.\n\u25ba universal: one vocabulary to work on all kinds of collections.\n\nThis makes them an attractive tool for software development",
    "Exercise Session 11\n\nIn these exercises, you are asked to write higher-order functions in the simple untyped language supported by the interpreter for recursive higher-order functions that we developed in the lectures.\n\nQUESTION 1\nIn this exercise, you will be working with Church numerals.\n\nChurch numerals are a representation of natural numbers using only functions. In this encoding, a number $n$ is represented by a function that maps any function $f$ to its $n$-fold composition.\n\nFor example, 0, 1, 2 and 3 are represented as follows:\n\n\\begin{verbatim}\ndef zero (f: \u03c4 \u2192 \u03c4) = \u03bb (x: \u03c4) \u2192 x\ndef one (f: \u03c4 \u2192 \u03c4) = \u03bb (x: \u03c4) \u2192 (f x)\ndef two (f: \u03c4 \u2192 \u03c4) = \u03bb (x: \u03c4) \u2192 (f (f x))\ndef three (f: \u03c4 \u2192 \u03c4) = \u03bb (x: \u03c4) \u2192 (f (f (f x)))\n\\end{verbatim}\n\nQuestion 1.1\nGive an implementation of the $suc$ function that takes a Church numeral and returns its successor.\n\nFor example, $(suc \\ zero)$ evaluates to the definition of $one$ and $(suc \\ one)$ evaluates to the definition of $two$.\n\nQuestion 1.2\nGive an implementation of the $add$ function that takes two Church numerals and returns their sum, using $suc$.\n\nQUESTION 2\nIn this exercise, you will be working with Church-encoded lists.\n\nMuch like Church numerals, Church-encoded lists are a representation of lists using only functions.\n\nIn this encoding, a list $l$ is represented by a function that takes $z$ to $l$'s elements and returns the first one if the list is empty or the application of $c$ to the first element and the next list if $l$ is non-empty:\n\n\\begin{verbatim}\n(nil) a c z = z\n(cons b l) a c z = c b (a c z)\n\\end{verbatim}\n\nFor example, $[1, 2, 3]$ would be represented in this encoding as follows:\n\n\\begin{verbatim}\n(cons 1 (cons 2 (cons 3 nil)))\n\\end{verbatim}\n\nWith this encoding, lists decomposition is achieved by \"applying\" the list to a pair of continuations, one for the empty and one for the non-empty case. For example, concatenation of two Church-encoded lists could be implemented as follows:\n\n\\begin{verbatim}\ndef cat (l1: \u2200 \u03b1 (\u03c41 \u21d2 \u03c42) \u2192 \u03c42) (l2: \u2200 \u03b1 (\u03c41 \u21d2 \u03c42) \u2192 \u03c42) : \u2200 \u03b1 (\u03c41 \u21d2 \u03c42) \u2192 \u03c42 =\n  l1 (\u03bb l12 b z \u2192 (cons b (cat l12 l2))) l2\n\\end{verbatim}",
    "Question 2.1\nGive an implementation of the size function that takes a Church-encoded list and returns its size as a Church numeral. You are allowed to use the succ function defined earlier.\n\nQuestion 2.2\nGive an implementation of the map function which takes a Church-encoded list and a function and returns the list mapped with the function (in the sense of l1st.map). You may use recursion in your definitions.\n\nQuestion 2.3\nGive an implementation of the foldRight function which takes a Church-encoded list and a function and returns the result of foldRight. You may use recursion in your definitions.\n\nNote: currying function input\n\nBy repeating the process n times...\n\nn-th successor of m.\n\n... the redex will be applied n times to m\n\nQUESTION 1\nBy counting the number of applications of the redex and replacing the variable y.\n\nEvery church numeral can be thought of as using the zero function followed by the n-th successor f.\n\nA church numeral is always in the form of:\n$\\lambda f. \\lambda x. f^{n}(x)$\n\nWhere f is an unknown function we want to apply.\n\nZero = $\\lambda f.\\lambda x.x$ n m\n\nSucc = $\\lambda n. \\lambda f. \\lambda x. f(n(f)(x))$\n\n...\nfzero = $\\lambda f.\\lambda x.x$\n\nfsucc = $\\lambda f.\\lambda n. \\lambda f. \\lambda x. f(n(f)(x))$\n\nGive an implementation of the succ function that defines the Church numeral successor.\nCreate a direct translation of the written definitions of zero and succ into lambda definitions.\n\n$q1$\n$zero = (\\lambda f \\rightarrow (\\lambda x \\rightarrow x))$\n\n$s\\lambda \\text {succ} = (\\lambda n \\rightarrow (\\lambda f \\rightarrow (\\lambda x \\rightarrow (f((n f) x)))))$\n\nQuestion 1.2\nGive an implementation of the add function that takes two Church numerals and returns their sum, using succ.\n\n$\\lambda add = (n \\rightarrow (m \\rightarrow n(\\text{succ}(m))))$\n\n0-th successor of m",
    "Much like Church numerals, Church-encoded lists are a representation of lists using only functions.\n\nIn this encoding, a list is represented by a function that takes two arguments and returns the first one if the list is empty or combines the first argument with the head of the list if the list is non-empty:\n\n\\[ \\left(2 :: 1 :: \\text{nil}\\right)\\ \\rightarrow \\ \\lambda c n.\\ c\\ 2\\ \\left(c \\ 1\\ n\\right) \\]\n\nFor example, \\( \\text{List(1, 2, 3)} \\) will be represented in this encoding as follows:\n\n\\[  \\lambda c n. c\\ 1\\ \\left(c\\ 2\\ \\left(c\\ 3\\ n\\right) \\right) \\]\n\nQuestion 2.1\n\nGive an implementation of the \ud835\udc60\ud835\udc56\ud835\udc67\ud835\udc52 function that takes a Church-encoded list and returns its size as a Church numeral. You are allowed to use the \ud835\udc60\ud835\udc62\ud835\udc50\ud835\udc50 function defined earlier.\n\n\n\\[ \\text{def}\\ \\lambda l.\\ \\left(\\lambda x.\\ \ud835\udc3f(x \\ 2)\\ 0\\right) \\rightarrow \\left(n.\\ \ud835\udc5b + 1 \\rightarrow \ud835\udc60\ud835\udc62\ud835\udc50\ud835\udc50(\\text{\ud835\udc60\ud835\udc56\ud835\udc67\ud835\udc52} (\ud835\udc61))\\right) \\]\n\n\nQuestion 2.2\n\nGive an implementation of the \ud835\udc5a\ud835\udc4e\ud835\udc5d function which takes a Church-encoded list and a function and returns the list mapped with the function on the set of non-empty lists. You may use recursion in your definition.\n\n\\[ \\text{def}\\ \\lambda \ud835\udc5a\ud835\udc4e\ud835\udc5d\\ =\\ \\left(\\lambda \ud835\udc53\\ n.\\ \ud835\udc5e\\left(\ud835\udc53(\\text{\ud835\udc5b2}\\right) \\rightarrow \ud835\udc5a\ud835\udc4e\ud835\udc5d(\\text{\ud835\udc53 \ud835\udc61}))\\right) \\]\n\n\nQuestion 2.3\n\nGive an implementation of the \ud835\udc53\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc40\ud835\udc4e\ud835\udc5d function which takes a Church-encoded list and a function and returns the result of flattening. You may use recursion in your definition.\n\n\\[ \\text{def \ud835\udc53\ud835\udc59\ud835\udc4e\ud835\udc61\ud835\udc40\ud835\udc4e\ud835\udc5d}\\ =\\ \\left( \\Rightarrow \ud835\udc5b2\\ = \\Rightarrow \ud835\udc5e2\\Rightarrow (\ud835\udc65\\rightarrow\u27e0 \ud835\udc61 \ud835\udc5b (n+1)\u27c2) \\text{def L(n2}\\left(\ud835\udc53(a\ud835\udc61)(a2)\\right)\\right) \\]",
    "Identity and Change\n\nPrinciples of Functional Programming\n\nMartin Odersky",
    "Identity and Change\n\nAssignment poses the new problem of deciding whether two expressions are \u201cthe same\u201d\n\nWhen one excludes assignments and one writes:\n\nval $x = E$; val $y = E$\n\nwhere $E$ is an arbitrary expression, then it is reasonable to assume that $x$ and $y$ are the same. That is to say that we could have also written:\n\nval $x = E$; val $y = x$\n\n(This property is usually called referential transparency)",
    "But once we allow the assignment, the two formulations are different. For example:\n\n    val x = BankAccount()\n    val y = BankAccount()\n\nQuestion: Are x and y the same?\n\n    0  Yes\n    0  No",
    "Operational Equivalence\n\nTo respond to the last question, we must specify what is meant by \"the same\".\n\nThe precise meaning of \"being the same\" is defined by the property of operational equivalence.\n\nIn a somewhat informal way, this property is stated as follows.\n\nSuppose we have two definitions $x$ and $y$.\n\n$x$ and $y$ are operationally equivalent if no possible test can distinguish between them.",
    "Testing for Operational Equivalence\n\nTo test if $x$ and $y$ are the same, we must\n\n- Execute the definitions followed by an arbitrary sequence of operations that involves $x$ and $y$, observing the possible outcomes.\n\\[ \n\\text{val } x = \\text{BankAccount}() \\\\\n\\text{val } y = \\text{BankAccount}() \\\\\nS \\\\\nx = \\text{BankAccount}() \\\\\ny = \\text{BankAccount}() \\\\\nS' = [x/y]S \n\\]\n\n- Then, execute the definitions with another sequence $S'$ obtained by renaming all occurrences of $y$ by $x$ in $S$.\n- If the results are different, then the expressions $x$ and $y$ are certainly different.\n- On the other hand, if all possible pairs of sequences $(S, S')$ produce the same result, then $x$ and $y$ are the same.",
    "Counterexample for Operational Equivalence\n\nBased on this definition, let's see if the expressions\n\nval x = BankAccount()\nval y = BankAccount()\n\ndefine values x and y that are the same.\n\nLet's follow the definitions by a test sequence:\n\nval x = BankAccount()\nval y = BankAccount()\nx.deposit(30) // : Int = 30\ny.withdraw(20) // java.lang.Error: insufficient funds",
    "Now rename all occurrences of $y$ with $x$ in this sequence. We obtain:\n\n$ \\text{val } x = \\text{BankAccount()} $\n\n$ \\text{val } y = \\text{BankAccount()} $\n\n$ x.deposit(30) \\quad // : \\text{ Int } = 30 $\n\n$ x.withdraw(20) \\quad // : \\text{ Int } = 10 $\n\nThe final results are different. We conclude that $x$ and $y$ are not the same.",
    "On the other hand, if we define\n\n$ \\text{val}\\ x = \\text{BankAccount}() $\n\n$ \\text{val}\\ y = x $\n\nthen no sequence of operations can distinguish between $x$ and $y$, so $x$ and $y$ are the same in this case.",
    "Assignment and The Substitution Model\n\nThe preceding examples show that our model of computation by substitution cannot be used.\n\nIndeed, according to this model, one can always replace the name of a value by the expression that defines it. For example, in\n```\nval x = BankAccount()\nval y = x\n```\nthe $x$ in the definition of $y$ could be replaced by $BankAccount()$.\n\nBut we have seen that this change leads to a different program!\n\nThe substitution model ceases to be valid when we add the assignment.\n\nIt is possible to adapt the substitution model by introducing a store, but this becomes considerably more complicated.",
    "Other Collections\n\nPrinciples of Functional Programming",
    "Other Sequences\n\nWe have seen that lists are linear. Access to the first element is much faster than access to the middle or end of a list.\n\nThe Scala library also defines an alternative sequence implementation, Vector.\n\nThis one has more evenly balanced access patterns than List.",
    "Operations on Vectors\n\nVectors are created analogously to lists:\n```scala\nval nums = Vector(1, 2, 3, -88)\nval people = Vector(\"Bob\", \"James\", \"Peter\")\n```\nThey support the same operations as lists, with the exception of `::`:\n\nInstead of `x :: xs`, there is\n```scala\nx +: xs  // Create a new vector with leading element x, followed by all elements of xs.\nxs :+ x  // Create a new vector with trailing element x, preceded by all elements of xs.\n```\n(Note that the `:` always points to the sequence.)",
    "Collection Hierarchy\n\nA common base class of List and Vector is Seq, the class of all sequences.\n\nSeq itself is a subclass of Iterable.",
    "Arrays and Strings support the same operations as Seq and can implicitly be converted to sequences where needed.\n\n(They cannot be subclasses of Seq because they come from Java)\n\nval xs: Array[Int] = Array(1, 2, 3)\nxs.map(x => 2 * x)\n\nval ys: String = \"Hello world!\"\nys.filter(_.isUpper)",
    "Ranges\n\nAnother simple kind of sequence is the range.\n\nIt represents a sequence of evenly spaced integers.\n\nThree operators:\n\nto (inclusive), until (exclusive), by (to determine step value):\n\nval r: Range = 1 until 5          1 2 3 4\nval s: Range = 1 to 5             1 2 3 4 5\n\n1 to 10 by 3                      1 4 7 10\n6 to 1 by -2                      6 4 2\n\nA Range is represented as a single object with three fields: lower bound, upper bound, step value.",
    "Some more Sequence Operations:\n\n```\nxs.exists(p)  true if there is an element x of xs such that p(x) holds, \n              false otherwise.\nxs.forall(p)  true if p(x) holds for all elements x of xs, false other- \n              wise.\nxs.zip(ys)    A sequence of pairs drawn from corresponding elements \n              of sequences xs and ys.\nxs.unzip      Splits a sequence of pairs xs into two sequences consist- \n              ing of the first, respectively second halves of all pairs.\nxs.flatMap(f) Applies collection-valued function f to all elements of\n              xs and concatenates the results\nxs.sum        The sum of all elements of this numeric collection.\nxs.product    The product of all elements of this numeric collection\nxs.max        The maximum of all elements of this collection (an\n              Ordering must exist)\nxs.min        The minimum of all elements of this collection\n```",
    "Example: Combinations\n\nTo list all combinations of numbers x and y where x is drawn from 1..M and y is drawn from 1..N:\n\n$$(1 \\text{ to } M).flatMap(x => (1 \\text{ to } N).map(y => (x, y)))$$\n\nreturns vector",
    "Example: Scalar Product\n\nTo compute the scalar product of two vectors:\n\ndef scalarProduct(xs: Vector[Double], ys: Vector[Double]): Double =\n    xs.zip(ys).map((x, y) => x * y).sum\n\nNote that there is some automatic decomposition going on here.\n\nEach pair of elements from xs and ys is split into its halves which are then passed as the x and y parameters to the lambda.",
    "Example: Scalar Product\n\nIf we wanted to be more explicit, we could also write scalar product like this:\n\n```scala\ndef scalarProduct(xs: Vector[Double], ys: Vector[Double]): Double =\n  xs.zip(ys).map(xy => xy._1 * xy._2).sum\n```",
    "Example: Scalar Product\n\nOn the other hand, if we wanted to be more even more concise, we could also write it like this:\n\n```scala\ndef scalarProduct(xs: Vector[Double], ys: Vector[Double]): Double =\n  xs.zip(ys).map(_ * _).sum\n```",
    "Exercise:\n\nA number $n$ is prime if the only divisors of $n$ are 1 and $n$ itself.\n\nWhat is a high-level way to write a test for primality of numbers? For once, value conciseness over efficiency.\n\n$\\texttt{def isPrime(n: Int): Boolean =}$\n\n$\\texttt{  (2 to n - 1).forall(d => n \\% d == 0)}$\n\nor:\n\n$2 \\leq n$.",
    "Translation of For\n\nPrinciples of Functional Programming",
    "The syntax of for is closely related to the higher-order functions map, flatMap and filter.\n\nFirst of all, these functions can all be defined in terms of for:\n\n```\ndef mapFun[T, U](xs: List[T], f: T => U): List[U] = \n    for x <- xs yield f(x)\n\ndef flatMap[T, U](xs: List[T], f: T => Iterable[U]): List[U] = \n    for x <- xs; y <- f(x) yield y\n\ndef filter[T](xs: List[T], p: T => Boolean): List[T] = \n    for x <- xs if p(x) yield x\n```",
    "Translation of For (1)\n\nIn reality, the Scala compiler expresses for-expressions in terms of map, flatMap and a lazy variant of filter.\n\nHere is the translation scheme used by the compiler (we limit ourselves here to simple variables in generators)\n\n1. A simple for-expression\n\nfor x <- e1 yield e2\n\nis translated to\n\ne1.map(x => e2)",
    "2. A for-expression\n\nfor x <- e1 if f; s yield e2\n\nwhere $f$ is a filter and $s$ is a (potentially empty) sequence of generators and filters, is translated to\n\nfor x <- e1.withFilter(x => f); s yield e2\n\n(and the translation continues with the new expression)\n\nYou can think of withFilter as a variant of filter that does not produce an intermediate list, but instead applies the following map or flatMap function application only to those elements that passed the test.",
    "Translation of For (3)\n\n3. A for-expression\n$$\\text{for } x \\leftarrow e1; y \\leftarrow e2; s \\, \\text{yield} \\, e3$$\nwhere s is a (potentially empty) sequence of generators and filters, is translated into\n$$e1.\\text{flatMap}(x => \\text{for } y \\leftarrow e2; s \\, \\text{yield} \\, e3)$$\n(and the translation continues with the new expression)",
    "Example\n\nTake the for-expression that computed pairs whose sum is prime:\n\nfor\n  i <- 1 until n\n  j <- 1 until i\n  if isPrime(i + j)\nyield (i, j)\n\nApplying the translation scheme to this expression gives:\n\n(1 until n).flatMap(i =>\n  (1 until i)\n    .withFilter(j => isPrime(i+j))\n    .map(j => (i, j)))\n\nThis is almost exactly the expression which we came up with first!",
    "Exercise\n\nTranslate\n\nfor b <- books; a <- b.authors if a.startsWith(\"Bird\")\n  yield b.title\n\ninto higher-order functions.",
    "Exercise\n\nfor b <- books; a <- b.authors if a.startsWith(\"Bird\")\nyield b.title\n\nThe expression above expands to which of the following two expressions?\n\n1.  \n\nbooks.flatMap(b => \n    b.authors.withFilter(a => \n        a.startsWith(\"Bird\")).map(a => b.title))\n\n2.  \n\nbooks.map(b => \n    b.authors.flatMap(a => \n        if a.startsWith(\"Bird\") then b.title))",
    "Generalization of for\n\nInterestingly, the translation of for is not limited to lists or sequences, or even collections;\n\nIt is based solely on the presence of the methods map, flatMap and withFilter.\n\nThis lets you use the for syntax for your own types as well - you must only define map, flatMap and withFilter for these types.\n\nThere are many types for which this is useful: arrays, iterators, databases, optional values, parsers, etc.",
    "For example, books might not be a list, but a database stored on some server.\n\nAs long as the client interface to the database defines the methods map, flatMap and withFilter, we can use the for syntax for querying the database.\n\nThis is the basis of database connection frameworks such as Slick or Quill, as well as big data platforms such as Spark.",
    "Variance\n\nPrinciples of Functional Programming",
    "Variance\n\nYou have seen the the previous session that some types should be covariant whereas others should not.\n\nRoughly speaking, a type that accepts mutations of its elements should not be covariant.\n\nBut immutable types can be covariant, if some conditions on methods are met.",
    "Definition of Variance\n\nSay $C[T]$ is a parameterized type and A, B are types such that $A <: B$.\n\nIn general, there are three possible relationships between $C[A]$ and $C[B]$:\n\n$C[A] <: C[B]$                              C is covariant\n$C[A] >: C[B]$                              C is contravariant\nneither $C[A]$ nor $C[B]$ is a subtype of the other       C is nonvariant",
    "Definition of Variance\n\nSay C[T] is a parameterized type and A, B are types such that A <: B.\n\nIn general, there are three possible relationships between C[A] and C[B]:\n\n$C[A] <: C[B]$ $ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $ C is covariant\n\n$C[A] >: C[B]$ $ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $ C is contravariant\n\nneither $C[A]$ nor $C[B]$ is a subtype of the other $ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $ C is nonvariant\n\nScala lets you declare the variance of a type by annotating the type parameter:\n\n```scala\nclass C[+A] { ... }         // C is covariant\nclass C[-A] { ... }         // C is contravariant\nclass C[A] { ... }          // C is nonvariant\n```",
    "Assume the following type hierarchy and two function types:\n\ntrait Fruit\nclass Apple extends Fruit\nclass Orange extends Fruit\n\ntype FtoO <: Fruit \u2192 Orange\ntype AtoF <: Apple \u2192 Fruit\n\nAccording to the Liskov Substitution Principle, which of the following should be true?\n\n$\\checkmark$ FtoO <: AtoF\n\n$\\times$ AtoF <: FtoO\n\n$0$ A and B are unrelated.",
    "Typing Rules for Functions\n\nGenerally, we have the following rule for subtyping between function types:\n\nIf $A2 <: A1$ and $B1 <: B2$, then\n\n$A1 => B1 <: A2 => B2$\n\nSo functions are contravariant in their argument type(s) and covariant in their result type.\n\nThis leads to the following revised definition of the $Function1$ trait:\n\n\\begin{verbatim}\npackage scala\ntrait Function1[-T, +U]:\n  def apply(x: T): U\n\\end{verbatim}",
    "Variance Checks\n\nWe have seen in the array example that the combination of covariance with certain operations is unsound.\n\nIn this case the problematic operation was the update operation on an array.\n\nIf we turn Array into a class, and update into a method, it would look like this:\n\nclass Array[+T]:\n    def update(x: T) = ...\n\nThe problematic combination is\n\n- the covariant type parameter T\n- which appears in parameter position of the method update.",
    "Variance Checks (2)\n\nThe Scala compiler will check that there are no problematic combinations when compiling a class with variance annotations.\n\nRoughly,\n\n- covariant type parameters can only appear in method results.\n- contravariant type parameters can only appear in method parameters.\n- invariant type parameters can appear anywhere.\n\nThe precise rules are a bit more involved, fortunately the Scala compiler performs them for us.",
    "Variance-Checking the Function Trait\n\nLet's have a look again at Function1:\n\n```scala\ntrait Function1[-T, +U] {\n  def apply(x: T): U\n}\n```\n\nHere,\n\n- $T$ is contravariant and appears only as a method parameter type\n- $U$ is covariant and appears only as a method result type\n\nSo the method is checks out OK.",
    "Let's get back to the previous implementation of lists.\n\nOne shortcoming was that Nil had to be a class, whereas we would prefer it to be an object (after all, there is only one empty list).\n\nCan we change that?\n\nYes, because we can make List covariant.\n\nHere are the essential modifications:\n\ntrait List[+T]\n  ...\n\nobject Empty extends List[Nothing]\n  ...",
    "Here a definition of lists that implements all the cases we have seen so far:\n\ntrait List[+T]:\n\n  def isEmpty = this match\n    case Nil => true\n    case _ => false\n    \n  override def toString =\n    def recur(prefix: String, xs: List[T]): String = xs match\n      case x :: xs1 => s\"$prefix$x${recur(\", \", xs1)}\"\n      case Nil => \")\"\n    recur(\"List(\", this)",
    "Idealized Lists(2)\n\ncase class ::[+T](head: T, tail: List[T]) extends List[T]\ncase object Nil extends List[Nothing]\n\nextension [T](x: T) def :: (xs: List[T]): List[T] = ::(x, xs)\n\nobject List:\n  def apply() = Nil\n  def apply[T](x: T) = x :: Nil\n  def apply[T](x1: T, x2: T) = x1 :: x2 :: Nil\n  ...\n\n(We'll see later how to do with just a single apply method using a vararg parameter.)",
    "Making Classes Covariant\n\nSometimes, we have to put in a bit of work to make a class covariant.\n\nConsider adding a `prepend` method to `List` which prepends a given element, yielding a new list.\n\nA first implementation of prepend could look like this:\n\n```\ntrait List[+T]:\n  def prepend(elem: T): List[T] = ::(elem, this)\n```\n\nBut that does not work!",
    "Exercise\n\nWhy does the following code not type-check?\n\ntrait List[+T]:\n  def prepend(elem: T): List[T] = :: (elem, this)\n\nPossible answers:\nO  prepend turns List into a mutable class.\nX  prepend fails variance checking.\nO  prepend's right-hand side contains a type error.",
    "Prepend Violates LSP\n\nIndeed, the compiler is right to throw out List with prepend, because it violates the Liskov Substitution Principle:\n\nHere's something one can do with a list xs of type $List[Fruit]$:\n\nxs.prepend(Orange)\n\nBut the same operation on a list ys of type $List[Apple]$ would lead to a type error:\n\nys.prepend(Apple)\n   ^ type mismatch\n     required: Apple\n     found:    Orange\n\nSo, $List[Apple]$ cannot be a subtype of $List[Fruit]$.",
    "Lower Bounds\n\nBut prepend is a natural method to have on immutable lists!\n\nQ: How can we make it variance-correct?",
    "Lower Bounds\n\nBut prepend is a natural method to have on immutable lists!\n\nQ: How can we make it variance-correct?\n\nWe can use a lower bound: $U$ is a supertype param of $T$.\n\n```scala\ndef prepend[U >: T](elem: U): List[U] = ::(elem, this)\n```\n\nThis passes variance checks, because:\n\n- covariant type parameters may appear in lower bounds of method type parameters\n- contravariant type parameters may appear in upper bounds.",
    "Assume prepend in trait List is implemented like this:\n\n```scala\ndef prepend [U >: T] (elem: U): List[U] = ::(elem, this)\n```\n\nWhat is the result type of this function:\n\n```scala\ndef f(xs: List[Apple], x: Orange) = xs.prepend(x) ?\n```\n\nPossible answers:\n0 does not type check\n0 List[Apple]\n0 List[Orange]\n0 List[Fruit]\n0 List[Any]\n\nuses Fruit as it is a supertype of Apple and Orange",
    "Extension Methods\n\nThe need for a lower bound was essentially to decouple the new parameter \nof the class and the parameter of the newly created object. Using an \nextension method such as in :: above, sidesteps the problem and is often \nsimpler:\n\n\\[\n\\text{extension [T](x: T):}\n\\]\n\\[\n\\text{def :: (xs: List[T]): List[T] = ::(x, xs)}\n\\]",
    "Lab 2: Purely Functional Sets\n\nIn this assignment, you will work with a functional representation of sets based on the mathematical notion of characteristic functions. The goal is to gain practice with higher-order functions.\n\nSETUP\n\n```\ncode --force --install-extension scala-lang.scala\n```\n\nYou can use the following commands to make a fresh clone of your repository:\n\nYou can always refer to \n\n- the example guide on the development workflow.\n- this guide for details on the submission system. Make sure to submit your assignment before the deadline indicated on Moodle.\n- The documentation of the Scala standard library\n- The documentation of the Java standard library\n\nREPRESENTATION\n\nWe will work with sets of integers.\n\nAs an example to motivate our representation, how would you represent the set of all negative integers? You cannot list them all... we need say by now: If you give me an integer, I can tell you whether it's in the set or not. In maths, we long for x, I would say x \u2264 0.\n\nMathematically, we call the function which takes an integer as argument and which returns a boolean indicating whether the given integer belongs to the set, the characteristic function of the set. For example, we can characterize the set of negative integers by the characteristic function $x => x \u2264 0$.\n\nThen, therefore to represent a set by its characteristic function and define a type alias for this type\n\n```\ntype FunSet = int => Boolean\n```\n\nUsing this representation, we define a function that tests for the presence of a value in a set:\n\n```\ndef contains(s: FunSet, elem: Int): Boolean = s(elem)\n```\n\n2.1 BASIC FUNCTIONS ON SETS",
    "Let's start by implementing basic functions on sets.\n\n1. Define a function which creates a singleton set from one integer value: the set represents the set of the one given element. Its signature is as follows:\n\n```\ndef singletonSet(elem: Int): FunSet\n```\n\n\nNow that we have a way to create singleton sets, we want to define a function that allow us to build bigger sets from smaller ones.\n\n2. Define the functions union, intersect, and diff, which takes two sets, and return, respectively, their union, intersection and differences. diff(s, t) returns a set which contains all the elements of the set $s$ that are not in the set $t$. These functions have the following signatures:\n\n```\ndef union(s: FunSet, t: FunSet): FunSet\n\ndef intersect(s: FunSet, t: FunSet): FunSet\n\ndef diff(s: FunSet, t: FunSet): FunSet\n```\n\n3. Define the function filter which selects only the elements of a set that are accepted by a given predicate $p$. The filtered elements are returned as a new set. The signature of filter is as follows:\n\n```\ndef filter(s: FunSet, p: Int => Boolean): FunSet\n```\n\n2.2 QUERIES AND TRANSFORMATIONS ON SETS\n\nIn this part, we are interested in functions used to make requests on elements of a set. The first function tests whether a given predicate is true for all elements of the set. This forall function has the following signature:\n\n```\ndef forall(s: FunSet, p: Int => Boolean): Boolean\n```\n\nNote that there is no direct way to find which elements are in a set, contains only allows to know whether a set contains a specific element. Thus we need to define our set in terms of something we can iterate. We shall consider that an integer $x$ is included in the set, and if so, do something with it. Here, we consider that an integer has the property $-1000 \\leq x \\leq 1000$.\n\nWe are free to use linear or higher recursion. For this, use a helper function nested in forall. Its structure is as follows (replace the ???):\n\n```\ndef forall(s: FunSet, p: Int => Boolean): Boolean = {\n\n  def iter(elem: Int): Boolean = {\n    if (???) ???\n    else if (???) ???\n    else iter(???) \n  }\n\n  iter(???)\n}\n```",
    "2. Using tools2, implement a function exists which tests whether a set contains at least one element for which the given predicate is true. Note that the functions forall and exists behave like the universal and existential quantifiers of first-order logic.\n\n\\[\n\\text{def exists}(s: \\text{FunSet}, p: \\text{Int} => \\text{Boolean}): \\text{Boolean}\n\\]\n\n3. Finally, write a function map which transforms a given set into another one by applying to each of its elements the given function. map has the following signature:\n\n\\[\n\\text{def map}(s: \\text{FunSet}, f: \\text{Int} => \\text{Int}): \\text{FunSet}\n\\]\n\nEXTRA HINTS\n- Sets are represented as functions. Think about what it means for an element to belong to a set, in terms of function evaluation. For example, how do you represent a set that contains all numbers between 1 and 100?\n- Most of the solutions for this assignment can be written as one-liners. If you have more, you probably need to rethink your solution. In other words, this assignment needs more thinking (whiteboard, pen and paper) than coding ;-).\n- If you are having some trouble with terminology, have a look at the glossary.",
    "Class Hierarchies\n\nPrinciples of Functional Programming",
    "Abstract Classes\n\nConsider the task of writing a class for sets of integers with the following operations.\n\n\\[\n\\text{abstract class IntSet:}\n\\]\n\\[\n\\{ \n\\text{def incl(x: Int): IntSet} \\\\\n\\text{def contains(x: Int): Boolean} \n\\}\n\\]\n\nIntSet is an abstract class.\n\nAbstract classes can contain members which are missing an implementation (in our case, both incl and contains); these are called abstract members.\n\nConsequently, no direct instances of an abstract class can be created, for instance an IntSet() call would be illegal.",
    "Class Extensions\n\nLet's consider implementing sets as binary trees.\n\nThere are two types of possible trees: a tree for the empty set, and a tree consisting of an integer and two sub-trees.\n\nHere are their implementations:\n\n```scala\nclass Empty() extends IntSet:\n  def contains(x: Int): Boolean = false\n  def incl(x: Int): IntSet = NonEmpty(x, Empty(), Empty())\n```",
    "Class Extensions (2)\n\nclass NonEmpty (elem: Int, left: IntSet, right: IntSet) extends IntSet:\n  \n  def contains(x: Int): Boolean =\n    if x < elem then left.contains(x)\n    else if x > elem then right.contains(x)\n    else true\n\n  def incl(x: Int): IntSet =\n    if x < elem then NonEmpty(elem, left.incl(x), right)\n    else if x > elem then NonEmpty(elem, left, right.incl(x))\n    else this\n\nend NonEmpty",
    "Terminology\n\nEmpty and NonEmpty both extend the class IntSet.\n\nThis implies that the types Empty and NonEmpty conform to the type IntSet, i.e.\n\n\u25b6 an object of type Empty or NonEmpty can be used wherever an object of type IntSet is required.",
    "Base Classes and Subclasses\n\nIntSet is called the superclass of Empty and NonEmpty.\n\nEmpty and NonEmpty are subclasses of IntSet.\n\nIn Scala, any user-defined class extends another class.\n\nIf no superclass is given, the standard class Object in the Java package java.lang is assumed.\n\nThe direct or indirect superclasses of a class C are called base classes of C.\n\nSo, the base classes of NonEmpty include IntSet and Object.",
    "Implementation and Overriding\n\nThe definitions of contains and incl in the classes Empty and NonEmpty implement the abstract functions in the base trait IntSet.\n\nIt is also possible to redefine an existing, non-abstract definition in a subclass by using override.\n\nExample\n\n\\[\n\\begin{array}{lll}\n\\text{abstract class } \\text{Base}: & & \\text{class } \\text{Sub extends Base}: \\\\\n\\text{def foo = 1} & \\text{non-abstract} & \\text{override def foo = 2} \\\\\n\\text{def bar: Int} & \\text{abstract} & \\text{def bar = 3} \\\\\n\\end{array}\n\\]\n\nNote: override is a safety to avoid re-defining functions accidentally.",
    "Object Definitions\n\nIn the IntSet example, one could argue that there is really only a single empty IntSet.\n\nSo it seems overkill to have the user create many instances of it.\n\nWe can express this case better with an object definition:\n\nobject Empty extends IntSet:\n  def contains(x: Int): Boolean = false\n  def incl(x: Int): IntSet = NonEmpty(x, Empty, Empty)\nend Empty\n\nThis defines a singleton object named Empty.\n\nNo other Empty instance can be (or needs to be) created.\n\nSingleton objects are values, so Empty evaluates to itself.",
    "Companion Objects\n\nAn object and a class can have the same name. This is possible since Scala has two global namespaces: one for types and one for values.\n\nClasses live in the type namespace, whereas objects live in the term namespace.\n\nIf a class and object with the same name are given in the same sourcefile, we call them companions. Example:\n\nclass IntSet ...\nobject IntSet:\n  def singleton(x: Int) = NonEmpty(x, Empty, Empty)\n\nThis defines a method to build sets with one element, which can be called as IntSet.singleton(elem).\n\nA companion object of a class plays a role similar to static class definitions in Java (which are absent in Scala).",
    "Programs\n\nSo far we have executed all Scala code from the REPL or the worksheet.\nBut it is also possible to create standalone applications in Scala.\nEach such application contains an object with a main method.\nFor instance, here is the \"Hello World!\" program in Scala.\n\n```\nobject Hello:\n   def main(args: Array[String]): Unit = println(\"hello world!\")\n```\n\nOnce this program is compiled, you can start it from the command line with\n\n```\n> scala Hello\n```",
    "Writing main methods is similar to what Java does for programs.\n\nScala also has a more convenient way to do it.\n\nA stand-alone application is alternatively a function that's annotated with @main, and that can take command line arguments as parameters:\n\n\\[\n\\begin{aligned}\n&\\text{@main def birthday(name: String, age: Int) =} \\\\\n&\\text{println(s\"Happy birthday, $name! $age years old already!\")}\n\\end{aligned}\n\\]\n\nOnce this function is compiled, you can start it from the command line with\n\n\\[\n> \\text{scala birthday Peter 11}\n\\]\n\nHappy Birthday, Peter! 11 years old already!",
    "Exercise\n\nWrite a method union for forming the union of two sets. You should implement the following abstract class.\n\nabstract class IntSet:\n  def incl(x: Int): IntSet\n  def contains(x: Int): Boolean\n  def union(other: IntSet): IntSet\nend IntSet",
    "Dynamic Binding\n\nObject-oriented languages (including Scala) implement dynamic method dispatch.\n\nThis means that the code invoked by a method call depends on the runtime type of the object that contains the method.\n\nExample\n\nEmpty.contains(1)",
    "Dynamic Binding\n\nObject-oriented languages (including Scala) implement dynamic method dispatch.\n\nThis means that the code invoked by a method call depends on the runtime type of the object that contains the method.\n\nExample\n\nEmpty.contains(1)\n\n\\[ \\to [1/x] \\ [Empty/this] \\ \\text{false} \\]",
    "Dynamic Binding\n\nObject-oriented languages (including Scala) implement dynamic method dispatch.\n\nThis means that the code invoked by a method call depends on the runtime type of the object that contains the method.\n\nExample\n\nEmpty.contains(1)\n\u2192 $ [1/x] \\ [Empty/this] \\ false $\n= false",
    "Dynamic Binding (2)\n\nAnother evaluation using NonEmpty:\n\n$(NonEmpty(7, Empty, Empty)).contains(7)$\n\n$\\rightarrow [7/\\text{elem}] [7/x] [\\text{new NonEmpty}(7, Empty, Empty)/\\text{this}]$\nif $x < \\text{elem}$ then this.left.contains(x)\nelse if $x > \\text{elem}$ then this.right.contains(x) else true\n\n$= $ if $7 < 7$ then $NonEmpty(7, Empty, Empty).left.contains(7)$\nelse if $7 > 7$ then $NonEmpty(7, Empty, Empty).right.contains(7)$ else true\n\n$\\rightarrow$ true",
    "Something to Ponder\n\nDynamic dispatch of methods is analogous to calls to higher-order functions.\n\nQuestion:\n\nCan we implement one concept in terms of the other?\n\n\u25ba Objects in terms of higher-order functions?\n\u25ba Higher-order functions in terms of objects?",
    "Exercise Session 3\n\nThis week we will play with genericity and object-oriented programming concepts.\n\nA binary search tree is a binary tree such that, for a node, all elements in the left sub-tree are smaller than the element at the node, and all elements in the right sub-tree are greater than the element at the node. Therefore, binary search trees do not contain duplicate elements.\n\nBecause we want to build a generic tree structure, we also need the notion of a comparator, or a less-than-or-equal operator (denoted\u00a0$\\leq$)\u00a0for two generic elements which satisfies the following properties:\n\n- Transitivity:\u00a0$a\\leq b\\ \\&\\ b\\leq c\\ \\Rightarrow a\\leq c$.\n- Reflexivity:\u00a0$a\\leq a,\\ \\forall a.$\n- Anti-symmetry:\u00a0$a\\leq b,\\ b\\leq a\\ \\Rightarrow a=b.$\n- Totality: either\u00a0$a\\leq b,\\ b\\leq a,\\ b$\u00a0is true (or both).\n\nNote that the above defines a total order.\n\nHere is the structure we will be using for implementing these trees:\n\n```scala\ntrait Tree[T]\ncase class EmptyTree[T](leq: (T, T) => Boolean) extends Tree[T]\ncase class Node[T](left: Tree[T], right: Tree[T], elem: T, leq: (T, T) => Boolean) extends Tree[T]\n```\n\nFor consistency, all subtrees must contain the same leq parameter. Creating an empty binary tree for integers looks like:\n\n```scala\nnew EmptyTree((x: Int, y: Int) => x <= y)\n```\n\nQUESTION 1\n\nGiven only\u00a0$\\leq$\u00a0for comparison, how can you test for equality? How about strictly-less-than?\n\n```scala\ndef eq[T](a: T, b: T, leq: (T, T) => Boolean): ??? // equality //\ndef lt[T](a: T, b: T, leq: (T, T) => Boolean): ??? // strictly less than //\n```\n\nQUESTION 2\n\nDefine the size method on Tree[T], which returns its size, i.e., the number of Nodes in the tree.\n\n```scala\ndef size[T](t: Tree[T]): Int = ???\n```\n\nImplement it in two ways:\n\n```scala\n```",
    "1. within Tree(T), using pattern matching.\n2. in the subclasses of Tree(T).\n\nQUESTION 3\nDefine the add method, that adds an element to a Tree(T), and returns the resulting tree:\n\n```python\ntrait Tree[T]:\n  def add(a: T): Tree[T] = ???\n\nRemember that trees do not have duplicate values. If it is already in the tree, the result should be \nunchanged.\n\nQUESTION 4\nDefine the function toList, which returns the sorted list representation for a tree. For example, \nemptyTree.add(2).add(1).add(3).toList should return List(1, 2, 3)\n\n```python\ntrait Tree[T]:\n  def toList: List[T] = ???\n\nYou can use the Nil operator for creating an empty list, and the :: operator for adding a new element to the \nhead of a list: 1 :: List(2, 3) == List(1, 2, 3). You are free to define auxiliary functions.\n\nQUESTION 5\nDefine the function sortedList, which takes an unsorted list where no two elements are equal, and returns \na new list that contains all the elements of the previous list (and only those), in increasing order.\n\n```scala\ndef sortedList[T](l: List[T], leq: (T, T) => Boolean, ls: List[T] = List()): ???\n\nHint: you might need to define some auxiliary functions.\n\nQUESTION 6\nIf all methods are implemented using pattern matching (i.e. there are no methods implemented in \nsubclasses), can you represent your tree type as an ADT (algebraic data type) using the enum syntax?\n```",
    "QUESTION 1\n\nGiven only leq for comparison, how can you test for equality? How about strictly-less-than?\n\n\\[\n\\begin{aligned}\n&\\text{def eq[T](a: T, b: T, leq: (T, T) => Boolean): ??? // equality}\\\\\n&\\text{def le[T](a: T, b: T, leq: (T, T) => Boolean): ??? // strictly less than}\n\\end{aligned}\n\\]\n\n\\[\n\\text{eq[T](...) = } \\\\\n\\text{if leq(a,b) \\&\\& leq(b,a) then true else false}\n\\]\n\n\\[\n\\text{This can also be done in one line:} \\\\\n\\text{eq[T](...) = leq(a,b) \\&\\& leq(b,a)}\n\\]\n\n\\[\n\\text{(le[T](...) = !eq(a, b) \\&\\& leq(a,b))}\n\\]\n\nQUESTION 2\n\nDefine the size method on Tree[T], which returns its size, i.e. the number of Nodes in the tree:\n\n\\[\n\\text{trait Tree[T]:} \\\\\n\\text{def size: Int = ???}\n\\]\n\nImplement it in two ways:\n\n1. within Tree[T], using pattern matching, in the subclasses of Tree[T].\n\n\\[\n\\begin{aligned}\n&\\text{trait Tree[T]} \\\\\n&\\text{def size: Int = this match}\\\\\n&\\text{case EmptyTree (leq) => 0}\\\\\n&\\text{case Node[pt, elem, left, leq] => 1+left.size + right.size}\n\\end{aligned}\n\\]\n\n2. defining in the root classes of Tree [T]:\n\n\\[\n\\begin{aligned}\n&\\text{- requires defining a method for the sub-classes:}\\\\\n&\\text{This can still be done}\n\\end{aligned}\n\\]",
    "trait Tree[T] :\n  def size : Int  // now define abstract method\n\ncase class EmptyTree[T](tpe: T => Boolean) extends Tree[T]\n  def size : Int = 0\n\ncase class Node[T](t: T, left: Tree[T], right: Tree[T]) extends Tree[T]\n  def size : Int = 1 + left.size + right.size\n\nQUESTION 3\n\nDefine the add method, that adds an element to a Tree[T], and returns the resulting tree:\n\nLet us use pattern matching:\n\ndef add (t, T) : Tree[T] = this match\n  case EmptyTree (tpe) => if !tpe(elem) then Node(elem, EmptyTree(, tpe), this, tpe = {x=>tpe(x) || x==elem}) else EmptyTree(tpe)\n  case Node (e, left, right) =>\n    if (elem = e) then\n      Node (e, left, right)\n    else if (elem < e) then this \n       Node (e, left.add(elem), right) else this\n    else Node (e, left, right.add (elem))\n\nQUESTION 4\n\nDefine the function toList, which returns the sorted list representation for a tree. For example,\nNode(2,Node(1,Empty, Empty) , Node(3,Empty,Empty)). toList should return List (1, 2, 3).\n\ndef toList: List[T] = this match\n  Case EmptyTree => List [T] ()\n  Case Node(e, left, right) => left.toList ::: e::right .toList\n\nYou can use the Nil operator for creating an empty list, and the :: operator for adding a new element to the head of a list (e.g., 1::List(2, 3) == List(1, 2, 3)). You are free to define auxiliary functions.",
    "def textract: List[T] =\n  def textractAcc (t: Tree[T], acc: List[T]): List[T] = tree match\n    case EmptyTree() => acc\n    case Node(e, left, right, d) =>\n      textractAcc(left, e :: textractAcc(right, acc))\n  textractAcc(this, Nil)\n\nQUESTION 5\n\nDefine the function sortList(L: List), which takes an unsorted list where no two elements are equal, and returns a new list that contains all the elements of the previous list (and only these), in increasing order.\n\nHint: you might need to define some auxiliary functions first.\n\ndef insertSorted ( x: T, l: List(T)): List(T) = { x, l } match\n  case (e, EmptyTree[T]) => Node(e,_,_,_,_),EmptyTree, List(e) \n  case insertSorted (e, Node(a,_,_,,_)) => append( Node(a,left,right), \n  List(e))\n\ndef buildTree (l :List (T)): Tree(T) => Node(T)=l match \n  case Nil => EmptyTree \n  case p :: ps => buildTree auxInsert( a :: acc.add(a)) \n\nQUESTION 6\n\nIf all methods are implemented using pattern matching  (i.e. there are no methods implemented in subclasses), can you implement the Tree as an ADT (algebraic data type) using the enum syntax?\n\nenum Tree[T]\n  case void\u2219T\n  case build( left: \u2219 Tree[T] right: \u2219 Tree[T] ): Tree\n  case def functHeap( ... )",
    "``` \n    case EmptyTree[log] ...\n    case Node (left ...\n\nLab 4:\n\nUsing FoldLeft function:\nTakes associative binary operator as parameter and uses it to collapse elements from collection\n\n$$\\text{Order of traversing elements is left to right.}$$\n$$\\text{def foldLeft(B)(op:B)(op:(B, A) => B)}$$\n$$lst.foldLeft[B](z)(op:(B,A) =>B)$$\n    $$z$$: List. type B\n    $$B$$, $$A$$: element types\n\nList functors in Scala:\nList[T] where $$T$$ is element type.\nList of lists:\n\n$$val nums = List(1::2::(3::(4::Nil))$$\nMapping lists: $$e: \\textbf{List}$$\n    (elem and base lists)\n\nTraversing along a list: list. (recursive)\n\nWe can  split lists into two cases for pattern matching:\n    case Nil =>\n    case head::tail =>\n```\n",
    "Double nested lists: List [(Char, Int)]\n\nresult = List.partition (predicate= (x1,...,xn)) -> (ones_1, ones_2)\n        elems of list that                     elems of list that don't\n        satisfy predicate                      satisfy predicate.\n\nlists.setWith(li:(A,A)) -> Boolean\n                             satisfy condition\n\nexample: List of type [(a_i, 1)] List  [2..  ( x | x< 5)]\n                [( Char, weight)]   sort [2..x] ( y::y )\n\nList [...].sortWith (- weight < weight) \n                      <--- will sort in increasing order of weight.\n\nUsing sortWith with list of type Code Tree:\n\nval ls = List (CodeTree)\nWe want to order ls by increasing weight.\nTo access weight of CodeTree, we use weight (t:: CodeTree).\n\nls.sortWith\n\nls.sortWith((A, B) => weight(A) < weight (B))\n                    satisfy condition\n\n      class. pair from List of type Code Tree\n                    satisfy condition\n\nequivalent notation:\n\nls.sortWith (weight(_) < weight (_))",
    "Fonction input with 2 sets of parentheses: (Currying)\n\nexample:\n\n\\[\nproduct (R : Int => Int) (a: Int, b: Int) : Int = \n\\begin{cases} \na > b \\text{ then } 1 \\\\ \nelse R(a) * product(R)(a + 1, b) \n\\end{cases}\n\\]\n\n\\[\nproduct (x => x * x)(1, 5) \\rightarrow Int: 14400\n\\]",
    "Higher-Order List Functions\n\nPrinciples of Functional Programming",
    "Recurring Patterns for Computations on Lists\n\nThe examples have shown that functions on lists often have similar structures.\n\nWe can identify several recurring patterns, like,\n\n\u25ba transforming each element in a list in a certain way,\n\u25ba retrieving a list of all elements satisfying a criterion,\n\u25ba combining the elements of a list using an operator.\n\nFunctional languages allow programmers to write generic functions that implement patterns such as these using higher-order functions.",
    "A common operation is to transform each element of a list and then return the list of results.\n\nFor example, to multiply each element of a list by the same factor, you could write:\n\n```scala\ndef scaleList(xs: List[Double], factor: Double): List[Double] = xs match\n  case Nil => xs\n  case y :: ys => y * factor :: scaleList(ys, factor)\n```",
    "This scheme can be generalized to the method map of the List class. A simple way to define map is as follows:\n\nextension [T](xs: List[T])\n  def map[U](f: T => U): List[U] = xs match\n    case Nil    => xs\n    case x :: xs => f(x) :: xs.map(f)\n\n(in fact, the actual definition of map is a bit more complicated, because it is tail-recursive, and also because it works for arbitrary collections, not just lists).\n\nUsing map, scalelist can be written more concisely.\n\ndef scalelist(xs: List[Double], factor: Double) =\n  xs.map(x => x * factor)",
    "Exercise\n\nConsider a function to square each element of a list, and return the result. Complete the two following equivalent definitions of squareList.\n\n```scala\ndef squareList(xs: List[Int]): List[Int] = xs match\n    case Nil => Nil\n    case y :: ys => y * y :: squareList(ys)\n\ndef squareList(xs: List[Int]): List[Int] =\n    xs.map(x => x * x)\n```",
    "Filtering\n\nAnother common operation on lists is the selection of all elements satisfying a given condition. For example:\n\n```scala\ndef posElems(xs: List[Int]): List[Int] = xs match\n  case Nil => xs\n  case y :: ys => if y > 0 then y :: posElems(ys) else posElems(ys)\n```",
    "Filter\n\nThis pattern is generalized by the method filter of the List class:\n\nextension [T](xs: List[T])\n  def filter(p: T => Boolean): List[T] = t^h$s match\n    case Nil => t$4$S\n    case x :: xs => if p(x) then x :: xs.filter(p) else xs.filter(p)\n\nUsing filter, posElems can be written more concisely.\n\ndef posElems(xs: List[Int]): List[Int] =\n  xs.filter(x => x > 0)",
    "Variations of Filter\n\nBesides filter, there are also the following methods that extract sublists based on a predicate:\n\n$xs.filterNot(p)$\nSame as $xs.filter(x => !p(x))$. The list consisting of those elements of $xs$ that do not satisfy the predicate $p$.\n\n$xs.partition(p)$\nSame as $(xs.filter(p), xs.filterNot(p))$, but computed in a single traversal of the list $xs$.\n\n$xs.takeWhile(p)$\nThe longest prefix of list $xs$ consisting of elements that all satisfy the predicate $p$.\n\n$xs.dropWhile(p)$\nThe remainder of the list $xs$ after any leading elements satisfying $p$ have been removed.\n\n$xs.span(p)$\nSame as $(xs.takeWhile(p), xs.dropWhile(p))$ but computed in a single traversal of the list $xs$.",
    "Exercise\n\nWrite a function pack that packs consecutive duplicates of list elements into sublists. For instance,\n\npack(List(\"a\", \"a\", \"a\", \"b\", \"c\", \"c\", \"a\"))\n\nshould give\n\nList(List(\"a\", \"a\", \"a\"), List(\"b\"), List(\"c\", \"c\"), List(\"a\"))\n\nYou can use the following template:\n\n```\n\tdef pack[T](xs: List[T]): List[List[T]] = xs match\n  \tcase Nil => Nil\n  \tcase x :: xs1 => \n    val (same, rest) = xs1.span(y => y == x)\n    (x :: same) :: pack(rest)\n```",
    "Exercise\n\nUsing pack, write a function encode that produces the run-length encoding of a list.\n\nThe idea is to encode n consecutive duplicates of an element x as a pair $(x, n)$. For instance,\n\nencode(List(\"a\", \"a\", \"a\", \"b\", \"c\", \"c\", \"a\"))\n\nshould give\n\nList(((\"a\", 3), (\"b\", 1), (\"c\", 2), (\"a\", 1))).",
    "Exercise\n\nUsing pack, write a function encode that produces the run-length encoding of a list.\n\n\\[\n\\text{def } \\text{encode}[T](\\text{xs: List}[T]): \\text{List}[(T, \\text{Int})] = ???\n\\]\n\n\\[\n\\text{pack}(\\text{xs}).\\text{map}(\\text{x} => (\\text{x}.\\text{head}, \\text{x}. \\text{length}))\n\\]\n\n\\[\n\\text{map}(\\text{x} => (\\text{x}, \\text{xs}.\\text{length}(\\text{x})))\n\\]",
    "How Classes are Organized\n\nPrinciples of Functional Programming",
    "Packages\n\nClasses and objects are organized in packages.\n\nTo place a class or object inside a package, use a package clause at the top of your source file.\n\n\\[\n\\text{package progfun.examples}\n\\]\n\n\\[\n\\text{object Hello}\n\\]\n\nThis would place Hello in the package progfun.examples.\n\nYou can then refer it by its fully qualified name, progfun.examples.Hello.\nFor instance, to run the Hello program:\n\n\\[\n\\text{> scala progfun.examples.Hello}\n\\]",
    "Imports\n\nSay we have a class Rational in package week3.\n\nYou can use the class using its fully qualified name:\n$$\\text{val r = week3.Rational(1, 2)}$$\n\nAlternatively, you can use an import:\n$$\\text{import week3.Rational}$$\n$$\\text{val r = Rational(1, 2)}$$",
    "Forms of Imports\n\nImports come in several forms:\n\nimport week3.Rational            // imports just Rational\nimport week3.(Rational, Hello)    // imports both Rational and Hello\nimport week3.*                    // imports everything in package week3\n\nThe first two forms are called named imports.\n\nThe last form is called a wildcard import.\n\nYou can import from either a package or an object.",
    "Automatic Imports\n\nSome entities are automatically imported in any Scala program.\n\nThese are:\n\n\u25ba All members of package $scala$\n\u25ba All members of package $java.lang$\n\u25ba All members of the singleton object $scala.Predef$\n\nHere are the fully qualified names of some types and functions which you have seen so far:\n\n\\[\n\\begin{aligned}\n\\text{Int} & \\quad \\text{scala.Int} \\\\\n\\text{Boolean} & \\quad \\text{scala.Boolean} \\\\\n\\text{Object} & \\quad \\text{java.lang.Object} \\\\\n\\text{require} & \\quad \\text{scala.Predef.require} \\\\\n\\text{assert} & \\quad \\text{scala.Predef.assert} \\\\\n\\end{aligned}\n\\]",
    "Scaladoc\n\nYou can explore the standard Scala library using the scaladoc web pages.\nYou can start at\nwww.scala-lang.org/api/current",
    "Traits\n\nIn Java, as well as in Scala, a class can only have one superclass.\n\nBut what if a class has several natural supertypes to which it conforms or from which it wants to inherit code?\n\nHere, you could use traits.\n\nA trait is declared like an abstract class, just with trait instead of abstract class.\n\ntrait Planar:\n  def height: Int\n  def width: Int\n  def surface = height * width",
    "Classes, objects and traits can inherit from at most one class but arbitrary many traits.\n\nExample:\n\nclass Square extends Shape, Planar, Movable ...\n\nTraits resemble interfaces in Java, but are more powerful because they can have parameters and can contain fields and concrete methods.",
    "this  $\\longrightarrow$  conforms to this\n\nthis  $ \\cdots$  can be converted to this.",
    "Top Types\n\nAt the top of the type hierarchy we find:\nAny              the base type of all types\n                         Methods: `==`, `!=`, `equals`, `hashCode`, `toString`\n\nAnyRef         The base type of all reference types;\n                         Alias of `java.lang.Object`\n\nAnyVal         The base type of all primitive types.",
    "The Nothing Type\n\nNothing is at the bottom of Scala's type hierarchy. It is a subtype of every other type.\n\nThere is no value of type Nothing.\n\nWhy is that useful?\n\n- To signal abnormal termination\n- As an element type of empty collections (see next session)",
    "Exceptions\n\nScala's exception handling is similar to Java's.\n\nThe expression\n\n$ \\text{throw Exc} $\n\naborts evaluation with the exception $\\text{Exc}$.\n\nThe type of this expression is $\\text{Nothing}$.",
    "What is the type of\n\nif true then 1 else false\n\n0  Int\n0  Boolean\n\u25cf  AnyVal\n0  Object\n0  Any\n\ntheir common supertype is AnyVal (which is also the type of if then else).\n",
    "Implementing a Simple Programming Language\n\nFunctional Programming (CS-210)\n\nViktor Kuncak\n\nEPFL",
    "Example program: \n(\n  def fact = (n => (if n then (* n (fact (- n 1))) else 1))\n  (fact 6)\n)\nevaluates to: 720\n\n(\n  def twice = (f => x => (f (f x)))\n  def square = (x => (* x x))\n  (twice square 3)\n)\nevaluates to: 81",
    "Program Representation: Abstract Syntax Trees\n\n```\n(def twice = (f => x => (f (f x)))\n def square = (x => (x * x)))\n (twice square 3))\n```\n\n```\nval defs : DefEnv = Map[String, Expr](\n  \"twice\" -> Fun(\"f\", Fun(\"x\",\n                          Call(N(\"f\"), Call(N(\"f\"), N(\"x\"))))),\n  \"square\" -> Fun(\"x\", BinOp(Times, N(\"x\"), N(\"x\"))))\nval expr = Call(Call(N(\"twice\"), N(\"square\")), C(3))\n```\n\n- We represent a program using expression tree called Abstract Syntax Tree (AST)\n- Our implementation is an interpreter, which traverses AST to produce the result\n- We discuss later briefly how to convert an input file into an abstract syntax tree;\n  more on that in the course Computer Language Processing (CS-320) next year",
    "101 Language of arithmetic and if expressions  \n102 Absolute value and its desugaring  \n103 Recursive functions implemented using substitutions  \n104 Environment instead of substitutions  \n105 Higher-order functions using substitutions  \n106 Higher-order functions using environments  \n107 Nested recursive definitions using environments",
    "Integer constants combined using arithmetic operations and the if conditional\n\nval expr1 = BinOp(Times, C(6), C(7))     // 6 * 7\nval cond1 = BinOp(LessEq, expr1, C(50))  // expr1 <= 50\nval expr2 = IfNonzero(cond1, C(10), C(20)) // if (cond1) 10 else 20\n\nHow to describe such trees?",
    "Integer constants combined using arithmetic operations and the if conditional\n\n```scala\nval expr1 = BinOp(Times, C(6), C(7))        // 6 * 7\nval cond1 = BinOp(LessEq, expr1, C(50))     // expr1 <= 50\nval expr2 = IfNonzero(cond1, C(10), C(20))  // if (cond1) 10 else 20\n```\n\nHow to describe such trees?\n\n```scala\nenum Expr\n  case C(c: BigInt)                     // integer constant\n  case BinOp(op: BinOps, e1: Expr, e2: Expr)  // binary operation\n  case IfNonzero(cond: Expr, trueE: Expr, falseE: Expr)\n\nenum BinOps\n  case Plus, Minus, Times, Power, LessEq\n```",
    "def str(e: Expr): String = e match\n  case C(c) => c.toString\n  case BinOp(op, e1, e2) => \n    s\"${strOp(op)} ${str(e1)} ${str(e2)}\" // string interpolation\n  case IfNonzero(cond, trueE, falseE) => \n    s\"(if ${str(cond)} then ${str(trueE)} else ${str(falseE)})\"\n\ndef strOp(op: BinOps): String = op match\n  case Plus => \"+\"\n  case Minus => \"-\"\n  case Times => \"*\"\n  case Power => \"^\"\n  case LessEq => \"<=\"\n\n> str(IfNonzero(BinOp(LessEq, C(4), C(50)), C(10), C(20)))\n(if (<= 4 50) then 10 else 20)",
    "def eval(e: Expr): BigInt = e match\n  case C(c) => c\n  case BinOp(op, e1, e2) => evalBinOp(op)(eval(e1), eval(e2))\n  case IfNonzero(cond, trueE, falseE) =>\n    if eval(cond) != 0 then eval(trueE) else eval(falseE)\n\ndef evalBinOp(op: BinOps)(x: BigInt, y: BigInt): BigInt = op match\n  case Plus => x + y\n  case Minus => x - y\n  case Times => x * y\n  case Power => x.pow(y.toInt)\n  case LessEq => if (x <= y) 1 else 0\n\n> eval(IfNonzero(BinOp(LessEq, C(4), C(50)), C(10), C(20)))\n10",
    "Absolute Value and Its Desugaring: Trees\n\nenum Expr\n  case C(c: BigInt)\n  case BinOp(op: BinOps, e1: Expr, e2: Expr)\n  case IfNonzero(cond: Expr, trueE: Expr, falseE: Expr)\n  case AbsValue(arg: Expr)  // new case\n\nHow to extend evaluator to work with absolute value as well? Two approaches:\nadd a case to the interpreter (exercise)\ntransform (desugar) trees to reduce them to previous cases\n\nSyntactic sugar = extra language constructs that are not strictly necessary because they can be expressed in terms of others (they make the language sweeter to use)\n\nDesugaring = automatically eliminating syntactic sugar by expanding constructs",
    "By definition of absolute value, we would like this equality to hold:\n\n$$\n\\text{abs} \\ x \\ \\equiv \\ \\text{if} \\ (<= \\ x \\ 0) \\ \\text{then} \\ (- \\ 0 \\ x) \\ \\text{else} \\ x\n$$\n\nthat is, at the level of AST,\n\n$$\n\\text{AbsValue}(x) \\ \\rightsquiggle\n\\ \\text{IfNonzero}(\\text{BinOp}(\\text{LessEq}, \\ x, \\ \\text{C}(0)),\n\\ \\text{BinOp}(\\text{Minus}, \\ \\text{C}(0), \\ x),\n\\ x)\n$$\n\nHow to write \\text{desugar function} that eliminates all occurrences of \\text{AbsValue}?\n\nReplace (recursively) each subtree \\text{AbsValue}(x) with its definition.",
    "def desugar(e: Expr): Expr = e match\n  case C(c) =>\n    C(c)\n  case BinOp(op, e1, e2) =>\n    BinOp(op, desugar(e1), desugar(e2))\n  case IfNonzero(cond, trueE, falseE) =>\n    IfNonzero(desugar(cond), desugar(trueE), desugar(falseE))\n  case AbsValue(arg) =>\n    val x = desugar(arg)\n    IfNonzero(BinOp(LessEq, x, C(0)),\n              BinOp(Minus, C(0), x),\n              x)",
    "def show(e: Expr): Unit =\n  println(\"original:\")\n  println(str(e))\n  val de = desugar(e)\n  println(\"desugared:\")\n  println(str(de))\n  println(\" ~~> \" + eval(de) + \"\\n\")\n\nshow(AbsValue(BinOp(Plus,C(10),C(-50))))\n\noriginal:\n(abs (+ 10 -50))\ndesugared:\n(if (<= (+ 10 -50) 0) then (- 0 (+ 10 -50)) else (+ 10 -50))\n~~> 40",
    "Combinatorial Search and For-Expressions\n\nPrinciples of Functional Programming",
    "Handling Nested Sequences\n\nWe can extend the usage of higher order functions on sequences to many calculations which are usually expressed using nested loops.\n\nExample: Given a positive integer $n$, find all pairs of positive integers $i$ and $j$, with $1 \\le j < i < n$ such that $i + j$ is prime.\n\nFor example, if $n = 7$, the sought pairs are\n\n\\[\n\\begin{array}{c|ccccccc}\ni & 2 & 3 & 4 & 5 & 6 & 6 & \\\\\nj & 1 & 2 & 3 & 2 & 1 & 5 & \\\\\ni+j & 3 & 5 & 7 & 7 & 7 & 11 &\n\\end{array}\n\\]",
    "Algorithm\n\nA natural way to do this is to:\n\n\u25ba Generate the sequence of all pairs of integers $(i, j)$ such that $1 \\leq j < i < n$.\n\u25ba Filter the pairs for which $i + j$ is prime.\n\nOne natural way to generate the sequence of pairs is to:\n\n\u25ba Generate all the integers $i$ between $1$ and $n$ (excluded).\n\u25ba For each integer $i$, generate the list of pairs $(i, 1), \\ldots, (i, i-1)$.\n\nThis can be achieved by combining until and map:\n\n$$1 \\text{ until } n.\\text{map}(i => (1 \\text{ until } i).\\text{map}(j => (i, j)))$$",
    "Generate Pairs\n\nThe previous step gave a sequence of sequences, let's call it xss.\n\nWe can combine all the sub-sequences using foldRight with ++:\n$xss.foldRight(Seq[Int]())(_ ++ _)$\nOr, equivalently, we use the built-in method flatten\n$xss.flatten$\n\nThis gives:\n$((1\\ until\\ n).map(i\\ =>$\n$(1\\ until\\ i).map(j\\ =>\\ (i,\\ j)))).flatten$",
    "Generate Pairs (2)\n\nHere's a useful law:\n\n$$xs.flatMap(f) = xs.map(f).flatten$$\n\nHence, the above expression can be simplified to\n\n$$(1\\ \\text{until}\\ n).flatMap(i\\ =>\\ (1\\ \\text{until}\\ i).map(j\\ =>\\ (i,\\ j)))$$",
    "Assembling the pieces\n\nBy reassembling the pieces, we obtain the following expression:\n\n$$(1 \\text{ until } n)\n  .\\text{flatMap}(i => (1 \\text{ until } i).map(j => (i, j)))\n  .\\text{filter}((x, y) => isPrime(x + y))$$\n\nThis works, but makes most people\u2019s head hurt.\n\nIs there a simpler way?",
    "For-Expressions \n\nHigher-order functions such as $map$, $flatMap$ or $filter$ provide powerful constructs for manipulating lists. \n\nBut sometimes the level of abstraction required by these functions makes the program difficult to understand. \n\nIn this case, Scala's $for$ expression notation can help.",
    "Let persons be a list of elements of class Person, with fields name and age.\n\n```scala\ncase class Person(name: String, age: Int)\n```\nTo obtain the names of persons over 20 years old, you can write:\n```scala\nfor p <- persons if p.age > 20 yield p.name\n```\nwhich is equivalent to:\n```scala\npersons\n  .filter(p => p.age > 20)\n  .map(p => p.name)\n```\nThe for-expression is similar to loops in imperative languages, except that it builds a list of the results of all iterations.",
    "A for-expression is of the form \n\n\\[\n\\text{for } s \\text{ yield } e\n\\]\n\nwhere $s$ is a sequence of generators and filters, and $e$ is an expression whose value is returned by an iteration.\n\n- A generator is of the form $p \\leftarrow e$, where $p$ is a pattern and $e$ an expression whose value is a collection.\n- A filter is of the form $\\text{if } f$ where $f$ is a boolean expression.\n- The sequence must start with a generator.\n- If there are several generators in the sequence, the last generators vary faster than the first.",
    "Use of For\n\nHere are two examples which were previously solved with higher-order functions:\n\nGiven a positive integer $n$, find all the pairs of positive integers $(i, j)$ such that $1 \\le j < i \\le n$, and $i + j$ is prime.\n\n\\[\n\\text{for}\n\\left\\{\n\\begin{array}{l}\ni \\leftarrow 1 \\text{ until } n \\\\\nj \\leftarrow 1 \\text{ until } i \\\\\n\\text{if isPrime}(i + j)\n\\end{array}\n\\right.\n\\text{yield} (i, j)\n\\]",
    "Write a version of scalarProduct (see last session) that makes use of a for:\n\n```scala\ndef scalarProduct(xs: List[Double], ys: List[Double]): Double = \n\n    (for (x, y) <= xs.zip(ys) yield x * y).sum\n```\n\nQuestion: What will the following produce?\n\n```scala\n(for x <- xs; y <- ys yield x * y).sum\n```\n\nAnswer: It would multiply every element of xs with every element of ys and sum up the results.",
    "Conditionals and Value Definitions\n\nPrinciples of Functional Programming",
    "Conditional Expressions\n\nTo express choosing between two alternatives, Scala has a conditional expression $if-then-else$.\n\nIt resembles an $if-else$ in Java, but is used for expressions, not statements.\n\nExample:\n$$\n\\text{def abs(x: Int) = if x >= 0 then x else -x}\n$$\n\n$$\nx >= 0\n$$ is a predicate, of type Boolean.",
    "Boolean expressions\n\nBoolean expressions b can be composed of\n\ntrue false // Constants\n!b // Negation\nb && b // Conjunction\nb || b // Disjunction\n\nand of the usual comparison operations:\n\ne <= e, e >= e, e < e, e > e, e == e, e != e",
    "Rewrite rules for Booleans\n\nHere are reduction rules for Boolean expressions (e is an arbitrary expression):\n\n$!true \\rightarrow false$\n\n$!false \\rightarrow true$\n\n$true \\&\\& e \\rightarrow e$\n\n$false \\&\\& e \\rightarrow false$\n\n$true || e \\rightarrow true$\n\n$false || e \\rightarrow e$\n\nNote that $\\&\\&$ and $||$ do not always need their right operand to be evaluated.\n\nWe say, these expressions use \u201cshort-circuit evaluation\u201d.",
    "Exercise: Formulate rewrite rules for if-then-else\n\n$if\\ true\\ then\\ e_1\\ else\\ e_2\\ \\rightarrow \\ e_1$\n\n$if\\ false\\ then\\ e_1\\ else\\ e_2\\ \\rightarrow \\ e_2$",
    "Value Definitions\n\nWe have seen that function parameters can be passed by value or be passed by name.\n\nThe same distinction applies to definitions.\n\nThe def form is \"by-name\", its right hand side is evaluated on each use.\n\nThere is also a val form, which is \"by-value\". Example:\n\nval x = 2  \nval y = square(x)\n\nThe right-hand side of a val definition is evaluated at the point of the definition itself.\n\nAfterwards, the name refers to the value.\n\nFor instance, y above refers to 4, not square(2).",
    "Value Definitions and Termination\n\nThe difference between val and def becomes apparent when the right hand side does not terminate. Given\n\n\\[\n\\text{def loop: Boolean = loop}\n\\]\n\nA definition\n\n\\[\n\\text{def x = loop}\n\\]\n\nis OK, but a definition\n\n\\[\n\\text{val x = loop}\n\\]\n\nwill lead to an infinite loop.",
    "Exercise\n\nWrite functions and and or such that for all argument expressions x and y:\n\n$ \\text{and}(x, y) == x \\ \\&\\& \\ y $ \\\n$ \\text{or}(x, y) == x \\ || \\ y $\n\n(do not use $\\ || $ and $\\ \\&\\&$ in your implementation)\n\nWhat are good operands to test that the equalities hold?\n\n$ \\text{def and} (x: \\text{Boolean}, y: \\text{Boolean}): \\text{Boolean} = $ \n$ \\quad \\text{if} \\ x \\ \\text{then} \\ y \\ \\text{else} \\ \\text{false} $\n\nA few tests:\n\n$ \\text{and (true, false) = false} $ \\\n$ \\text{and (true, true) = true} $ ",
    "We should also test with non-terminating evaluations!\nand(false, loop) = Non termination !!!\n\n\\begin{align*}\n  change \\ to \\ mode \\ of \\ CBV \\{ \n    & n(f, \\text{and} (x: \\text{Boolean}, y \\Rightarrow \\text{Boolean}) : \\text{Boolean} =  \\\\\n    & \\quad \\quad if \\ x\\ then \\ y \\ else \\ \\text{false}\n  \\}\n\\end{align*}",
    "Maps\n\nPrinciples of Functional Programming",
    "Map\n\nAnother fundamental collection type is the map.\n\nA map of type Map[Key, Value] is a data structure that associates keys of type Key with values of type Value.\n\nExamples:\n\nval romanNumerals = Map(\"I\" -> 1, \"V\" -> 5, \"X\" -> 10)\nval capitalOfCountry = Map(\"US\" -> \"Washington\", \"Switzerland\" -> \"Bern\")",
    "Maps are Iterables\n\nClass Map[Key, Value] extends the collection type Iterable[(Key, Value)].\n\nTherefore, maps support the same collection operations as other iterables do. Example:\n\nval countryOfCapital = capitalOfCountry.map((x, y) => (y, x))\n// Map(\"Washington\" -> \"US\", \"Bern\" -> \"Switzerland\")\n\nNote that maps extend iterables of key/value pairs.\n\nIn fact, the syntax key -> value is just an alternative way to write the pair (key, value). (-> implemented as an extension method in Predef).\n\nextension (k:V) def -> (v:V) = (k, v)",
    "Maps are Functions\n\nClass Map[Key, Value] also extends the function type Key => Value, so maps can be used everywhere functions can.\n\nIn particular, maps can be applied to key arguments:\n\ncapitalOfCountry(\"US\") // \"Washington\"",
    "Querying Map\n\nApplying a map to a non-existing key gives an error:\n\ncapitalOfCountry(\"Andorra\")\n// java.util.NoSuchElementException: key not found: Andorra\n\nTo query a map without knowing beforehand whether it contains a given key, you can use the get operation:\n\ncapitalOfCountry.get(\"US\") // Some(\"Washington\")\ncapitalOfCountry.get(\"Andorra\") // None\n\nThe result of a get operation is an Option value.",
    "The Option Type\n\nThe Option type is defined as:\n\ntrait Option[+A]\n\ncase class Some[+A](value: A) extends Option[A]\nobject None extends Option[Nothing]\n\nThe expression map.get(key) returns\n\n\ud83d\udd39 None        if map does not contain the given key.\n\ud83d\udd39 Some(x)   if map associates the given key with the value x.",
    "Decomposing Option\n\nSince options are defined as case classes, they can be decomposed using pattern matching:\n\n```scala\ndef showCapital(country: String) = capitalOfCountry.get(country) match\n   case Some(capital) => capital\n   case None => \"missing data\"\n```\n\nshowCapital(\"US\")    // \"Washington\"\nshowCapital(\"Andorra\") // \"missing data\"\n\nOptions also support quite a few operations of the other collections.\n\nI invite you to try them out!",
    "Updating Maps\n\nFunctional updates of a map are done with the + and ++ operations:\n\n\\[ m + (k -> v) \\]\nThe map that takes key 'k' to value 'v' and is otherwise equal to 'm'\n\n\\[ m ++ kvs \\]\nThe map 'm' updated via '+' with all key/value pairs in 'kvs'\n\nThese operations are purely functional. For instance,\n\n\\[ \\text{val m1 = Map(\"red\" -> 1, \"blue\" -> 2)} \\]\n\\[ \\text{val m2 = m1 + (\"blue\" -> 3)} \\]\n\\[ \\text{m1} \\]\n\\[ \\Rightarrow \\text{m1 = Map(red -> 1, blue -> 2)} \\]\n\\[ \\Rightarrow \\text{m2 = Map(red -> 1, blue -> 3)} \\]\n\\[ \\Rightarrow \\text{Map(red -> 1, blue -> 2)} \\]",
    "Sorted and GroupBy\n\nTwo useful operations known from SQL queries are groupBy and orderBy.\n\norderBy on a collection can be expressed using sortWith and sorted.\n\n```\nval fruit = List(\"apple\", \"pear\", \"orange\", \"pineapple\")\nfruit.sortWith(_.length < _.length)   // List(\"pear\", \"apple\", \"orange\", \"pineapple\")\nfruit.sorted                         // List(\"apple\", \"orange\", \"pear\", \"pineapple\")\n```\n\ngroupBy is available on Scala collections. It partitions a collection into a map of collections according to a discriminator function f.\n\nExample:\n\n```\nfruit.groupBy(_.head)                //=> Map(p -> List(pear, pineapple),\n                                   //           a -> List(apple),\n                                   //           o -> List(orange))\n```",
    "Map Example\n\nA polynomial can be seen as a map from exponents to coefficients.\n\nFor instance, $x^3 - 2x + 5$ can be represented with the map.\n\nMap: $\\{0 \\rightarrow 5, 1 \\rightarrow -2, 3 \\rightarrow 1\\}$\n\nBased on this observation, let's design a class Polynom that represents polynomials as maps.\n\n$x^3 + 0 \\cdot x^2 = x^3$\n\nbut we don't have exponent 2 in our map.",
    "Default Values\n\nSo far, maps were partial functions. Applying a map to a key value in map(key) could lead to an exception, if the key was not stored in the map.\n\nThere is an operation withDefaultValue that turns a map into a total function:\n\nval cap1 = capitalOfCountry.withDefaultValue(\"<unknown>\") \ncap1(\"Andorra\") // \"<unknown>\"",
    "Variable Length Argument Lists\n\nIt's quite inconvenient to have to write\n\nPolynom(Map(1 -> 2.0, 3 -> 4.0, 5 -> 6.2))\n\nCan one do without the Map(...)?\nProblem: The number of key -> value pairs passed to Map can vary.\n\nWe can accommodate this pattern using a repeated parameter.\n```scala\ndef Polynom(bindings: (Int, Double)*) =\n  Polynom(bindings.toMap.withDefaultValue(0))\n```\nPolynom(1 -> 2.0, 3 -> 4.0, 5 -> 6.2)\n\nInside the Polynom function, bindings is seen as a Seq[(Int, Double)].",
    "Final Implementation of Polynom\n\nclass Polynom(nonZeroTerms: Map[Int, Double]):\n  def this(bindings: (Int, Double)*) = this(bindings.toMap)\n\n  def terms = nonZeroTerms.withDefaultValue(0.0)\n  def +(other: Polynom) = \n    Polynom(terms ++ other.terms.map((exp, coeff) => (exp, terms(exp) + coeff)))\n\n  override def toString =\n    val termStrings = \n      for (exp, coeff) <- terms.toList.sorted.reverse\n      yield \n        val exponent = if exp == 0 then \"\" else s\"x^$exp\"\n        s\"$coeff$exponent\"\n    if terms.isEmpty then \"0\" else termStrings.mkString(\" + \")",
    "The $+$ operation on Polynom used map concatenation with $++$. Design another version of $+$ in terms of foldLeft:\n\n```scala\ndef + (other: Polynom) = \n    Polynom(other.terms.foldLeft(???) (addTerm))\n```\n\n```scala\ndef addTerm(terms: Map[Int, Double], term: (Int, Double)) =\n    ??? val (exp, coeff) = term\n    terms + (exp -> (terms(exp)+coeff))\n```\n\nWhich of the two versions do you believe is more efficient?\n\n0  The version using $++$\n\n0  The version using foldLeft",
    "Exercise\n\nThe + operation on Polynoms used map concatenation with ++. Design another version of + in terms of foldLeft:\n\n```scala\ndef + (other: Polynoms) =\n  Polynom(other.terms.foldLeft(terms)(addTerm))\n\ndef addTerm(terms: Map[Int, Double], term: (Int, Double)) =\n  val (exp, coeff) = term\n  terms + (exp, coeff + terms(exp))\n```\n\nWhich of the two versions do you believe is more efficient?\n\nO The version using ++\nX The version using foldLeft",
    "Exercise\n\nThe + operation on Polynom used map concatenation with ++. Design another version of + in terms of foldLeft:\n\n```scala\ndef + (other: Polynom) =\n  Polynom(other.terms.foldLeft(terms)(addTerm))\n\ndef addTerm(terms: Map[Int, Double], term: (Int, Double)) =\n  val (exp, coeff) = term\n  terms + (exp, coeff + terms(exp))\n```\n\nWhich of the two versions do you believe is more efficient?\n\nO The version using ++\nX The version using foldLeft",
    "Exercise Session 1\n\nIn this session, we will work on tail recursion.\n\nQUESTION 1: FACTORIAL\n\nRecall the factorial function that you saw in class:\n```python\ndef factorial(n: Int): Int =\n  if n = 0 then 1\u00a0\n  else n * factorial(n - 1)\n```\nDefine a tail recursive version of it, by replacing ??? with an appropriate implementation in the following snippet:\n```python\nimport scala.annotation.tailrec\n@tailrec\ndef facto(n: Int, acc: Int): Int = ???\ndef factorial(n: Int): Int = facto(n, 1)\n```\nQuestion: What would be the advantage of making fact an inner function to factorial?\n\nGitlab Instructions\n\nQUESTION 2: SUM OF ELEMENTS ON A LIST\n\nDefine a function that takes a list of integers and sums them. You can use the functions head, tail, and isEmpty on lists, as you have seen for your homework.\n```python\ndef sumList(xs: List[Int]): Int = ???\n```\nConvert your definition into a tail-recursive one.\n\nGitlab Instructions\n\nQUESTION 3: FAST EXPONENTIATION\n\nFast exponentiation is a technique to optimize the exponentiation of numbers:\n$$ b^{2*n} = (b^n)^2 $$\n$$ b^{2*n+1} = b * (b^n)^2 $$\n\nDefine a function that implements this fast exponentiation. Can you define a tail recursive version as well?\n```python\ndef fastExpo(base: Int, exp: Int): Int = ???\n```\nGitlab Instructions",
    "QUESTION 4: TAIL RECURSIVE FIBONACCI\n\nDefine a function that computes the n-th Fibonacci number.\n\nCan you define a tail recursive version as well?\n\nThe Fibonacci recurrence is given as follows: \n$$\nf(n) = \\begin{cases} \nn & \\text{if } n \\text{ is 0 or 1} \\\\\nf(n-1) + f(n-2) & \\text{otherwise}\n\\end{cases}\n$$\n\nA) Factorial\n\n```python\ndef Factorial(n: Int): Int =\n    def Fact(n: Int, acc: Int): Int =\n        if n == 0 then acc\n        else Fact(n - 1, n * acc)\n\n    Fact(n, 1)\n```\n\n```python\nFact(Fact(3,1)\nFact(3,1)\nFact(2, 3*1)\nFact(1, 2*3)\nFact(0, 1*2*3=6)\n```\n\n= acc: 6\n\n2) Sum of elements of a list:\n\n```python\ndef Sum(list(xs: List[Int]): Int =\n    def InnerSum(xs: List[Int], acc: Int): Int =\n        xs match \n            case Nil => acc\n            case head::tail => InnerSum(tail, head + acc)\n    InnerSum(xs, 0)\n```",
    "3) Fast exponential :\n\n```\ndef FastExp(base : Int, exp : Int) : Int =\n  require(exp >= 0)\n  def innerexp(base : Int, exp : Int, acc : Int) : Int =\n    if exp == 0 then acc\n    if (exp % 2 == 0) then innerexp(base, exp / 2, acc)\n    else innerexp(base, exp-1, acc * base) \n  innerexp(base, exp, 1)\n```\n\n$2^5 = 2^2\\cdot2^2 \\cdot2 = 2\\cdot(2\\cdot2) = 2 \\cdot((2\\cdot2)\\cdot(2\\cdot2)\\cdot2)$\n\n$2^6 = 2\\cdot2\\cdot(2\\cdot2)\\cdot2 = 2^2 \\cdot2^2 = 2 \\cdot (2\\cdot2). = [2\\cdot2 \\cdot2]|2$\n\n$3^5 = par(exp,3,5)=innerexp_\n\n```\n3^5\npar(exp,3,5)=innerexp{\n  3,\n  5\n  acc(f,1)\n3,\n}\n```\n\n4) Compute nth fibonacci under :\n\n```\ndef Fibanocci(n : Int) : Int =\n  require(n>=0)\n  def Inner(cumset : Int, minusone : Int, then : Int) : Int =\n    if then == n then cumset\n    Inner(minuse, acc=acc+1) when [then+1]\n```",
    "if \\$n=0\\$ then 0\nelse Inner(1,0,1)\n\n\\[\n\\begin{align*}\n\\mathscr{L}(s) &= \\mathscr{L}(a)+\\mathscr{L}(z) = [\\mathscr{L}(3),\\mathscr{L}(2)]+[\\mathscr{L}(2)+\\mathscr{L}(1)] \\\\\n&= [[\\mathscr{L}(2), \\mathscr{L}(1)], \\mathscr{L}(0)] + [[\\mathscr{L}(1), \\mathscr{L}(0)], 1] \\\\\n&= [[[\\mathscr{L}(1), \\mathscr{L}(0)], 1] + 1] + [[1+\\mathscr{L}(0)+1] \\\\\n&= 1+0+1+1+0+1+0+1 \\\\\n&= 5.\n\\end{align*}\n\\]",
    "Exercise Session 6\n\nFor comprehensions and monads\n\nQUESTION 1.1\n\nConsider a directed graph given by its set of (directed) edges stored as a list of pairs of nodes:\n\ntype NodeId = Int\ntype DirectedEdge = (NodeId, NodeId)\ntype DirectedGraph = List[DirectedEdge]\n\nDefine, non-recursively, the triangles function that finds all cycles of length 3, with three distinct nodes, in the given graph. You should use a for comprehension.\n\ndef triangles(edges: DirectedGraph): List[(NodeId, NodeId, NodeId)] = for ...\n\nEach cycle should appear only once. For instance, given the edges\n\nList((1, 2), (2, 3), (3, 1))\n\nYou should return exactly one of the three following possibilities:\n\n(1, 2, 3), (2, 3, 1), (3, 1, 2)\n\nYou are free to decide which of the three you return.\n\nQUESTION 1.2\n\nAfter that, translate the for comprehension you wrote in the appropriate combination of map/flatMap/filter calls.\n\nQUESTION 2\n\nMonads are often defined with a map method in addition to flatMap:\n\ntrait M[T] {\n  def flatMap[U](f: T => M[U]): M[U]\n  def map[U](f: T => U): M[U]\n}\n\nWhere map and flatMap are related by the following law:\n\nMonad/Functor Consistency:\nm.map(f) == m.flatMap(x => unit(f(x)))\n\nIn fact, monads form a very general algebraic structure called Functors. We say that a type F is a Functor if F[T] has a map method with the following signature",
    "trait F[T] {\n  def map[U](f: T => U): F[U]\n}\n\nAnd there is a unit method for F with the following signature:\n\ndef unit[T](x: T): F[T]\n\nSuch that map and unit fulfill the following laws:\n\nIdentity:\nm.map(x => x) === m\n\nAssociativity:\nm.map(f).map(g) === m.map(x => g(f(x)))\n\nProve that any Monad with a map method that fulfills the Monad/Functor Consistency law is also a Functor.",
    "QUESTION 1.1\n\nConsider a directed graph given by its set of (directed) edges stored as a list of pairs of nodes:\n\n\\[\n\\text{edges = [(n0,n1), (n0,n2)]}\n\\]\n\nWhere each ni is a string identifying a function that finds all cycles of length 3, with three distinct nodes, in the given graph. You should use a set for comprehension.\n\n\\[\n\\begin{aligned}\n\\text{def find\\_triangles(edges: List[Tuple[str, str]]) -> Set[Tuple[str, str, str]]:}\n\\end{aligned}\n\\]\n\nEach cycle should appear only once. For instance, given the edges:\n\n\\[\n\\begin{aligned}\n&\\text{n1 \\rightarrow n2, } \\\\\n&\\text{n2 \\rightarrow n3, } \\\\\n&\\text{n3 \\rightarrow n1}\n\\end{aligned}\n\\]\n\nYou should return the node order of the form following possibilities:\n\n\\[\n\\begin{aligned}\n&(n1,n2,n3), \\\\\n&(n2,n3,n1), \\\\\n&(n3,n1,n2)\n\\end{aligned}\n\\]\n\nlet: $e1 = (e1.1, e1.2), e1.\\_2 = (e2.1, e2.2) \\blacksquare \\newline \\therefore (n1, n2) \\wedge (n2, n1)$\n\nFor a triangle, we need some other vertex N, s.t. there exist edges:\n\n\\[\n\\begin{aligned}\n&(e1.1, N)  \\wedge  (e1.2,N)\n\\end{aligned}\n\\]\n\nTo avoid counting same cycle in opposite directions, we only consider case when:\n\n\\[\ne1.1 < e1.2\n\\]\n\nTo avoid counting same cycle with different starting points, we only consider cycles starting with smallest edge.\n\n\\textbf{Impl\u00e9mentation:}\n\\[\n\\text{for } e1: \\newline\n    e1 \\in \\text{edges} \\newline\n    \\text{if} \\quad (e1.1 < e1.2)\n\\]\n\n\\[\ne2 \\in \\text{edges}\n\\]\n\n\\[\n\\text{if}(e1.1 == e2.2 - 1 ) \\vspace{0.1in}  \\text{edge.}contains(e2.2 - 2, e1.1) \n\\]\n\n$\\mathclap{\\sub}\n\n\\[\n\\boxed{\\sub\n\nse}\n}$\n\n$\\mathcal{ax}$\n",
    "if $(e_{1..-1} < e_{2..-2} \\;\\&\\; e_{2..-1} = e_{2..-2})$ \\{\n    yield $(e_{1..-1}, e_{1..-2}, e_{2..-2})$\n\\}\n\nQUESTION 1.2\nAfter that, translate the for comprehension you wrote in the appropriate combination of map/filter/filter calls.\n\n\\[\nedges.filter( e1 \\Rightarrow e1.left < e1.right).filter( e1 \\Rightarrow \n\\]\n\n\\[\nedges.filter( e1 \\Rightarrow e1.left < e1.right \\;\\&\\; edges.contains(e2 \\Rightarrow e2, e1.-1)) \\Rightarrow\n\\]\n\n\\[\n(e1.-1 < e2) \\;\\&\\; e2.-1 = e2.-2\n\\]\n\n\\[\n].filter( e2 \\Rightarrow \n\\]\n\n\\[\n\\}\n\\]\n\n\\[\n(e1.-1, e1.-2, e2.-2)\n\\]\n\n\\[\n].map\n\\]",
    "Blocks and Lexical Scope\n\nPrinciples of Functional Programming\n\nStill with sqrt(x) example - we will now improve it",
    "Nested functions\n\nIt's good functional programming style to split up a task into many small functions.\n\nBut the names of functions like sqrtIter, improve, and isGoodEnough matter only for the implementation of sqrt, not for its usage.\n\nNormally we would not like users to access these functions directly.\n\nWe can achieve this and at the same time avoid \"name-space pollution\" by putting the auxiliary functions inside sqrt.",
    "The sqrt Function, Take 2\n\n```python\ndef sqrt(x: Double) = {\n    def sqrtIter(guess: Double, x: Double): Double = \n        if isGoodEnough(guess, x) then guess\n        else sqrtIter(improve(guess, x), x)\n\n    def improve(guess: Double, x: Double) = \n        (guess + x / guess) / 2\n\n    def isGoodEnough(guess: Double, x: Double) = \n        abs(square(guess) - x) < 0.001\n\n    sqrtIter(1.0, x)\n}\n```\n\nauxiliary functions defined within sqrt (x). Only defined within function.",
    "Blocks in Scala\n\n- A block is delimited by braces { ... }.\n  { val x = f(3)\n    x * x\n  }\n\n- It contains a sequence of definitions or expressions.\n- The last element of a block is an expression that defines its value.\n- This return expression can be preceded by auxiliary definitions.\n- Blocks are themselves expressions; a block may appear everywhere an expression can.\n- In Scala 3, braces are optional (i.e. implied) around a correctly indented expression that appears after =, then, else, ...",
    "val x = 0\ndef f(y: Int) = y + 1\nval result = \n  val x = f(3)\n  x * x\n\nThe definitions inside a block are only visible from within the block.\nThe definitions inside a block shadow definitions of the same names outside the block.",
    "Exercise: Scope Rules\n\nQuestion: What is the value of result in the following program?\n\nval x = 0\ndef f(y: Int) = y + 1\nval y = 4\nval x = f(3)\nx = (3) + 1 = 4\ny = 4\nval x = (4) + 1 = 5\nval result = y + x = (4) + (5) = 9\n\nPossible answers:\n0\n0\n16\n32\nreduction does not terminate",
    "Lexical Scoping\n\nDefinitions of outer blocks are visible inside a block unless they are shadowed.\n\nTherefore, we can simplify $sqrt$ by eliminating redundant occurrences of the $x$ parameter, which means everywhere the same thing:",
    "The sqrt Function, Take 3\n\n```\ndef sqrt(x: Double) = {\n    def sqrtIter(guess: Double): Double =\n        if isGoodEnough(guess) then guess\n        else sqrtIter(improve(guess))\n    \n    def improve(guess: Double) =\n        (guess + x / guess) / 2\n    \n    def isGoodEnough(guess: Double) =\n        abs(square(guess) - x) < 0.001\n    \n    sqrtIter(1.0)\n}\n```",
    "Semicolons\n\nIf there are more than one statements on a line, they need to be separated by semicolons:\n\n$val \\ y = x + 1; y \\times y$\n\nSemicolons at the end of lines are usually left out.\n\nYou could write\n\n$val \\ x = 1;$\n\nthis is useless (in scala).\n\nbut it would not be very idiomatic in Scala.",
    "Summary\n\nYou have seen simple elements of functional programming in Scala.\n\n\u25ba arithmetic and boolean expressions\n\u25ba conditional expressions if-then-else\n\u25ba functions with recursion\n\u25ba nesting and lexical scope\n\nYou have learned the difference between the call-by-name and call-by-value evaluation strategies.\n\nYou have learned a way to reason about program execution: reduce expressions using the substitution model.\n\nThis model will be an important tool for the coming sessions.",
    "Polymorphism\n\nPrinciples of Functional Programming",
    "Cons-Lists\n\nA fundamental data structure in many functional languages is the immutable linked list.\n\nIt is constructed from two building blocks:\n\n$Nil$  the empty list\n\n$Cons$  a cell containing an element and the remainder of the list.",
    "Examples for Cons-Lists\n\nList(1, 2, 3)\n\nList(List(true, false), List(3))\n\nFirst element is a list\n\nsecond element",
    "Here's an outline of a class hierarchy that represents lists of integers in this fashion:\n\npackage week3\n\ntrait IntList ...\nclass Cons(val head: Int, val tail: IntList) extends IntList ...\nclass Nil() extends IntList ...\n\nA list is either\n\n- an empty list Nil(), or\n- a list Cons(x, xs) consisting of a head element $x$ and a tail list $xs$.",
    "Value Parameters\n\nNote the abbreviation $(\\text{val head: Int, val tail: IntList})$ in the definition of Cons.\n\nThis defines at the same time parameters and fields of a class.\n\nIt is equivalent to:\n\nclass Cons(_head: Int, _tail: IntList) extends IntList:\n    val head = _head\n    val tail = _tail\n\nwhere _head and _tail are otherwise unused names.",
    "Type Parameters\n\nIt seems too narrow to define only lists with Int elements.\n\nWe'd need another class hierarchy for Double lists, and so on, one for each possible element type.\n\nWe can generalize the definition using a type parameter:\n\npackage week3\n\ntrait List[T]\nclass Cons[T](val head: T, val tail: List[T]) extends List[T]\nclass Nil[T] extends List[T]\n\nType parameters are written in square brackets, e.g. [T].",
    "trait List[T]:\n  def isEmpty: Boolean\n  def head: T\n  def tail: List[T]\n\nclass Cons[T](val head: T, val tail: List[T]) extends List[T]:\n  def isEmpty = false\n\nclass Nil[T] extends List[T]:\n  def isEmpty = true\n  def head = throw new NoSuchElementException(\"Nil.head\")\n  def tail = throw new NoSuchElementException(\"Nil.tail\")",
    "Generic Functions\n\nLike classes, functions can have type parameters.\n\nFor instance, here is a function that creates a list consisting of a single element.\n\n```scala\ndef singleton[T](elem: T) = Cons[T](elem, Nil[T])\n```\n\nWe can then write:\n\n```scala\nsingleton[Int](1)\nsingleton[Boolean](true)\n```",
    "Type Inference\n\nIn fact, the Scala compiler can usually deduce the correct type parameters from the value arguments of a function call.\n\nSo, in most cases, type parameters can be left out. You could also write:\n\nsingleton(1)\nsingleton(true)",
    "Types and Evaluation\n\nType parameters do not affect evaluation in Scala.\n\nWe can assume that all type parameters and type arguments are removed before evaluating the program.\n\nThis is also called type erasure.\n\nLanguages that use type erasure include Java, Scala, Haskell, ML, OCaml.\n\nSome other languages keep the type parameters around at run time, these include C++, C#, F#.",
    "Polymorphism\n\nPolymorphism means that a function type comes \"in many forms\".\n\nIn programming it means that\n\n\u25b6 the function can be applied to arguments of many types, or\n\u25b6 the type can have instances of many types.",
    "Polymorphism\n\nPolymorphism means that a function type comes \u201cin many forms\u201d.\n\nIn programming it means that\n\n\u25ba the function can be applied to arguments of many types, or\n\u25ba the type can have instances of many types.\n\nWe have seen two principal forms of polymorphism:\n\n\u25ba subtyping: instances of a subclass can be passed to a base class\n\u25ba generics: instances of a function or class are created by type parameterization.",
    "Exercise\n\nWrite a function nth that takes a list and an integer n and selects the n'th element of the list.\n\ndef nth[T](xs: List[T], n: Int): Int = ???\n\nElements are numbered from 0.\n\nIf index is outside the range from 0 up the length of the list minus one, a IndexOutOfBoundsException should be thrown.\n\n```\ndef nth[T](xs: List[T], n: Int): T =\n  if (xs.isEmpty) throw new IndexOutOfBoundsException\n  else if (n == 0) xs.head\n  else nth (xs.tail, n-1)\n\nnth(CONS(1, CONS(2, CONS(3, NIL()))), 2)\n```",
    "Discrete Event Simulation\n\nPrinciples of Functional Programming",
    "Advanced Example: Discrete Event Simulation\n\nWe now consider an example of how assignments and higher-order functions can be combined in interesting ways.\n\nWe will construct a digital circuit simulator.\n\nThis example also shows how to build programs that do discrete event simulation.",
    "Digital Circuits\n\nLet's start with a small description language for digital circuits.\nA digital circuit is composed of wires and of functional components.\nWires transport signals that are transformed by components.\nWe represent signals using booleans true and false.\nThe base components (gates) are:\n\u25ba The Inverter, whose output is the inverse of its input.\n\u25ba The AND Gate, whose output is the conjunction of its inputs.\n\u25ba The OR Gate, whose output is the disjunction of its inputs.\nOther components can be constructed by combining these base components.\nThe components have a reaction time (or delay), i.e. their outputs don't change immediately after a change to their inputs.",
    "Digital Circuit Diagrams\n\nNeed code representation for these three operators.\n\nHALF ADDER\n\nFULL ADDER\n\nWe also need wires to connect actions.",
    "A Language for Digital Circuits\n\nWe describe the elements of a digital circuit using the following Scala classes and functions.\nTo start with, the class Wire models wires.\n\nWires can be constructed as follows:\nval a = Wire(); val b = Wire(); val c = Wire()\n\nor, equivalently:\n\nval a, b, c = Wire()\n\nThen, there exist the following functions, which create base components, as a side effect.\n\ndef inverter(input: Wire, output: Wire): Unit\ndef andGate(in1: Wire, in2: Wire, output: Wire): Unit\ndef orGate(in1: Wire, in2: Wire, output: Wire): Unit",
    "Constructing Components\n\nMore complex components can be constructed from these. For example, a half-adder can be defined as follows:\n\n```\ndef halfAdder(a: Wire, b: Wire, s: Wire, c: Wire): Unit = \n  val d = Wire()\n  val e = Wire()\n  orGate(a, b, d)\n  andGate(a, b, c)\n  inverter(c, e)\n  andGate(d, e, s)\n```",
    "More Components\n\nThis half-adder can in turn be used to define a full adder:\n\ndef fullAdder(a: Wire, b: Wire, cin: Wire, sum: Wire, cout: Wire): Unit = \n  val s = Wire()\n  val c1 = Wire()\n  val c2 = Wire()\n  halfAdder(a, cin, s, c1)\n  halfAdder(b, s, sum, c2)\n  orGate(c1, c2, cout)",
    "What logical function does this program describe?\n\n```scala\ndef f(a: Wire, b: Wire, c: Wire): Unit = {\n  val d, e, f, g = Wire()\n  inverter(a, d)\n  inverter(b, e)\n  andGate(a, b, f)\n  andGate(b, d, g)\n  orGate(f, g, c)\n}\n```\n$T$: not , $\\neg a =d$\n$V$: or\nFinal result: True if either $a$ and $b$ or $\\neg b$ and $a$\nequivalently\n$0 \\quad a \\quad b \\quad \\neg b \\quad 0 \\quad a \\& (\\neg b \\& a) \\quad 0 \\quad b \\neq a$\n$0 \\quad a == b \\quad 0 \\quad a != b \\quad 0 \\quad a \\& b$",
    "Implementation\n\nThe class Wire and the functions inverter, andGate, and orGate represent a small description language of digital circuits.\n\nWe now give the implementation of this class and its functions which allow us to simulate circuits.\n\nThese implementations are based on a simple API for discrete event simulation.",
    "Actions\n\nA discrete event simulator performs actions, specified by the user at a given moment.\n\nAn action is a function that doesn\u2019t take any parameters and which returns Unit:\n\n$ \\text{type Action = () => Unit} $\n\nThe time is simulated; it has nothing to with the actual time.",
    "A concrete simulation happens inside an object that inherits from the abstract class Simulation, which has the following signature:\n\n```\ntrait Simulation:\n  type Action = () => Unit\n  def currentTime: Int = ???\n  def afterDelay(delay: Int)(block: => Unit): Unit = ???\n  def run(): Unit = ???\nend Simulation\n```\n\nHere,\n\ncurrentTime returns the current simulated time in the form of an integer.\n\nafterDelay registers an action to perform after a certain delay (relative to the current time, currentTime).\n\nrun performs the simulation until there are no more actions waiting.",
    "Simulation  \nGates  \nCircuits\nhalf adder, etc...  \ndelays  \nsin/cosine, sawtooth  ",
    "A wire must support three basic operations:\n\ngetSignal(): Boolean\n\nReturns the current value of the signal transported by the wire.\n\nsetSignal(sig: Boolean): Unit\n\nModifies the value of the signal transported by the wire.\n\naddAction(a: Action): Unit\n\nAttaches the specified procedure to the actions of the wire. All of the attached actions are executed at each change of the transported signal.",
    "Implementing Wires\n\nHere is an implementation of the class Wire:\n\nclass Wire:\n   private var sigVal = false\n   private var actions: List[Action] = List()\n\n   def getSignal(): Boolean = sigVal\n\n   def setSignal(s: Boolean): Unit =\n      if s != sigVal then\n         sigVal = s\n         actions.foreach(_()) \u27f6 for a \u2190 actions do a()\n\n   def addAction(a: Action): Unit =\n      actions = a :: actions\n      a()",
    "State of a Wire\n\nThe state of a wire is modeled by two private variables:\n\nsigval represents the current value of the signal.\n\nactions represents the actions currently attached to the wire.",
    "The Inverter\n\nWe implement the inverter by installing an action on its input wire.\n\nThis action produces the inverse of the input signal on the output wire.\n\nThe change must be effective after a delay of $InverterDelay$ units of simulated time.\n\nWe thus obtain the following implementation:\n\n```python\ndef inverter(input: Wire, output: Wire): Unit =\n    def invertAction(): Unit =\n        val inputSig = input.getSignal()\n        afterDelay(InverterDelay) { output.setSignal(!inputSig) }\n    input.addAction(invertAction)\n```",
    "The AND Gate\n\nThe AND gate is implemented in a similar way.\n\nThe action of an AND gate produces the conjunction of input signals on the output wire.\n\nThis happens after a delay of $AndGateDelay$ units of simulated time.\n\nWe thus obtain the following implementation:\n\n```scala\ndef andGate(in1: Wire, in2: Wire, output: Wire): Unit = {\n  def andAction(): Unit = {\n    val in1Sig = in1.getSignal()\n    val in2Sig = in2.getSignal()\n    afterDelay(AndGateDelay) { output.setSignal(in1Sig & in2Sig) }\n  }\n  in1.addAction(andAction)\n  in2.addAction(andAction)\n}\n```",
    "The OR Gate\n\nThe OR gate is implemented analogously to the AND gate.\n\n```\ndef orGate(in1: Wire, in2: Wire, output: Wire): Unit = {\n  def orAction(): Unit = {\n    val in1Sig = in1.getSignal()\n    val in2Sig = in2.getSignal()\n    afterDelay(OrGateDelay) { output.setSignal(in1Sig | in2Sig) }\n  }\n  in1.addAction(orAction)\n  in2.addAction(orAction)\n}\n```",
    "Exercise\n\nWhat happens if we compute in1Sig and in2Sig inline inside afterDelay instead of computing them as values?\n\n```scala\ndef orGate2(in1: Wire, in2: Wire, output: Wire): Unit =\n  def orAction(): Unit =\n    afterDelay(orGateDelay) { \n      output.setSignal(in1.getSignal | in2.getSignal)\n    }\n  in1.addAction(orAction)\n  in2.addAction(orAction)\n```\n\n0 'orGate' and 'orGate2' have the same behavior.\nX 'orGate2' does not model OR gates faithfully.",
    "The Simulation Trait\n\nAll we have left to do now is to implement the Simulation trait.\n\nThe idea is to keep in every instance of the Simulation trait an agenda of actions to perform.\n\nThe agenda is a list of Events. Each event is composed of an action and the time when it must be produced.\n\nThe agenda list is sorted in such a way that the actions to be performed first are in the beginning.\n\n```\ntrait Simulation:\n  ...\n  private case class Event(time: Int, action: Action)\n  private type Agenda = List[Event]\n  private var agenda: Agenda = List()\n```",
    "Handling Time\n\nThere is also a private variable, curtime, that contains the current simulation time:\n\n    private var curtime = 0\n\nAn application of the afterDelay(delay)(block) method inserts the task\n\n    Event(curtime + delay, () => block)\n\ninto the agenda list at the right position.",
    "Implementing AfterDelay\n\ndef afterDelay(delay: Int)(block: => Unit): Unit =\n  val item = Event(currentTime + delay, () => block)\n  agenda = insert(agenda, item)\n\nThe insert function is straightforward:\n\nprivate def insert(ag: List[Event], item: Event): List[Event] = ag match\n  case first :: rest if first.time <= item.time =>\n    first :: insert(rest, item)\n  case _ =>\n    item :: ag",
    "The event handling loop removes successive elements from the agenda, and performs the associated actions.\n\nprivate def loop(): Unit = agenda match\n  case first :: rest =>\n    agenda = rest\n    curtime = first.time\n    first.action()\n    loop()\n  case Nil =>",
    "Implementing Run\n\nAn application of the run method removes successive elements from the agenda, and performs the associated actions.\n\nThis process continues until the agenda is empty:\n\ndef run(): Unit =\n  afterDelay(0) {\n    println(s\"*** simulation started, time = $currentTime ***\")\n  }\n  loop()",
    "Probes\n\nBefore launching the simulation, we still need a way to examine the changes of the signals on the wires.\n\nTo this end, we define the function probe.\n\ndef probe(name: String, wire: Wire): Unit =\n  def probeAction(): Unit =\n    println(s\"$name $currentTime value = ${wire.getSignal()}\")\n  wire.addAction(probeAction)",
    "Defining Technology-Dependent Parameters\n\nIt's convenient to pack all delay constants into their own trait which can be mixed into a simulation. For instance:\n\ntrait Delays:\n  def InverterDelay = 2\n  def AndGateDelay = 3\n  def OrGateDelay = 5\n\nobject sim extends Circuits, Delays",
    "Here's a sample simulation that you can do in the worksheet.\n\nDefine four wires and place some probes.\n\n```\nimport sim.*\nval input1, input2, sum, carry = Wire()\nprobe(\"sum\", sum)\nprobe(\"carry\", carry)\n```\n\nNext, define a half-adder using these wires:\n\n```\nhalfAdder(input1, input2, sum, carry)\n```",
    "Launching the Simulation\n\nNow give the value true to input1 and launch the simulation:\n\ninput1.setSignal(true)\nrun()\n\nTo continue:\n\ninput2.setSignal(true)\nrun()",
    "A Variant\n\nAn alternative version of the OR-gate can be defined in terms of AND and INV.\n\n```\ndef orGateAlt(in1: Wire, in2: Wire, output: Wire): Unit =\n\tval notIn1, notIn2, notOut = Wire()\n\tinverter(in1, notIn1); inverter(in2, notIn2)\n\tandGate(notIn1, notIn2, notOut)\n\tinverter(notOut, output)\n```\n$$a \\lor b = \\neg (\\neg a \\land \\neg b)$$",
    "Exercise\n\nQuestion: What would change in the circuit simulation if the implementation of orGateAlt was used for OR?\n\n0 Nothing. The two simulations behave the same.\n\n0 The simulations produce the same events, but the indicated times are different.\n\n\u2299 The times are different, and orGateAlt may also produce additional events.\n\n0 The two simulations produce different events altogether.",
    "Summary\n\nState and assignments make our mental model of computation more complicated.\n\nIn particular, we lose referential transparency.\n\nOn the other hand, the assignment allows us to formulate certain programs in an elegant way.\n\nExample: discrete event simulation.\n\nHere, a system is represented by a mutable list of actions.\nThe effect of actions, when they\u2019re called, change the state of objects and can also install other actions to be executed in the future.\n\nAs always, the choice between functional and imperative programming must be made depending on the situation.",
    "Lazy Evaluation\n\nPrinciples of Functional Programming",
    "Lazy Evaluation\n\nThe proposed implementation suffers from a serious potential performance problem: If tail is called several times, the corresponding lazy list will be recomputed each time.\n\nThis problem can be avoided by storing the result of the first evaluation of tail and re-using the stored result instead of recomputing tail.\n\nThis optimization is sound, since in a purely functional language an expression produces the same result each time it is evaluated.\n\nWe call this scheme lazy evaluation (as opposed to by-name evaluation in the case where everything is recomputed, and strict evaluation for normal parameters and val definitions.)",
    "Lazy Evaluation in Scala\n\nHaskell is a functional programming language that uses lazy evaluation by default.\n\nScala uses strict evaluation by default, but allows lazy evaluation of value definitions with the lazy val form:\n\n$ \\text{lazy val x = expr} $",
    "Exercise:\n\nConsider the following program:\n\ndef expr =\n  val x = { print(\"x\"); 1 }\n  lazy val y = { print(\"y\"); 2 }\n  def z = { print(\"z\"); 3 }\n  z + y + x + z + y + x\n  \nexpr\n\nIf you run this program, what gets printed as a side effect of evaluating expr?\n\nz  \nxyz xyz  ",
    "Lazy Vals and Lazy Lists\n\nUsing a lazy value for tail, TailLazyList.cons can be implemented more efficiently: \n\n```scala\ndef cons[T](hd: T, tl: => LazyList[T]) = new TailLazyList[T]:\n  def head = hd\n  lazy val tail = tl\n```\n\ntail val is stored and reused if we call it again.",
    "To convince ourselves that the implementation of lazy lists really does avoid unnecessary computation, let's observe the execution trace of the expression:\n\nlazyRange(1000, 10000).filter(isPrime).apply(1)\n\n--> (if 1000 >= 10000 then empty // by expanding lazyRange\nelse cons(1000, lazyRange(1000 + 1, 10000))\n.filter(isPrime).apply(1))\n\n--> cons(1000, lazyRange(1000 + 1, 10000))\n.filter(isPrime).apply(1) // by evaluating if",
    "Let's abbreviate cons(1000, lazyRange(1000 + 1, 10000)) to C1.\nC1.filter(isPrime).apply(1)\n\n--> (if C1.isEmpty then C1\nelse if isPrime(C1.head) then cons(C1.head, C1.tail.filter(isPrime))\nelse C1.tail.filter(isPrime))\n.apply(1)\n\n--> (if isPrime(C1.head) then cons(C1.head, C1.tail.filter(isPrime))\nelse C1.tail.filter(isPrime))\n// by eval. if\n.apply(1)\n\n--> (if isPrime(1000) then cons(C1.head, C1.tail.filter(isPrime))\nelse C1.tail.filter(isPrime))\n// by eval. head\n.apply(1)",
    "Evaluation Trace (3)\n\n-->> (if false then cons(C1.head, C1.tail.filter(isPrime))   // by eval. isPrime\n      else C1.tail.filter(isPrime))\n      .apply(1)\n\n-->> C1.tail.filter(isPrime).apply(1)                       // by eval. if\n\n-->> lazyRange(1001, 10000)\n      .filter(isPrime).apply(1)                              // by eval. tail\n\nThe evaluation sequence continues like this until:\n\n-->> lazyRange(1009, 10000)\n      .filter(isPrime).apply(1)\n\n-->> cons(1009, lazyRange(1009 + 1, 10000))                  // by eval. lazyRange\n      .filter(isPrime).apply(1)",
    "Evaluation Trace (4)\n\nLet's abbreviate $cons(1009, lazyRange(1009 + 1, 10000))$ to $C2$.\n\n$C2.filter(isPrime).apply(1)$\n\n$--> cons(1009, C2.tail.filter(isPrime)).apply(1)$\n\n$--> if 1 == 0 then cons(1009, C2.tail.filter(isPrime)).head \\space //by \\space eval. \\space apply$\n$else cons(1009, C2.tail.filter(isPrime)).tail.apply(0)$\n\nAssuming apply is defined like this in LazyList[$T$]:\n\n$def \\ apply(n: \\ Int): \\ T =$\n$ \\ if \\space n == 0 \\space then \\space head$\n$ \\ else \\space tail.apply(n-1)$",
    "Let's abbreviate $ \\text{cons}(1009, \\text{lazyRange}(1009 + 1, 10000)) $ to $ \\text{C2} $.\n\n$ \\text{C2.filter(isPrime).apply(1)} $\n\n$ \\quad --> \\text{cons}(1009, \\text{C2.tail.filter(isPrime)}).apply(1) \\quad // \\text{by eval. filter} $\n\n$ \\quad --> \\text{if } 1 = 0 \\text{ then cons}(1009, \\text{C2.tail.filter(isPrime)}).head \\quad // \\text{by eval. apply} $\n$ \\quad \\quad \\quad \\text{else cons}(1009, \\text{C2.tail.filter(isPrime)}).tail.apply(0) $\n\n$ \\quad --> \\text{cons}(1009, \\text{C2.tail.filter(isPrime)}).tail.apply(0) \\quad // \\text{by eval. if} $\n\n$ \\quad --> \\text{C2.tail.filter(isPrime).apply(0)} \\quad // \\text{by eval. tail} $\n\n$ \\quad --> \\text{lazyRange}(1010, 10000).filter(isPrime).apply(0) \\quad // \\text{by eval. tail} $",
    "Evaluation Trace (5)\n\nThe process continues until\n\n--> lazyRange(1013, 10000).filter(isPrime).apply(0)\n\n--> cons(1013, lazyRange(1013 + 1, 10000))\n    .filter(isPrime).apply(0)               // by eval. lazyRange\n    \nLet C3 be a shorthand for cons(1013, lazyRange(1013 + 1, 10000).\n\n== C3.filter(isPrime).apply(0)\n\n--> cons(1013, C3.tail.filter(isPrime)).apply(0)   // by eval. filter\n\n--> 1013                // by eval. apply\n\nOnly the part of the lazy list necessary to compute the result has been constructed.",
    "RealWorld Lazy List\n\nThe simplified implementation shown for LazyList has a lazy tail, but not a lazy head, nor a lazy isEmpty.\n\nThe real implementation is lazy for all three operations.\n\nTo do this, it maintain a lazy state variable, like this:\n\nclass LazyList[+T](init: => State[T]):\n    lazy val state: State[T] = init\n\nenum State[T]:\n    case Empty\n    case Cons(hd: T, tl: LazyList[T])",
    "Evaluation and Operators\n\nPrinciples of Functional Programming",
    "Classes and Substitutions\n\nWe previously defined the meaning of a function application using a computation model based on substitution. Now we extend this model to classes and objects.\n\nQuestion: How is an instantiation of the class $C(e_1, \\ldots, e_n)$ evaluated?\n\nAnswer: The expression arguments $e_1, \\ldots, e_n$ are evaluated like the arguments of a normal function. That\u2019s it.\n\nThe resulting expression, say, $C(v_1, \\ldots, v_n)$, is already a value.",
    "Now suppose that we have a class definition,\n\nclass C(x_1, ..., x_k) { ... def f(y_1, ..., y_n) = b ... }\n\nwhere\n\n- The formal parameters of the class are $x_1, ..., x_k$.\n- The class defines a method $f$ with formal parameters $y_1, ..., y_n$.\n\n(The list of function parameters can be absent. For simplicity, we have omitted the parameter types.)\n\nQuestion: How is the following expression evaluated?\n\n\\[ \nC(v_1, ..., v_k).f(w_1, ..., w_n) \n\\]",
    "Answer: The expression $C(v_1, ..., v_n) = f(w_1, ..., w_n)$ is rewritten to:\n\n$[w_1/y_1, ..., w_n/y_n][v_1/x_1, ..., v_n/x_n][C(v_1, ..., v_n)/ \\text{this}] b$\n\nThere are three substitutions at work here:\n\n- the substitution of the formal parameters $y_1, ..., y_n$ of the function $f$ by the arguments $w_1, ..., w_n$,\n- the substitution of the formal parameters $x_1, ..., x_n$ of the class $C$ by the class arguments $v_1, ..., v_n$,\n- the substitution of the self reference $\\text{this}$ by the value of the object $C(v_1, ..., v_n)$.",
    "Object Rewriting Examples\n\nRational(1, 2).numer\n\n\u27f9 [1/x,2/y][Rational(1,2)/this]x\n\n= 1\n\nRational(1, 2).less(Rational(2, 3))\n\n\u27f9 [1/x,2/y][Rational(2,3)/that][Rational(1,2)/this]\nthis.numer * that.denom < that.numer * this.denom\n\n= Rational(1, 2).numer * Rational(2, 3).denom < Rational(2, 3).numer * Rational(1, 2).denom\n\n\u27f9 1 * 3 < 2 * 2\n\n\u27f9 true",
    "Extension Methods\n\nHaving to define all methods that belong to a class inside the class itself can lead to very large classes, and is not very modular.\n\nMethods that do not need to access the internals of a class can alternatively be defined as extension methods.\n\nFor instance, we can add min and abs methods to class Rational like this:\n\nextension (r: Rational):\n  def min(s: Rational): Boolean = if s.less(r) then s else r\n  def abs: Rational = Rational(r.numer.abs, r.denom)\n",
    "Using Extension Methods\n\nExtensions of a class are visible if they are listed in the companion object of a class (as in the code above) or if they defined or imported in the current scope.\n\nMembers of a visible extensions of class C can be called as if they were members of C. E.g.\n\n$Rational(1/2).min(Rational(2/3))$\n\nCaveats:\n\n\u25ba Extensions can only add new members, not override existing ones.\n\u25ba Extensions cannot refer to other class members via this",
    "Extension Methods and Substitutions\n\nExtension method substitution works like normal substitution, but\n\n\ud83d\udd39 instead of this it's the extension parameter that gets substituted,\n\ud83d\udd39 class parameters are not visible, so do not need to be substituted at all.\n\nRational(1, 2).min(Rational(2, 3))\n\n$\\Rightarrow [Rational(1,2)/r] [Rational(2,3)/s]$ if $x$.less$(r)$ then $s$ else $r$\n\n= \n\nif $Rational(2, 3)$.less$(Rational(1, 2))$\nthen $Rational(2, 3)$ \nelse $Rational(1, 2)$",
    "Operators\n\nIn principle, the rational numbers defined by Rational are as natural as integers.\n\nBut for the user of these abstractions, there is a noticeable difference:\n\n\u25ba  We write $x + y$, if $x$ and $y$ are integers, but\n\u25ba  We write $r.add(s)$ if $r$ and $s$ are rational numbers.\n\nIn Scala, we can eliminate this difference. We proceed in two steps.",
    "Step 1: Relaxed Identifiers\n\nOperators such as + or < count as identifiers in Scala. \n\nThus, an identifier can be:\n\u25b6 Alphanumeric: starting with a letter, followed by a sequence of letters or numbers.\n\u25b6 Symbolic: starting with an operator symbol, followed by other operator symbols.\n\u25b6 The underscore character \u2018_\u2019 counts as a letter.\n\u25b6 Alphanumeric identifiers can also end in an underscore, followed by some operator symbols.\n\nExamples of identifiers:\n\nx1     *     +?%&     vector_++     counter_=",
    "Step 1: Relaxed Identifiers\n\nSince operators are identifiers, it is possible to use them as method names.\nE.g.\n\n```scala\nextension (x: Rational):\n  def + (y: Rational): Rational = x.add(y)\n  def * (y: Rational): Rational = x.mul(y)\n...\n```\n\nThis allows rational numbers to be used like Int or Double:\n\n```scala\nval x = Rational(1, 2)\nval y = Rational(1, 3)\nx * x + y * y * y\n```",
    "Step 2: Infix Notation\n\nAn operator method with a single parameter can be used as an infix operator.\n\nAn alphanumeric method with a single parameter can also be used as an infix operator if it is declared with an @infix annotation. E.g.\n\n```\nextension (x: Rational):\n   @infix def min(that Rational): Rational = ...\n```\n\nIt is therefore possible to write\n\n```\nr + s     /* in place of */     r.+(s)\nr < s                          r.<(s)\nr min s                        r.min(s)\n```",
    "Precedence Rules\n\nThe precedence of an operator is determined by its first character.\n\nThe following table lists the characters in increasing order of priority precedence:\n\n(all letters) \\textcolor{red}{(lowest priority)}\n\n|\n\n^\n\n&\n\n< >\n\n= !\n\n:\n\n+ -\n\n* / %\n\n(all other special characters) \\textcolor{red}{(Highest priority precedence)}",
    "Provide a fully parenthesized version of\n\n$a + b ^? c ?^ d \\text{ less } a ==? b \\mid c$\n\nEvery binary operation needs to be put into parentheses, but the structure of the expression should not change.",
    "Pattern Matching\n\nPrinciples of Functional Programming",
    "Reminder: Decomposition\n\nThe task we are trying to solve is find a general and convenient way to access heterogeneous data in a class hierarchy.\n\nAttempts seen previously:\n\u25ba Classification and access methods: quadratic explosion\n\u25ba Type tests and casts: unsafe, low-level\n\u25ba Object-oriented decomposition: causes coupling between data and operations, need to touch all classes to add a new method.",
    "Solution 2: Functional Decomposition with Pattern Matching\n\nObservation: the sole purpose of test and accessor functions is to reverse the construction process:\n\n\u25ba Which subclass was used?\n\u25ba What were the arguments of the constructor?\n\nThis situation is so common that many functional languages, Scala included, automate it.",
    "Case Classes\n\nA case class definition is similar to a normal class definition, except that it is preceded by the modifier case. For example: \n\n```\ntrait Expr\ncase class Number(n: Int) extends Expr\ncase class Sum(e1: Expr, e2: Expr) extends Expr\n```\nLike before, this defines a trait Expr, and two concrete subclasses Number and Sum. \n\nHowever, these classes are now empty. So how can we access the members?\n\n*solution.*",
    "Pattern matching is a generalization of switch from C/Java to class hierarchies.\n\nIt's expressed in Scala using the keyword match.\n\nExample\n\n```\ndef eval(e: Expr): Int = e match\n  case Number(n) => n\n  case Sum(e1, e2) => eval(e1) + eval(e2)\n```",
    "Match Syntax\n\nRules:\n- match is preceded by a selector expression and is followed by a sequence of cases, pat => expr.\n- Each case associates an expression expr with a pattern pat.\n- A MatchError exception is thrown if no pattern matches the value of the selector.",
    "Forms of Patterns\n\nPatterns are constructed from:\n- constructors, e.g. Number, Sum,\n- variables, e.g. n, e1, e2,\n- wildcard patterns ___, \n- constants, e.g. 1, true, \n- type tests, e.g. n: Number\n\nVariables always begin with a lowercase letter.\n\nThe same variable name can only appear once in a pattern. So, Sum(x, x) is not a legal pattern.\n\nNames of constants begin with a capital letter, with the exception of the reserved words null, true, false.",
    "Evaluating Match Expressions\n\nAn expression of the form\n\n$$e \\; \\text{match} \\; \\{ \\; \\text{case} \\; p_1 \\Rightarrow e_1 \\; \\ldots \\; \\text{case} \\; p_n \\Rightarrow e_n \\; \\}$$\n\nmatches the value of the selector $e$ with the patterns $p_1, \\ldots, p_n$ in the order in which they are written.\n\nThe whole match expression is rewritten to the right-hand side of the first case where the pattern matches the selector $e$.\n\nReferences to pattern variables are replaced by the corresponding parts in the selector.",
    "What Do Patterns Match?\n\n- A constructor pattern $c(p_1, ..., p_n)$ matches all the values of type $c$ (or a subtype) that have been constructed with arguments matching the patterns $p_1, ..., p_n$.\n- A variable pattern $x$ matches any value, and binds the name of the variable to this value.\n- A constant pattern $c$ matches values that are equal to $c$ (in the sense of $==$).\n\n$ n : Number \\rightarrow$ would match any value that is a number and match it with name $n$.",
    "eval(Sum(Number(1), Number(2)))\n\n\u2192\n\nSum(Number(1), Number(2)) match\n  case Number(n) => n\n  case Sum(e1, e2) => eval(e1) + eval(e2)\n\n\u2192\n\neval(Number(1)) + eval(Number(2))",
    "Example (2)\n\n$\\rightarrow$\n\n\\[\n\\text{Number} (1) \\text{ match}\n\\newline\n\\text{case Number} (n) \\Rightarrow n\n\\newline\n\\text{case Sum} (e_1, e_2) \\Rightarrow \\text{eval}(e_1) + \\text{eval}(e_2)\n\\newline\n+ \\text{eval} (\\text{Number} (2))\n\\]\n\n$\\rightarrow$\n\n\\[\n1 + \\text{eval}(\\text{Number}(2))\n\\]\n\n$\\rightarrow$\n\n\\[\n3\n\\]",
    "Of course, it's also possible to define the evaluation function as a method of the base trait.\n\nExample\n\ntrait Expr:\n  def eval: Int = this match\n    case Number(n) => n\n    case Sum(e1, e2) => e1.eval + e2.eval",
    "Exercise\n\nWrite a function show that uses pattern matching to return the representation of a given expressions as a string.\n\n```python\ndef show(e: Expr): String = ???\n\n  case Number(n) => n.toString\n  case Sum(e1, e2) => s\"${show(e1)} + ${show(e2)}\"\n```",
    "Exercise (Optional, Harder)\n\nAdd case classes Var for variables $x$ and Prod for products $x \\times y$ as discussed previously.\n\nChange your show function so that it also deals with products.\n\nPay attention you get operator precedence right but to use as few parentheses as possible.\n\nExample\n\n\\[\n\\text{Sum(Prod(2, Var(\"x\")), Var(\"y\"))}\n\\]\n\nshould print as \u201c$2 \\times x + y$\u201d. But\n\n\\[\n\\text{Prod(Sum(2, Var(\"x\")), Var(\"y\"))}\n\\]\n\nshould print as \u201c$(2 + x) \\times y$\u201d.",
    "case class Prod(e1:Expr, e2:Expr) extends Expr\n\ndef showP(e:Expr): String = e match\n  case e:Sum => s\"${show(e)}\"\n  case _ => show(e)\n\ncase Prod(e1,e2) => s\"${showP(e1)} x ${showP(e2)}\"",
    "Parsing with Combinators\n\nFunctional Programming (CS-210)\n\nEPFL",
    "People write code using \\textit{text} (sequences of characters).\n\n```\n(def double(n) = (n + n)\n double 4)\n```",
    "People write code using text (sequences of characters).\n```\n(def double(n) = (n + n)\n double 4)\n```\nBut writing an interpreters (or compilers) is way easier on trees.\nDefs(\n    List((\"double\", Fun(\"n\", BinOp(Plus, N(\"n\"), N(\"n\"))))),\n         Call(N(\"double\"), C(4))))",
    "People write code using text (sequences of characters).\n\n\"\"\"\n(def double(n) = (n + n)\n  double 4)\n\"\"\"\n\nBut writing an interpreters (or compilers) is way easier on trees.\n\nDefs(\n  List((\"double\", Fun(\"n\", BinOp(Plus, N(\"n\"), N(\"n\"))))),\n    Call(N(\"double\"), C(4)))\n)\n\nThis representation immediately exposes the structure of the code, while the text representation does not.",
    "Therefore, in such projects somebody has to write a conversion from text to trees.\ndef parse(input: List[Char]): Expr",
    "Therefore, in such projects somebody has to write a conversion from text to trees.\n```python\ndef parse(input: List[Char]): Expr\n```\nIf you take *Computer Language Processing (CS-320)*, this person will be you!",
    "Writing such functions can be very tricky. *Parser Combinators* are one way to go about handling this complexity.",
    "Writing such functions can be very tricky. Parser Combinators are one way to go about handling this complexity.\n\nSimple idea:\n\u25ba Very simple basic parsers\n\u25ba Ways to combine parsers into more complex parsers",
    "There exist many parser combinator libraries in Scala:",
    "There exist many parser combinator libraries in Scala:\n  * Scala Parser Combinators\n    github.com/scala/scala-parser-combinators",
    "There exist many parser combinator libraries in Scala:\n\n- Scala Parser Combinators\n  github.com/scala/scala-parser-combinators\n- FastParse\n  www.lihaoyi.com/fastparse/",
    "There exist many parser combinator libraries in Scala:\n\n- Scala Parser Combinators\n  github.com/scala/scala-parser-combinators\n\n- FastParse\n  www.lihaoyi.com/fastparse/\n\n- Scallion\n  github.com/epfl-lara/scallion",
    "There exist many parser combinator libraries in Scala:\n\n- Scala Parser Combinators\n  github.com/scala/scala-parser-combinators\n\n- FastParse\n  www.lihaoyi.com/fastparse/\n\n- Scallion\n  github.com/epfl-lara/scallion\n\nWhat I will present is the general idea behind many such libraries.",
    "There exist many parser combinator libraries in Scala:\n- Scala Parser Combinators\n  github.com/scala/scala-parser-combinators\n- FastParse\n  www.lihaoyi.com/fastparse/\n- Scallion\n  github.com/epfl-lara/scallion\n\nWhat I will present is the general idea behind many such libraries. The actual implementation may vary but the basic interface will often remain the same.",
    "Parser objects\n\ndef parse(input: List[Char]): Expr",
    "Parser objects\n\n```python\ndef parse(input: List[Char]): Expr\n```\n\nTurning it into a class:\n```python\ncase class Parser(parse: List[Char] => Expr)\n```",
    "Parser objects\n\n```python\ndef parse(input: List[Char]): Expr\n```\nTurning it into a class:\n```scala\ncase class Parser(parse: List[Char] => Expr)\n```\nReturning the remaining input:\n```scala\ncase class Parser(parse: List[Char] => (Expr, List[Char]))\n```",
    "Parser objects\n\ndef parse(input: List[Char]): Expr\nTurning it into a class:\ncase class Parser(parse: List[Char] => Expr)\n\nReturning the remaining input:\ncase class Parser(parse: List[Char] => (Expr, List[Char]))\n\nReturning multiple alternatives:\ncase class Parser(parse: List[Char] => LazyList[(Expr, List[Char])])",
    "Parser objects\n\ndef parse(input: List[Char]): Expr\nTurning it into a class:\ncase class Parser(parse: List[Char] => Expr)\n\nReturning the remaining input:\ncase class Parser(parse: List[Char] => (Expr, List[Char]))\n\nReturning multiple alternatives:\ncase class Parser(parse: List[Char] => LazyList[(Expr, List[Char])])\n\nAbstracting over the type of trees:\ncase class Parser[+A](parse: List[Char] => LazyList[(A, List[Char])])",
    "// Method of Parser[+A]\ndef apply(input: List[Char]): Option[A] = {\n  this\n    .parse(input)\n    .filter(_._2.isEmpty)\n    .map(_._1)\n    .headOption\n}",
    "def parse(input: List[Char]): Tree = {\n  val parser: Parser[Tree] = ???\n\n  parser(input).getOrElse{ throw new ParseError() }\n}",
    "def parse(input: List[Char]): Tree = {\n  val parser: Parser[Tree] = ???  // How to build this?\n\n  parser(input).getOrElse{ throw new ParseError() }\n}",
    "Example: Parser for sums\n\nval letter: Parser[Char] = elem (_.isLetter)\n\nval variable: Parser[SumExpr] = letter.map(Var(_))\n\nval digit: Parser[Char] = elem (_ . isDigit)\n\nval number: Parser[SumExpr] = \n\tmany (digit)\n\t\t.filter( _. length > 0)\n\t\t.map(ds => Num(BigInt (ds.mkString (\"\"))))\n\nval atom: Parser[SumExpr] = number | variable\n\nval plus: Parser[Char] = elem ('+')\n\nval sum: Parser[SumExpr] =\n\t(atom ~ many(plus ~> atom)).map {\n\t\tcase n ~ ns => Sum(n +: ns)\n\t}",
    "Building Parsers",
    "Basic Parsers\n\nMatching a single character:\n```\nval item: Parser[Char] =\n  Parser(input => input match {\n    case c :: cs => LazyList((c, cs))\n    case _ => LazyList()\n  })\n```",
    "Basic Parsers\n\nReturning a value without looking at the input:\n```scala\ndef success[A](value: A): Parser[A] = \n  Parser(input => LazyList((value, input)))\n```",
    "Returning a value without looking at the input:\n\n$ \\text{def success}[A](\\text{value: } A): \\text{Parser}[A] = \\text{Parser}(\\text{input } => \\text{LazyList}((\\text{value}, \\text{ input}))) $\n\nAlways failing:\n\n$ \\text{val failure: Parser}[ \\text{Nothing}] = \\text{Parser}(\\text{input } => \\text{LazyList}()) $",
    "Building Complex Parsers",
    "Building Complex Parsers",
    "Filtering out unwanted values:\n\n```\n// Method of Parser[+A]\ndef filter(predicate: A => Boolean): Parser[A] =\n  Parser(input => this.parse(input).filter {\n    case (value, _) => predicate(value)\n  })\n```",
    "Filtering out unwanted values:\n\n// Method of Parser[+A]\ndef filter(predicate: A => Boolean): Parser[A] = \n    Parser(input => this.parse(input).filter {\n        case (value, _) => predicate(value)\n    })\n\ndef elem(predicate: Char => Boolean): Parser[Char] = \n    item.filter(predicate)",
    "Filtering Out Values\n\nFiltering out unwanted values:\n\n```scala\n// Method of Parser[+A]\ndef filter(predicate: A => Boolean): Parser[A] =\n  Parser(input => this.parse(input).filter {\n    case (value, _) => predicate(value)\n  })\n\ndef elem(predicate: Char => Boolean): Parser[Char] =\n  item.filter(predicate)\n\ndef elem(char: Char): Parser[Char] =\n  elem(_ == char)\n```",
    "Transforming Values\n\nModifying the parsed value:\n\n```scala\n// Method of Parser[+A]\ndef map[B](function: A => B): Parser[B] =\n  Parser(input => this.parse(input).map {\n    case (value, rest) => (function(value), rest)\n  })\n```\n\nExample:\n```scala\nval variable: Parser[SumExpr] = letter.map(Var(_))\n```",
    "Sequencing parsers:\n\n```scala\n// Method of Parser[+A]\ndef ~[B](that: Parser[B]): Parser[(A, B)] = \n    Parser(input => \n        for {\n            (leftValue, leftRest) <- this.parse(input)\n            (rightValue, rightRest) <- that.parse(leftRest)\n        } yield ((leftValue, rightValue), rightRest))\n```",
    "Parser combinator libraries generally introduce a bit of sugar...\n\n// Method of Parser[+A]\ndef ~[B](that: Parser[B]): Parser[A ~ B] = \n//  ^^^^^^^^ \n\nInstead of pairs, they will use something like:\ncase class ~[+A, +B](_1: A, _2: B)",
    "Sequencing Parsers\n\nParser combinator libraries generally introduce a bit of sugar...\n```scala\n// Method of Parser[+A]\ndef ~[B](that: Parser[B]): Parser[A ~ B] = \n// ^^^^^^\n```\n\nInstead of pairs, they will use something like:\n```scala\ncase class ~[+A, +B](_1: A, _2: B)\n```\nWhich is simply to provide better looking pattern matching:\n```scala\nval sum: Parser[SumExpr] =\n  (atom ~ many(plus ~> atom)).map {\n    case n ~ ns => Sum(n +: ns)\n  }\n```",
    "Sequencing Parsers\n\nSometimes, we wish to only keep the value from one side of a sequence and ignore the other.",
    "Sequencing Parsers\n\nSometimes, we wish to only keep the value from one side of a sequence and ignore the other.\n\n// Methods of Parser[+A]\ndef <~(that: Parser[Any]): Parser[A] = (this ~ that).map {\n  case left ~ _ => left\n}",
    "Sequencing Parsers\n\nSometimes, we wish to only keep the value from one side of a sequence and ignore the other.\n\n// Methods of Parser[+A]\ndef <~(that: Parser[Any]): Parser[A] = (this ~ that).map {\n  case left ~ _ => left\n}\n\ndef ~>[B](that: Parser[B]): Parser[B] = (this ~ that).map {\n  case _ ~ right => right\n}",
    "Introducing Alternatives\n\nSpecifying alternatives:\n\n```\n// Method of Parser[+A]\ndef |[B >: A](that: Parser[B]): Parser[B] =\n    Parser(input => this.parse(input) #:: that.parse(input))\n```",
    "Introducing Alternatives\n\nSpecifying alternatives:\n\n// Method of Parser[+A]\ndef [[B >: A](that: Parser[B]): Parser[B] = \n  Parser(input => this.parse(input) #:: that.parse(input))\n\nExample:\n\nval atom: Parser[SumExpr] = number | variable",
    "Making a parser optional:\n\n```scala\n// Method of Parser[+A]\ndef optional: Parser[Option[A]] =\n  this.map(Some(_)) | success(None)\n```",
    "Using Recursion\n\nHow to parse sums with parentheses?",
    "Using Recursion\n\nHow to parse sums with parentheses?\n\n\"$(1+2) + (x+y)$\"",
    "Using Recursion\n\nHow to parse sums with parentheses?\n\" (1+2)+(x+y) \"\n\nUsing recursion!",
    "Using Recursion\n\nHow to parse sums with parentheses?\n\"(1+2)+(x+y)\"\n\nUsing recursion!\n\n\\begin{verbatim}\nlazy val parensSum = elem('(') ~> sum <~ elem(')')\n\\end{verbatim}\n\n\\begin{verbatim}\nlazy val atom: Parser[SumExpr] = number | variable | parensSum\n\\end{verbatim}\n\n\\begin{verbatim}\nval plus: Parser[Char] = elem('+')\n\\end{verbatim}\n\n\\begin{verbatim}\nlazy val sum: Parser[SumExpr] = {\n  (atom ~ many(plus ~> atom)).map {\n    case n ~ ns => Sum(n :: ns)\n  }\n}\n\\end{verbatim}",
    "Using Recursion\n\nHow to parse sums with parentheses?\n\"(1+2)+(x+y)\"\n\nUsing recursion!\n\n```\nlazy val parensSum = elem('(') ~> sum <~ elem(')')\n\nlazy val atom: Parser[SumExpr] = number | variable | parensSum\n\nval plus: Parser[Char] = elem('+')\n\nlazy val sum: Parser[SumExpr] = defer { // < Change here!\n    (atom ~ many(plus ~> atom)).map {\n        case n ~ ns => Sum(n :: ns)\n    }\n}\n```",
    "Using Recursion\n\ndef defer[A](parser: => Parser[A]): Parser[A] = {\n  lazy val cached: Parser[A] = parser\n  Parser(cached.parse(_))\n}",
    "Repeating a parser:\n\n```scala\ndef many[A](parser: Parser[A]): Parser[List[A]] = {\n  lazy val repeated: Parser[List[A]] = defer {\n    (parser ~ repeated).map { case x ~ xs => x :: xs } |\n    success(List())\n  }\n\n  repeated\n}\n```",
    "Using Recursion\n\nSome libraries don't have defer, and instead pass arguments by name instead of by value for the various combinators.\n\n// Methods of Parser[+A]\ndef ~[B](that: => Parser[B]): Parser[A ~ B] = ...\n\ndef |[B >: A](that: => Parser[B]): Parser[B] = ...",
    "Handling Spaces\n\nSpaces everywhere!\nval input =\n  \"  (3 + 4 ) + x + y  \"\n// ^  ^  ^   ^   ^ ^ ^  ^",
    "Spaces everywhere!\n```scala\nval input = \" (3  +  4 )  +  x  +  y  \"\n// ^  ^  ^ ^ ^ ^  ^ ^ ^  ^ ^  ^\n```\n\nOne solution:\n```scala\nval space: Parser[Char] = elem(_.isWhitespace)\n```",
    "Handling Spaces\n\nSpaces everywhere!\n```\nval input = \" (3 + 4 ) + x + y   \"\n// ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^\n```\nOne solution:\n```\nval space: Parser[Char] = elem(_.isWhitespace)\n\ndef token[A](parser: Parser[A]): Parser[A] = parser <~ many(space)\n```",
    "Handling Spaces\n\nSpaces everywhere! \n```scala\nval input = \n   \" (3 + 4 ) + x y \" \n// ^ ^ ^ ^ ^ ^ ^ ^\n\nOne solution:\nval space: Parser[Char] = elem(_.isWhitespace)\n\ndef token[A](parser: Parser[A]): Parser[A] = parser <~ many(space)\n\nval variable: Parser[SumExpr] = token(letter.map(Var(_)))\n```",
    "Handling Spaces\n\nSpaces everywhere!\nval input =\n  \" (3 + 4 ) + x + y \"\n// ^ ^ ^ ^ ^ ^ ^ ^ ^ ^\n\nOne solution:\nval space: Parser[Char] = elem(_.isWhitespace)\n\ndef token[A](parser: Parser[A]): Parser[A] = parser <~ many(space)\n\nval variable: Parser[SumExpr] = token(letter.map(Var(_)))\n\nlazy val parser: Parser[SumExpr] = many(space) ~> sum",
    "Another solution is to write a lexer to handle spaces, comments and more!\n\ndef lex(input: List[Char]): List[Token] = ...",
    "Another solution is to write a lexer to handle spaces, comments and more!\n\n```python\ndef lex(input: List[Char]): List[Token] = ...\n```\n\nThen, the parser operates on sequences of tokens instead of Chars.\n\n```python\ndef parse(input: List[Token]): Expr = ...\n```",
    "Another solution is to write a lexer to handle spaces, comments and more!\n\n```python\ndef lex(input: List[Char]): List[Token] = ...\n```\n\nThen, the parser operates on sequences of tokens instead of Chars.\n\n```python\ndef parse(input: List[Token]): Expr = ...\n```\n\nSome parser combinators support both styles, and even provide ways to write lexers using the similar combinators.",
    "But wait, there's more!",
    "Let's go back to sequencing...\n\n// Method of Parser[+A]\ndef ~[B](that: Parser[B]): Parser[(A, B)] = \n    Parser(input => \n        for { \n            (leftValue, leftRest)     <- this.parse(input)\n            (rightValue, rightRest)   <- that.parse(leftRest)\n        } yield ((leftValue, rightValue), rightRest))",
    "Sequencing Revisited\n\nLet's go back to sequencing...\n\n// Method of Parser[+A]\ndef ~[B](that: Parser[B]): Parser[(A, B)] =\n  Parser(input =>\n    for {\n      (leftValue, leftRest)    <- this.parse(input)\n      (rightValue, rightRest)  <- that.parse(leftRest)\n                                // ^ leftValue is unused.\n    } yield ((leftValue, rightValue), rightRest))",
    "Let's go back to sequencing...\n\n// Method of Parser[+A]\ndef ~[B](that: A => Parser[B]): Parser[B] =\n    Parser(input =>\n        for {\n            (leftValue, leftRest)  <- this.parse(input)\n            (rightValue, rightRest) <- that(leftValue).parse(leftRest)\n            // ^ leftValue is passed to that.\n        } yield (rightValue, rightRest))",
    "Let's rename ~ to something you already know:\n\n// Method of Parser[+A]\ndef flatMap[B](that: A => Parser[B]): Parser[B] =\n  Parser(input =>\n    for {\n      (leftValue, leftRest)   <- this.parse(input)\n      (rightValue, rightRest) <- that(leftValue).parse(leftRest)\n      // ^ leftValue is passed to that.\n    } yield (rightValue, rightRest))",
    "Parser is a Monad!\n\ndef unit[A](x: A): Parser[A] = success(x)",
    "Parser is a Monad!\n\ndef unit[A](x: A): Parser[A] = success(x)\n\nMonad laws\nAssociativity $p.flatMap(f).flatMap(g) == p.flatMap(f(_).flatMap(g))$\n\nLeft unit $unit(x).flatMap(f) == f(x)$\n\nRight unit $p.flatMap(unit(_)) == p$",
    "Thanks to `Parser` being a Monad, you can write sequences of parsers using for-notation.\n\n```\nval ifExpr: Parser[Expr] = \n for { \n   _ <- keyword(\"if\")\n   c <- expr\n   _ <- keyword(\"then\")\n   t <- expr\n   _ <- keyword(\"else\")\n   e <- expr\n } yield IfExpr(c, t, e)\n```",
    "For-notation for Parsers\n\nThanks to Parser being a Monad, you can write sequences of parsers using for-notation.\n\nval ifExpr: Parser[Expr] = \n  for {\n    _ <- keyword(\"if\")\n    c <- expr\n    _ <- keyword(\"then\")\n    t <- expr\n    _ <- keyword(\"else\")\n    e <- expr\n  } yield IfExpr(c, t, e)\n\nval tagged: Parser[XML] = \n  for {\n    o <- openTag\n    c <- contents\n    _ <- closeTag(o.name)\n  } yield Tagged(o, c)",
    "- Parsing and why it is important.",
    "Summary\n\n- Parsing and why it is important.\n- What parser combinators are.",
    "Summary\n\n\u25ba Parsing and why it is important.\n\u25ba What parser combinators are.\n\u25ba How the various combinators can be implemented.",
    "- Parsing and why it is important.\n- What parser combinators are.\n- How the various combinators can be implemented.\n- Ways to handle lexical analysis.",
    "- Parsing and why it is important.\n- What parser combinators are.\n- How the various combinators can be implemented.\n- Ways to handle lexical analysis.\n- That \\texttt{Parser} is a Monad!",
    "Summary\n\n\u25ba Parsing and why it is important.\n\u25ba What parser combinators are.\n\u25ba How the various combinators can be implemented.\n\u25ba Ways to handle lexical analysis.\n\u25ba That Parser is a Monad!\n\nTake a look at the parser for the interpreter language!",
    "Reasoning About Lists\n\nPrinciples of Functional Programming",
    "Laws of Concat\n\nRecall the concatenation operation ++ on lists.\n\nWe would like to verify that concatenation is associative, and that it admits the empty list Nil as neutral element to the left and to the right:\n\n$(xs ++ ys) ++ zs = xs ++ (ys ++ zs)$\n$xs ++ Nil = xs$\n$Nil ++ xs = xs$\n\nQ: How can we prove properties like these?\n\n=> Use structural induction on lists",
    "Recall the principle of proof by natural induction:\n\nTo show a property $P(n)$ for all the integers $n \\geq b$,\n\n\u25ba Show that we have $P(b)$ (base case),\n\u25ba for all integers $n \\geq b$ show the induction step: if one has $P(n)$, then one also has $P(n+1)$.",
    "Given:\n\ndef factorial(n: Int): Int = \n  if n == 0 then 1       // 1st clause\n  else n * factorial(n-1)  // 2nd clause\n\nShow that, for all $n >= 4$ \n\n$factorial(n) >= power(2, n)$",
    "Base Case\n\nBase case: 4\n\nThis case is established by simple calculations:\n\n$factorial(4) = 24 >= 16 = power(2, 4)$",
    "Induction Step\n\nInduction step: $n+1$\n\nWe have for $n \\ge 4$:\n\n$factorial(n + 1)$\n\n$\\ge (n + 1) * factorial(n)$ // by 2nd clause in factorial\n\n$> 2 * factorial(n)$ // by calculating\n\n$\\ge 2 * power(2, n)$ // by induction hypothesis\n\n$= power(2, n + 1)$ // by definition of power",
    "Referential Transparency\n\nNote that a proof can freely apply reduction steps as equalities to some part of a term.\n\nThat works because pure functional programs don't have side effects; so that a term is equivalent to the term to which it reduces.\n\nThis principle is called referential transparency.",
    "Structural Induction\n\nThe principle of structural induction is analogous to natural induction:\n\nTo prove a property $P(xs)$ for all lists $xs$,\n\n\u25ba show that $P(\\text{Nil})$ holds (base case),\n\u25ba for a list $xs$ and some element $x$, show the induction step: if $P(xs)$ holds, then $P(x\\, ::\\, xs)$ also holds.",
    "Let's show that, for lists xs, ys, zs:\n\n$$(xs ++ ys) ++ zs = xs ++ (ys ++ zs)$$\n\nTo do this, use structural induction on xs. From the previous implementation of ++,\n\n```\nextension [T](xs: List[T])\n  def ++ (ys: List[T]) = xs match\n    case Nil => ys\n    case x :: xs1 => x :: (xs1 ++ ys)\n```\n\ndistill two defining clauses of ++:\n\n$${\\text {Nil ++ ys = ys // 1st clause}}$$\n$${\\text {(x :: xs1) ++ ys = x :: (xs1 ++ ys) // 2nd clause}}$$",
    "Base Case\n\nBase case: Nil\n\nFor the left-hand side we have:\n\n$$(Nil ++ ys) ++ zs$$\n$$= ys ++ zs \\hspace{0.5em} // by 1st clause of ++$$\n\nFor the right-hand side, we have:\n\n$$Nil ++ (ys ++ zs)$$\n$$= ys ++ zs \\hspace{0.5em} // by 1st clause of ++$$\n\nThis case is therefore established.",
    "Induction Step: LHS\n\nInduction step: $ x :: xs $\n\nFor the left-hand side, we have:\n\n$((x :: xs) ++ ys) ++ zs$\n$= (x :: (xs ++ ys)) ++ zs$ \\ \\ \\ \\ \\ \\ // by 2nd clause of ++\n$= x :: ((xs ++ ys) ++ zs)$ \\ \\ \\ \\ \\ \\ // by 2nd clause\n$= x :: (xs ++ (ys ++ zs))$ \\ \\ \\ \\ \\ \\ \\ \\ \\ // by induction hypothesis\n$= (x :: xs) ++ (ys ++ zs)$ \\ \\ \\ \\ \\ \\ \\ \\ \\ // by induction hypothesis (allowed as we don't use it on x)\n\n- assume true for $xs$\n- and show true for $x :: xs$ (i.e., add elem x to $xs$)",
    "Induction Step: RHS\n\nFor the right hand side we have:\n\n$$(x :: \\text{xs}) ++ (\\text{ys} ++ \\text{zs})$$\n\n$$= x :: (\\text{xs} ++ (\\text{ys} ++ \\text{zs})) // \\text{by 2nd clause of } ++$$\n\nSo this case (and with it, the property) is established.",
    "Show by induction on $xs$ that $xs \\; ++ \\; Nil = xs$.\n\nHow many equations do you need for the inductive step?\n\n$$\n\\begin{array}{ l c }\nx & 2 \\\\\n0 & 3 \\\\\n0 & 4 \\\\\n\\end{array}\n$$\n\n$$\n(x :: xs) \\; ++ \\; Nil \\stackrel{\\text{2nd clause}}{=} x :: (xs \\; ++ \\; Nil) \\stackrel{\\text{inductive step}}{=} x :: xs\n$$",
    "Scala Syntax Summary\n\nPrinciples of Functional Programming",
    "Language Elements Seen So Far:\n\nWe have seen language elements to express types, expressions and definitions.\n\nBelow, we give their context-free syntax in Extended Backus-Naur form (EBNF), where\n\n$|$ denotes an alternative,\n$\\left[...\\right]$ an option (0 or 1),\n$\\left\\{...\\right\\}$ a repetition (0 or more).",
    "Types\n\nType            = SimpleType | FunctionType\nFunctionType    = SimpleType '=>' Type\n                | '(' [Types] ')' '=>' Type\nSimpleType      = Ident\nTypes           = Type {',' Type}\n\nA type can be:\n\n\u25ba A numeric type: Int, Double (and Byte, Short, Char, Long, Float).\n\u25ba The Boolean type with the values true and false.\n\u25ba The String type.\n\u25ba A function type, like Int => Int, (Int, Int) => Int.\n\nLater we will see more forms of types.",
    "Expressions\n\nExpr = InfixExpr | FunctionExpr\n      | if Expr then Expr else Expr\nInfixExpr = PrefixExpr | InfixExpr Operator InfixExpr\nOperator = ident\nPrefixExpr = [\u2018+\u2019 | \u2018-\u2019 | \u2018!\u2019 | \u2018\u223c\u2019 ] SimpleExpr\nSimpleExpr = ident | literal | SimpleExpr \u2018.\u2019 ident\n         | Block\nFunctionExpr = Bindings \u2018=>\u2019 Expr\nBindings = ident\n        | \u2018(\u2019 [Binding {\u2018,\u2019 Binding}] \u2018)\u2019\nBinding = ident [\u2018:\u2019 Type]\nBlock = \u2018{\u2019 (Def \u2018;\u2019) Expr \u2018}\u2019\n      | <indent> (Def \u2018;\u2019) Expr <outdent>\n",
    "An expression can be:\n\u25ba An identifier such as $x$, isGoodEnough,\n\u25ba A literal, like $0$, $1.0$, \"abc\",\n\u25ba A function application, like $sqrt(x)$,\n\u25ba An operator application, like $-x$, $y + x$,\n\u25ba A selection, like $math.abs$,\n\u25ba A conditional expression, like $if x < 0$ then $-x$ else $x$,\n\u25ba A block, like ${ val x = abs(y) ; x * 2 }$\n\u25ba An anonymous function, like $x => x + 1$.",
    "Definitions\n\nDef           = FunDef | ValDef\nFunDef  = def ident \u2018(\u2019 [Parameters] \u2018)\u2019 \u2018:\u2019 Type \u2018=\u2019 Expr\nValDef     = val ident [\u2018:\u2019 Type] \u2018=\u2019 Expr\nParameter = ident \u2018:\u2019 [\u2018=>\u2019] Type\nParameters = Parameter {\u2018,\u2019 Parameter}\n\nA definition can be:\n\u25b6 A function definition, like def square(x: Int) = x * x\n\u25b6 A value definition, like val y = square(2)\n\nA parameter can be:\n\u25b6 A call-by-value parameter, like (x: Int),\n\u25b6 A call-by-name parameter, like (y: => Double).",
    "Loops\n\nPrinciples of Functional Programming\n\nMartin Odersky",
    "Loops\n\nProposition: Variables are enough to model all imperative programs.\n\nBut what about control statements like loops?\n\nWe can model them using functions.\n\nExample: Here is a Scala program that uses a while loop:\n\ndef power(x: Double, exp: Int): Double =\n  var r = 1.0\n  var i = exp\n  while i > 0 do { r = r * x; i = i - 1 }\n  r\n\nIn Scala, while-do is a built-in control construct\n\nBut how could we define while using a function (call it whileDo)?",
    "Definition of whileDo\n\nThe function whileDo can be defined as follows:\n\n```\ndef whileDo(condition: => Boolean)(command: => Unit): Unit =\n  if condition then\n    command\n    whileDo(condition)(command)\n  else ()\n```\n\nNote: The condition and the command must be passed by name so that they're reevaluated in each iteration.\n\nNote: whileDo is tail recursive, so it can operate with a constant stack size.",
    "Exercise\n\nWrite a function implementing a repeat loop that is used as follows:\n\n```\nrepeatUntil {\n    command\n} ( condition )\n```\n\nIt should execute `command` one or more times, until `condition` is true.\n\nThe `repeatUntil` function starts like this:\n\n```scala\ndef repeatUntil(command: => Unit)(condition: => Boolean)= \n    command\n    if (!condition) then repeatUntil(command)(condition)\n```",
    "Is it also possible to obtain the following syntax?\n\nrepeat {\n  command\n} until ( condition )\n?\n\n\\[\n\\text{repeat (command) until (condition)}\n\\]\n\n\\[\n\\text{def repeat( body => Unit) = While( body)}\n\\]",
    "For-Loops\n\nThe classical for loop in Java can not be modeled simply by a higher-order function.\n\nThe reason is that in a Java program like\n\nfor (int i = 1; i < 3; i = i + 1) { System.out.print(i + \" \"); }\n\nthe arguments of for contain the declaration of the variable i, which is visible in other arguments and in the body.\n\nHowever, in Scala there is a kind of for loop similar to Java\u2019s extended for loop:\n\nfor i <- 1 until 3 do System.out.print(s\"$i \")\n\nThis displays 1 2.",
    "Translation of For-Loops\n\nFor-loops translate similarly to for-expressions, but using the foreach\ncombinator instead of map and flatMap.\n\nforeach is defined on collections with elements of type T as follows:\n\ndef foreach(f: T => Unit): Unit =\n// apply 'f' to each element of the collection\n\nExample\n\nfor i <- 1 until 3; j <- \"abc\" do println(s\"$i $j\")\n\ntranslates to:\n\n(1 until 3).foreach(i => \"abc\".foreach(j => println(s\"$i $j\")))",
    "Decomposition\n\nPrinciples of Functional Programming",
    "Decomposition\n\nSuppose you want to write a small interpreter for arithmetic expressions.\n\nTo keep it simple, let's restrict ourselves to numbers and additions.\n\nExpressions can be represented as a class hierarchy, with a base trait Expr and two subclasses, Number and Sum.\n\nTo treat an expression, it's necessary to know the expression\u2019s shape and its components.\n\nThis brings us to the following implementation.",
    "Expressions\n\ntrait Expr:\n  def isNumber: Boolean\n  def isSum: Boolean\n  def numValue: Int\n  def leftOp: Expr\n  def rightOp: Expr\n\nclass Number(n: Int) extends Expr:\n  def isNumber = true\n  def isSum = false\n  def numValue = n\n  def leftOp = throw Error(\"Number.leftOp\")\n  def rightOp = throw Error(\"Number.rightOp\")",
    "class Sum(e1: Expr, e2: Expr) extends Expr:\n    def isNumber = false\n    def isSum = true\n    def numValue = throw Error(\"Sum.numValue\")\n    def leftOp = e1\n    def rightOp = e2",
    "Evaluation of Expressions\n\nYou can now write an evaluation function as follows.\n\n```scala\ndef eval(e: Expr): Int =\n  if e.isNumber then e.numValue\n  else if e.isSum then eval(e.leftOp) + eval(e.rightOp)\n  else throw Error(\"Unknown expression \" + e)\n```\n\nProblem: Writing all these classification and accessor functions quickly becomes tedious! (imagine when we have a lot of subclasses ...)\n\nProblem: There's no static guarantee you use the right accessor functions. You might hit an Error case if you are not careful.",
    "Adding New Forms of Expressions\n\nSo, what happens if you want to add new expression forms, say\n\nclass Prod(e1: Expr, e2: Expr) extends Expr   // e1 * e2\nclass Var(x: String) extends Expr             // Variable 'x'\n\nYou need to add methods for classification and access to all classes defined above.",
    "Question\n\nTo integrate Prod and Var into the hierarchy, how many new method definitions do you need?\n\n(including method definitions in Prod and Var themselves, but not counting methods that were already given on the slides)\n\nPossible Answers\n\n0  \n0  \n0  \n0  \n0  \n9  \n10  \n19  \n25  \n35  \n40",
    "Question\n\nTo integrate Prod and Var into the hierarchy, how many new method definitions do you need?\n\n(including method definitions in Prod and Var themselves, but not counting methods that were already given on the slides)\n\nPossible Answers\n\n0 \t9\n\n0 \t10\n\n0 \t19\n\n0 \t25\n\n0 \t35\n\n0 \t40",
    "Non-Solution: Type Tests and Type Casts\n\nA \"hacky\" solution could use type tests and type casts.\n\nScala let's you do these using methods defined in class Any:\n\ndef isInstanceOf[T]: Boolean  // checks whether this object's type conforms to T\ndef asInstanceOf[T]: T        // treats this object as an instance of type 'T'\n// throws 'ClassCastException' if it isn't.\n\nThese correspond to Java's type tests and casts\n\nScala                           Java\nx.isInstanceOf[T]               x instanceof T\nx.asInstanceOf[T]               (T) x\n\nBut their use in Scala is discouraged, because there are better alternatives.",
    "Eval with Type Tests and Type Casts\n\nHere's a formulation of the eval method using type tests and casts:\n\n```scala\ndef eval(e: Expr): Int = \n    if e.isInstanceOf[Number] then\n        e.asInstanceOf[Number].numValue\n    else if e.isInstanceOf[Sum] then\n        eval(e.asInstanceOf[Sum].leftOp) \n        + eval(e.asInstanceOf[Sum].rightOp)\n    else throw Error(\"Unknown expression \" + e)\n```\n\nThis is ugly and potentially unsafe.\n\n{Nous good solutions ...}\n\n",
    "Solution 1: Object-Oriented Decomposition\n\nFor example, suppose that all you want to do is evaluate expressions.\n\nYou could then define:\n\ntrait Expr:\n  def eval: Int\n  def show: Int\n\nclass Number(n: Int) extends Expr:\n  def eval: Int = n\n  def show: Int\n\nclass Sum(e1: Expr, e2: Expr) extends Expr:\n  def eval: Int = e1.eval + e2.eval\n  def show: Int\n\nBut what happens if you'd like to display expressions now?\n\nYou have to define new methods in all the subclasses.",
    "Assessment of OO Decomposition\n\n- OO decomposition mixes data with operations on the data.\n- This can be the right thing if there's a need for encapsulation and data abstraction.\n- On the other hand, it increases complexity (*) and adds new dependencies to classes.\n- It makes it easy to add new kinds of data but hard to add new kinds of operations.\n\n(*) In the literal sense of the word:\ncomplex = plaited, woven together\n\nThus, complexity arises from mixing several things together.",
    "Limitations of OO Decomposition\n\nOO decomposition only works well if operations are on a single object.\n\nWhat if you want to simplify expressions, say using the rule:\n\n$a * b + a * c \\quad -> \\quad a * (b + c)$\n\nProblem: This is a non-local simplification. It cannot be encapsulated in the method of a single object.\n\nYou are back to square one; you need test and access methods for all the different subclasses.",
    "Contextual Abstraction\n\nPrinciples of Functional Programming",
    "what comes with the text,\nbut is not in the text",
    "Context Takes Many Forms\n\n\u25ba the current configuration\n\u25ba the current scope\n\u25ba the meaning of \"<\" on this type\n\u25ba the user on behalf of which the operation is performed\n\u25ba the security level in effect\n\u25ba ...\n\nCode becomes more modular if it can abstract over context.\n\nThat is, functions and classes can be written without knowing in detail the context in which they will be called or instantiated.",
    "How Is Context Represented?\n\nSo far:\n\u25ba global values $i.e., no abstraction - this is often too rigid$\n\u25ba global mutable variables $what \\ if \\ different \\ modules \\ need \\ different \\ settings? \\ interference \\ can \\ be \\ dangerous$\n\u25ba \"Monkey Patching\" $- more \\ powerful \\ ways \\ to \\ shoot \\ yourself \\ in \\ the \\ foot$\n\u25ba dependency injection frameworks $ (e.g., \\ Spring, \\ Guice) - outside \\ the \\ language, \\ rely \\ on \\ bytecode \\ rewriting \\ \\rightarrow \\ harder \\ to \\ understand \\ and \\ debug$",
    "Functional Context Representation\n\nIn functional programming, the natural way to abstract over context is with function parameters.\n\n    + flexible\n    + types are checked\n    + not relying on side effects\n\nBut sometimes this is too much of a good thing! It can lead to\n\n    \u2013 many function arguments\n    \u2013 which hardly ever change\n    \u2013 repetitive, errors are hard to spot",
    "Example: Sorting\n\nWe have seen sort functions. For instance, here's an outline of a method sort that takes as parameter a $List[Int]$ and returns another $List[Int]$ containing the same elements, but sorted:\n\n```scala\ndef sort(xs: List[Int]): List[Int] = \n  ...\n  ... if x < y then ...\n  ...\n```\n\nAt some point, this method has to compare two elements x and y of the given list.",
    "Making sort more General\n\nProblem: How to parameterize sort so that it can also be used for lists with elements other than Int, such as Double or String?\n\nA straightforward approach would be to use a polymorphic type T for the type of elements:\n\n```plaintext\n    def sort[T](xs: List[T]): List[T] = ...\n```\n\nBut this does not work, because there\u2019s not a single comparison method < that works for all types.\n\nIn other words, we need to ask the question: What is the meaning of $<$ on type T at the call site?\n\nThis means querying the call-site context.\n",
    "Parameterization of sort\n\nThe most flexible design is to pass the comparison operation as an additional parameter:\n\n```scala\ndef sort[T](xs: List[T])(lessThan: (T, T) => Boolean): List[T] =\n  ...\n  if lessThan(x, y) then ...\n  ...\n```",
    "Calling Parameterized sort\n\nWe can now call sort as follows:\n\nval ints = List(-5, 6, 3, 2, 7)\nval strings = List(\"apple\", \"pear\", \"orange\", \"pineapple\")\n\nsort(ints)((x, y) => x < y)\nsort(strings)((s1, s2) => s1.compareTo(s2) < 0)",
    "Parameterization with Ordering\n\nThere is already a class in the standard library that represents orderings:\n\nscala.math.Ordering[A]\n\nProvides ways to compare elements of type A. So, instead of parameterizing with the lessThan function, we could parameterize with Ordering instead:\n\ndef sort[T](xs: List[T])(ord: Ordering[T]): List[T] =\n  ...\n  ... if ord.lt(x, y) then ...\n  ...",
    "Ordering Instances\n\nCalling the new sort can be done like this:\n\nimport scala.math.Ordering\n\nsort(ints)(Ordering.Int)\nsort(strings)(Ordering.String)\n\nThis makes use of the values Int and String defined in the scala.math.Ordering object, which produce the right orderings on integers and strings.\n\nobject Ordering:\n    val Int = new Ordering[Int]:\n        def compare(x: Int, y: Int) =\n            if x < y then -1 else if x > y then 1 else 0",
    "Problem: Passing around Ordering arguments is cumbersome.\n\n```\nsort(ints)(Ordering.Int)\nsort(strings)(Ordering.String)\n```\n\nSorting a $List[Int]$ value always uses the same $Ordering.Int$ argument, sorting a $List[String]$ value always uses the same $Ordering.String$ argument, and so on...",
    "Implicit Parameters\n\nWe can reduce the boilerplate by making ord an implicit parameter.\n\n```scala\ndef sort[T](xs: List[T])(using ord: Ordering[T]): List[T] = ...\n```\n\nThen, calls to sort can omit the ord parameter:\n\n```scala\nsort(ints)\nsort(strings)\n```\n\nThe compiler infers the argument value based on its expected type.",
    "Type Inference\n\nWe have seen that the compiler is able to infer types from values.\n\nThat is, the previous calls to sort are augmented as follows:\n\n```\nsort(ints)\nsort(strings)\n```",
    "Term Inference\n\nThe Scala compiler is also able to do the opposite, namely to infer expressions (aka terms) from types.\n\nWhen there is exactly one \"obvious\" value for a type, the compiler can provide that value to us.\n\nsort[Int](ints)(using Ordering.Int)\nsort[String](strings)(using Ordering.String)",
    "Tuples and Generic Methods\n\nPrinciples of Functional Programming",
    "Sorting Lists Faster\n\nAs a non-trivial example, let's design a function to sort lists that is more efficient than insertion sort.\n\nA good algorithm for this is merge sort. The idea is as follows:\n\nIf the list consists of zero or one elements, it is already sorted.\n\nOtherwise,\n\n- Separate the list into two sub-lists, each containing around half of the elements of the original list.\n- Sort the two sub-lists.\n- Merge the two sorted sub-lists into a single sorted list.\n\napply\nRecursively",
    "Here is the implementation of that algorithm in Scala:\n\n```scala\ndef msort(xs: List[Int]): List[Int] =\n    val n = xs.length / 2\n    if n == 0 then xs\n    else\n        def merge(xs: List[Int], ys: List[Int]) = ???\n        val (fst, snd) = xs.splitAt(n)\n        merge(msort(fst), msort(snd))\n```",
    "The splitAt function on lists returns two sublists\n\n\u25ba the elements up the the given index\n\u25ba the elements from that index\n\nThe lists are returned in a pair.\n\n$def\\ splitAt(n: Int) = (xs.take(n),\\ xs.drop(n))$",
    "Detour: Pair and Tuples\n\nThe pair consisting of x and y is written $(x, y)$ in Scala.\n\nExample\n\n$val\\ pair = (\"answer\",\\ 42)\\ \\Rightarrow\\ pair:\\ (String,\\ Int)\\ =(answer, 42)$\n\nThe type of pair above is $(String,\\ Int)$.\n\nPairs can also be used as patterns:\n\n$val\\ (label, value)\\ =\\ pair\\ \\Rightarrow\\ label:\\ String =\\ answer,\\ value:\\ Int =\\ 42$\n\nThis works analogously for tuples with more than two elements.",
    "Translation of Tuples\n\nFor small (\u2217) $n$, the tuple type $(T_1, . . ., T_n)$ is an abbreviation of the parameterized type\n$$scala.Tuplen[T_1, . . ., T_n]$$\n\nA tuple expression $(e_1, . . ., e_n)$ is equivalent to the function application\n$$scala.Tuplen(e_1, . . ., e_n)$$\n\nA tuple pattern $(p_1, . . ., p_n)$ is equivalent to the constructor pattern\n$$scala.Tuplen(p_1, . . ., p_n)$$\n\n(\u2217) Currently, \u201csmall\u201d \uff1d up to 22. There\u2019s also a TupleXXL class that handles Tuples larger than that limit.",
    "The Tuple class\n\nHere, all $Tuple_n$ classes are modeled after the following pattern:\n\n\\[\n\\text{case class Tuple2[T1, T2](_1: +T1, _2: +T2):}\n\\]\n\\[\n\\text{override def toString = \"(\" + _1 + \",\" + _2 + \")\"} \n\\]\n\nThe fields of a tuple can be accessed with names ._1, ._2 ...\n\nSo instead of the pattern binding\n\n\\[\n\\text{val (label, value) = pair}\n\\]\n\none could also have written:\n\n\\[\n\\text{val label = pair._1} \\quad \\text{accesses first element of tuple pair}\n\\]\n\\[\n\\text{val value = pair._2}\n\\]\n\nBut the pattern matching form is generally preferred.",
    "Here is a definition of the merge function:\n\n```scala\ndef merge(xs: List[Int], ys: List[Int]) = (xs, ys) match\n  case (Nil, ys) => ys\n  case (xs, Nil) => xs\n  case (x :: xs1, y :: ys1) =>\n    if x < y then x :: merge(xs1, ys)\n    else y :: merge(xs, ys1)\n```",
    "Making Sort More General\n\nProblem: How to parameterize msort so that it can also be used for lists with elements other than Int?\n\n```python\ndef msort[T](xs: List[T]): List[T] = ???\n```\ndoes not work, because the comparison < in merge is not defined for arbitrary types T.\n\nIdea: Parameterize merge with the necessary comparison function.",
    "Parameterization of Sort\n\nThe most flexible design is to make the function sort polymorphic and to pass the comparison operation as an additional parameter:\n\n```python\ndef msort[T](xs: List[T])(lt: (T, T) => Boolean) = \n    ...\n    merge(msort(fst)(lt), msort(snd)(lt))\n```\n\nMerge then needs to be adapted as follows:\n\n```python\ndef merge[T](xs: List[T], ys: List[T]) = (xs, ys) match\n    ...\n    case (x :: xsl, y :: ysl) =>\n        if lt(x, y) then ...\n        else ...\n```",
    "Calling Parameterized Sort\n\nWe can now call msort as follows:\n\nval xs = List(-5, 6, 3, 2, 7)\nval fruits = List(\"apple\", \"pear\", \"orange\", \"pineapple\")\n\nmsort(xs)((x: Int, y: Int) => x < y)\nmsort(fruits)((x: String, y: String) => x.compareTo(y) < 0)\n\nOr, since parameter types can be inferred from the call msort(xs):\n\nmsort(xs)((x, y) => x < y)\n\ncompiles can infer missing parameters from their types\n\n\\( \\otimes \\) and \\( \\oplus \\) are equivalent",
    "Context Passing\n\nPrinciples of Functional Programming",
    "Context Passing vs Type Classes\n\nType classes are about *type instances of generic traits*. E.g.:\n\n\u25ba What is the definition of $TC[A]$ for the type class trait TC and the type argument A?\n\nIf we want to make $A$ a type parameter, we need an implicit parameter to go with it.\n\nOn the other hand, there are also uses for abstracting over values of a simple type, asking\n\n\u25ba What is the currently valid definition of type $T$?",
    "Example: Execution contexts\n\nTo do computations in parallel, runtimes need thread schedulers.\n\nThere's usually a default scheduler, but it should be possible to override that choice in parts of the code.\n\nHow are references to schedulers propagated?\n\nIn Scala, they are embedded in values of types ExecutionContext. The default is:\n\n    given global as ExecutionContext = ForkJoinContext()\n\nThis defines the execution context global as an alias of an existing value (i.e. a freshly created ForkJoinContext)\n\nThe evaluation of ForkJoinContext is done lazily: the ForkJoinContext is created the first time global is used.",
    "Propagating Execution Contexts\n\nExecution contexts rarely change, but they should be changeable everywhere.\n\nThis is a poster-child for implicit parameters.\n\n    def processItems(...)(using ExecutionContext) = ...",
    "Other Use Cases\n\nPassing a piece of the context as an implicit parameter of a certain type is quite common.\n\nFor instance, we might want to propagate implicitly\n\n\u25ba the current configuration,\n\u25ba the available set of capabilities,\n\u25ba the security level in effect,\n\u25ba the layout scheme to render some data,\n\u25ba The persons that have access to some data.",
    "Example: A Conference Management System\n\nLet's say we design a system to discuss papers submitted to a conference.\n\u25ba The papers have already been given a score by the reviewers.\n\u25ba To discuss, reviewers need to see various pieces of information about the papers.\n\u25ba Some reviewers are also authors of papers. \n\u25ba An author of a paper should never see at this phase the score the paper received from the other reviewers.\n\nConsequence: Every query of the conference needs to know who is seeing the results of the operation and this needs to be propagated.\nFor a given toplevel query the set of persons seeing its results will largely stay the same.\nBut it can change, for instance when a reviewer delegates part of the task to another person.",
    "case class Person(name: String)\ncase class Paper(title: String, authors: List[Person], body: String)\n\nobject ConfManagement:\n  type Viewers = Set[Person]\n\nclass Conference(ratings: (Paper, Int)*):\n  private val realScore = ratings.toMap\n\n  def papers: List[Paper] = ratings.map(_._1).toList\n\n  def score(paper: Paper, viewers: Viewers): Int =\n    if paper.authors.exists(viewers.contains) then -100\n    else realScore(paper)",
    "def rankings(viewers: Viewers): List[Paper] = \n    papers.sortBy(score(_, viewers)).reverse\n\ndef ask[T](p: Person, query: Viewers => T) = \n    query(Set(p))\n\ndef delegateTo[T](p: Person, query: Viewers => T)(viewers: Viewers): T = \n    query(viewers + p)\n\nend Conference \nend ConfManagement\n\n\u25ba If one of the viewers is also an author if the paper, the score is \n    masked, returning -100 instead of the real score. \n\u25ba The same masking also has to be done in derived operations, such as \n    rankings.",
    "val Smith = Person(\"Smith\")\nval Peters = Person(\"Peters\")\nval Abel = Person(\"Abel\")\nval Black = Person(\"Black\")\nval Ed = Person(\"Ed\")\n\nval conf = Conference(\n  Paper(\"How to grow beans\", List(Smith, Peters), \"...\") -> 92,\n  Paper(\"Organic gardening\", List(Abel, Peters), \"...\") -> 83,\n  Paper(\"Composting done right\", List(Black, Smith), \"...\") -> 99,\n  Paper(\"The secret life of snails\", authors = List(Ed), \"...\") -> 77\n)",
    "Which authors have at least two papers with a score over 80?\n\n```\ndef highlyRankedProlificAuthors(asking: Person): Set[Person] =\n  def query(viewers: Viewers): Set[Person] =\n    val highlyRanked =\n      conf.rankings(viewers).takeWhile(conf.score(_, viewers) > 80).toSet\n    for\n      p1 <- highlyRanked\n      p2 <- highlyRanked\n      author <- p1.authors\n      if p1 != p2 && p2.authors.contains(author)\n    yield author\n  conf.ask(asking, query)\n```\n\nThe answer depends on who is asking!\n",
    "Problem: So far passing viewers is a convention.\n\nNothing prevents just passing the empty set of viewers to a query.\n\n\\[\n\\text{conf.rankings(Set()).takeWhile(conf.score(_, Set()) > 80)}\n\\]\n\nFix: Make the Viewers type alias opaque:\n\n\\[\n\\text{opaque type Viewers = Set[Person]}\n\\]",
    "Opaque Type Aliases\n\nGiven an opaque type alias such as\n\nobject ConfManagement:\n    opaque type Viewers = Set[Person]\n\nthe equality $Viewers = Set[Person]$ is known only within the scope where the alias is defined. (in this case, within the ConfManagement object)\n\nEverywhere else Viewers is treated as a separate, abstract type.",
    "Why Does This Help Against Tampering?\n\nWhen asking a query, we have to pass a Viewers set to the conference management methods.\n\nBut Viewers is an unknown abstract type; hence there is no way to create a Viewers instance outside the ConfManagement object.\n\nSo the only way to get a viewers value is in the parameter of a query, where the conference management system provides the actual value.\n\nTherefore, in\n\n$ \\text{conf.rankings(viewers).takeWhile(conf.score(_, viewers) > 80).toSet} $\n\nwe are forced to pass viewers on to rankings and score since that's the only Viewers value we have access to.\n\nCaveat: This assumes that queries are not nested, since otherwise an inner query could access the viewers parameter of an outer one.",
    "Discussion\n\nBack to the conference management code:\n\n\u25ba One downside is that we have to pass viewers arguments along everywhere they are needed.\n\u25ba This seems pointless, since by design there is only a single value we could pass!\n\u25ba It also quickly gets tedious as the codebase grows.\n\u25ba Can't this be automated?\n\nOf course: Just use implicit parameters.",
    "Using using Clauses\n\nclass Conference(ratings: (Paper, Int)*):\n  ...\n  def score(paper: Paper)(viewers: Viewers): Int =\n    if paper.authors.exists(viewers.contains) then -100\n    else realScore(paper)\n  def rankings(viewers: Viewers): List[Paper] =\n    papers.sortBy(score(_, viewers)).reverse\n  def delegateTo[T](p: Person, query: Viewers => T)(viewers: Viewers): T =\n    query(viewers + p)\n  ...\n\nconf.rankings(viewers).takeWhile(conf.score(_, viewers) > 80).toSet",
    "Using using Clauses\n\nclass Conference(ratings: (Paper, Int)*):\n  ...\n  def score(paper: Paper)(using viewers: Viewers): Int =\n    if paper.authors.exists(viewers.contains) then -100\n    else realScore(paper)\n  def rankings(using viewers: Viewers): List[Paper] =\n    papers.sortBy(score(_)).reverse\n  def delegateTo[T](p: Person, query: Viewers => T)(using viewers: Viewers):\n    query(viewers + p)\n  ...\n\nconf.rankings.takeWhile(conf.score(_) > 80).toSet",
    "Another Benefit of Opacity\n\nThe implicit parameters are of type $Viewers$, which is an opaque type alias.\n\nThis has another benefit: Since outside $ConfManagement, Viewers$ is a type different from all others, there's no chance to connect $Viewers$ implicit parameters with given instances for other types.\n\nOn the other hand, if $Viewers$ was a regular type alias of $Set[Person]$ we might accidentally have given instances for other sets of persons in scope, which would then be eligible candidates for $Viewers$ parameters.",
    "Be Specific\n\nMorale: Given instances should have specific types and/or be local in scope.\n\nFor example, this is a terrible idea:\n\ngiven Int = 1\ndef f(x: Int)(using delta: Int) = x + delta\n\nNever use a common type such as Int or String as the type of a globally visible given instance!",
    "You have seen in week 4 an enum for arithmetic expressions. Let's augment it with a Let form:\n```plaintext\nenum Expr:\n  case Number(num: Int)\n  case Sum(x: Expr, y: Expr)\n  case Prod(x: Expr, y: Expr)\n  case Var(name: String)\n  case Let(name: String, rhs: Expr, body: Expr)\nimport Expr._\nWrite an eval function for expressions of this type.\ndef eval(e: Expr): Int = ???\nLet(\u201dx\u201d, e1, e2) should be evaluated like (val x = e1; e2).\nYou can assume that every Var(x) occurs in the body of an enclosing Let(x, e, b).\n```\n",
    "Use a map from variable names to their defined values as an implicit parameter.\n\nThe map is initially empty and is augmented in every Let node.\n\nThis suggests the following outline:\n\n```scala\ndef eval(e: Expr): Int = \n  def recur(e: Expr)(using env: Map[String, Int]): Int = ???\n\n  recur(e)(using Map())\n```",
    "def eval(e: Expr): Int =\n  def recur(e: Expr)(using env: Map[String, Int]): Int = e match\n    case Number(n)       => n\n    case Sum(x, y)       => recur(x) + recur(y)\n    case Prod(x, y)      => recur(x) * recur(y)\n    case Var(name)       => env(name)\n    case Let(name, rhs, body) => recur(body)(using env + (name -> recur(rhs)))\n  recur(e)(using Map())",
    "Case Study\n\nPrinciples of Functional Programming",
    "The Water Pouring Problem\n\n- You are given some glasses of different sizes.\n- Your task is to produce a glass with a given amount of water in it.\n- You don't have a measure or balance.\n- All you can do is:\n  - fill a glass (completely)\n  - empty a glass\n  - pour from one glass to another until the first glass is empty or the second glass is full.\n\nExample task:\nYou have two glasses. One holds 7 units of water, the other 4. Produce a glass filled with 6 units of water.",
    "Strategy\n\nIssues:\n- Compute all fields dist 1 from empty\n- Compute all fields dist 2 from empty\netc...",
    "States and Moves\n\nRepresentations:\n  Glass: Int (glasses are numbered 0, 1, 2)\n  State: Vector[Int] (one entry per glass)\ni.e. Vector(2, 3) would be a state where we have two glasses that have 2 and 3 units of water in it.\n\nMoves:\n  Empty(glass)\n  Fill(glass)\n  Pour(from, to)",
    "Variants\n\nIn a program of the complexity of the pouring program, there are many choices to be made.\n\nChoice of representations.\n\n\u25ba Specific classes for moves and paths, or some encoding?\n\u25ba Object-oriented methods, or naked data structures with functions?\n\nThe present elaboration is just one solution, and not necessarily the shortest one.",
    "Guiding Principles for Good Design\n\u25ba Name everything you can.\n\u25ba Put operations into natural scopes.\n\u25ba Keep degrees of freedom for future refinements.",
    "101 Language of arithmetic and if expressions\n102 Absolute value and its desugaring\n103 Recursive functions implemented using substitutions\n104 Environment instead of substitutions\n105 Higher-order functions using substitutions\n106 Higher-order functions using environments\n107 Nested recursive definitions using environments",
    "We would like to handle examples like this one:\n\n```\ndef fact n =\n   (if n then (* n (fact (- n 1))) else 1)\n   (fact 6)\n```\n\nWhat do we need to add to our abstract syntax trees?\n\u25ba names inside expressions to refer to parameters (n)\n\u25ba calls to user-defined functions (fact 6)\n\u25ba definitions (map function names to parameters and function bodies)",
    "I03: Recursive Function Definitions: Trees and Factorial Example\n\nenum Expr\ncase C(c: BigInt)\ncase N(name: String)  // immutable variable\ncase BinOp(op: BinOps, e1: Expr, e2: Expr)\ncase IfNonzero(cond: Expr, trueE: Expr, falseE: Expr)\ncase Call(function: String, args: List[Expr])  // function call\n\ncase class Function(params: List[String], body: Expr)\ntype DefEnv = Map[String, Function]  // function names to definitions\n\nval defs : DefEnv = Map[String, Function](\n  \"fact\" -> Function(List(\"n\"), // formal parameter \"n\", body:\n    IfNonzero(N(\"n\"),\n      BinOp(Times, N(\"n\"),\n        Call(\"fact\", List(BinOp(Minus, N(\"n\"), C(1)))),\n        C(1)))\n  )  // if n then (n * (fact (n - 1))) else 1",
    "I03: Idea of Evaluation Based Using Substitution\n\n   \u25b6 evaluate arguments so they become constants\n   \u25b6 look up function body, replace formal parameters with constants\n   \u25b6 evaluate replaced function body\n\ndef fact n = (if n then (* n (fact (- n 1))) else 1)\n(fact 3)\n(if 3 then (* 3 (fact (- 3 1))) else 1)\n  (fact 2)\n  (if 2 then (* 2 (fact (- 2 1))) else 1)\n    (fact 1)\n    (if 1 then (* 1 (fact (- 1 1))) else 1)\n      (fact 0)\n      (if 0 then (* 0 (fact (- 0 1))) else 1)\n      1\n    1\n  1\n2\n6",
    "I03: eval Using Substitution\n\n```scala\ndef eval(e: Expr): BigInt = e match\n  case C(c) => c\n  case N(n) => error(s\"Unknown name '$n'\") // should never occur\n  case BinOp(op, e1, e2) =>\n    evalBinOp(op(eval(e1), eval(e2)))\n  case IfNonzero(cond, trueE, falseE) =>\n    if eval(cond) != 0 then eval(trueE)\n    else eval(falseE)\n  case Call(fName, args) => // the only new case we handle\n    defs.get(fName) match // defs is a global map with all functions \n    case Some(f) => // f has body: Expr and params: List[String]\n      val evaledArgs = args.map((e: Expr) => (eval(e)))\n      val bodySub = substAll(f.body, f.params, evaledArgs)\n      eval(bodySub) // may contain further recursive calls \n                    // bodySub should no longer have N(...).\n```",
    "// substitute all n with r in expression e\ndef subst(e: Expr, n: String, r: Expr): Expr = e match\n  case C(c) => e\n  case N(s) => if s==n then r else e\n  case BinOp(op, e1, e2) =>\n    BinOp(op, subst(e1,n,r), subst(e2,n,r))\n  case IfNonzero(c, trueE, falseE) =>\n    IfNonzero(subst(c,n,r), subst(trueE,n,r), subst(falseE,n,r))\n  case Call(f, args) =>\n    Call(f, args.map(subst(_,n,r)))\n\ndef substAll(e: Expr, names: List[String],\n        replacements: List[Expr]): Expr =\n  (names, replacements) match\n    case (n :: ns, r :: rs) => substAll(subst(e,n,r), ns, rs)\n    case _ => e",
    "def div x y =  \n  (if (<= y x) then (+ 1 (div (- x y) y)) else 0)\n\n(div 15 6)\n(if (<= 6 15) then (+ 1 (div (- 15 6) 6)) else 0)\n  | (div 9 6)\n  | (if (<= 6 9) then (+ 1 (div (- 9 6) 6)) else 0)\n  |    | (div 3 6)\n  |    | (if (<= 6 3) then (+ 1 (div (- 3 6) 6)) else 0)\n  |    | 0\n  | +--> 1 \n  +--> 2\n\nThis completes the interpreter for recursive computable functions. Every computable function that maps an $n$-tuple of integers into an integer can be described in it and our interpreter can execute it! We can even encode data structures as large integers.",
    "Reduction of Lists\n\nPrinciples of Functional Programming",
    "Reduction of Lists\n\nAnother common operation on lists is to combine the elements of a list using a given operator.\n\nFor example:\n\n$ \\text{sum(List(x1,...,xn))} \\quad = \\quad 0 + x1 + ... + xn $\n\n$ \\text{product(List(x1,...,xn))} \\quad = \\quad 1 * x1 * ... * xn $\n\nWe can implement this with the usual recursive schema:\n\n\\[\n\\text{def sum(xs: List[Int]): Int = xs match}\n\\]\n\\[\n\\quad \\text{case Nil} \\quad => \\quad 0\n\\]\n\\[\n\\quad \\text{case y :: ys => y + sum(ys)}\n\\]",
    "ReduceLeft\n\nThis pattern can be abstracted out using the generic method reduceLeft:\n\nreduceLeft inserts a given binary operator between adjacent elements of a list:\n\n$list(x1, ..., xn).reduceLeft(op) = x1.op(x2)....op(xn)$\n\nUsing reduceLeft, we can simplify:\n\n$ \\text{def sum(xs: List[Int])} = (0 :: xs).reduceLeft((x, y) => x + y) $\n\n$ \\text{def product(xs: List[Int])} = (1 :: xs).reduceLeft((x, y) => x * y) $",
    "A Shorter Way to Write Functions\n\nInstead of ((x, y) => x * y)), one can also write shorter:\n\n$(_ * _) $\n\nEvery _ represents a new parameter, going from left to right.\n\nThe parameters are defined at the next outer pair of parentheses (or the whole expression if there are no enclosing parentheses).\n\nSo, sum and product can also be expressed like this:\n\n$ def\\ sum(xs: List[Int])\\ =\\ (0\\ : :\\ xs).reduceLeft(_ + _) $\n\n$ def\\ product(xs: List[Int])\\ =\\ (1\\ : :\\ xs).reduceLeft(_ * _) $",
    "FoldLeft\n\nThe function reduceLeft is defined in terms of a more general function, foldLeft.\n\nfoldLeft is like reduceLeft but takes an accumulator, z, as an additional parameter, which is returned when foldLeft is called on an empty list.\n\n\\[\n\\text{List}(x1, \\ldots, xn).foldLeft(z)(op) = z \\, . \\, op(x1) \\, . \\, op(\\ldots) \\, . \\, op(xn)\n\\]\n\nSo, sum and product can also be defined as follows:\n\\[\n\\begin{align*}\n\\text{def} \\;\\text{sum(xs: List[Int])} &= \\text{xs.foldLeft(0)(_ + _)} \\\\\n\\text{def} \\;\\text{product(xs: List[Int])} &= \\text{xs.foldLeft(1)(_ * _)}\n\\end{align*}\n\\]",
    "Implementations of ReduceLeft and FoldLeft\n\nfoldLeft and reduceLeft can be implemented in class List as follows.\n\nabstract class List[T]: \n\ndef reduceLeft(op: (T, T) => T): T = this match \n  case Nil     => throw IllegalOperationException(\"Nil.reduceLeft\") \n  case x :: xs => xs.foldLeft(x)(op) \n\ndef foldLeft[U](z: U)(op: (U, T) => U): U = this match \n  case Nil     => z \n  case x :: xs => xs.foldLeft(op(z, x))(op)",
    "Applications of foldLeft and reduceLeft unfold on trees that lean to the left.\n\nThey have two dual functions, foldRight and reduceRight, which produce trees which lean to the right, i.e.,\n\n$ \\text{List}(x_1, ..., x_{n-1}, x_n).\\text{reduceRight(op)} = x_1.\\text{op}(x_2.\\text{op}(... \\, x_{n-1}.\\text{op}(x_n)...)) $\n\n$ \\text{List}(x_1, ..., x_n).\\text{foldRight}(z)(\\text{op}) = x_1.\\text{op}(x_2.\\text{op}(... \\, x_{n-1}.\\text{op}(x_n \\text{op}(z)...))) $",
    "Implementation of FoldRight and ReduceRight\n\nThey are defined as follows\n\n```scala\ndef reduceRight(op: (T, T) => T): T = this match\n  case Nil        => throw UnsupportedOperationException(\"Nil.reduceRight\")\n  case x :: Nil   => x\n  case x :: xs    => op(x, xs.reduceRight(op))\n\ndef foldRight[U](z: U)(op: (T, U) => U): U = this match\n  case Nil        => z\n  case x :: xs    => op(x, xs.foldRight(z)(op))\n```",
    "Difference between FoldLeft and FoldRight\n\nFor operators that are associative and commutative, foldLeft and foldRight are equivalent (even though there may be a difference in efficiency).\n\nBut sometimes, only one of the two operators is appropriate.\n\n- FoldLeft can often be made recursive\n\n- FoldRight not so much.",
    "Exercise\n\nHere is another formulation of concat:\n\n\\[\n\\text{def concat}[T](\\text{xs: List}[T], \\text{ys: List}[T]): \\text{List}[T] = \\text{xs.foldRight(ys)(_ :: _)}\n\\]\n\nHere, it isn't possible to replace foldRight by foldLeft. Why?\n\n\\[\n\\begin{array}{c c c}\nx & \\text{The types would not work out} \\\\\no & \\text{The resulting function would not terminate} \\\\\no & \\text{The result would be reversed} \\\\\n\\end{array}\n\\]",
    "Back to Reversing Lists\n\nWe now develop a function for reversing lists which has a linear cost.\nThe idea is to use the operation foldLeft:\n\n```\ndef reverse[T](xs: List[T]): List[T] = xs.foldLeft(z?)(op?)\n```\n\nAll that remains is to replace the parts z? and op?.\n\nLet's try to compute them from examples.",
    "Deduction of Reverse (1)\n\nTo start computing $z^2$, let's consider reverse($\\text{Nil}$).\n\nWe know reverse($\\text{Nil}$) == $\\text{Nil}$, so we can compute as follows:\n\n$\\text{Nil}$\n\n= reverse($\\text{Nil}$)\n\n= $\\text{Nil}$.foldLeft($z^2$)(op)\n\n= $z^2$\n\nConsequently, $z^2 = \\text{Nil}$",
    "Deduction of Reverse (2)\n\nWe still need to compute op?. To do that let\u2019s plug in the next simplest list after Nil into our equation for reverse:\n\n\\[ \\text{List}(x) \\]\n\n\\[ = \\text{reverse}(\\text{List}(x)) \\]\n\n\\[ = \\text{List}(x).foldLeft(\\text{Nil})(op?) \\]\n\n\\[ = \\text{op?}(\\text{Nil}, x) \\]\n\nConsequently, op?(Nil, x) = List(x) = x :: Nil.\n\nThis suggests to take for op? the operator :: but with its operands swapped.",
    "Deduction of Reverse(3)\n\nWe thus arrive at the following implementation of reverse.\n\n```scala\ndef reverse[a](xs: List[T]): List[T] =\n    xs.foldLeft(List[T]())((xs, x) => x :: xs)\n```\n\nRemark: the type parameter in List[T]() is necessary for type inference.\n\nQ: What is the complexity of this implementation of reverse?\n\nA: Linear in xs",
    "Complete the following definitions of the basic functions map and length on lists, such that their implementation uses foldRight:\n\n```scala\ndef mapFun[T, U](xs: List[T], f: T => U): List[U] = \n  xs.foldRight(List[U]())((y, ys) => f(y) :: ys)\n\ndef lengthFun[T](xs: List[T]): Int =\n  xs.foldRight(0)((y, n) => n + 1)\n```",
    "EPFL\n\nAbstract Algebra and Type Classes\n\nPrinciples of Functional Programming",
    "Doing Abstract Algebra with Type Classes\n\nType classes let one define concepts that are quite abstract, and that can be instantiated with many types. For instance:\n\ntrait SemiGroup[T]:\n  extension (x: T) def combine (y: T): T\n\nThis models the algebraic concept of a semigroup with an associative operator combine.\n\nWe can then define methods that work for all semigroups. For instance:\n\ndef reduce[T: SemiGroup](xs: List[T]): T =\n  xs.reduceLeft(_.combine(_))\n",
    "Type Class Hierarchies\n\nAlgebraic type classes often form natural hierarchies. For instance, a monoid is defined as a semigroup with a left and right unit element.\n\nHere's its natural definition:\n\ntrait Monoid[T] extends SemiGroup[T]:\n    def unit: T",
    "Generalize reduce to work on lists of $T$ where $T$ has a Monoid instance such that it also works for empty lists.\n\n```scala\ndef reduce[T](xs: List[T])(using m: Monoid[T]): T =\n  xs.foldLeft(m.unit)(_.combine(_))\n```",
    "Using Context Bounds\n\nIn the previous example we had to pass an explicitly named type class instance m: Monoid[T] to reduce, so that we could refer to m.unit.\n\nOne could alternatively use a context bound and a summon.\n\n```\ndef reduce[T: Monoid](xs: List[T]): T = \n  xs.reduceLeft(summon[Monoid[T]].unit)(_.combine(_))\n```",
    "Streamlining Access\n\nA simpler calling syntax can be obtained if we do some preparation in the Monoid trait itself.\n\n```scala\ntrait Monoid[T] extends SemiGroup[T]:\n  def unit: T\n  object Monoid:\n    def apply[T](using m: Monoid[T]): Monoid[T] = m\n```\n\nThis defines a global function Monoid.apply[T] that returns the Monoid[T] instance that is currently visible.\n\nWith this helper, reduce can be written like this:\n\n```scala\ndef reduce[T: Monoid](xs: List[T]): T =\n  xs.reduceLeft(Monoid[T].unit)(_.combine(_))\n```",
    "Multiple Typeclass Instances\n\nIt's possible to have several given instances for a typeclass/type pair. For instance, Int could be a Monoid in (at least) two ways:\n\nwith + as combine and 0 as unit, or\nwith * as combine and 1 as unit.\n\n```scala\ngiven sumMonoid: Monoid[Int] with\n extension (x: Int) def combine(y: Int): Int = x + y\n def unit: Int = 0\n\ngiven prodMonoid: Monoid[Int] with\n extension (x: Int) def combine(y: Int): Int = x * y\n def unit: Int = 1\n```",
    "Define the sum and product functions on List[Int] in terms of reduce.\n\n```scala\ndef sum(xs: List[Int]): Int = reduce(xs)(using sumMonoid)\ndef product(xs: List[Int]): Int = reduce(xs)(using prodMonoid)\n```\n\nWhat happens if you leave out the using arguments?\n\nAn ambiguity error.",
    "Typeclass Laws\n\nAlgebraic type classes are not just defined by their type signatures but also by the laws that hold for them.\n\nFor example, any given instance of $Monoid[T]$ should satisfy the laws:\n\n$x.combine(y).combine(z) == x.combine(y.combine(z))$\n\n$unit.combine(x) == x$\n\n$x.combine(unit) == x$\n\nwhere $x, y, z$ are arbitrary values of type $T$ and $unit = Monoid.unit[T]$.\n\nThe laws can be verified either by a formal or informal proof, or by testing them.\n\nA good way to test that an instance is lawful is using randomized testing with a tool like ScalaCheck.",
    "Exercise Session 4\n\nThis week, we will work on the idea of variance, and on pattern matching.\n\nQUESTION 1\n\nRecall that:\nLists are covariant in their only type parameter.\nFunctions are contravariant in the argument, and covariant in the result.\n\nConsider the following hierarchies:\n\nclass Fruit\nclass Banana extends Fruit\nclass Apple extends Fruit\nclass Juice\nclass AppleJuice extends Juice\nclass Liquid\n\nConsider also the following typing relationships for $A, B, C, D, E,$ and $F$:\n\nFill in the subtyping relation between the types below. Bear in mind that in the left hand side neither type is a\nsubtype of the other:\n\n\\[\n\\begin{array}{|l|l|}\n\\hline\n\\text{Left hand side} & \\text{Right hand side} \\\\\n\\hline\n\\text{List[Banana] <=> List[Fruit]} & (A \\le B) => (List[A] \\le List[B]) \\\\\n\\hline\n\\text{List[Fruit] <=> List[Juice]} & \\text{X} \\\\\n\\hline\n\\text{Banana => Juice <=> Banana => Liquid} & (B \\le D) => ((A => B) \\ge (A => D)) \\\\\n\\hline\n\\text{A => Liquid <=> B => Liquid} & (A \\ge B) => ((A => C) \\le (B => D)) \\\\\n\\hline\n\\text{Fruit => Juice <=> Fruit => Juice} & A \\le B, C \\le D => ((A => C) \\le (B => D)) \\\\\n\\hline\n\\text{(Fruit => Fruit) => Juice <=> (Fruit => Juice) => Juice} & (B => C) \\le (D => E) => ((A => B) => C)      \\ge ((A => D) => E) \\\\\n\\hline\n\\end{array}\n\\]\n\nQUESTION 2\n\nThe following data type represents simple arithmetic expressions:\n\n\\[\n\\begin{array}{|l|}\n\\hline\n\\text{enum Expr} \\\\\n\\text{\\{case Num(i: Int)}\\\\\n\\text{case Sum(e1: Expr, e2: Expr)} \\\\\n\\text{case Var(name: String)} \\\\\n\\hline\n\\end{array}\n\\]",
    "```text\ncase Sum(e1: Expr, e2: Expr)\ncase Prod(e1: Expr, e2: Expr)\n\nDefine a function deriv(expr: Expr, v: String): Expr returning the expression that is the partial derivative of expr with respect to the variable v.\n\ndef deriv(expr: Expr, v: String): Expr = ???\n\nHere\u2019s an example run of the function:\n\n3 deriv(Sum(Prod(Var(\"x\"), Var(\"y\")), Var(\"x\")), \"x\")\nSum(Prod(deriv(Var(\"x\"),\"x\"), Prod(Var(\"x\"), Var(\"y\"))), Number(0))\n\nQUESTION 3\n\nWrite an expression simplifier that applies some arithmetic simplifications to an expression. For example, it would turn the above monstrous result into the following expression:\n\nProd(Var(\"x\"), Number(2))\n\n2) deriv(expr: Expr, v: String) : Expr = expr match\ncase Number(i) => 0\ncase Var(name) => if name == v then 1 else 0\ncase Sum(e1, e2) => Sum(deriv(e1,v), deriv(e2,v))\ncase Prod(e1,e2) => Sum(Prod(deriv(e1,v), e2), Prod(e1, deriv(e2,v)))\n\n3) def simplify(expr : Expr) : Expr = expr match\ncase Sum(e0, e1) =>\nsimplify(e0), simplify(e1)) match\ncase (Number(x), Number(y)) => Number(x + y)\ncase (Number(0), e1) => e1 case (e0, Number(0)) => e0\ncase (e0, e1) => Sum(e0, e1)\ncase Prod(e0, e1) =>\nsimplify(e0), simplify(e1) match\ncase (Number(x,y)) => Number(x * y)\ncase (Number(0), _) => Number(0)\ncase (Number(1), e1) => e1\ncase (e0, Number(1)) => e0 case (e0, e1) => Prod(e0, e1)\n```",
    "pattern match inside pattern match\n\ncase Prod(a, b) =>\n    (simplify(a), simplify(b)) match\n\ncase ...\n\nExercise 1:\n\n| argument  | result |\n| --------- | ------ |\n| $(B => C)$ | $D$    |\n| argument  | result |\n| $(A => D)$ | $D$    |\n| function de l'argument | result | \n\nNeed to check:\n\n1. Restructuring of (inner) function is consistent, is it with the argument of outer function?\n2. Final result is consistent, final result.\n\n1. $\\begin{aligned}\n   &((B => C) => D)\\\\\n   &B : \\sin A \\Longrightarrow C : \\cos \n\\end{aligned}$\n\n2. $\\{ \\begin{aligned}\n   &((B => C) => D)\\\\\n   &((A => D) => D)\\\\\n   &B : \\sin C \\Longrightarrow (\\Longrightarrow) => true \n\\end{aligned}$",
    "Example: Square roots with Newton\u2019s method\n\nPrinciples of Functional Programming",
    "Task\n\nWe will define in this session a function \n\n/** Calculates the square root of parameter x **/\ndef sqrt(x: Double): Double = ...\n\nThe classical way to achieve this is by successive approximations using Newton's method.",
    "Method\n\nTo compute $\\sqrt{x}$:\n\u25ba Start with an initial estimate $y$ (let\u2019s pick $y = 1$).\n\u25ba Repeatedly improve the estimate by taking the mean of $y$ and $x/y$.\n\nExample: $\\sqrt{2}$\n\nEstimation    Quotient $\\left(\\frac{x}{y}\\right)$    Mean $\\left(\\frac{y + \\frac{x}{y}}{2}\\right)$\n1             2 / 1 = 2                            1.5\n1.5           2 / 1.5 = 1.333                      1.4167\n1.4167        2 / 1.4167 = 1.4118                  1.4142\n1.4142        ...                                   ...",
    "First, define a function which computes one iteration step\n\n```scala\ndef sqrtIter(guess: Double, x: Double): Double =\n  if isGoodEnough(guess, x) then guess\n  else sqrtIter(improve(guess, x), x)\n```\n\nNote that `sqrtIter` is recursive, its right-hand side calls itself.\nRecursive functions need an explicit return type in Scala.\nFor non-recursive functions, the return type is optional.",
    "Second, define a function improve to improve an estimate and a test to check for termination:\n\n```scala\ndef improve(guess: Double, x: Double) = \n  (guess + x / guess) / 2\n\ndef isGoodEnough(guess: Double, x: Double) = \n  abs(guess * guess - x) < 0.001\n```",
    "Third, define the sqrt function:\n\n```scala\ndef sqrt(x: Double) = sqrtIter(1.0, x)\n```",
    "1. The $isGoodEnough$ test is not very precise for small numbers and can lead to non-termination for very large numbers. Explain why.\n2. Design a different version of $isGoodEnough$ that does not have these problems.\n3. Test your version with some very very small and large numbers, e.g.\n   0.001\n   0.1e-20\n   1.0e20\n   1.0e50",
    "Data Abstraction\n\nPrinciples of Functional Programming",
    "Data Abstraction\n\nThe previous example has shown that rational numbers aren't always represented in their simplest form. (Why? $\\frac{66}{42}$, $\\frac{33}{21}$)\nOne would expect the rational numbers to be simplified:\nreduce them to their smallest numerator and denominator by dividing both with a divisor.\n\nWe could implement this in each rational operation, but it would be easy to forget this division in an operation.\n\nA better alternative consists of simplifying the representation in the class when the objects are constructed: The Solution.",
    "class Rational(x: Int, y: Int):\n    private def gcd(a: Int, b: Int): Int =\n        if b == 0 then a else gcd(b, a % b)\n    private val g = gcd(x, y)\n    def numer = x / g\n    def denom = y / g\n...\n\ngcd and g are private members; we can only access them from inside the Rational class.\n\nIn this example, we calculate gcd immediately, so that its value can be re-used in the calculations of numer and denom.",
    "It is also possible to **call gcd in the code of numer and denom**:\n\n```python\nclass Rational(x: Int, y: Int):\n    private def gcd(a: Int, b: Int): Int =\n        if b == 0 then a else gcd(b, a % b)\n    def numer = x / gcd(x, y)\n    def denom = y / gcd(x, y)\n```\n\nThis can be advantageous **if it is expected that the functions numer and denom are called infrequently**.",
    "It is equally possible to turn numer and denom into vals, so that they are computed only once:\n```scala\nclass Rational(x: Int, y: Int):\n  private def gcd(a: Int, b: Int): Int =\n    if b == 0 then a else gcd(b, a % b)\n  val numer = x / gcd(x, y)\n  val denom = y / gcd(x, y)\n```\nThis can be advantageous if the functions numer and denom are called often.",
    "The Client's View\n\nClients observe exactly the same behavior in each case.\n\nThis ability to choose different implementations of the data without affecting clients is called data abstraction.\n\nIt is a cornerstone of software engineering.",
    "Self Reference\n\nOn the inside of a class, the name this represents the object on which the current method is executed.\n\nExample\nAdd the functions less and max to the class Rational.\n\nclass Rational(x: Int, y: Int):\n\n    def less(that: Rational): Boolean =\n        numer * that.denom < that.numer * denom\n\n    def max(that: Rational): Rational =\n        if this.less(that) then that else this",
    "Self Reference (2)\n\nNote that a simple name m, which refers to another member of the class, is an abbreviation of this.m. Thus, an equivalent way to formulate less is as follows.\n\n$$\n\\text{def less(that: Rational): Rational =}\n$$\n$$\n\\text{this.numer * that.denom < that.numer * this.denom}\n$$",
    "Preconditions\n\nLet's say our Rational class requires that the denominator is positive.\n\nWe can enforce this by calling the require function.\n\n```scala\nclass Rational(x: Int, y: Int):\n  require(y > 0, \"denominator must be positive\")\n  ...\n```\n\nrequire is a predefined function.\n\nIt takes a condition and an optional message string.\n\nIf the condition passed to require is false, an IllegalArgumentException is thrown with the given message string.",
    "Assertions\n\nBesides require, there is also assert.\n\nAssert also takes a condition and an optional message string as parameters. E.g.\n\n```\nval x = sqrt(y)\nassert(x >= 0)\n```\n\nLike require, a failing assert will also throw an exception, but it\u2019s a different one: `AssertionError` for assert, `IllegalArgumentException` for require.\n\nThis reflects a difference in intent\n\n\u25ba require is used to enforce a precondition on the caller of a function.\n\u25ba assert is used as to check the code of the function itself.",
    "Constructors\n\nIn Scala, a class implicitly introduces a constructor. This one is called the primary constructor of the class.\n\nThe primary constructor\n\u25ba takes the parameters of the class\n\u25ba and executes all statements in the class body (such as the require a couple of slides back).",
    "Auxiliary Constructors\n\nScala also allows the declaration of auxiliary constructors.\n\nThese are methods named this\n\nExample Adding an auxiliary constructor to the class Rational.\n\nclass Rational(x: Int, y: Int):\n  def this(x: Int) = this(x, 1)\n...\n\nRational(2) \u2192 2/1",
    "End Markers\n\nWith longer lists of definitions and deep nesting, it\u2019s sometimes hard to see where a class or other construct ends.\n\nEnd markers are a tool to make this explicit.\n\nclass Rational(x: Int, y: Int):\n    def this(x: Int) = this(x, 1)\n\n    ...\n  \nend Rational\n\n-And end marker is followed by the name that's defined in the definition that ends at this point.\n\n-It must align with the opening keyword (class in this case).",
    "End Markers\n\nEnd markers are also allowed for other constructs.\n\ndef sqrt(x: Double): Double =\n    ...\nend sqrt\n\nif x >= 0 then\n    ...\nelse\n    ...\nend if\n\nIf the end marker terminates a control expression such as if, the beginning keyword is repeated.",
    "Modify the Rational class so that rational numbers are kept unsimplified internally, but the simplification is applied when numbers are converted to strings.\n\nDo clients observe the same behavior when interacting with the rational class?\n\n0\tyes\n0\tno\n0\tyes for small sizes of denominators and nominators and small numbers of operations.",
    "Functional Programming Principles in Scala\n\nPrinciples of Functional Programming\nMartin Odersky",
    "Programming Paradigms\n\nParadigm: In science, a paradigm describes distinct concepts or thought patterns in some scientific discipline.\n\nMain programming paradigms:\n\u25ba imperative programming\n\u25ba functional programming\n\u25ba logic programming\n\nOrthogonal to it:\n\u25ba object-oriented programming",
    "Review: Imperative programming\n\nImperative programming is about\n\n- modifying mutable variables,\n- using assignments\n- and control structures such as if-then-else, loops, break, continue, return.\n\nThe most common informal way to understand imperative programs is as instruction sequences for a Von Neumann computer.",
    "There's a strong correspondence between\nMutable variables \u2248 memory cells\nVariable dereferences \u2248 load instructions\nVariable assignments \u2248 store instructions\nControl structures \u2248 jumps\n\nProblem: Scaling up. How can we avoid conceptualizing programs word by word?\n\nReference: John Backus, Can Programming Be Liberated from the von. Neumann Style?, Turing Award Lecture 1978.",
    "Scaling Up\n\nIn the end, pure imperative programming is limited by the \"Von Neumann\" bottleneck: \n*One tends to conceptualize data structures word-by-word.*\n\nWe need other techniques for defining high-level abstractions such as collections, polynomials, geometric shapes, strings, documents.\n\nIdeally: Develop *theories* of collections, shapes, strings, ...",
    "What is a Theory?\n\nA theory consists of\n\n- one or more data types\n- operations on these types\n- laws that describe the relationships between values and operations\n\nNormally, a theory does not describe mutations!",
    "Theories without Mutation\n\nFor instance the theory of polynomials defines the sum of two polynomials by laws such as:\n\n$(ax + b) + (cx + d) = (a + c)x + (b + d)$\n\nBut it does not define an operator to change a coefficient while keeping the polynomial the same!",
    "Theories without Mutation\n\nFor instance the theory of polynomials defines the sum of two polynomials by laws such as:\n\n$ (ax + b) + (cx + d) = (a + c)x + (b + d) $\n\nBut it does not define an operator to change a coefficient while keeping the polynomial the same!\n\nWhereas in an imperative program one can write:\n\n```\nclass Polynomial { double[] coefficient; }\nPolynomial p = ...;\np.coefficient[0] = 42;\n```",
    "Other example:\n\nThe theory of strings defines a concatenation operator ++ which is associative:\n\n$(a ++ b) ++ c = a ++ (b ++ c)$\n\nBut it does not define an operator to change a sequence element while keeping the sequence the same!\n\n(This one, some languages do get right; e.g. Java's strings are immutable)",
    "Consequences for Programming\n\nIf we want to implement high-level concepts following their mathematical theories, there\u2019s no place for mutation.\n\n- The theories do not admit it.\n- Mutation can destroy useful laws in the theories.\n\nTherefore, let\u2019s\n\n- concentrate on defining theories for operators expressed as functions,\n- avoid mutations,\n- have powerful ways to abstract and compose functions.",
    "Functional Programming\n\n\u25ba In a restricted sense, functional programming (FP) means programming without mutable variables, assignments, loops, and other imperative control structures.\n\u25ba In a wider sense, functional programming means focusing on the functions and immutable data.\n\u25ba In particular, functions can be values that are produced, consumed, and composed.\n\u25ba All this becomes easier in a functional language.",
    "- In a restricted sense, a functional programming language is one which does not have mutable variables, assignments, or imperative control structures.\n- In a wider sense, a functional programming language enables the construction of elegant programs that focus on functions and immutable data structures.\n- In particular, functions in a FP language are first-class citizens. This means\n  - they can be defined anywhere, including inside other functions\n  - like any other value, they can be passed as parameters to functions and returned as results\n  - as for other values, there exists a set of operators to compose functions",
    "Some functional programming languages\n\n- Lisp, Scheme, Racket, Clojure\n- SML, Ocaml, F#\n- Haskell\n- Scala\n\nBy now, concepts and constructs from functional languages are also found in many traditional languages.",
    "History of FP languages\n\n1959      (Lisp)\n1975-77   ML, FP, Scheme\n1978      (Smalltalk)\n1986      Standard ML\n1990      Haskell, Erlang\n2000      OCaml\n2003      Scala\n2005      F#\n2007      Clojure\n2017      Idris\n2020      Scala 3\n\nScala 3 is the language we will use in this course.",
    "Origins of FP\n\n1930s: Lambda Calculus (Alonzo Church)\n\u25ba Shown to be equivalent to Turing Machines\n\u25ba Stays relevant today as one of the theoretical foundations of FP\n\n1959: Lisp\n\u25ba Functions and recursive data tools for artificial intelligence research\n\n1980/90s: ML, Haskell, ...\n\u25ba New type systems with a strong connection to mathematical logic",
    "Why Functional Programming?\n\n- Reduce errors\n- Improve modularity\n- Higher-level abstractions\n- Shorter code\n- Increased developer productivity",
    "Why Functional Programming Now?\n\n1. It's an effective tool to handle concurrency and parallelism, on every scale.\n2. Our computers are not Van-Neuman machines anymore. They have\n   \u25b6 parallel cores\n   \u25b6 clusters of servers\n   \u25b6 distribution in the cloud\n\nThis causes new programming challenges such as\n   \u25b6 cache coherency\n   \u25b6 non-determinism",
    "Recommended Book (1)\n\nStructure and Interpretation of Computer Programs. Harold Abelson and Gerald J. Sussman. 2nd edition. MIT Press 1996.\n\nA classic. Many parts of the course and quizzes are based on it, but we change the language from Scheme to Scala.\n\nThe full text can be downloaded here.",
    "Recommended Book (2)\n\nProgramming in Scala. Martin Odersky, Lex Spoon, and Bill Venners. 4th edition. Artima 2019.\n\nThe standard language introduction and reference.",
    "Other Recommended Books\n\nThere are many other good introductions to Scala. Among them:",
    "Exercise Session 5\n\nStructural Induction\n\nQUESTION 1\n\nProve that the following equivalence holds by using inductive reasoning:\n\nlist map f (map g xs) == list map (f.andThen g)\n\nAxioms:\n1. Nil: map f [] == nil\n2. Cons: $\\forall$ xs x f $map f(x::xs)== f(x) :: (xs map f)$ \n3. f.andThen g(f(x)) == g(f(x))\n\nNote: Be very precise in your proof:\n * Clearly state which axiom you use at each step, and when/if you use the induction hypothesis.\n * Use only 1 axiom/hypothesis at each step, and only once. Applying 2 axioms requires 2 steps.\n * Underline the part of an equation on which you apply your next rewriting step.\n * Make sure to state what you want to prove, and what your induction hypothesis is, if any.\n \nQUESTION 2\n\nA more complicated proof (midterm 2016)\n\nWe want to implement a function sum(list: List[Int]): Int,\nInt, which returns the sum of the elements of a list of Ints. We can easily specify that function as follows:\n\n$\\forall \\ l: \\text { List [ Int ] } . \\ \\text { sum } ( l ) == \\sum _{ x \\in l } x$\n\nIf we naively translate this specification into a Scala implementation, we end up with a uselessly non-tail recursive function. Besides, defining the recursion ourselves is wasteful. Instead, we implement it using\n\ndef sum(intlist: List[int]): Int = {\n   list.foldleft[o](add) == sum(list)\n}\n\nHowever, that implementation is not trivially correct anymore. We would like to prove that it is correct for all lists of integers. In other words, we want to prove that\n\nlist.foldleft[o](add) == sum(list)\n\n$$\\sum_{i=0}^{n-1} a_i = (a_0 + a_1 + \\cdots + a_{n-2} ) + a_{n-1}= \\begin{cases} \n= &  \\sum_{i=0}^{n-1} \\\\ = & \\sum_{i=n-1} a_0 \\end{cases}$$",
    "for all lists of integers.\n\nIn addition to the specification of Sum (1-2), you may use the following axioms:\n\n$$\n\\begin{array}{l}\n(3) Nil.foldleft(f)(z) == z\\\\\n(4) x::xs.foldleft(f)(z) == xs.foldleft(f)(f(z, x))\\\\\n(5) addb(a, b) == a + b\\\\\n(6) 0 + a == a\\\\\n(7) (a + b) + c == a + (b + c)\\\\\n(8) a + 0 == a\\\\\n\\end{array}\n$$\n\nAxioms 3-5 follow from the implementations of foldleft and add. Axioms 6-8 encode well-known properties of int.+, commutativity, associativity, and neutral element.\n\n**Your task:** prove the following lemma by structural induction:\n\n$$\\text{list.foldleft(add)(z) == z + sum(list)}$$\n\nFrom that lemma, we can \"trivially\" (with the help of axioms 6 and 8) derive that the implementation of betterSum is correct by substituting 0 for z in the lemma. You are not asked to do that last bit.\n\n**QUESTION 1**\n\nUsing the list.map function defined below, show how induction works in practice using preordered sets\n\n$map$ takes in a function f:\n\n$$\\begin{array}{l}\n1 $\\quad\\text{Assign an element in A type}\\\\\n2 $\\quad\\text{Assign another element in type B}\\\\\n3 $\\quad\\text{map correlates\\ldots few more}\\\\\n4 $\\quad\\text{Each element in set}\n\\end{array}$$\n\n1) $\\quad \\text{list.map($A$ $\\Rightarrow B$) \\\\}$\n\nie: list.map(elem => elem,2)\n\nmap converts a collection A to another B by applying a function to every element in A.",
    "Base case: Show $P(Nil)$.\n\nLHS: $Nil$ map $f$ map $g$ $\\overset{(1)}{=} Nil$ map $g \\overset{(2)}{=} Nil$\nRHS: $Nil$ map $(f \\cdot g) \\overset{(2)}{=} Nil$\n\nAssume case $P(xs)$: $xs$ map $f$ map $g \\overset{(3)}{=} xs$ map $(f \\cdot then \\cdot g)$\n\nInduction step: Show $P(x :: xs)$.\n\nLHS: $(x :: xs)$ map $f$ map $g$ $\\overset{(3), (2)}{=} (f(x) :: xs$ map $f$) map $g \\overset{(1)}{=} g(f(x)) :: (xs$ map f$ \\cdot g) \\overset{assumption}{=} g(f(x)) \\cdot then \\cdot g$\n       $\\overset{(1)}{=} (g \\cdot (f(x))) \\overset{(2)}{=} (xs$ map $(f \\cdot then \\cdot g)(xs$ map $(f \\cdot then g))$\n\nRHS: $: (x :: xs)\\: map (f \\cdot then g) \\overset{(1)}{=} (g(f(x))) :: (xs$ map $(f \\cdot then g)(xs$ map $(f \\cdot then g)$ (f $ \\cdot then \\cdot g)(xs) \\overset{ assumptions}==$\n\n$QED$\n\nPar\u00e9ntesis:\n\nUsing foldLeft function:\nfoldLeft: takes as arguments an accumulator and uses it to collapse elements from left to right.\nSo we can write $sum(xs)$ as $list.foldLeft(o)(ord)$\n\n$def sum(xs: List[Int])\\ = \\  xs.foldLeft\\\\ lprod(xs: List[Int]): prod(xs)= xs.foldLeft(1)$ $\\ \\cdot (*)\n\n2) Your task: prove the following lemma by structural induction:\n$List.foldLeft(o)(f)(xs)+ List.foldLeft$o)(f)(ys) = List.foldLeft o(f ys)((++ ys)\n\n$sum(nil) == o$\n $sum(x :: xs) == sum(xs) = x + sum(xs)\n\nlist.foldRight (sum) = o$+ sum(xs\\\\ o \\cdot xs)$\n$list.cons xs = x s :: xs f\n\ndef betterSumList(list[()): int = List.foldL (o xx) ( o )\n\ndef add0 (acc) (c) : o \\cdot effort\n\n\\ def sum(xs: List [Int): int \\= \\:xs.foldLeft(0)$(ind + ord  g) ord)) \u0434\u043e\u0440: List. foldRight\n\n$def betterSumList(xs) xs = s f x)((um\n$list.foldRight[) accs foldright()\n\n$def add0 (acc) c.0 as front +. (o s c)$\n\n\n    \n",
    "Base case: $list = Nil, z$\n\\[LHS: Nil.foldLeft(z)(add) = z\\]\n\\[RHS: z + sum(Nil) = z\\]\n\nAssume: $list = x:xs$\n\\[xs.foldLeft(z)(add) = z + sum(xs) \\text{(IH)}\\]\n\nInduce: $list = x:xs, z$\n\\[LHS: (x:xs).foldLeft(z)(add)\\]\n\\[xs.foldLeft(z)(add))(add(x)\\]\n\\[xs.foldLeft(z))(add) + x\\]\n\\[z + sum(xs)) + x\\]\n\\[z + (sum(xs) + x)\\]\n\\[z + sum(x:xs)\\]\n\nTabl e working:\n\\[\\text{-immutable object\\ cannot be chaged}\\]\n\\[STL queueBy (K) \\beta: A) = \\text { immutable Map(K \\, < &)\\]\n\nQueue content of list by key and value based on predicate funtion f\n\nMaps:\n\\[Map(\"x\"->\"25\")\\]\n\\[Map(\"y\"->\"25\")\\]\n\nA Map has a collection of key-value pairs\n\\text { Note: keys are unique in the map}\n\nBasic operation on Map:\n\\[isEmpty : \\text { returns an } \\text { and true if map is empty}\\] isEmpty returns true iff map is empty",
    "Map concatenation: map1 ++ map2\n\ndef toList: List[A] => returns a List containing all elements of this map.\n\nMap[A, B] ++ [Map\\Values (B, it => C)] = Map[A, C]\nMapVlaues apply function to values of map (B => C) => return new map with same keys but trasnformed values (C).\n\ncollection.view => returns a view of collection. (not allow us to perform operation on the view)\n\nmap function\ncollections = (c1,c2,...)\ncollection.map(f) = collection(f(c1), f(c2), ...)\n\nflatten:\ncombining a List from a List of Lists\n\ncase Nil => List()\ncase x :: xs => x ++ flat (xs1), pattern = flat (l1, l2, l3)\n\nFlat Map => same effect of map and flatten\nList(L1, L2).flatMap(f ) = List(f(L1) ++ f(L2))\nList() .flatMap(f) = List()\n\nNote: with the flatMap, lists with the criteria are concatenated into list Optimization => list of list\n\ndef mapList(f:A => List[U]): List[U] = xs match\ncase Nil => Nil\ncase x :: xs1 => f(x) ++ xs1. flatMap(f)\ncase x1 :: Nil => f(x1)",
    "Operations of chars and strings:\n\nchar.toLowerCase String.toLowerCase()\n\nList.mkString(sep: String) : String\n\n   -> Returns all chars from list in a string with a separator `sep`.\n\nApply function:\n\nLet's define a function: \n\nval f = (x: Int) => x + 1\nthen,\n$g.apply(2) == g(2) = f(2) + 1 = 3$\n\nOther example:\n\nval myMap = Map[key -> value]\n\nmyMap.apply(somekey) = returns value associated to the key `somekey` in myMap\n\nFor comprehension:\n \nsep.open(Logic[+B](x:B): Unit\n\n -> applies function $f$ to all the detail of this shrinkable collection\n\nNice example :",
    "def foo (n: Int, v: Int) =\n  for i <- 0 until n\n  for j <- 0 until n\n  if $ij \\neq v$ then yield $(i,j)$\n\nfor (10, 10) : foo\n    $(i,j) = yield((8j + 6i + ij + i)$ :\n\nThm 1: $i = 0 \\land j = 0 \\implies ij \\neq v$ is not in yield, in yield.\n\nThm 2: $i \\neq 0 \\land j = 9 \\implies ij \\neq v$ never, in yield.\n\nThm 1: $i \\neq 0 \\land j \\neq 9 \\implies ij = v$ never, in yield any ...\n\nThm 20: $i \\land j \\neq i$ never in yield  $(1,9)$\n\nCombinatorics function: occurance = [(10,1), (11,2)]\n\ncase $(i,j) = 1 = Seq (1,2)$\n\nfor sup (n,t) <- Combinators (n, t) = Seq(2(1), fns (1,2), fns(1, 2, t def ...)) ...\n    for (n, t) = i = 7\n        case Seq = combin(VAR)\n\n        t(functions) else FALSE = n : map do pred true (True(NIL)\n\n          ns != 0 = Seq  n.p (3(-2))\n\n\\[ \\text{yield((fn (1, 7))} \\]\n\n... = \\text{com NIL or} \\\\\n    ... fns(NIL)\n\\[\\text{!ns = +1 map} (VAR fns)\\]\n\nDetector:\n\ns (not) if map in NIL  \n\n\\[\\text{fns fns = VAR} \\]\n\n... fns (1,1)\n        = TRUE\n... \\text{Seq (6 ...}\n\n fns ...  FALSE",
    "$\\lceil  $\n\n$n \\rightarrow 0 \\;to\\; + : \\; landing $\n\n*Special:*\n\n- when n = 0: List (Zst (1), Zst (b1), Zst (b2))\n\n- when n = 1: $(a,i)$ :: Zst(a1)\n\n                $(a,1)$ :: Zst(b,1)\n\n                $(a,1)$ :: Zst(b,2)",
    "101 Language of arithmetic and if expressions\n102 Absolute value and its desugaring\n103 Recursive functions implemented using substitutions\n104 Environment instead of substitutions\n105 Higher-order functions using substitutions\n106 Higher-order functions using environments\n107 Nested recursive definitions using environments",
    "def twice = (f => (x => (f (f x))))\ndef square = (x => (x * x))\n\n((twice square) 3)\n= ((twice square) 3)\nFUN: (f => (y => (f (f y)))) ARG: (x => (x * x))\n=> (y => ((x => (x * x)) ((x => (x * x)) y)))\n=> (y => ((x * x) ((x => (x * x)) y)))\nFUN: (x => (x * x)) ARG: 3\n=> ((x * x) ((x => (x * x)) 3))\n=> ((x * x) (3 * 3))\n=> ((x * x) 9)\nFUN: (x => (x * x)) ARG: 9\n=> (9 * 9)\n=> 81",
    "I05: Trees for Higher-Order Functions\n\nNow we have a case for creating a function anywhere in the expression (param => body)\nArgument of function call need not be a name but can be an expression\nA function has exactly one argument (use currying if needed)\n\nenum Expr\n  case C(c: BigInt)\n  case N(name: String)\n  case BinOp(op: BinOps, e1: Expr, e2: Expr)\n  case IfNonzero(cond: Expr, trueE: Expr, falseE: Expr)\n  case Call(fun: Expr, arg: Expr)      // fun can be expression itself\n  case Fun(param: String, body: Expr)  // param => body\n\nCall(Fun(\"x\", BinOp(Times, N(\"x\"), N(\"x\"))),\n     C(3))                           // x => (* x x)(3)\n                                     // 3\n\n(x => (* x x))(3)\n(* 3 3)\n9",
    "Result can be a function, so we return an Expr (not BigInt)\n\n```scala\ndef eval(e: Expr): Expr = e match\n  case C(c) => e\n  case N(n) => eval(defs(n)) // find in global defs, then eval\n  case BinOp(op, e1, e2) =>\n    evalBinOp(op)(eval(e1), eval(e2))\n  case IfNonzero(cond, trueE, falseE) =>\n    if eval(cond) != C(0) then eval(trueE)\n    else eval(falseE)\n  case Fun(_,_) => e // functions evaluate to themselves\n  case Call(fun, arg) =>\n    eval(fun) match\n      case Fun(n,body) => eval(subst(body, n, eval(arg)))\n```",
    "// substitute all n with r in expression e\ndef subst(e: Expr, n: String, r: Expr): Expr = e match\n  case C(c) => e\n  case N(s) => if s==n then r else e\n  case BinOp(op, e1, e2) =>\n    BinOp(op, subst(e1,n,r), subst(e2,n,r))\n  case IfNonzero(cond, trueE, falseE) =>\n    IfNonzero(subst(cond,n,r), subst(trueE,n,r), subst(falseE,n,r))\n  case Call(f, arg) =>\n    Call(subst(f,n,r), subst(arg,n,r))\n  case Fun(formal,body) =>\n    if formal==n then e // do not substitute under (n => ...)\n    else Fun(formal, subst(body,n,r))",
    "```\n(def twice = (f => x => (f (f x)))\ndef fact n = (if n then (* n (fact (- n 1))) else 1)\n(twice fact 3))\n~~> 720\n\n(def twice1 = (f => fact => (f (f fact))))\ndef fact n = (if n then (* n (fact (- n 1))) else 1)\n(twice1 fact 3))\n\nFUN: (f => (fact => (f (f fact))))\nARG: (n => (if n then (* n (fact (- n 1))) else 1)) \nFUN: (fact => ((n => (if n then (* n (fact (- n 1))) else 1))\n                ((n => (if n then (* n (fact (- n 1))) else 1)) fact))) \nARG: 3 \n(if 3 then (* 3 ((3 (- 3 1))) else 1) \n~3 ((- 3 1)) \njava.lang.Exception: Cannot apply non-function 3 in a call\n```\nWhat went wrong ?\n```\n",
    "Exercise Session 9\n\nQUESTION 1\nFor each one of the functions map, foldlLeft and foldRight, write two implementations:\n1. A functional version that calls itself recursively.\n2. An imperative version that uses a mutable variable and a loop, and does not call itself recursively.\nYou also have to implement those 3 function from scratch, without using other functions.\n\nQuestion 1.1\nImplement the map function:\n\ndef map( l: List[S], f: T -> S): List[T] = ???\n\nExamples of successful runs:\nassert(map(List(1,2,3), x => x + 1) == List(2,3,4))\nassert(map(List(),(x: Int) => x * 3) == List())\n\nQuestion 1.2\nImplement the foldLeft function:\n\ndef foldLeft[B]( l: List[S], z: B, f: (B, S) -> B): B = ???\n\nExamples of successful runs:\nassert(foldleft(List(1, 2, 3),0,_ + _) == 6)\nassert(foldleft(List(),0,... + ...)== 0)\n\nQuestion 1.3\nImplement the foldRight function:\n\nT => S): List[T] = ???\n\nExamples of successful runs:\nassert(foldRight(List(1, 2, 3),0,_ + _) == 6)\nassert(foldRight(List(1, 2, 3), \" \", _.toString + _) == \"123\")\n\nQUESTION 2\nImplement the groupBy function:\n\ndef groupBy (l: List[S], f: T -> S): Map[S, List[T]] = ??? \n\nWrite two versions:\n1. One that uses foldRight.\n2. One that uses a mutable var and a loop.\n\nExamples of successful runs:\nassert(groupBy(List(1, 2, 3), _ % 2) ==\n                               Map(1 -> List(1, 3), 0 -> List(2))\nGenerally: why not use foldLeft instead of foldRight?\n\nQUESTION 3\nRemember the Pascal function that you wrote in the first Lab. Here is in Scala in which n begin a message on ecran:\ndef pascal(c: Int, r: Int): Int = {\n    if (c == 0 || c == r) 1\n    else pascal(c - 1, r - 1) + pascal (c, r - 1)\n}\nAnd here is an example output:\nassert (pascal(2, 4) == 6)\nMost common is not the same results are computed more than necessary. To alleviate this write an imperative version of the function that stores the results of every call in a hashmap.",
    "QUESTION 1\nFor each one of the functions map, foldleft and foldright, write two implementations:\n1. A functional version that calls itself recursively.\n2. An imperative version that uses a mutable variable and a loop, and does not call itself recursively.\nYou should implement these functions from scratch, without using other functions.\n\nQuestion 1.1\nImplement the map function:\n\ndef map[T, S](xs: List[T], f: T => S): List[S] = ???\n\nExamples of successful runs:\n\nassert(map(List(), (x: Int) => 2 * x) == Nil)\nassert(map(List(1, 2, 4), (x: Int) => 2 * x) == List(2, 4, 8))\n\nRecursive:\n\ndef map[T, S](xs: List[T], f: T => S): List[S] = xs match {\n\tcase h::xs  => f(h)::map(xs, f)\n\tcase Nil  => Nil\n}\n\nImperative:\n\ndef map[T, S](xs: List[T], f: T => S): List[S] =\nval res: List[S] = Nil\nfor x <- xs do\n\tres = f(x) \u2237 res\nres.reverse\n\nQuestion 1.2\nImplement the foldRight function:\n\ndef foldRight[T, U](xs: List[T], z: U, f: (T, U) => U): U = ???\n\nExamples of successful runs:\n\nassert(foldRight(List(), 0, _ + _) == 0)\nassert(foldRight(List(\"a\", \"b\", \"c\"), \"\", _ + _) == \"abc\")",
    "**Recursive:**\n\n$\\text{def foldLeft[T, S] (xs : List[T], z : S, f : (T, S) => S) : S =}$\n\n$\\ \\ \\text{xs match { }$\n\n$\\ \\ \\ \\ \\text{case Nil => z}$\n\n$\\ \\ \\ \\ \\text{case h :: xs => foldLeft(xs, f (h, z))}$\n\n$\\ \\ \\ \\}}$\n\n**Imperative:**\n\n$\\text{def foldLeft[T, S] (xs : List[T], z : S, f : (T, S) => S) : S =}$\n\n$\\ \\ \\ \\ \\text{var acc = z}$\n\n$\\ \\ \\ \\ \\text{for (x <- xs) acc = f(x, acc)}$\n\n$\\ \\ \\ \\ \\text{acc}$\n\n**Question 1.3**\n\nImplement the foldLeft function:\n\n$\\ \\ \\ \\ \\text{scala> foldLeft(List(1, 2, 3), 0, (x : Int, y : Int) => x + y)}$\n\n$\\ \\ \\ \\ \\text{res0 : Int = 6?}$\n\n$\\ \\ \\ \\ \\text{scala> val sl = List(\"a\", \"b\", \"c\") }$\n\n$\\ \\ \\ \\ \\text{scala> foldLeft(sl, \"\", (x : String, y : String) => x + y) }$\n\n$\\ \\ \\ \\ \\text{res1 : String = \"abc\"}$\n\nExamples of successful runs:\n\n$\\ \\ \\ \\ \\text{assert(foldLeft(List(1, 2, 3), 0, _ + _) == 6)}$\n\n$\\ \\ \\ \\ \\text{assert(foldLeft(sl, \"\", _ + _) == \"abc\")}$\n\n**Recursive:**\n\n$\\text{def foldLeft[T, S] (xs : List[T], z : S, f : (T, S) => S) : S =}$\n\n$\\ \\ \\text{xs match { }$\n\n$\\ \\ \\ \\ \\text{case Nil => z}$\n\n$\\ \\ \\ \\ \\text{case (h :: t) => foldLeft(t, f(h, z), f)}$\n\n$\\ \\ \\ \\}}$\n\n**Imperative:**\n\n$\\text{def foldLeft[T, S] (xs : List[T], z : S, f : (T, S) => S) : S =}$\n\n$\\ \\ \\ \\ \\text{var acc = z}$\n\n$\\ \\ \\ \\ \\text{for (x <- xs) do}$\n\n$\\ \\ \\ \\ \\ \\ \\ \\ \\text{acc = f(x, acc)}$\n\n$\\ \\ \\ \\ \\text{acc}$",
    "QUESTION 2\n\nImplement the groupBy function:\n\ndef groupBy[S, T](xs: List[T], f: T => S): Map[S, List[T]] = {\n  /* ... */\n}\n\nWrite two versions:\n1. One that uses foldRight.\n2. One that uses a mutable var and a loop.\n\nval TEST_LIST = List(1, 2, 3, 4, 5, 6)\nval UNIT = (_: Int) % 2\nassert(groupBy(TEST_LIST, UNIT) == Map(1 -> List(1, 3, 5), 0 -> List(2, 4, 6)))\n\n\nUsing foldRight:\n\ndef groupBy[S,T](xs: List[T], f: T => S): Map[S, List[T]] =\n  xs.foldRight(Map[S, List[T]]())((e: T, acc: Map[S, List[T]]) =>\n  {\n    val key = f(e)\n    val prevValue = acc.getOrElse(key, List[T]())\n    acc.updated(key, e :: prevValue)\n  }\n)\n\n\nOption method:\n\nobjectOption:\n  def getOrElse (arg):\n    'returns (Right value) if it is a 'Some()' or returns arg instead\n  \n\nsomeMap.getOrElse (key List()) =>\n  returns value corresponding to key if it already exists in Map else will just return an empty List: List()\n\nImperative:\n\ndef groupBy[S,T](xs: List[T], f: T => S): Map[S, List[T]] = {\n  var acc = Map[S, List[T]]()\n",
    "for x <- x_s.toSeq do\n  val fKey  = f(x)\n  val possible = arc.getOrElse(fKey, List())\n  arc = arc.updated( fKey, x :: possible)\narc\n\nQUESTION 3\n\nFormulate the pascal function that you wrote in the lecture in its simplest form. Submit a long listing. As in:\n\ndef pascal(c: Int, r: Int): Int =\n  if(c <=0 || c >=r)\n    1\n  else\n    pascal(c-1, r-1) + pascal(c, r-1)\n\nAnd here is an example output:\n\nscala> for( c <- 0 to 10) { print(pascal(c, 10) + \" \") }\n1 10 45 120 210 252 210 120 45 10 1\n\nHere you should show how the results are computed using caching. Submit the new pascal function with caching in a listing in the box below:\n\nval cache = scala.collection.mutable.HashMap[(Int,Int), Int]()\ndef pascal(c: Int, r: Int): Int =\n  val key = (c,r)\n  cache.get(key) match {\n    case None =>\n      printIn(\"Compute pascal(\"c, r\") \")\n      val cs=\n        if (c <=0 || c >=r) then\n          1\n        else\n          pascal(c-1,r-1) + pascal(c, r-1)\n      cache(key) = cs",
    "case Some(val) => cs\n\n[ Just return value 'c' it is already in the HashMap. ]",
    "Exceptional Monads\n\nPrinciples of Functional Programming\n\nMartin Odersky",
    "Exceptions\n\nExceptions in Scala are defined similarly as in Java.\n\nAn exception class is any subclass of $java.lang.Throwable$, which has itself subclasses $java.lang.Exception$ and $java.lang.Error$. Values of exception classes can be thrown.\n\n```scala\nclass BadInput(msg: String) extends Exception(msg)\nthrow BadInput(\"missing data\")\n```\n\nA thrown exception terminates computation, if it is not handled with a try/catch.",
    "Handling Exceptions with try/catch\n\nA try/catch expression consists of a body and one or more handlers.\nExample:\n\n```scala\ndef validatedInput(): String =\n  try getInput()\n  catch\n    case BadInput(msg) => println(msg); validatedInput()\n    case ex: Exception => println(\"fatal error; aborting\"); throw ex\n```",
    "try/catch Expressions\n\nAn exception is caught by the closest enclosing catch handler that matches its type.\n\nThis can be formalized with a variant of the substitution model. Roughly:\n\ntry e[throw ex] catch case x: Exc => handler\n\n-->\n\n$[x := ex]$handler\n\nHere, ex: Exc and e is some arbitrary \"evaluation context\"\n\n- that throw ex as next instruction to execute and\n- that does not contain a more deeply nested handler that matches ex.",
    "Critique of try/catch\n\nExceptions are a low-overhead way for handling abnormal conditions.  \nBut there have also some shortcomings.\n\n* They don\u2019t show up in the types of functions that throw them. (in Scala, in Java they do show up in throws clauses but that has its own set of downsides).\n\n* They don\u2019t work in parallel computations where we want to communicate an exception from one thread to another.\n\nSo in some situations it makes sense to see an exception as a normal function result value, instead of something special.\n\nThis idea is implemented in the scala.util.Try type.",
    "Handling Exceptions with the Try Type\n\nTry resembles Option, but instead of Some/None there is a Success case with a value and a Failure case that contains an exception:\n\nabstract class Try[+T]\ncase class Success[+T](x: T) extends Try[T] \ncase class Failure(ex: Exception) extends Try[Nothing]\n\nA primary use of Try is as a means of passing between threads and processes results of computations that can fail with an exception.",
    "Creating a Try\n\nYou can wrap up an arbitrary computation in a Try.\n\n\\[\n\\text{Try(expr)} \\quad // \\text{gives Success(someValue) or Failure(someException)}\n\\]\n\nHere's an implementation of Try.apply:\n\n\\begin{verbatim}\nimport scala.util.control.NonFatal\n\nobject Try:\n  def apply[T](expr: => T): Try[T] =\n    try Success(expr)\n    catch case NonFatal(ex) => Failure(ex)\n\\end{verbatim}\n\nHere, NonFatal matches all exceptions that allow to continue the program.",
    "Composing Try\n\nJust like with Option, Try-valued computations can be composed in for-expressions.\n\nfor\n    x <- computeX\n    y <- computeY\nyield f(x, y)\n\nIf computeX and computeY succeed with results Success(x) and Success(y), this will return Success(f(x, y)).\n\nIf either computation fails with an exception ex, this will return Failure(ex).",
    "Definition of flatMap and map on Try\n\nextension [T](xt: Try[T]):\n  def flatMap[U](f: T => Try[U]): Try[U] = xt match\n    case Success(x) => try f(x) catch case NonFatal(ex) => Failure(ex)\n    case fail: Failure => fail\n\n  def map[U](f: T => U): Try[U] = xt match\n    case Success(x) => Try(f(x))\n    case fail: Failure => fail\n\nSo, for a Try value t,\n\nt.map(f) == t.flatMap(x => Try(f(x)))\n           == t.flatMap(f andThen Try)",
    "Exercise\n\nIt looks like Try might be a monad, with unit = Try.\n\nIs it?\n\n0 Yes\n\n0 No, the associative law fails\n\n0 No, the left unit law fails\n\n0 No, the right unit law fails\n\n0 No, two or more monad laws fail.",
    "Solution\n\nIt turns out the left unit law fails.\n\n$$ Try(expr).flatMap(f)\u00a0\\ne\u00a0f(expr) $$\n\nIndeed the left-hand side will never throw a non-fatal exception whereas the right-hand side will throw any exception thrown by expr or f.\n\nHence, Try trades one monad law for another law which is more useful in this context:\nAn expression composed from 'Try', 'map', 'flatMap' will never throw a non-fatal exception.\n\nCall this the \"bullet-proof\" principle.",
    "Conclusion\n\nWe have seen that for-expressions are useful not only for collections.\n\nMany other types also define map, flatMap, and withFilter operations and with them for-expressions.\n\nExamples: Generator, Option, Try.\n\nMany of the types defining flatMap are monads.\n\n(If they also define withFilter, they are called \u201cmonads with zero\u201d).\n\nThe three monad laws give useful guidance in the design of library APIs.",
    "Subtyping and Generics\n\nPrinciples of Functional Programming",
    "Polymorphism\n\nTwo principal forms of polymorphism:\n\u25ba subtyping\n\u25ba generics\n\nIn this session we will look at their interactions.\n\nTwo main areas:\n\u25ba bounds\n\u25ba variance",
    "Type Bounds\n\nConsider the method assertAllPos which\n\n\u25ba takes an IntSet\n\u25ba returns the IntSet itself if all its elements are positive\n\u25ba throws an exception otherwise\n\nWhat would be the best type you can give to assertAllPos? Maybe:",
    "Type Bounds\n\nConsider the method assertAllPos which\n\n\u25ba takes an IntSet\n\u25ba returns the IntSet itself if all its elements are positive\n\u25ba throws an exception otherwise\n\nWhat would be the best type you can give to assertAllPos? Maybe:\n\ndef assertAllPos(s: IntSet): IntSet\n\nIn most situations this is fine, but can one be more precise?",
    "Type Bounds\n\nOne might want to express that assertAllPos takes Empty sets to Empty sets and NonEmpty sets to NonEmpty sets.\n\nA way to express this is: \n\n\\[\n\\text{def } assertAllPos[S < : IntSet](r: S): S = ...\n\\]\n\nHere, $<: IntSet$ is an upper bound of the type parameter $S$.\n\nIt means that $S$ can be instantiated only to types that conform to IntSet.\n\nGenerally, the notation\n\n$S <: T$ means: $S$ is a subtype of $T$, and\n\n$S >: T$ means: $S$ is a supertype of $T$, or $T$ is a subtype of $S$.",
    "Lower Bounds\n\nYou can also use a lower bound for a type variable.\n\nExample\n\n$[S >: NonEmpty]$\n\nintroduces a type parameter $S$ that can range only over supertypes of $NonEmpty$.\n\nSo $S$ could be one of $NonEmpty$, $IntSet$, $AnyRef$, or $Any$.\n\nWe will see in the next session examples where lower bounds are useful.",
    "Mixed Bounds\n\nFinally, it is also possible to mix a lower bound with an upper bound. For instance,\n\n\\[ S >: NonEmpty <: IntSet \\]\n\nwould restrict $S$ any type on the interval between NonEmpty and IntSet.",
    "Covariance\n\nThere's another interaction between subtyping and type parameters we need to consider. Given:\n\n$NonEmpty <: IntSet$\n\nis\n\n$List[NonEmpty] <: List[IntSet]$  ?\n\nIntuitively, this makes sense: A list of non-empty sets is a special case of a list of arbitrary sets.\n\nWe call types for which this relationship holds covariant because their subtyping relationship varies with the type parameter.\n\nDoes covariance make sense for all types, not just for $List$?",
    "Arrays\n\nFor perspective, let\u2019s look at arrays in Java (and C#).\n\nReminder:\n\u25ba An array of T elements is written $T[]$ in Java.\n\u25ba In Scala we use parameterized type syntax $Array[T]$ to refer to the same type.\n\nArrays in Java are covariant, so one would have:\n\\[ \\text{NonEmpty}[] <: \\text{IntSet}[] \\]",
    "Array Typing Problem\n\nBut covariant array typing causes problems.\n\nTo see why, consider the Java code below.\n\n```java\nNonEmpty[] a = new NonEmpty[]{\n    new NonEmpty(1, new Empty(), new Empty())};\n\nIntSet[] b = a;\nb[0] = new Empty();  // Will lead to run-time error\nNonEmpty s = a[0];\n```\n\nIt looks like we assigned in the last line an Empty set to a variable of type NonEmpty!\n\nWhat went wrong?",
    "The Liskov Substitution Principle\n\nThe following principle, stated by Barbara Liskov, tells us when a type can be a subtype of another.\nIf $A \\leq B$, then everything one can to do with a value of type B one should also be able to do with a value of type A.\n\n[The actual definition Liskov used is a bit more formal. It says:\nLet $q(x)$ be a property provable about objects x of type B. Then $q(y)$ should be provable for objects y of type A where $A \\leq B$.\n]",
    "The problematic array example would be written as follows in Scala:\n\n$\\begin{align*}\n\\text{val a: Array}[NonEmpty] &= \\text{Array(NonEmpty}(1), \\text{Empty}(), \\text{Empty}()) \\\\\n\\text{val b: Array}[IntSet] &= a \\\\\nb(0) &= \\text{Empty} \\\\\n\\text{val s: NonEmpty} &= a(0)\n\\end{align*}$\n\nWhen you try out this example, what do you observe?\n0     A type error in line 1\n0     **A type error in line 2**\n0     A type error in line 3\n0     A type error in line 4\n0     A program that compiles and throws an exception at run-time\n0     A program that compiles and runs without exception",
    "Exercise\n\nThe problematic array example would be written as follows in Scala:\n\n\\[\n\\begin{aligned}\n&\\text{val a: Array[NonEmpty] = Array(NonEmpty(1, Empty(), Empty()))}\\\\\n&\\text{val b: Array[IntSet] = a}\\\\\n&\\text{b(0) = Empty()}\\\\\n&\\text{val s: NonEmpty = a(0)}\n\\end{aligned}\n\\]\n\nWhen you try out this example, what do you observe?\n\n\\[\n\\begin{aligned}\n0 &\\ \\text{A type error in line 1}\\\\\n0 &\\ \\text{A type error in line 2}\\\\\n0 &\\ \\text{A type error in line 3}\\\\\n0 &\\ \\text{A type error in line 4}\\\\\n0 &\\ \\text{A program that compiles and throws an exception at run-time}\\\\\n0 &\\ \\text{A program that compiles and runs without exception}\n\\end{aligned}\n\\]",
    "Elements of Programming\n\nPrinciples of Functional Programming",
    "Elements of Programming\n\nEvery non-trivial programming language provides:\n- primitive expressions representing the simplest elements\n- ways to combine expressions\n- ways to abstract expressions, which introduce a name for an expression by which it can then be referred to.",
    "The Read-Eval-Print Loop\n\nFunctional programming is a bit like using a calculator\n\nAn interactive shell (or REPL, for Read-Eval-Print-Loop) lets one write expressions and responds with their value.\n\nThe Scala REPL can be started by simply typing\n\n> scala",
    "Here are some simple interactions with the REPL\n\nscala> 87 + 145\nres0: Int = 232\n\nFunctional programming languages are more than simple calculators because they let one define values and functions:\n\nscala> def size = 2\nsize: Int\n\nscala> 5 * size\nres1: Int = 10",
    "Evaluation\n\nA non-primitive expression is evaluated as follows.\n\n1. Take the leftmost operator\n2. Evaluate its operands (left before right)\n3. Apply the operator to the operands\n\nA name is evaluated by replacing it with the right hand side of its definition\n\nThe evaluation process stops once it results in a value\n\nA value is a number (for the moment)\n\nLater on we will consider also other kinds of values",
    "Example\n\nHere is the evaluation of an arithmetic expression:\n\ndef pi = 3.14159\n\ndef radius = 10\n\n$(2 * \\text{pi}) * \\text{radius}$",
    "Here is the evaluation of an arithmetic expression:\n\n$(2 * \\pi) * \\text{radius}$\n\n$(2 * 3.14159) * \\text{radius}$\n\n$6.28318 * \\text{radius}$\n\n$6.28318 * 10$\n\n$62.8318$",
    "Parameters\n\nDefinitions can have parameters. For instance:\n\n```scala\ndef square(x: Double) = x * x\nsquare: (x: Double)Double\n```\n\n```scala\nsquare(2)\n4.0\n```\n\n```scala\nsquare(5 + 4)\n81.0\n```\n\n```scala\nsquare(square(4))\n256.0\n```\n\n```scala\ndef sumOfSquares(x: Double, y: Double) = square(x) + square(y)\nsumOfSquares: (x: Double, y: Double)Double\n```",
    "Parameter and Return Types\n\nFunction parameters come with their type, which is given after a colon\n\n$ \\text{def power(x: Double, y: Int): Double = ...} $\n\nIf a return type is given, it follows the parameter list.\n\nPrimitive types are as in Java, but are written capitalized:\n\nInt        32-bit integers\nLong       64-bit integers\nFloat      32-bit floating point numbers\nDouble     64-bit floating point numbers\nChar       16-bit unicode characters\nShort      16-bit integers\nByte       8-bit integers\nBoolean    boolean values true and false",
    "Evaluation of Function Applications\n\nApplications of parameterized functions are evaluated in a similar way as operators:\n\n1. Evaluate all function arguments, from left to right\n2. Replace the function application by the function's right-hand side, and, at the same time\n3. Replace the formal parameters of the function by the actual arguments.",
    "Example\n\nsumOfSquares(3, 2+2)\nsumOfSquares(3, 4)\nsquare(3) + square(4)\n3 * 3 + square(4)\n9 + square(4)\n9 + 4 * 4\n9 + 16\n25",
    "The substitution model\n\nThis scheme of expression evaluation is called the substitution model.\n\nThe idea underlying this model is that all evaluation does is reduce an expression to a value.\n\nIt can be applied to all expressions, as long as they have no side effects.\n\nThe substitution model is formalized in the $\\lambda$-calculus, which gives a foundation for functional programming.",
    "Termination\n\n\u25ba Does every expression reduce to a value (in a finite number of steps)?\n\n\u25ba No. Here is a counter-example\n\n```scala\ndef loop: Int = loop\n```\n\nloop\n\nIf we reference loop, its body will be replaced by the reference.\n\nNever terminates!",
    "Changing the evaluation strategy\n\nThe interpreter reduces function arguments to values before rewriting the function application.\n\nOne could alternatively apply the function to unreduced arguments.\n\nFor instance:\n\nsumOfSquares(3, 2+2)\nsquare(3) + square(2+2)\n3 * 3 + square(2+2)\n9 + square(2+2)\n9 + (2+2) * (2+2)\n9 + 4 * (2+2)\n9 + 4 * 4\n9 + 16\n25",
    "Call-by-name and call-by-value\n\nThe first evaluation strategy is known as call-by-value, the second is known as call-by-name.\n\nBoth strategies reduce to the same final values as long as\n\n\u25b8 the reduced expression consists of pure functions, and\n\u25b8 both evaluations terminate.\n\nCall-by-value has the advantage that it evaluates every function argument only once.\n\nCall-by-name has the advantage that a function argument is not evaluated if the corresponding parameter is unused in the evaluation of the function body.",
    "Call-by-name vs call-by-value\n\nQuestion: Say you are given the following function definition:\n\n$ \\text{def} \\ \\text{test}(x: \\text{Int}, y: \\text{Int}) = x * x * x $\n\nFor each of the following function applications, indicate which evaluation strategy is fastest (has the fewest reduction steps)\n\n\\[\n\\begin{array}{cccc}\n\\text{CBV} & \\text{CBN} & \\text{same} & \\text{#steps} \\\\\n0 & 0 & 0 & \\text{test}(2, 3) \\\\\n0 & 0 & 0 & \\text{test}(3+4, 8) \\\\\n0 & 0 & 0 & \\text{test}(7, 2*4) \\\\\n0 & 0 & 0 & \\text{test}(3+4, 2*4) \\\\\n\\end{array}\n\\]",
    "Call-by-name vs call-by-value\n\ndef test(x: Int, y: Int) = x * x * x\n\ntest(2, 3)            same\ntest(3+4, 8)      CBV { better eval.\ntest(7, 2+3)      CBN   complexity.\ntest(3+4, 2+4) same }\n\nLet x=2+3 y=5+2\n\nCBN: input visible names into function eval.\ntest(x,y) = x * x * x = (2+3) * (2+3) * (2+3) = 125 = 25\n\nCBV: first evaluates/computes input variables, and then executes function:\ntest(x,y) = test(5,6) = (5)*(5)*(5) = 25",
    "Exercise Session 8\n\nQUESTION 1\n\nIn this exercise, we will define instances of the $t a$ type class.\n\nRecall the $Orderingt[ a]$ type class introduced in the lecture. An instance of $Orderingt[a]$ allows us to compare values of type $a$ to see which one (if any) is smaller. Similarly, an instance of $t[a]$ allows us to compare values of type $a$ to see if they are equal.\n\nWe can define it as follows:\n```scala\ntrait Eq[T]:\n  extention (x: T)\n    def eq (y: T): Boolean\n```\n\nQuestion 1.1\n\nWrite a given instance to create $t [ List [ T ]]$ from a $t [ T ]$.\n\nQuestion 1.2\n\nWrite a given instance to create $t [ T, U, S ]$ from $t [ T, U ]$ and t$ [ U, S ]$.\n\nQuestion 1.3\n\nWrite a given instance to create $t [ Person ]$. Make use of both the definition you have written previously.\n\ncase class Person(name: String, age: Int, hobbies: List$ [ String ])$\n\nQuestion 1.4\n\nExplain why the using argument to $summon$ (you may need to assign names to your given definitions):\n\n```scala\nt$ [ Person ] $ summon\n```\n\nQUESTION 2\n\nSome testing frameworks such as $Scalatest$/$Scala$, $Mocha$ ($JavaScript$) or $BSpec$ ($Ruby$) allow to organize tests hierarchically by closing them in nested groups.\n\nIn this exercise, our goal is to write our own tests framework with support for this feature. Here is an example usage:\n\n```scala\ndescribe (\"A set\"):\n  it (\"empty\"):\n    assert ( Set. empty. size = == 0)\nobject describe:\n  def apply (name: String) (body: Unit = > Unit): Unit =\n    println (nane)\n    body\n```\n\n```scala\ndescribe (\"A set\"):\n  it (\"empty\"):\n    assert (Set. empty. size == 0)\n```",
    "// About \"A Set when empty\".\n\nit(\"should have size 0\") {\n  assert(Set.empty.size == 0)\n}\n\n// FIXME: Add tests of this test set\n// \"A Set when empty\" should have size 2. \n\nit(\"should have size 2\") { // This is wrong!\n  assert(Set.empty.size == 2)\n}\n\ndescribe(\"when non-empty\") {\n  it(\"should have the correct size\") {\n    assert(Set(1, 2, 3).size == 3)\n  }\n}\n\n/* Set\n *  empty\n *  A Set when non-empty\n *    should have size 0\n *  + should have size 0\n *  - should have size 2\n *  + should have the correct size\n */\n\nThe last 4 comment lines show the content printed to the standard output.\n\nBefore starting the sub-exercises, ask yourself, how could the describe and it functions be implemented? How is it possible for the lines printed to have the correct indentation? Inevitably, this means that the implementation of the it function has to \"know\" in which group (more precisely, at which depth) it is! How can this be achieved, without using mutable state?\n\nThe answer lies in the usage (in sub-exercises 2.3 and 2.4) of given instances, using clauses and context functions.\n\nQuestion 2.1\n\nIn order to represent nestable groups, we will use the following case class:\n\ncase class TestGroup(\n  name: String,\n  tests: Seq[TestGroup] = None // omis\n)\n\nThe two test groups from the example above would be represented as:\n\nval empty = TestGroup(\"empty\", Seq.empty)\nval nonEmpty = TestGroup(\"non-empty\", Seq(last))\n\ngr Set = TestGroup(\"A Set\", Seq(empty, nonEmpty))\n\nWhat should the group's computeDepth function that, given a group, computes its depth:\n\ndef groupDepth(group: Option[TestGroup]): Int = ???\n\nExample of possible expected_Output:\n\nassert(groupDepth(None) == 0)\nassert(groupDepth(Some(empty)) == 1)\nassert(groupDepth(Some(nonEmpty)) == 2)",
    "Our framework will support different logger implementations. They will all implement the Logger trait:\n\n```\ntrait Logger:\n  def startGroup(group: TestGroup): Unit\n  def testResult(result: Result): Unit\n  def endGroup(): Unit\n\ncase class Option(assertionError: Option[AssertionError])\n```\n\nstartGroup will be called every time a group is entered, while testResult will be called after each unit test is executed.\n\nYour task in this sub-exercise is to implement an IndentLogger object that will print indented groups and test results as in the introductory example:\n\n```\nobject IndentLogger extends Logger:\n  // Print the two levels of groups with the\n  // indent shown\n  def startGroup(group: TestGroup): Unit = ???\n  // Print the successful tests\n  def testResult(result: Result): Unit = ???\n  // Print the end group and a tick\n  def endGroup(): Unit = ???\n```\n\nExample of successful runs (comments show what is printed from println):\n\n```\nIndentLogger.startGroup(renderSvg)\nIndentLogger.startGroup(renders the incompleted)\nGroup: renders the incompleted\nIndentLogger.testResult(Success)\n  Some test: \u2714\nIndentLogger.testResult(Success)\n  SomeOtherTest: \u2714\nIndentLogger.endGroup()\nIndentLogger.endGroup()\n\n//this should have 3 \u26a0\ufe0f\n  Hint in Scala, you can repeat a string n-times using the * operator:\n    \u201ca\u201d * 10 // \u201chahahahahaha\u201d \u27a1\ufe0f\n```\n\nQuestion 2.3\n\nWe now will define the core of our framework: the lift function. This function is responsible for enclosing and executing a block and, more specifically a MillUnit\u2019s result bounds.\n\nlift function must enclose the callee-name/body argument inside a try block and catch AssertionError exceptions. If the block succeeds, log a success message. If it throws or fails, you should call the .so and log an informative error message.",
    "Question 2.4\n\nYour last but not least task is to find the correct signature for the describe function and to implement it.\n\nSolutions:\n\nQUESTION 1\n\nIn this exercise, we will define instances of the Eq type class.\n\nRecall the OrderEq[T] type class introduced in the lecture. An instance of OrderEq[A] allows us to compare values of type A to each other and to get an ordering. Similarly, an instance of Eq[A] allows us to compare values of type A to see if they are equal.\n\nYou can define an Eq instance like this:\n\n```scala\ncase class Eq[A](eq: (A, A) => Boolean)\n```\n\n**Exercise 1.1:**\n\nWrite a given instance to create Eq[List[T]] from a Eq[T].\n\n```scala\ngiven Eq[List[T]](using eqT: Eq[T]): Eq[List[T]] with\n  extension (xs: List[T])\n    def eq (ys: List[T]): Boolean =\n      (xs, ys) match\n      case (hx :: tx, hy :: ty) => hx == hy && tx == ty\n      case (Nil, Nil) => true\n      case _ => false\n```",
    "Question 1.2\n\nWrite a given instance to create $Eq(T, (T, u, S))$ from $Eq(T, t)$ and $Eq(S)$.\n\ngiven $EqTuple[T, U, S] (using Eq[T], Eq[U], Eq[S]) : Eq[(T, U, S)]$ with \n  extension (x : (T, U, S))\n  \ndef == (y : (T, U, S)) : Boolean =\n  x._1 == y._1 && x._2 == y._2 && x._3 == y._3\n\n\nQuestion 1.3\n\nNeed to define an order class for Eq on $String$ and $Int$.\n\ngiven Eq[String] : Eq[String] with\n  extension (x : String)\n  \ndef == (y : String) : Boolean =\n  x.equals(y)\n\ngiven Eq[Int] : Eq[Int] with\n  extension (x : Int)\n  \ndef == (y : Int) : Boolean =\n  x == y\n\ngiven Eq[List[A]] (using Eq[A]) : Eq[List[A]] with\n  extension (xs : List[A])\n  \ndef == (ys : List[A]) : Boolean =\n  (xs, ys) match\n    case (Nil, Nil) => true\n    case (x :: xs, y :: ys) => x == y && xs == ys\n    case _ => false",
    "Question 1.4\nExplicitly write the using argument to sumsq (you may need to assign names to your given definitions).\n\n```haskell\nsumsq [ Eq[ Enum[] ] ] (using\n  EqNum (using\n    EqTuple ( using \n      EqString,\n      EqInt\n    )\n  )\n  EqList(using EqString)\n)\n```",
    "QUESTION 2\n\nTry deriving hierarchical methods such as Splendid (Splink) Modulo Overlapping or Hiero (Hiero) able to organize texts hierarchically according to their closest equivalences.\nBy doing this exercise, we get used to our own tools such frameworks with support for this feature. Here is an example usage of this exercise too:\n\n```\nprotocol Person {\n  var name: String get   // the name of the person\n  var age: Int get       // the age of the person\n  var aliases: [String] get\n}\n\nextension Person {\n  // Returns true if the person has the alias `name`\n  func hasAlias (_ name: String) -> Bool {\n    return aliases.contains(name)\n  }\n}\n\nstruct Employee: Person {\n  let name: String\n  let age: Int\n  let aliases: [String]\n  let company: String\n}\n```\n\nThe `hasAlias` method from the `Person` protocol may be used from the standard output.\n\nThe Hierarchical method performs an initial compiler check of `Employee` like the rest of functions we implemented here. It also uses more hierarchical data classes with different `aliases` checks that you can reproduce in various ways.\n\nThe library we use automatically accepts `e` with keyword `groups` which defaults to zero. If any (or none) cleanup is left out to users.\n\nYour task for this section is to implement a hierarchical feature, such depths as in `aAlias`, feature `e` versatility.\n\nQuestion 2\n\nFor Question 2 part implement groups we will need the following core class:\n```\nsealed trait Tree [Tree[Groups]] {\n}\n```\nThe goal of Equation for example above would be represented as:\n```\na) empty\na) foo\n```\nYour first task is to implement the constructor classes. Node gets a group, computes its depth:\n```\nclass Depths {\n  val depths = new Depth\n}\n\ndef apply (groups: TreeGroups)\n```\n\ndef groupDepth(group: Option[Tree[Groups]]): Int = \n\na group can (as count) have a peak of type Tree[Group].\n\ngroup match { \n  case None => 0",
    "Question 2.2 Note: Option has two cases: Some None\n\nOur framework will support different logger implementations. They will all implement the Logger trait:\n\n```scala\ntrait Logger {\n  def startGroup(name: String): Unit\n  def endGroup(): Unit\n  def log(msg: String): Unit\n}\n```\n\n`startGroup` will be called every time a group is entered, while `endGroup` will be called after each test suite is executed. Your task in this exercise is to implement an IndentLogger object that will print indented groups and test results as in the example below:\n\n```scala\nobject IndentLogger extends Logger {\n  private var groupDepth: List[String] = Nil\n\n  def startGroup(name: String): Unit = {\n    printIndent()\n    println(name)\n    groupDepth = name :: groupDepth\n  }\n\n  def endGroup() : Unit{\n    groupDepth = groupDepth.tail\n  }\n\n  def log(msg: String): Unit = {\n    printIndent()\n    println(msg)\n  }\n\n  private def printIndent(): Unit = print(\"  \" * groupDepth.size)\n}\n```\n\nExample of execution, to illustrate how what is printed from println\u2019s:\n```scala\nobject Main {\n  def main(args: Array[String]): Unit = {\n    val logger: Logger = IndentLogger\n    logger.startGroup(\"All tests\")\n    logger.log(\"Hello test 1\")\n    logger.startGroup(\"Group 1\")\n    logger.log(\"Hello test 2\")\n    logger.endGroup()\n    logger.log(\"Hello test 3\")\n    logger.endGroup()\n  }\n}\n```\n```\nAll tests\nHello test 1\n  Group 1\n  Hello test 2\nHello test 3\n```\n\nHint: In Scala, you can join a string n times using the * operator.\n\n```scala\nobject IndentLogger extends Logger {\ndef startGroup(name: String) : Unit = printIn\nprintln(  )\n+ = (groupDepth( (Some(group()))\n-)) 1)\n+ group.name\n```",
    "def testResult(name: String, group: Option[TestGroup], exec: Option[TestExecution]): Unit = \n  println(\n    s\" * ${group.fold(group) (-> Check whether Option is defined. \n    + (if (exec.isDefined) then '-> else '.')) \n    + ' ' + name\n  )\n2.3) Defining the it function: \n- The function creates and executes a single test case. \n- Function should execute the call-by-name body argument inside a try block and catch AssertionError exceptions.\n- If body executes successfully, the logger.testResult should be called with None as the exec argument.\n\ndef it(name: String)(Body: => Unit)(using group: Option[TestGroup] = None, logger: Logger = logger) = \n  try\n    body \n    logger.testResult(name, group, None)\n  catch case e: AssertionError => logger.testResult(name, group, Some(e))",
    "Question 2.4\n\nYour last but not least task is to find the correct signature for the describe function and to implement it.\n\n```scala\ndef describe(name : String)(body : Option[TestGroup] ?=> Unit)\n  (using parentGroup : Option[TestGroup] = None,\n   logger : Logger) =\n\n  val group = TestGroup(name, parentGroup)\n  logger.startup(group)\n  body(using Some(group))\n```",
    "Higher-Order Functions\n\nPrinciples of Functional Programming",
    "Higher-Order Functions\n\nFunctional languages treat functions as first-class values.\n\nThis means that, like any other value, a function can be passed as a parameter and returned as a result.\n\nThis provides a flexible way to compose programs.\n\nFunctions that take other functions as parameters or that return functions as results are called higher order functions.",
    "Example:\n\nTake the sum of the integers between a and b:\n\n\\[\n\\text{def sumInts(a: Int, b: Int): Int =} \\\\\n\\text{if a > b then 0 else a + sumInts(a + 1, b)}\n\\]\n\nTake the sum of the cubes of all the integers between a and b:\n\n\\[\n\\text{def cube(x: Int): Int = x * x * x} \\\\\n\\text{def sumCubes(a: Int, b: Int): Int =} \\\\\n\\text{if a > b then 0 else cube(a) + sumCubes(a + 1, b)}\n\\]",
    "Example (ctd)\n\nTake the sum of the factorials of all the integers between a and b:\n\ndef sumFactorials(a: Int, b: Int): Int =\n  if a > b then 0 else factorial(a) + sumFactorials(a + 1, b)\n\nThese are special cases of\n\n$$\\sum_{n=a}^{b} f(n)$$\n\nfor different values of f.\n\nCan we factor out the common pattern?",
    "Let's define:\n\ndef sum(f: Int => Int, a: Int, b: Int): Int =\n  if a > b then 0\n  else f(a) + sum(f, a + 1, b)\n\nWe can then write:\n\ndef sumInts(a: Int, b: Int) = sum(id, a, b)\ndef sumCubes(a: Int, b: Int) = sum(cube, a, b)\ndef sumFactorials(a: Int, b: Int) = sum(fact, a, b)\n\nwhere\n\ndef id(x: Int): Int = x\ndef cube(x: Int): Int = x * x * x\ndef fact(x: Int): Int = if x == 0 then 1 else x * fact(x - 1)",
    "Function Types\n\nThe type $A => B$ is the type of a function that takes an argument of type $A$ and returns a result of type $B$.\n\nSo, $Int => Int$ is the type of functions that map integers to integers.",
    "Anonymous Functions\n\nPassing functions as parameters leads to the creation of many small functions.\n\u25ba Sometimes it is tedious to have to define (and name) these functions using def.\n\nCompare to strings: We do not need to define a string using def. Instead of\n\n```python\ndef str = \"abc\"; println(str)\n```\nWe can directly write\n\n```python\nprintln(\"abc\")\n```\n\nbecause strings exist as literals. Analogously we would like function literals, which let us write a function without giving it a name.\n\nThese are called anonymous functions.",
    "Anonymous Function Syntax\n\nExample: A function that raises its argument to a cube:\n$(x: \\text{Int}) => x * x * x$\n\nHere, $(x: \\text{Int})$ is the parameter of the function, and $x * x * x$ is it's body.\n\nThe type of the parameter can be omitted if it can be inferred by the compiler from the context.\n\nIf there are several parameters, they are separated by commas:\n$(x: \\text{Int}, y: \\text{Int}) => x + y$",
    "Anonymous Functions are Syntactic Sugar\n\nAn anonymous function $(x_1 : T_1, ..., x_n : T_n) \\Rightarrow E$ can always be expressed using def as follows:\n\\[\n\\{ \\text{def } f(x_1 : T_1, ..., x_n : T_n) = E; f \\}\n\\]\nwhere $f$ is an arbitrary, fresh name (that's not yet used in the program).\n\nOne can therefore say that anonymous functions are syntactic sugar.",
    "Summation with Anonymous Functions\n\nUsing anonymous functions, we can write sums in a shorter way:\n\n```scala\ndef sumInts(a: Int, b: Int) = sum(x => x, a, b)\ndef sumCubes(a: Int, b: Int) = sum(x => x * x * x, a, b)\n```\n\nno need to define type for parameters.\n=> compiler knows that sum function expects a function from int to int so can infer.",
    "The sum function uses linear recursion. Write a tail-recursive version by replacing the ???s.\n\ndef sum(f: Int => Int, a: Int, b: Int): Int =\n    def loop(a: Int, acc: Int): Int =\n        if ??? then ???\n        else loop(???, ???)\n    loop(???, ???)",
    "def sum(f: Int => Int, a: Int, b: Int): Int =\n  def loop(a: Int, acc: Int): Int =\n    if a > b then acc\n    else loop(a+1, acc+f(a))\n  loop(a , 0)",
    "A Larger Equational Proof on Lists\n\nPrinciples of Functional Programming",
    "A Law of Reverse\n\nFor a more difficult example, let's consider the reverse function.\n\nWe pick its inefficient definition, because its more amenable to equational proofs:\n\n$ \\text{Nil} . \\text{reverse} = \\text{Nil} $ // 1st clause\n$ (x :: \\text{xs}) . \\text{reverse} = \\text{xs} . \\text{reverse} ++ \\text{List}(x) $ // 2nd clause\n\nWe'd like to prove the following proposition\n\n$\\text{xs} . \\text{reverse} . \\text{reverse} = \\text{xs}$",
    "Proof\n\nBy induction on xs. The base case is easy:\n\n$$\\text{Nil}. \\text{reverse}. \\text{reverse}$$\n$$= \\text{Nil}. \\text{reverse} \\quad \\text{// by 1st clause of reverse}$$\n$$= \\text{Nil} \\quad \\text{// by 1st clause of reverse}$$",
    "Proof\n\nBy induction on $xs$. The base case is easy:\n\n\\[ \n\\text{Nil.reverse.reverse} \\\\\n= \\text{Nil.reverse} \\quad // \\text{by 1st clause of reverse} \\\\\n= \\text{Nil} \\quad // \\text{by 1st clause of reverse} \n\\]\n\nFor the induction step, let's try:\n\n\\[ \n(x :: xs).reverse.reverse \\\\\n= (xs.reverse ++ \\text{List}(x)).reverse \\quad // \\text{by 2nd clause of reverse} \n\\]",
    "Proof\n\nBy induction on $xs$. The base case is easy:\n\n$$\n\\begin{align*}\nNil.reverse.reverse & = Nil.reverse \\quad \\text{// by 1st clause of reverse} \\\\\n& = Nil \\quad \\text{// by 1st clause of reverse}\n\\end{align*}\n$$\n\nFor the induction step, let's try:\n\n$$\n\\begin{align*}\n(x :: xs).reverse.reverse & = (xs.reverse ++ List(x)).reverse \\quad \\text{// by 2nd clause of reverse}\n\\end{align*}\n$$\n\nWe can't do anything more with this expression, therefore we turn to the right-hand side:\n\n$$\n\\begin{align*}\nx :: xs & = x :: xs.reverse.reverse \\quad \\text{// by induction hypothesis}\n\\end{align*}\n$$\n\nBoth sides are simplified in different expressions.",
    "To Do\n\nWe still need to show:\n\n$$(xs.reverse ++ \\text{List}(x)).reverse = x :: xs.reverse.reverse$$\n\nTrying to prove it directly by induction doesn't work.\n\nWe must instead try to generalize the equation. For any list ys,\n\n$$(ys ++ \\text{List}(x)).reverse = x :: ys.reverse$$\n\nThis equation can be proved by a second induction argument on ys.",
    "(Nil ++ List(x)).reverse   // to show: = x :: Nil.reverse",
    "$(Nil ++ List(x)).reverse \\quad // \\text{to show:} = x :: Nil.reverse$\n\n$= \\quad List(x).reverse \\quad // \\text{by 1st clause of } ++$",
    "Auxiliary Equation, Base Case\n\n\\[\n(\\text{Nil} ++ \\text{List}(x)).\\text{reverse} \\quad // \\text{to show: } = x :: \\text{Nil.reverse}\n\\]\n\\[\n= \\text{List}(x).\\text{reverse} \\quad // \\text{by lst clause of } ++\n\\]\n\\[\n= (x :: \\text{Nil}).\\text{reverse} \\quad // \\text{by definition of List}\n\\]",
    "Auxiliary Equation, Base Case\n\n$$(\\text{Nil} ++ \\text{List}(x)).\\text{reverse} \\quad // \\text{to show: } = x :: \\text{Nil}.\\text{reverse}$$\n\n$$= \\text{List}(x).\\text{reverse} \\quad // \\text{by 1st clause of } ++$$\n\n$$= (x :: \\text{Nil}).\\text{reverse} \\quad // \\text{by definition of List}$$\n\n$$= \\text{Nil} ++ (x :: \\text{Nil}) \\quad // \\text{by 2nd clause of reverse}$$",
    "Auxiliary Equation, Base Case\n\n$(\\text{Nil} ++ \\text{List}(x)).\\text{reverse}$  // to show: $= x :: \\text{Nil}.\\text{reverse}$\n\n$= \\text{List}(x).\\text{reverse}$  // by 1st clause of $++$\n\n$= (x :: \\text{Nil}).\\text{reverse}$  // by definition of List\n\n$= \\text{Nil} ++ (x :: \\text{Nil})$  // by 2nd clause of reverse\n\n$= x :: \\text{Nil}$  // by 1st clause of $++$",
    "Auxiliary Equation, Base Case\n\n$(\\text{Nil} ++ \\text{List}(x)).\\text{reverse}$ // to show: $= x :: \\text{Nil}.\\text{reverse}$\n\n$= \\text{List}(x).\\text{reverse}$ // by 1st clause of ++\n\n$= (x :: \\text{Nil}).\\text{reverse}$ // by definition of List\n\n$= \\text{Nil} ++ (x :: \\text{Nil})$ // by 2nd clause of reverse\n\n$= x :: \\text{Nil}$ // by 1st clause of ++\n\n$= x :: \\text{Nil}.\\text{reverse}$ // by 1st clause of reverse",
    "Auxiliary Equation, Inductive Step\n\n$((y :: ys) ++ \\text{List}(x)).\\text{reverse}$\n// to show: $= x :: (y :: ys).\\text{reverse}$",
    "Auxiliary Equation, Inductive Step\n\n$((y :: ys) ++ \\text{List}(x)).\\text{reverse}$  \\hspace{1cm} // to show: $= x :: (y :: ys).\\text{reverse}$\n\n$= (y :: (ys ++ \\text{List}(x))).\\text{reverse}$  \\hspace{1cm} // by 2nd clause of ++",
    "$((y :: ys) ++ \\text{List}(x)).\\text{reverse}$ \\hspace{20pt} // to show: $= x :: (y :: ys).\\text{reverse}$\n\n$= (y :: (ys ++ \\text{List}(x))).\\text{reverse}$ \\hspace{20pt} // by 2nd clause of ++\n\n$= (ys ++ \\text{List}(x)).\\text{reverse} ++ \\text{List}(y)$ \\hspace{20pt} // by 2nd clause of reverse",
    "$((y :: ys) ++ \\text{List}(x)).\\text{reverse}$  \\hfill // to show: $= x :: (y :: ys).\\text{reverse}$\n\n$= (y :: (ys ++ \\text{List}(x))).\\text{reverse}$  \\hfill // by 2nd clause of ++\n\n$= (ys ++ \\text{List}(x)).\\text{reverse} ++ \\text{List}(y)$  \\hfill // by 2nd clause of reverse\n\n$= (x :: ys.\\text{reverse}) ++ \\text{List}(y)$  \\hfill // by the induction hypothesis",
    "$$(y :: ys) ++ \\text{List}(x)).\\text{reverse} \\quad \\quad //\\text { to show: } = x :: ((y :: ys).\\text{reverse})$$\n$$(y :: (ys ++ \\text{List}(x))).\\text{reverse} \\quad \\quad //\\text{ by 2nd clause of } ++$$\n$$(ys ++ \\text{List}(x)).\\text{reverse} ++ \\text{List}(y) \\quad \\quad //\\text{ by 2nd clause of } \\text{reverse}$$\n$$(x :: ys.\\text{reverse}) ++ \\text{List}(y) \\quad \\quad //\\text{ by the induction hypothesis}$$\n$$x :: (ys.\\text{reverse} ++ \\text{List}(y)) \\quad \\quad //\\text{ by 1st clause of } ++$$",
    "$$(y :: ys) ++ \\text{List}(x)).\\text{reverse} \\quad \\text{// to show: } = x :: (y :: ys).\\text{reverse}))$$\n$$= (y :: (ys ++ \\text{List}(x))).\\text{reverse} \\quad \\text{// by 2nd clause of ++}$$\n$$= (ys ++ \\text{List}(x)).\\text{reverse} ++ \\text{List}(y) \\quad \\text{// by 2nd clause of reverse}$$\n$$= (x :: ys.\\text{reverse})) ++ \\text{List}(y) \\quad \\text{// by the induction hypothesis}$$\n$$= x :: (ys.\\text{reverse} ++ \\text{List}(y)) \\quad \\text{// by 1st clause of ++}$$\n$$= x :: (y :: ys).\\text{reverse} \\quad \\text{// by 2nd clause of reverse}$$\n\nThis establishes the auxiliary equation, and with it the main proposition.",
    "Exercise\n\nProve the following distribution law for map over concatenation.\n\nFor any lists $xs$, $ys$, function $f$:\n\n$$(xs ++ ys).map(f) = xs.map(f) ++ ys.map(f)$$\n\nYou will need the clauses of $++$ as well as the following clauses for $map$:\n\n$$Nil.map(f) = Nil$$\n$$(x :: xs).map(f) = f(x) :: xs.map(f)$$",
    "Computing with Infinite Sequences\n\nPrinciples of Functional Programming",
    "Infinite Lists\n\nYou saw that the elements of a lazy list are computed only when they are needed to produce a result.\n\nThis opens up the possibility to define infinite lists!\n\nFor instance, here is the (lazy) list of all integers starting from a given number:\n\n\\[\n\\text{def from(n: Int): LazyList[Int] = n \\#:: from(n+1)}\n\\]\n\nThe list of all natural numbers:\n\n\\[\n\\text{val nats = from(0)}\n\\]\n\nThe list of all multiples of 4:\n\n\\[\n\\text{nats.map(\\_ * 4)}\n\\]",
    "The Sieve of Eratosthenes\n\nThe Sieve of Eratosthenes is an ancient technique to calculate prime numbers.\n\nThe idea is as follows:\n- Start with all integers from 2, the first prime number.\n- Eliminate all multiples of 2.\n- The first element of the resulting list is 3, a prime number.\n- Eliminate all multiples of 3.\n- Iterate forever. At each step, the first number in the list is a prime number and we eliminate all its multiples.\n\nif it is a prime number, we eliminate all multiples of it\n\nThis needs to be done with lazy lists (no upper bound)",
    "The Sieve of Eratosthenes in Code\n\nHere's a function that implements this principle:\n\n```python\ndef sieve(s: LazyList[Int]): LazyList[Int] =\n  s.head #:: sieve(s.tail.filter(_ % s.head != 0))\n\nval primes = sieve(from(2))\n```\n\nTo see the list of the first N prime numbers, you can write\n\n```python\nprimes.take(N).toList\n```",
    "Back to Square Roots\n\nOur previous algorithm for square roots always used a isGoodEnough test to tell when to terminate the iteration.\n\nWith lazy lists we can now express the concept of a converging sequence without having to worry about when to terminate it:\n\n```scala\ndef sqrtSeq(x: Double): LazyList[Double] =\n  def improve(guess: Double) = (guess + x / guess) / 2\n  lazy val guesses: LazyList[Double] = 1 #: : guesses.map(improve)\n  guesses\n\n1  #::  i(1)  #:: i(i(1))  #:: i(i(i(1)))  #:: i(i(i(i(1))))) \n```",
    "Termination\n\nWe can add isGoodEnough later.\n\n```scala\ndef isGoodEnough(guess: Double, x: Double) =\n  ((guess * guess - x) / x).abs < 0.0001\n\nsqrtSeq(2).filter(isGoodEnough(_, 2))\n```",
    "Exercise:\n\nConsider two ways to express the infinite list of multiples of a given number N:\n\n\\[\n\\text{val xs = from(1).map(_ * N)}\n\\]\n\n\\[\n\\text{val ys = from(1).filter(_ \\% N == 0)}\n\\]\n\nWhich of the two lazy lists generates its results faster?\n\nX \\[ \\text{from(1).map(_ * N)} \\] \nO \\[ \\text{from(1).filter(_ \\% N == 0)} \\] \nO there's no difference",
    "Implicit Function Types\n\nPrinciples of Functional Programming",
    "Repetitive Using Clauses\n\nIn last version of the conference management system of the last session we got rid of explicit Viewers arguments.\n\nBut we still need explicit using parameter clauses.\n\n```python\ndef score(paper: Paper)(using Viewers): Int = ...\ndef rankings(using Viewers): List[Paper] = ...\ndef delegateTo(p: Person, query: Viewers => T)(using Viewers): T = ...\n```\n\nCan we get rid of these as well?",
    "Lambdas With Using Clauses\n\nLet's massage the definition of rankings a bit:\n\n```scala\ndef rankings = (viewers: Viewers) ?=>\n    papers.sortBy(score(_, viewers)).reverse\n```\n\nThe ? signifies that we want the parameter viewers be implicit so that its arguments can be inferred.\n\nWhat is its type?\n\n- For a normal anonymous function it would be:\n  Viewers => List[Paper]\n\n- For an anonymous function with a using clause it is:\n  Viewers ?=> List[Paper]",
    "Implicit Function Types\n\nViewers ?>= List[Paper] is called an implicit function type.\n\nThere are two typing rules involving such types.\n\n1. Implicit functions get their arguments inferred just like methods with using clauses. In\n  val f: A ?=> B\n  given a: A\n  f\nthe expression f expands to f(using a).\n\n2. Implicit functions get created on demand.\nIf the expected type of an expression b is A ?=> B, then b expands to the anonymous function (_: A) ?=> b.",
    "Example Application\n\nLet's use implicit function types in our conference management system.\n\nFirst, introduce a type alias\n\ntype Viewed[T] = Viewers ?=> T\n\nThis is just for conciseness; Viewed[T] is easier to read than Viewers ?=> T and it expresses the point we want to make.",
    "Now, perform the apply two changes:\n\n1. Replace every method signature ending in\n(using Viewers): SomeType\nwith\n: Viewed[SomeType]\n\n2. Replace function type parameter\nquery: Viewers => SomeType\nwith\nquery: Viewed[SomeType]",
    "Trade Types for Type Parameters\n\nImplicit Parameters in using clauses trade types for terms.\n\n\u25ba The developer writes down the required type of the parameter.\n   The compiler infers an expression (i.e. a term) for it.\n\nImplicit Function Types go one step further. They trade types for parameters.\n\n\u25ba The developer writes down the return type of the method.\n   The compiler infers one or more method parameters that match the type.",
    "Another way to look at it is to see implicit function types, as second degree context abstractions.\n\n- Implicit parameters in using clauses abstract over the context at the call site. They are first-degree context abstractions.\n- Implicit function types allow to abstract over using clauses (in the original sense: they allow to introduce a name such as \\texttt{Viewed} that can be used instead of writing explicit parameter clauses).\n- So, together with type aliases, they enable abstractions of context abstractions.",
    "Objects Everywhere\n\nPrinciples of Functional Programming",
    "Pure Object Orientation\n\nA pure object-oriented language is one in which every value is an object.\n\nIf the language is based on classes, this means that the type of each value is a class.\n\nIs Scala a pure object-oriented language?\n\nAt first glance, there seem to be some exceptions: primitive types, functions.\n\nBut, let\u2019s look closer:",
    "Standard Classes\n\nConceptually, types such as Int or Boolean do not receive special treatment in Scala. They are like the other classes, defined in the package scala.\n\nFor reasons of efficiency, the Scala compiler represents the values of type scala.Int by 32-bit integers, and the values of type scala.Boolean by Java\u2019s Booleans, etc.",
    "The Boolean type maps to the JVM's primitive type boolean.\n\nBut one could define it as a class from first principles:\n\n```\npackage idealized.scala \nabstract class Boolean extends AnyVal: \n  def ifThenElse[T](t: => T, e: => T): T \n\n  def && (x: => Boolean): Boolean = ifThenElse(x, false) \n  def || (x: => Boolean): Boolean = ifThenElse(true, x) \n  def unary_! : Boolean = ifThenElse(false, true) \n\n  def == (x: Boolean): Boolean = ifThenElse(x, x.unary_!) \n  def != (x: Boolean): Boolean = ifThenElse(x.unary_! , x) \nend Boolean\n```",
    "Boolean Constants\n\nHere are constants true and false that go with Boolean in idealized.scala:\n\n```\npackage idealized.scala\n\nobject true extends Boolean:\n  def ifThenElse[T](t: => T, e: => T) = t\n\nobject false extends Boolean:\n  def ifThenElse[T](t: => T, e: => T) = e\n```",
    "Provide an implementation of an implication operator ==> for class idealized.scala.Boolean.\n\n\\[\n\\text{extension (x: Boolean):}\n\\]\n\\[\n\\text{def ==> (y: Boolean) = x.ifThenElse(y, true)} \n\\]\n\nThat is, if $x$ is true, $y$ has to be true also, whereas if $x$ is false, $y$ can be arbitrary.\n\ntrue if $a ==> b$ \\( \\ \\text{(implementation should be true if a implies b)} \\ \\)\n\nso,\n\n\\[\nx.==>(y: Boolean) = if \\ x \\ is \\ true \\ then \\ y \\ else \\ y \\ is \\ false \\ then \\ true.\n\\]",
    "The class Int\n\nHere is a partial specification of the class scala.Int.\n\nclass Int:\n  def + (that: Double): Double\n  def + (that: Float): Float\n  def + (that: Long): Long\n  def + (that: Int): Int           // same for -, *, /, %\n  \n  def << (cnt: Int): Int           // same for >>, >>>\n  \n  def & (that: Long): Long\n  def & (that: Int): Int           // same for |, ^",
    "The class Int (2)\n\ndef == (that: Double): Boolean\ndef == (that: Float): Boolean\ndef == (that: Long): Boolean // same for !=, <, >, <=, >=\n...\nend Int\n\nCan it be represented as a class from first principles (i.e. not using primitive ints)?",
    "Provide an implementation of the abstract class Nat that represents non-negative integers.\n\nabstract class Nat:\n  def isZero: Boolean\n  def predecessor: Nat\n  def successor: Nat\n  def + (that: Nat): Nat\n  def - (that: Nat): Nat\nend Nat",
    "Exercise (2)\n\nDo not use standard numerical classes in this implementation.\nRather, implement a sub-object and a sub-class:\n\nobject Zero extends Nat:\n   \u2026\n\nclass Succ(n: Nat) extends Nat:\n   \u2026\n\nOne for the number zero, the other for strictly positive numbers.\n(this one is a bit more involved than previous quizzes).",
    "object Zero extends Nat: \ndef isZero: Boolean = false\ndef predecessor: Nat = ???\ndef successor: Nat = Succ(this)\ndef +(that: Nat): Nat = that\ndef -(that: Nat): Nat = if that.isZero then this else ??? \nend Zero\n\nclass Succ(n: Nat) extends Nat: \ndef isZero: Boolean = false\ndef predecessor: Nat = n\ndef successor: Nat = Succ(this)\ndef +(that: Nat): Nat = Succ(n + that)\ndef -(that: Nat): Nat = if that.isZero then this else n - that.predecessor\nend Succ",
    "Structural Induction on Trees\n\nPrinciples of Functional Programming",
    "Structural Induction on Trees\n\nStructural induction is not limited to lists; it applies to any tree structure. The general induction principle is the following:\n\nTo prove a property $P(t)$ for all trees $t$ of a certain type,\n\n- show that $P(l)$ holds for all leaves $l$ of a tree,\n- for each type of internal node $t$ with subtrees $s_1, \\ldots, s_n$, show that $P(s_1) \\land \\ldots \\land P(s_n)$ implies $P(t)$.",
    "Example: IntSets\n\nRecall our definition of IntSet with the operations contains and incl:\n\nabstract class IntSet:\n   def incl(x: Int): IntSet\n   def contains(x: Int): Boolean\n\nobject Empty extends IntSet:\n   def contains(x: Int): Boolean = false\n   def incl(x: Int): IntSet = NonEmpty(x, Empty, Empty)",
    "case class NonEmpty(elem: Int, left: IntSet, right: IntSet) extends IntSet:\n\ndef contains(x: Int): Boolean =\n  if x < elem then left.contains(x)\n  else if x > elem then right.contains(x)\n  else true\n\ndef incl(x: Int): IntSet =\n  if x < elem then NonEmpty(elem, left.incl(x), right)\n  else if x > elem then NonEmpty(elem, left, right.incl(x))\n  else this",
    "The Laws of IntSet\n\nWhat does it mean to prove the correctness of this implementation?\n\nOne way to define and show the correctness of an implementation consists of proving the laws that it respects.\n\nIn the case of IntSet, we have the following three laws:\n\nFor any set $s$, and elements $x$ and $y$:\n\n$Empty.contains(x) \\quad = \\quad false$\n\n$s.incl(x).contains(x) \\quad = \\quad true$\n\n$s.incl(x).contains(y) \\quad = \\quad s.contains(y) \\quad \\text{if } x \\neq y$\n\n(In fact, we can show that these laws completely characterize the desired data type.)",
    "Proving the Laws of IntSet (1)\n\nHow can we prove these laws?\n\nProposition 1: $Empty.contains(x) = false.$\n\nProof: According to the definition of contains in Empty.",
    "Proposition 2: $s.\\text{incl}(x).\\text{contains}(x) = \\text{true}$\n\nProof by structural induction on $s$.\n\nBase case: $\\text{Empty}$\n\n$\\text{Empty}.\\text{incl}(x).\\text{contains}(x)$\n$$= \\text{NonEmpty}(x, \\text{Empty}, \\text{Empty}).\\text{contains}(x) \\ \\ \\ \\ \\text{// by definition of Empty.incl }$$\n$$= \\text{true} \\ \\ // \\ \\text{by definition of NonEmpty.contains}$$",
    "Proving the Laws of IntSet (3)\n\nInduction step: $\\text{NonEmpty}(x, l, r)$\n\n$\\text{NonEmpty}(x, l, r).\\text{incl}(x).\\text{contains}(x)$\n\n$= \\text{NonEmpty}(x, l, r).\\text{contains}(x)$\n\n$= \\text{true}$",
    "Proving the Laws of IntSet (4)\n\nInduction step: NonEmpty(y, l, r) where y < x\n\nNonEmpty(y, l, r).incl(x).contains(x)\n\n= NonEmpty(y, l, r.incl(x)).contains(x) // by definition of NonEmpty.incl\n\n= r.incl(x).contains(x) // by definition of NonEmpty.contains\n\n= true // by the induction hypothesis\n\nInduction step: NonEmpty(y, l, r) where y > x is analogous",
    "Proposition 3. If $x \\neq y$ then\n\n$$ xs.incl(y).contains(x) = xs.contains(x) .$$\n\nProof by structural induction on $s$. Assume that $y < x$ (the dual case $x < y$ is analogous).\n\n**Base case:** Empty\n\n$$\n\\begin{aligned}\n    Empty.incl(y).contains(x) & \\quad // \\text{to show:} = Empty.contains(x) \\\\\n    &= NonEmpty(y, Empty, Empty).contains(x) \\quad // \\text{by definition of} \\ Empty.incl \\\\\n    &= Empty.contains(x) \\quad // \\text{by definition of} \\ NonEmpty.contains\n\\end{aligned}\n$$",
    "Proving the Laws of IntSet (6)\n\nFor the inductive step, we need to consider a tree $NonEmpty(z, l, r)$. We distinguish five cases:\n\n1. $z = x$\n2. $z = y$\n3. $z < y < x$\n4. $y < z < x$\n5. $y < x < z$",
    "First Two Cases: $z = x$, $z = y$\n\n\\textbf{Induction step:} NonEmpty$(x, 1, r)$\n\nNonEmpty$(x, 1, r)$.incl$(y)$.contains$(x)$ \\quad // to show: $=$ NonEmpty$(x, 1, r)$.contains$(x)$\n\n$=$ NonEmpty$(x, 1$.incl$(y), r)$.contains$(x)$ \\quad // by definition of NonEmpty.incl\n\n$=$ true \\quad // by definition of NonEmpty.contains\n\n$=$ NonEmpty$(x, 1, r)$.contains$(x)$ \\quad // by definition of NonEmpty.contains\n\n\\textbf{Induction step:} NonEmpty$(y, 1, r)$\n\nNonEmpty$(y, 1, r)$.incl$(y)$.contains$(x)$ \\quad // to show: $=$ NonEmpty$(y, 1, r)$.contains$(x)$\n\n$=$ NonEmpty$(y, 1$.incl$(y), r)$.contains$(x)$ \\quad // by definition of NonEmpty.incl",
    "Case $z < y$\n\n**Induction step**: $NonEmpty(z, l, r) \\ \\mathbf{where} \\ z < y < x$\n\n$NonEmpty(z, l, r).incl(y).contains(x)$  \\ \\ \\ \\ \\ \\ //  to show     :  $NonEmpty(z, l, r).contains(x)$\\\\\n$=$ $NonEmpty(z, l, r.incl(y)).contains(x)$  \\ \\ \\ \\ \\ \\ //  by definition of $NonEmpty.incl$ \\\\\n$=$  $r.incl(y).contains(x)$  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\ //  by definition of $NonEmpty.contains$ \\\\\n$=$  $r.contains(x)$  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ //  by the induction hypothesis \\\\\n$=$ $NonEmpty(z, l, r).contains(x)$ \\ \\ \\ \\ \\ \\ \\ \\ //  by definition of $NonEmpty.contains$",
    "Case $y < z < x$\n\n**Induction step:** $ \\text{NonEmpty}(z, l, r) \\text{ where } y < z < x$\n\\[\n\\begin{aligned}\n\\text{NonEmpty}(z, l). \\text{incl}(y). \\text{contains}(x) & \\quad // \\text{to show: } \\text{NonEmpty}(z, l, r). \\text{contains}(x) \\\\\n= \\text{NonEmpty}(z, l. \\text{incl}(y), r). \\text{contains}(x) & \\quad // \\text{by definition of NonEmpty.incl} \\\\\n= r. \\text{contains}(x) & \\quad // \\text{by definition of NonEmpty.contains} \\\\\n= \\text{NonEmpty}(z, l, r). \\text{contains}(x) & \\quad // \\text{by definition of NonEmpty.contains}\n\\end{aligned}\n\\]",
    "Case $x < z$\n\nInduction step: $\\text{NonEmpty}(z, l, r) \\ \\text{where} \\ y < x < z$\n\n$\\text{NonEmpty}(z, l, r).\\text{incl}(y).\\text{contains}(x)$ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ // to show: $\\ \\text{NonEmpty}(z, l, r).\\text{contains}(x)$ \\\\ \\\\\n\\ \\ \\ = $\\text{NonEmpty}(z, l.\\text{incl}(y), r).\\text{contains}(x)$ \\ \\ \\ \\ \\ // by definition of $\\ \\text{NonEmpty}.\\text{incl}$ \\\\ \\\\\n\\ \\ \\ = $l.\\text{incl}(y).\\text{contains}(x)$ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ // by definition of $\\ \\text{NonEmpty}.\\text{contains}$ \\\\ \\\\\n\\ \\ \\ = $l.\\text{contains}(x)$ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ // by the induction hypothesis \\\\ \\\\\n\\ \\ \\ = $\\text{NonEmpty}(z, l, r).\\text{contains}(x)$ \\ \\ \\ // by definition of $\\ \\text{NonEmpty}.\\text{contains}$ \\\\ \\\\\n\nThese are all the cases, so the proposition is established.",
    "Suppose we add a function union to IntSet:\n\nabstract class IntSet:\n  ...\n  def union(other: IntSet): IntSet\n\nobject Empty extends IntSet:\n  ...\n  def union(other: IntSet) = other\n\nclass NonEmpty(x: Int, l: IntSet, r: IntSet) extends IntSet:\n  ...\n  def union(other: IntSet): IntSet = l.union(r.union(other)).incl(x)",
    "The correctness of union can be translated into the following law:\n\n**Proposition 4:**\n\n$ xs.union(ys).contains(x) = xs.contains(x) \\, \\| \\, ys.contains(x)$\n\nShow proposition 4 by using structural induction on $xs$.",
    "Evaluation Strategies and Termination\n\nPrinciples of Functional Programming",
    "Call-by-name, Call-by-value and termination\n\nYou know from the last module that the call-by-name and call-by-value evaluation strategies reduce an expression to the same value, as long as both evaluations terminate.\n\nBut what if termination is not guaranteed?\n\nWe have:\n\n- If CBV evaluation of an expression $e$ terminates, then CBN evaluation of $e$ terminates, too.\n- The other direction is not true\n\nSome expressions terminate under CBN but not CBV.",
    "Non-termination example\n\nQuestion: Find an expression that terminates under CBN but not under CBV.",
    "Non-termination example\n\nLet's define\n\n```python\ndef first(x: Int, y: Int) = x\n```\nand consider the expression first(1, loop).\n\nUnder CBN:\n```\nfirst(1, loop)\n\u2193\n1\n```\nUnder CBV:\n```\nfirst(1, loop)\nDoes not terminate!!\n```",
    "Scala normally uses call-by-value.\n\nBut if the type of a function parameter starts with => it uses call-by-name.\n\nExample:\n\ndef constOne(x: Int, y: => Int) = 1\n\nLet's trace the evaluations of\n\n    constOne(1+2, loop)\n\nand\n\n    constOne(loop, 1+2)",
    "Trace of const0ne(1 + 2, loop)\n\nconst0ne(1 + 2, loop)\nconst0ne(3, loop)\n1\nThis terminates",
    "Trace of const0ne(loop, 1 + 2)\n\nconst0ne(loop, 1 + 2)\nconst0ne(loop, 1 + 2)\nconst0ne(loop, 1 + 2)\n...\n\nevaluation never terminates.",
    "Functions and State\n\nPrinciples of Functional Programming\n\nMartin Odersky",
    "Functions and State\n\nUntil now, our programs have been side-effect free.\n\nTherefore, the concept of time wasn't important.\n\nFor all programs that terminate, any sequence of actions would have given the same results.\n\nThis was also reflected in the substitution model of computation.",
    "Programs can be evaluated by rewriting.\n\nThe most important rewrite rule covers function applications:\n\ndef $f(x_1, ..., x_n) = B$:  ... $f(v_1, ..., v_n)$ \n\n\u21d2\n\ndef $f(x_1, ..., x_n) = B$:  ... $[v_1/x_1, ..., v_n/x_n]B$\n\ncall of function is replaced by its body\nparams replaced by their values.",
    "Say you have the following two functions iterate and square:\n```python\ndef iterate(n: Int, f: Int => Int, x: Int) =\n  if n == 0 then x else iterate(n-1, f, f(x))\n\ndef square(x: Int) = x * x\n```\nThen the call iterate(1, square, 3) gets rewritten as follows:\n\\[\n\\begin{aligned}\n&\\Rightarrow \\text{if } 1 == 0 \\text{ then } 3 \\text{ else iterate(1-1, square, square(3))} \\\\\n&\\Rightarrow \\text{iterate(0, square, square(3))} \\\\\n&\\Rightarrow \\text{iterate(0, square, 3 * 3)} \\\\\n&\\Rightarrow \\text{iterate(0, square, 9)} \\\\\n&\\Rightarrow \\text{if 0 == 0 then 9 else iterate(0-1, square, square(9))} \\Rightarrow 9\n\\end{aligned}\n\\]",
    "Observation:\n\nRewriting can be done anywhere in a term, and all rewritings which terminate lead to the same solution.\n\nThis is an important result of the $\\lambda$-calculus, the theory behind functional programming.\n\nExample:\n\n\\texttt{if 1 == 0 then 3 else iterate(1 - 1, square, square(3))}\n\n\\texttt{iterate(0, square, square(3))}\n\n$9$\n\n\\texttt{if 1 == 0 then 3 else iterate(1 - 1, square, 3 * 3)}",
    "Stateful Objects\n\nOne normally describes the world as a set of objects, some of which have state that changes over the course of time.\n\nAn object has a state if its behavior is influenced by its history.\n\nExample: a bank account has a state, because the answer to the question\n\u201ccan I withdraw 100 CHF ?\u201d\nmay vary over the course of the lifetime of the account.",
    "Implementation of State\n\nEvery form of mutable state is constructed from variables.\n\nA variable definition is written like a value definition, but with the keyword var in place of val:\n\n    var x: String = \"abc\"\n    var count = 111\n\nJust like a value definition, a variable definition associates a value with a name.\n\nHowever, in the case of variable definitions, this association can be changed later through an assignment, like in Java:\n\n    x = \"hi\"\n    count = count + 1",
    "State in Objects\n\nIn practice, objects with state are usually represented by objects that have some variable members. For instance, here is a class modeling a bank account.\n\nclass BankAccount:\n  private var balance = 0\n\ndef deposit(amount: Int): Unit =\n  if amount > 0 then balance = balance + amount\n\ndef withdraw(amount: Int): Int =\n  if 0 < amount && amount <= balance then\n    balance = balance - amount\n    balance\n  else throw Error(\"insufficient funds\")",
    "State in Objects (2)\n\nThe class BankAccount defines a variable balance that contains the current balance of the account.\n\nThe methods deposit and withdraw change the value of the balance through assignments.\n\nNote that balance is private in the BankAccount class, it therefore cannot be accessed from outside the class.\n\nTo create bank accounts, we use the usual notation for object creation:\n\n$ \\text{val account = BankAccount()} $ ",
    "Working with Mutable Objects\n\nHere is a worksheet that manipulates bank accounts.\n\nval account = BankAccount()        // account: BankAccount = ...\naccount.deposit(50)                // \naccount.withdraw(20)               // : Int = 30\naccount.withdraw(20)               // : Int = 10\naccount.withdraw(15)               // java.lang.Error: insufficient funds\n\nApplying the same operation to an account twice in a row produces different results. Clearly, accounts are stateful objects.",
    "Statefulness and Variables\n\nRemember the implementation of TailLazyList. Instead of using a lazy val, we could also implement non-empty lazy lists using a mutable variable:\n\n```scala\ndef cons[T](hd: T, tl: => TailLazyList[T]) = new TailLazyList[T]:\n  def head = hd\n  private var tlOpt: Option[TailLazyList[T]] = None\n  def tail: T = tlOpt match\n    case Some(x) => x\n    case None => tlOpt = Some(tl); tail\n```\n\nQuestion: Is the result of cons a stateful object?\n\n```\n0  X\n0  No\nX  It depends: No, if the rest of the program is purely functional\n```",
    "Statefulness and Variables (2)\n\nConsider the following class:\n\nclass BankAccountProxy(ba: BankAccount):\n  def deposit(amount: Int): Unit = ba.deposit(amount)\n  def withdraw(amount: Int): Unit = ba.withdraw(amount)\n\nQuestion: Are instances of BankAccountProxy stateful objects?\n\n\u2a00 Yes\n\u3007 No",
    "Currying\n\nPrinciples of Functional Programming",
    "Motivation\n\nLook again at the summation functions:\n\n```\ndef sumInts(a: Int, b: Int)    = sum(x => x, a, b)\ndef sumCubes(a: Int, b: Int)   = sum(x => x * x * x, a, b)\ndef sumFactorials(a: Int, b: Int) = sum(fact, a, b)\n```\n\nQ:\nNote that a and b get passed unchanged from sumInts and sumCubes into sum.\n\nCan we be even shorter by getting rid of these parameters?",
    "Functions Returning Functions\n\nLet's rewrite sum as follows.\n\n```scala\ndef sum(f: Int => Int): (Int, Int) => Int = \n  def sumF(a: Int, b: Int): Int = \n    if a > b then 0 \n    else f(a) + sumF(a + 1, b)\n  sumF\n```\n\nsum is now a function that returns another function.\n\nThe returned function sumF applies the given function parameter f and sums the results.",
    "We can then define:\n\n$$\\text{def } \\text{sumInts} = \\text{sum}(x \\Rightarrow x) : (\\text{Int}, \\text{Int}) \\Rightarrow \\text{Int}$$\n$$\\text{def } \\text{sumCubes} = \\text{sum}(x \\Rightarrow x \\times x \\times x)$$\n$$\\text{def } \\text{sumFactorials} = \\text{sum}(\\text{fact})$$\n\nThese functions can in turn be applied like any other function:\n\n$$\\text{sumCubes}(1, 10) + \\text{sumFactorials}(10, 20)$$",
    "Consecutive Stepwise Applications\n\nIn the previous example, can we avoid the sumInts, sumCubes, ... middlemen?\nOf course:\n\\[ \\text{sum} \\ (\\text{cube}) \\ (1, \\ 10) \\]\n- \\text{sum(cube)} applies sum to cube and returns the \\text{sum of cubes} function.\n- \\text{sum(cube)} is therefore equivalent to \\text{sumCubes}.\n- This function is next applied to the arguments \\((1, \\ 10)\\).\n\nGenerally, function application associates to the left:\n\n\\[ \\text{sum(cube)} \\ (1, \\ 10) \\quad == \\quad (\\text{sum} \\ (\\text{cube})) \\ (1, \\ 10) \\]",
    "Multiple Parameter Lists\n\nThe definition of functions that return functions is so useful in functional programming that there is a special syntax for it in Scala.\n\nFor example, the following definition of sum is equivalent to the one with the nested sumf function, but shorter:\n\n```scala\ndef sum(f: Int => Int)(a: Int, b: Int): Int = \n  if a > b then 0 else f(a) + sum(f)(a + 1, b)\n```",
    "Expansion of Multiple Parameter Lists\n\nIn general, a definition of a function with multiple parameter lists\n\n$$\\text{def } f(ps_1)\\ldots(ps_n)=E$$\n\nwhere $n > 1$, is equivalent to\n\n$$\\text{def } f(ps_1)\\ldots(ps_{n-1})=\\{\\text{def } g(ps_n) = E; g\\}$$\n\nwhere $g$ is a fresh identifier. Or for short:\n\n$$\\text{def } f(ps_1)\\ldots(ps_{n-1})=(ps_n \\Rightarrow E)$$",
    "By repeating the process $n$ times\n\n$$\\text{def } f(ps_1)\\ldots(ps_{n-1})(ps_n) = E$$\n\nis shown to be equivalent to\n\n$$\\text{def } f = (ps_1 \\Rightarrow (ps_2 \\Rightarrow \\ldots (ps_n \\Rightarrow E)\\ldots))$$\n\nThis style of definition and function application is called *currying*, named for its instigator, Haskell Brooks Curry (1900-1982), a twentieth century logician.\n\nIn fact, the idea goes back even further to Sch\u00f6nfinkel and Frege, but the term *currying* has stuck.",
    "More Function Types\n\nQuestion: Given,\n\ndef sum(f: Int => Int)(a: Int, b: Int): Int = ...\n\nWhat is the type of sum ?\n\nAnswer:\n\n$(Int => Int) => (Int, Int) => Int$\n\nNote that function types associate to the right. That is to say that\n\n$Int => Int => Int$\n\nis equivalent to\n\n$Int => (Int => Int)$",
    "1. Write a product function that calculates the product of the values of a function for the points on a given interval.\n\n2. Write $factorial$ in terms of $product$.\n\n3. Can you write a more general function, which generalizes both $sum$ and $product$?",
    "1)\n\\[ \\text{product (g: Int => Int)(a: Int, b: Int): Int =} \\]\n\\[ \\text{\\ \\ \\ if a > b then 1 else g(a) * product(g)(a + 1, b)} \\]\n\\[ \\text{product (x => x * x)(1, 5)} \\]\n\\[ \\text{\\ \\ \\ Int = 14 400} \\]\n\n2)\n\\[ \\text{def fact(n: Int) = product(x => x)(1,n)} \\]\n\\[ \\text{fact(5)} \\]\n\\[ \\text{\\ \\ \\ Int = 120} \\]\n\n3)\n\\[ \\text{def mapReduce(g: Int => Int, combine: (Int, Int) => Int, zero: Int)(a: Int, b: Int): Int =} \\]\n\\[ \\text{\\ \\ \\ def recur(a: Int): Int = } \\]\n\\[ \\text{\\ \\ \\ \\ \\ \\ if a > b then zero} \\]\n\\[ \\text{\\ \\ \\ \\ \\ \\ else combine(g(a), recur(a+1))} \\]\n\\[ \\text{\\ \\ \\ recur(a)} \\]\n\n\\[ \\text{def sum(f: Int => Int) = mapReduce(f, (x,y) => x + y, 0)} \\]\n\\[ \\text{def product(f: Int => Int) = mapReduce(f, (x,y) => x * y, 1)} \\]",
    "There is no content to extract from the image provided.",
    "EPFL\n\nEnums\n\nPrinciples of Functional Programming",
    "Pure Data\n\nIn the previous sessions, you have learned how to model data with class hierarchies.\n\nClasses are essentially bundles of functions operating on some common values represented as fields.\n\nThey are a very useful abstraction, since they allow encapsulation of data.\n\nBut sometimes we just need to compose and decompose pure data without any associated functions.\n\nCase classes and pattern matching work well for this task.",
    "A Case Class Hierarchy\n\nHere's our case class hierarchy for expressions again:\n\ntrait Expr\nobject Expr:\n  case class Var(s: String) extends Expr\n  case class Number(n: Int) extends Expr\n  case class Sum(e1: Expr, e2: Expr) extends Expr\n  case class Prod(e1: Expr, e2: Expr) extends Expr\n  \nNote: No methods here.\nOnly case classes.\n\nThis time we have put all case classes in the Expr companion object, in order not to pollute the global namespace.\n\nSo it's Expr.Number(1) instead of Number(1), for example.\n\nOne can still \u201cpull out\u201d all the cases using an import.\n\nimport Expr._",
    "A Case Class Hierarchy\n\nHere's our case class hierarchy for expressions again:\n\ntrait Expr\nobject Expr:\n  case class Var(s: String) extends Expr\n  case class Number(n: Int) extends Expr\n  case class Sum(e1: Expr, e2: Expr) extends Expr\n  case class Prod(e1: Expr, e2: Expr) extends Expr\n\nPure data definitions like these are called algebraic data types, or ADTs for short.\n\nThey are very common in functional programming.\n\nTo make them even more convenient, Scala offers some special syntax.",
    "Enums for ADTs\n\nAn *enum* enumerates all the cases of an ADT *and nothing else*.\n\nExample\n\n```scala\nenum Expr:\n  case Var(s: String)\n  case Number(n: Int)\n  case Sum(e1: Expr, e2: Expr)\n  case Prod(e1: Expr, e2: Expr)\n```\n\nThis *enum* is equivalent to the case class hierarchy on the previous slide, but is shorter, since it avoids the repetitive `class ... extends Expr` notation.",
    "Pattern Matching on ADTs\n\nMatch expressions can be used on enums as usual. For instance, to print expressions with proper parameterization:\n\n```scala\ndef show(e: Expr): String = e match\n  case Expr.Var(x) => x\n  case Expr.Number(n) => n.toString\n  case Expr.Sum(a, b) => s\"${show(a)} + ${show(a)}\"\n  case Expr.Prod(a, b) => s\"${show(a)} * ${show(a)}\"\n```\n\n```scala\nimport Expr._ {alternative}\ndef showP(e: Expr): String = e match\n  case e: Sum => s\"${show(expr)}\"\n  case _ => show(expr)\n```",
    "Simple Enums\n\nCases of an enum can also be simple values, without any parameters.\n\nExample\n\nDefine a Color type with values Red, Green, and Blue:\n\n```\nenum Color:\n    case Red\n    case Green\n    case Blue\n```\n\nWe can also combine several simple cases in one list:\n\n```\nenum Color:\n    case Red, Green, Blue\n```",
    "Pattern Matching on Simple Enums\n\nFor pattern matching, simple cases count as constants:\n\nenum DayOfWeek:\n    case Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday\n\nimport DayOfWeek._\n\ndef isWeekend(day: DayOfWeek) = day match\n    case Saturday | Sunday => true\n    case _ => false",
    "Enumerations can take parameters and can define methods.\n\nExample:\n\n```scala\nenum Direction(val dx: Int, val dy: Int):\n    case Right extends Direction(1, 0)      // ordinal 0.\n    case Up  extends Direction(0, 1)        // ordinal 1.\n    case Left extends Direction(-1, 0)      // ordinal 2.\n    case Down extends Direction(0, -1)      // ordinal 3.\n\n    def leftTurn = Direction.values((ordinal + 1) % 4)\nend Direction\n\nval r = Direction.Right\nval u = x.leftTurn       // u = Up\nval v = (u.dx, u.dy)     // v = (1, 0)\n```",
    "Notes:\n\u25b6 Enumeration cases that pass parameters have to use an explicit extends clause\n\u25b6 The expression $e.ordinal$ gives the ordinal value of the enum case $e$. Cases start with zero and are numbered consecutively.\n\u25b6 $values$ is an immutable array in the companion object of of an enum that contains all enum values.\n\u25b6 Only simple cases have ordinal numbers and show up in $values$, parameterized cases do not.",
    "The Direction enum is expanded by the Scala compiler to roughly the following structure:\n\nabstract class Direction(val dx: Int, val dy: Int):\n  def rightTurn = Direction.values((ordinal - 1) % 4)\nobject Direction:\n  val Right = new Direction(1, 0) {}\n  val Up = new Direction(0, 1) {}\n  val Left = new Direction(-1, 0) {}\n  val Down = new Direction(0, -1) {}\nend Direction\n\nThere are also compiler-defined helper methods ordinal in the class and values and valueOf in the companion object.",
    "Domain Modeling\n\nADTs and enums are particularly useful for domain modelling tasks where one needs to define a large number of data types without attaching operations.\n\nExample: Modelling payment methods.\n\nenum PaymentMethod:\n  case CreditCard(kind: Card, holder: String, number: Long, expires: Date)\n  case PayPal(email: String)\n  case Cash\n\nenum Card:\n  case Visa, Mastercard, Amex",
    "Summary\n\nIn this unit, we covered two uses of enum definitions:\n\n- as a shorthand for hierarchies of case classes, ADT\n- as a way to define data types accepting alternative values,\n\nThe two cases can be combined: an enum can comprise parameterized and simple cases at the same time.\n\nEnums are typically used for pure data, where all operations on such data are defined elsewhere.",
    "Functional Random Generators\n\nPrinciples of Functional Programming\nMartin Odersky",
    "Other Uses of For-Expressions\n\nQuestion: Are for-expressions tied to collection-like things such as lists, sets, or databases?\n\nAnswer: No! All that is required is some interpretation of map, flatMap and withFilter.\n\nThere are many domains outside collections that afford such an interpretation.\n\nExample: random value generators.",
    "Random Values\n\nYou know about random numbers:\n\nval rand = java.util.Random()\nrand.nextInt()\n\nQuestion: What is a systematic way to get random values for other domains, such as\n\n- booleans, strings, pairs and tuples, lists, sets, trees\n\n?",
    "Generators\n\nLet's define a trait Generator[T] that generates random values of type T:\n\ntrait Generator[+T]:\n  def generate(): T\n\nSome instances:\n\nval integers = new Generator[Int]:\n  val rand = java.util.Random()\n  def generate() = rand.nextInt()",
    "Generators\n\nLet's define a trait Generator[T] that generates random values of type T:\n\ntrait Generator[+T]:\n  def generate(): T\n\nSome instances:\n\nval booleans = new Generator[Boolean]:\n  def generate() = integers.generate() > 0",
    "Generators\n\nLet's define a trait Generator[T] that generates random values of type T:\n\ntrait Generator[+T]:\n  def generate(): T\n\nSome instances:\n\nval pairs = new Generator[(Int, Int)]:\n  def generate() = (integers.generate(), integers.generate())",
    "Can we avoid the new `Generator ...` boilerplate?\n\nIdeally, we would like to write:\n\n    val booleans = for x <- integers yield x > 0\n\n    def pairs[T, U](t: Generator[T], u: Generator[U]) =\n        for x <- t; y <- u yield (x, y)\n\nWhat does this expand to?",
    "Can we avoid the new Generator ... boilerplate?\n\nIdeally, we would like to write:\n\n```scala\nval booleans = integers.map(x => x > 0)\n\ndef pairs[T, U](t: Generator[T], u: Generator[U]) =\n    t.flatMap(x => u.map(y => (x, y)))\n```\n\nNeed map and flatMap for that!",
    "Here's a more convenient version of Generator:\n\ntrait Generator[+T]:\n  def generate(): T\n\nextension [T, S](g: Generator[T])\n  def map(f: T => S) = new Generator[S]:\n    def generate() = f(g.generate())",
    "Here's a more convenient version of Generator:\n\ntrait Generator[+T]:\n  def generate(): T\n\nextension [T, S](g: Generator[T])\n  def map(f: T => S) = new Generator[S]:\n    def generate() = f(g.generate())\n\n  def flatMap(f: T => Generator[S]) = new Generator[S]:\n    def generate() = f(g.generate()).generate()",
    "We can also implement map and flatMap as methods of class Generator:\n\ntrait Generator[+T]:\n  def generate(): T\n\n  def map[S](f: T => S) = new Generator[S]:\n    def generate() = f(Generator.this.generate())\n  def flatMap[S](f: T => Generator[S]) = new Generator[S]:\n    def generate() = f(Generator.this.generate()).generate()\n\nNote the use of Generator.this to the to refer to the this of the \u201couter\u201d object of class Generator.",
    "The booleans Generator\n\nWhat does this definition resolve to?\n\nval booleans = for x <- integers yield x > 0\n\nval booleans = integers.map(x => x > 0)\n\nval booleans = new Generator[Boolean];\ndef generate() = ((x: Int) => x > 0)(integers.generate())\n\nval booleans = new Generator[Boolean];\ndef generate() = integers.generate() > 0",
    "The pairs Generator\n\ndef pairs[T, U](t: Generator[T], u: Generator[U]) = t.flatMap(\n  x => u.map(y => (x, y)))\n)\n\ndef pairs[T, U](t: Generator[T], u: Generator[U]) = t.flatMap(\n  x => new Generator[(T, U)] { def generate() = (x, u.generate()) })\n  \n)\n\ndef pairs[T, U](t: Generator[T], u: Generator[U]) = new Generator[(T, U)]:\n  def generate() = (new Generator[(T, U)]:\n    def generate() = (t.generate(), u.generate())\n  ).generate()\n)\n\ndef pairs[T, U](t: Generator[T], u: Generator[U]) = new Generator[(T, U)]:\n  def generate() = (t.generate(), u.generate())\n  \n",
    "def single[T](x: T): Generator[T] = new Generator[T]:\n  def generate() = x\n\ndef range(lo: Int, hi: Int): Generator[Int] =\n  for x <- integers yield lo + x.abs % (hi - lo)\n\ndef oneOf[T](xs: T*): Generator[T] =\n  for idx <- range(0, xs.length) yield xs(idx)",
    "A list is either an empty list or a non-empty list.\n\n```python\ndef lists: Generator[List[Int]] =\n  for\n    isEmpty <- booleans\n    list <- if isEmpty then emptyLists else nonEmptyLists\n  yield list\n\ndef emptyLists = single(Nil)\n\ndef nonEmptyLists =\n  for\n    head <- integers\n    tail <- lists\n  yield head :: tail\n```",
    "A Tree Generator\n\nCan you implement a generator that creates random Tree objects?\n\nenum Tree:\n    case Inner(left: Tree, right: Tree)\n    case Leaf(x: Int)\n\n\ndef trees: Generator[Tree]=\n    for\n        isLeaf <- boolean\n        tree <- if isLeaf then leaf else inner\n    yield\n        tree\n\ndef leaf =\n    for x <- integer yield Tree.Leaf(x)\n\ndef inner =\n    for x <- trees, y <- trees yield Tree.Inner(x,y)",
    "Application: Random Testing\n\nYou know about unit tests:\n\u25ba Come up with some some test inputs to program functions and a postcondition.\n\u25ba The postcondition is a property of the expected result.\n\u25ba Verify that the program satisfies the postcondition.\n\nQuestion: Can we do without the test inputs?\n\nYes, by generating random test inputs.",
    "Using generators, we can write a random test function:\n\n```scala\ndef test[T](g: Generator[T], numTimes: Int = 100)\n           (test: T => Boolean): Unit =\n  for i <- 0 until numTimes do\n    val value = g.generate()\n    assert(test(value), s\"test failed for $value\")\n  println(s\"passed $numTimes tests\")\n```",
    "Random Test Function\n\nExample usage:\n\ntest(pairs(lists, lists)) {\n  (xs, ys) => (xs ++ ys).length > xs.length\n}\n\nQuestion: Does the above property always hold?\n\n0\nYes\nNo",
    "Shift in viewpoint: Instead of writing tests, write properties that are assumed to hold.\n\nThis idea is implemented in the ScalaCheck tool.\n\nforAll { (l1: List[Int], l2: List[Int]) =>\n  l1.size + l2.size == (l1 ++ l2).size\n}\n\nIt can be used either stand-alone or as part of ScalaTest.",
    "Using Clauses and Given Instances\n\nPrinciples of Functional Programming\n\nMartin Odersky and Julien Richard-Foy",
    "Using Clauses\n\nAn implicit parameter is introduced by a using parameter clause:\n\n\\[\n\\text{def sort[T](xs: List[T])(using ord: Ordering[T]): List[T] = ...}\n\\]\n\nA matching explicit argument can be passed in a using argument clause:\n\n\\[\n\\text{sort(strings)(using Ordering.String)}\n\\]\n\nBut the argument can also be left out (and it usually is).\n\nIf the argument is missing, the compiler will infer one from the parameter type.\n\n\\[\n\\text{sort(strings)}\n\\]",
    "Multiple parameters can be in a using clause:\n\n    def f(x: Int)(using a: A, b: B) = ...\n    f(x)(using a, b)\n\nOr, there can be several using clauses in a row:\n\n    def f(x: Int)(using a: A)(using b: B) = ...\n\nusing clauses can also be freely mixed with regular parameters:\n\n    def f(x: Int)(using a: A)(y: Boolean)(using b: B) = ...\n    f(x)(using a)(y)(using b)",
    "Parameters of a using clause can be anonymous:\n\n```scala\ndef sort[T](xs: List[T])(using ord: Ordering[T]): List[T] =\n  ...\n  ... merge(sort(fst), sort(snd))(using ord)\n\ndef merge[T](xs: List[T])(using ord: Ordering[T]): List[T] = ...\n```\n\nThis is useful if the body of sort does not mention ord at all, but simply passes it on as an implicit argument to further methods.",
    "Context Bounds\n\nSometimes one can go further and replace the using clause with a context bound for a type parameter.\n\nWith a context bound:\n\n```scala\ndef printSorted[T: Ordering](as: List[T]) = println(sort(as))\n```\n\nMore generally, a method definition such as:\n\n```scala\ndef f[T: U1, . . . Un](ps): R = . . .\n```\n\nis expanded to:\n\n```scala\ndef f[T](ps) using U1[T], . . . , Un[T]): R = . . .\n```",
    "Given Instances\n\nFor the previous example to work, the Ordering.Int definition must be a given instance:\n\nobject Ordering:\n\n\\textbf{given Int: Ordering[Int] with}\n    def compare(x: Int, y: Int): Int =\n        if x < y then -1 else if x > y then 1 else 0\n\nThis code defines a given instance of type Ordering[Int], named Int.",
    "Anonymous Given Instances\n\nGiven instances can be anonymous. Just omit the instance name:\n\n    given Ordering[Double] with\n        def compare(x: Int, y: Int): Int = ...\n\nThe compiler will synthesize a name for an anonymous instance:\n\n    given given_Ordering_Double: Ordering[Double] with\n        def compare(x: Int, y: Int): Int = ...",
    "Summoning an Instance\n\nOne can refer to a (named or anonymous) instance by its type:\n  summon[Ordering[Int]]\n  summon[Ordering[Double]]\n\nThese expand to:\n  Ordering.Int\n  Ordering.given_Ordering_Double\n\nsummon is a predefined method. It can be defined like this:\n  def summon[T](using x: T) = x",
    "Implicit Parameter Resolution\n\nSay, a function takes an implicit parameter of type $T$. The compiler will search a given instance that:\n* has a type compatible with $T$,\n* is visible at the point of the function call, or is defined in a companion object associated with $T$.\n\nIf there is a single (most specific) instance, it will be taken as actual arguments for the inferred parameter.\n\nOtherwise it's an error.",
    "Given Instances Search Scope\n\nThe search for a given instance of type T includes:\n\n- all the given instances that are visible (inherited, imported, or defined in an enclosing scope).\n- the given instances found in a companion object associated with T.\n\nThe definition of associated is quite general. Besides the companion object of a class itself, the compiler will also consider\n\n- companion objects associated with any of T's inherited types\n- companion objects associated with any type argument in T\n- if T is an inner class, the outer objects in which it is embedded.",
    "Companion Objects Associated With a Queried Type\n\nIf the compiler does not find a given instance matching the queried type T in the lexical scope, it continues searching in the companion objects associated with T.\n\nConsider the following hierarchy:\n\ntrait Foo[T]\n\ntrait Bar[T] extends Foo[T]\n\ntrait Baz[T] extends Bar[T]\n\ntrait X\n\ntrait Y extends X\n\nIf a given instance of type Bar[Y] is required, the compiler will look into the companion objects Bar, Y, Foo, and X (but not Baz).",
    "Importing Given Instances\n\nSince given instances can be anonymous, how can they be imported?\n\nIn fact, there are three ways to import a given instance.\n\n1. By-name:\n   import scala.math.Ordering.Int\n\n2. By-type:\n   import scala.math.Ordering.{given Ordering[Int]}\n   import scala.math.Ordering.{given Ordering[?]}\n\n3. With a wildcard:\n   import scala.math.given\n\nSince the names of givens don't really matter, the second form of import is preferred since it is most informative.",
    "Exercise\n\n```scala\nval xs = List(3, 1, 2)\nsort(xs)\n```\n\nIn the above example of the sort method call, where does the compiler find the given instance of type $Ordering[Int]$?\n\no In the enclosing scope\n\no Via a given import\n\nx In a companion object associated with the type $Ordering[Int]$\n\n\u25ba The given instance is found in the Ordering companion object",
    "No Given Instance Found\n\nIf there is no available given instance matching the queried type, an error is reported:\n\nscala> def f(using n: Int) = ()\nscala> f\n          ^\nerror: no implicit argument of type Int was found for parameter n of method f",
    "Ambiguous Given Instances\n\nIf more than one given instance is eligible, an ambiguity is reported:\n\ntrait C:\n  val x: Int\ngiven c1: C with\n  val x = 1\ngiven c2: C with\n  val x = 2\n\nf(using c: C) = ()\nf\n^\n\nerror: ambiguous implicit arguments:\n  both value c1 and value c2\nmatch type C of parameter c of method f\n\nWe could pass argument explicitly:\n$f(using\\ c2)$",
    "Priorities\n\nActually, several given instances matching the same type don't generate an ambiguity if one is more specific than the other.\n\nIn essence, a definition\n\n\\[ \\text{given a: A} \\]\n\nis more specific than a definition\n\n\\[ \\text{given b: B} \\]\n\nif:\n\n- \\( a \\) is in a closer lexical scope than \\( b \\), or\n- \\( a \\) is defined in a class or object which is a subclass of the class defining \\( b \\), or\n- type \\( A \\) is a generic instance of type \\( B \\), or \n- type \\( A \\) is a subtype of type \\( B \\).",
    "Which given instance is summoned here?\n\n```scala\nclass A[T](x: T)\ngiven universal[T](using x: T): A[T](x)\ngiven specific: A[Int](2)\nsummon[A[Int]]\n```\n\nmore specific instances will be chosen over general ones",
    "Which given instance is summoned here?\n\n```scala\ntrait A:\n  given ac: C\ntrait B extends A:\n  given bc: C\nobject O extends B:\n  val x = summon[C]\n```\nbc defined in subclasses so is more specific",
    "Priorities: Example (3)\n\nWhich given instance is summoned here?\n\ngiven ac: C\ndef f() =\n  given b: C\n  def g(using c: C) = ()\n\n          g\n  ^ chose inner instance.",
    "Summary\n\nIn this lecture we have introduced a way to do type-directed programming, with the help of a language mechanism that infers values from types.\n\nThere has to be a unique (most specific) given instance matching the queried type for it to be used by the compiler.\n\nGiven instances are searched in the enclosing lexical scope (imports, parameters, inherited members) as well as in the companion objects associated with the queried type.",
    "Lazy Lists\n\nPrinciples of Functional Programming\n\nLaziness = computing something as late as possible. (i.e. not before value is needed).",
    "Collections and Combinatorial Search\n\nWe've seen a number of immutable collections that provide powerful operations, in particular for combinatorial search.\n\nFor instance, to find the second prime number between 1000 and 10000:\n\n$$(1000 \\text{ to } 10000).filter(\\text{isPrime})(1)$$\n\nThis is much shorter than the recursive alternative:\n\n```python\ndef secondPrime(from: Int, to: Int) = nthPrime(from, to, 2)\ndef nthPrime(from: Int, to: Int, n: Int): Int =\n  if from >= to then throw Error(\"no prime\")\n  else if isPrime(from) then\n    if n == 1 then from else nthPrime(from + 1, to, n - 1)\n  else nthPrime(from + 1, to, n)\n```",
    "But from a standpoint of performance,\n\n$(1000 \\text{ to } 10000).filter(isPrime)(1)$\n\nis pretty bad; it constructs all prime numbers between 1000 and 10000 in a list, but only ever looks at the first two elements of that list.\n\nReducing the upper bound would speed things up, but risks that we miss the second prime number all together.",
    "Delayed Evaluation\n\nHowever, we can make the short-code efficient by using a trick:\n'Avoid computing the elements of a sequence until they are needed for the evaluation result (which might be never)'\n\nThis idea is implemented in a new class, the LazyList.\n\nLazy lists are similar to lists, but their elements are evaluated only on demand.",
    "Defining Lazy Lists\n\nLazy lists are defined from a constant LazyList.empty and a constructor LazyList.cons.\n\nFor instance,\n\nval xs = LazyList.cons(1, LazyList.cons(2, LazyList.empty))\n\nThey can also be defined like the other collections by using the object LazyList as a factory.\n\nLazyList(1, 2, 3)\n\nThe to(LazyList) method on a collection will turn the collection into a lazy list:\n\n(1 to 1000).to(LazyList)  res0: LazyList[Int] = LazyList(<not computed>)",
    "Let's try to write a function that returns (lo until hi).to(LazyList) directly:\n\n```\ndef lazyRange(lo: Int, hi: Int): LazyList[Int] =\n  if lo >= hi then LazyList.empty\n  else LazyList.cons(lo, lazyRange(lo + 1, hi))\n```\n\nCompare to the same function that produces a list:\n\n```\ndef listRange(lo: Int, hi: Int): List[Int] =\n  if lo >= hi then Nil\n  else lo :: listRange(lo + 1, hi)\n```",
    "Comparing the Two Range Functions\n\nThe functions have almost identical structure yet they evaluate quite differently.\n\n- listRange(start, end) will produce a list with $end - start$ elements and return it.\n- lazyRange(start, end) returns a single object of type LazyList.\n- The elements are only computed when they are needed, where \"needed\" means that someone calls head or tail on the lazy list.",
    "Methods on Lazy Lists\n\nLazyList supports almost all methods of List. For instance, to find the second prime number between 1000 and 10000:\n\nLazyList.range(1000, 10000).filter(isPrime)(1)",
    "LazyList Cons Operator\n\nThe one major exception is ::.\n\n$x :: xs$ always produces a list, never a lazy list.\n\nThere is however an alternative operator #:: which produces a lazy list.\n\n$x \\#:: xs \\quad == \\quad \\text{LazyList.cons}(x, xs)$\n\n\\#:: can be used in expressions as well as patterns.",
    "Implementation of Lazy Lists\n\nThe implementation of lazy lists is quite subtle.\n\nAs a simplification, we consider for now that lazy lists are only lazy in their tail. head and isEmpty are computed when the lazy list is created.\n\nThis is not the actual behavior of lazy lists, but makes the implementation simpler to understand.\n\nHere's the trait TailLazyList:\n\n```\ntrait TailLazyList[+A] extends Seq[A]:\n  def isEmpty: Boolean\n  def head: A\n  def tail: TailLazyList[A]\n  ...\n```\n\nAs for lists, all other methods can be defined in terms of these three.",
    "Implementation of Lazy Lists (2)\n\nConcrete implementations of lazy lists are defined in the TailLazyList companion object. Here\u2019s a first draft:\n\n```scala\nobject TailLazyList:\n  def cons[T](hd: T, tl: => TailLazyList[T]) = new TailLazyList[T]:\n    def isEmpty = false\n    def head = hd\n    def tail = tl\n    override def toString = \"LazyList(\" + hd + \", ?)\"\n \n  val empty = new TailLazyList[Nothing]:\n    def isEmpty = true\n    def head = throw NoSuchElementException(\"empty.head\")\n    def tail = throw NoSuchElementException(\"empty.tail\")\n    override def toString = \"LazyList()\"\n```",
    "Difference to List\n\nThe only important difference between the implementations of List and (simplified) LazyList concern tl, the second parameter of TailLazyList.cons.\n\nFor lazy lists, this is a by-name parameter.\n\nThat's why the second argument to TailLazyList.cons is not evaluated at the point of call.\n\nInstead, it will be evaluated each time someone calls tail on a TailLazyList object.",
    "Other LazyList Methods\n\nThe other lazy list methods are implemented analogously to their list counterparts.\n\nFor instance, here\u2019s filter:\n\n\\[\n\\text{extension [T](xs: TailLazyList[T]):}\n\\]\n\\[\n\\text{def filter(p: T => Boolean): TailLazyList[T] =}\n\\]\n\\[\n\\text{  if isEmpty then xs}\n\\]\n\\[\n\\text{  else if p(xs.head) then cons(xs.head, xs.tail.filter(p))}\n\\]\n\\[\n\\text{  else xs.tail.filter(p)}\n\\]",
    "Consider this modification of lazyRange.\n\n```python\ndef lazyRange(lo: Int, hi: Int): TailLazyList[Int] =\n  print(lo+\" \")\n  if lo >= hi then TailLazyList.empty\n  else TailLazyList.cons(lo, lazyRange(lo + 1, hi))\n```\n\nWhen you write lazyRange(1, 10).take(3).tolist\nwhat gets printed?\n\n```\n0\t    Nothing\n0\t    1\n0\t    1 2 3\n0\t    1 2 3 4\n0\t    1 2 3 4 5 6 7 8 9\n```",
    "Exercise\n\nConsider this modification of lazyRange.\n\n\\[\n\\begin{aligned}\n&\\text{def lazyRange(lo: Int, hi: Int): TailLazyList[Int] =} \\\\\n&\\quad \\text{print(lo+ \")} \\\\\n&\\quad \\text{if lo >= hi then TailLazyList.empty} \\\\\n&\\quad \\text{else TailLazyList.cons(lo, lazyRange(lo + 1, hi))}\n\\end{aligned}\n\\]\n\nWhen you write lazyRange(1, 10).take(3).toList what gets printed?\n\n\\[\n\\begin{array}{cccc}\n0 & & \\text{Nothing} \\\\\n\\textcolor{red}{\\textbf{X}} & 0 & 1 & 2 \\ \\3 \\\\\n0 & 1 \\ 2 \\ 3 \\ 4 \\ \\5 \\ \\6 \\ \\7 \\ \\8 \\ \\9 \\\\\n\\end{array}\n\\]",
    "101 Language of arithmetic and if expressions  \n102 Absolute value and its desugaring  \n103 Recursive functions implemented using substitutions  \n104 Environment instead of substitutions  \n105 Higher-order functions using substitutions  \n106 Higher-order functions using environments  \n107 Nested recursive definitions using environments",
    "So far we used a special global environment defs to express recursion\nWe could create locally anonymous functions, but without a way to call them recursively.\nIn this step of the interpreter, we introduce the Defs expression case for adding (nested, local) mutually recursive functions:\n\n```\nenum Expr\n    case C(c: BigInt)\n    case N(name: String)\n    case IfNonzero(cond: Expr, trueE: Expr, falseE: Expr)\n    case Call(function: Expr, arg: Expr)\n    case Fun(param: String, body: Expr)\n    case Defs(defs: List[(String, Expr)], rest: Expr)\n```",
    "107: Nested recursive definitions using environments\n\nSo far we used a special global environment defs to express recursion\nWe could create locally anonymous functions, but without a way to call them\nrecursively.\nIn this step of the interpreter, we introduce the Defs expression case for adding\n(nested, local) mutually recursive functions:\n```\nenum Expr\n  case C(c: BigInt)\n  case N(name: String)\n  case IfNonzero(cond: Expr, trueE: Expr, falseE: Expr)\n  case Call(function: Expr, arg: Expr)\n  case Fun(param: String, body: Expr)\n  case Defs(defs: List[(String, Expr)], rest: Expr)\n\ntype Env = String => Option[Value]\n```",
    "def evalEnv(e: Expr, env: Env): Value = e match ...\n  case N(n) => env(n) match // no use of defs, only env\n  case Some(v) => v\n  case Fun(n,body) => Value.Ff(v: Value) => // same as before\n    val env1: String => Option[Value] =\n      (s:String) => if s==n then Some(v) else env(s)\n    evalEnv(body, env1) }\n  case Call(fun, arg) => evalEnv(fun,env) match // same\n    case Value.Ff(f) => f(evalEnv(arg,env))\n  case Defs(defs, rest) => //\n    def env1: Env = // extended environment\n      (s:String) =>\n        lookup(defs, s) match // list lookup in local defs \n          case None => env(s) // fall back to outer scope\n          case Some(body) => Some(evalEnv(body, env1)) // rec\n    evalEnv(rest, env1)",
    "def evalEnv(e: Expr, env: Env): Value = e match ...\n  case N(n) => env(n) match // no use of defs, only env\n    case Some(v) => v\n  case Fun(n,body) => Value.F{(v: Value) => // same as before\n    val env1: String => Option[Value] =\n      (s: String) => if s==n then Some(v) else env(s)\n    evalEnv(body, env1) }\n  case Call(fun, arg) => evalEnv(fun,env) match // same\n    case Value.F(f) => f(evalEnv(arg,env))\n  case Defs(defs, rest) => //\n    def env1: Env = // extended environment\n      (s: String) =>\n        lookup(defs, s) match // list lookup in local defs\n          case None => env(s) // fall back to outer scope\n          case Some(body) => Some(evalEnv(body, env)) // nonrec\n    evalEnv(rest, env1)\n\n",
    "def evalEnv(e: Expr, env: Env): Value = e match ...\n  case Defs(defs, rest) => //\n    def env1: Env =\n      lookup(defs, s) match // list lookup in local defs\n        case None => env(s) // fall back to outer scope\n        case Some(body) => Some(evalEnv(body, env)) // nonrec\n  evalEnv(rest, env1)\n\n(def fact = (n => (if n then (* n (fact (- n 1))) else 1))\n(fact 6))\n\njava.lang.Exception: Unknown name 'fact' in top-level environment",
    "def evalEnv(e: Expr, env: Env): Value = e match ...\n  case Defs(defs, rest) => //\n    def env1: Env = // extended environment\n      (s:String) =>\n        lookup(defs, s) match // list lookup in local defs\n          case None => env(s) // fall back to outer scope\n          case Some(body) => Some(evalEnv(body, env1)) // rec\n    evalEnv(rest, env1)\n\n(def fact = (n => (if n then (* n (fact (- n 1))) else 1))\n (fact 6))\n\n~~> 720",
    "We start evaluation in the initial environment:\n```\nevalEnv(e, initEnv)\n```\n```\nval initEnv: Env =\n  (s: String) => s match\n    case \"+\"  => lift2int(_ + _)\n    case \"-\"  => lift2int(_ - _)\n    case \"*\"  => lift2int(_ * _)\n    case \"^\"  => lift2int((x: BigInt, y: BigInt) => x.pow(y.toInt))\n    case \"<=\" => lift2int(\n      (x: BigInt, y: BigInt) => if x <= y then 1 else 0)\n    case _    => error(s\"Unknown name '$s' in initial environment\")\n```\nWe no longer need BinOp as special expression form",
    "def lift2int(f: (BigInt, BigInt) => BigInt): Option[Value] = \n  import Value._\n  Some(F(\n    (v1: Value) => F(\n      (v2: Value) => {\n        (v1, v2) match\n          case (I(i1), I(i2)) => I(f(i1, i2))\n          case _ => error(\"wrong operator type\")\n      })))\n",
    "(def twice = (f => x => (f (f x))))\n(def fact n = (if n then (* n (fact (- n 1))) else 1))\n(twice fact 3))\n~~> 720\n\n(def twice1 = (f => fact => (f (f fact))))\n(def fact n = (if n then (* n (fact (- n 1))) else 1))\n(twice1 fact 3))\n\nFUN: (f => (fact => (f (f fact))))\nARG: (n => (if n then (* n (fact (- n 1))) else 1))\nFUN: (fact => ((n => (if n then (* n (fact (- n 1))) else 1)) (fact => (f (f fact)))))\nARG: 3\n(if 3 then (* 3 (* 3 1)) else 1)\n(3 - 1))\n\njava.lang.Exception: Cannot apply non-function 3 in a call",
    "105: Variable Capture\n\ndef subst(e: Expr, n: String, r: Expr): Expr = e match\n  ...\n  case Fun(formal,body) =>\n    if formal==n then e  // do not subsitute under (n => ...)\n    else Fun(formal, subst(body,n,r))\n\nThe last line exhibits variable capture problem.\nIf \u2018formal\u2019 occurs free in \u2018r\u2019, then it will be captured by Fun(formal,...) even though\nthat outside occurrence of \u2018formal\u2019 in \u2018r\u2019 has nothing to do with the bound variable in\nthe anonymous function.\n\nFUN:  (f => (fact => ((f fact fact))))\nARG: (n => (if n then (* n (fact (- n 1))) else 1))\nfact => ((n => (if n then (* n (fact (- n 1))) else 1 ))\n          ((n => (if n then (* n (fact (- n 1))) else 1 )) fact))\n\nWhen we supply the integer argument we will also substitute it instead of the name of\nthe factorial function, resulting in run-time error (or, in other cases, wrong result).",
    "In situation like this:\nFUN: $(f \\Rightarrow (fact \\Rightarrow (f (f fact))))$\nARG: $(n \\Rightarrow (\\text{if }n\\text{ then }(* n (fact (- n 1))) \\text{ else }1))$\n\nwhen substituting ARG inside the body of FUN, we first rename bound variable in FUN body into one that does not occur in ARG:\nFUN: $(f \\Rightarrow (\\text{fact'} \\Rightarrow (f (f \\text{fact'}))))$\nARG: $(n \\Rightarrow (\\text{if }n\\text{ then }(* n (fact (- n 1))) \\text{ else }1))$\n\nInstead of fact' we can choose any fresh name for bound variable!\nResult then evaluates correctly:\n$$\n\\text{fact'} \\Rightarrow ((n \\Rightarrow (\\text{if }n\\text{ then }(* n (fact (- n 1))) \\text{ else }1)) \\text{ fact'})\n$$\n= \n$$\n((n \\Rightarrow (\\text{if }n\\text{ then }(* n (\\text{fact'} (- n 1))) \\text{ else }1)) \\text{ fact'})\n$$",
    "I05: Renaming Bound Variables in Subst\n\nWe call our previous substitution naive substitution:\n\n\\[\n\\text{def subst0(e: Expr, n: String, r: Expr): Expr = e match ...}\n\\]\n\\[\n\\text{case Fun(formal, body) =>}\n\\]\n\\[\n\\quad \\text{if formal==n then e else Fun(formal, subst0(body,n,r))}\n\\]\n\nTo avoid problems, we use capture-avoiding substitution:\n\n\\[\n\\text{def subst(e: Expr, n: String, r: Expr): Expr = e match ...}\n\\]\n\\[\n\\text{case Fun(formal,body) =>}\n\\]\n\\[\n\\quad \\text{if formal==n then e else}\n\\]\n\\[\n\\quad \\text{val fvs = freeVars(r)}\n\\]\n\\[\n\\quad \\text{val (formal1, body1) =}\n\\]\n\\[\n\\quad \\quad \\text{if fvs.contains(formal) then // rename bound formal}\n\\]\n\\[\n\\quad \\quad \\quad \\text{val formal1 = differentName(formal, fvs)}\n\\]\n\\[\n\\quad \\quad \\quad \\text{(formal1, subst0(body, formal1, N(formal1)))}\n\\]\n\\[\n\\quad \\quad \\text{else (formal, body)}\n\\]\n\\[\n\\quad \\text{Fun(formal1, subst(body1,n,r)) // substitute either way}\n\\]",
    "I05: Free Variables and Finding a Different Name\n\n```\ndef differentName(n: String, s: Set[String]): String =\n  if s.contains(n) then differentName(n + \"'\", s)\n  else n\n\ndef freeVars(e: Expr): Set[String] = e match\n  case C(c) => Set()\n  case N(s) => Set(s)\n  case BinOp(op, e1, e2) => freeVars(e1) ++ freeVars(e2)\n  case IfNonzero(cond, trueE, falseE) =>\n    freeVars(cond) ++ freeVars(trueE) ++ freeVars(falseE)\n  case Call(f, arg) => freeVars(f) ++ freeVars(arg)\n  case Fun(formal, body) => freeVars(body) - formal\n```",
    "Monads\n\nPrinciples of Functional Programming\n\nMartin Odersky",
    "Monads\n\nData structures with $map$ and $flatMap$ seem to be quite common.\n\nIn fact there's a name that describes this class of data structures together with some algebraic laws that they should have.\n\nThey are called monads.",
    "What is a Monad?\n\nA monad $M$ is a parametric type $M[T]$ with two operations, flatMap and unit, that have to satisfy some laws.\n\n\\[\n\\begin{aligned}\n&\\text{extension } [T, U](m: M[T]) \\\\\n&\\text{def flatMap(f: T => M[U]): M[U]} \n\\end{aligned}\n\\]\n\n\\[\n\\text{def unit[T](x: T): M[T]}\n\\]\n\nIn the literature, flatMap is also called bind. It can be an extension method, or be defined as a regular method in the monad class M.",
    "Examples of Monads\n\n\u25ba List is a monad with $unit(x) = List(x)$\n\u25ba Set is a monad with $unit(x) = Set(x)$\n\u25ba Option is a monad with $unit(x) = Some(x)$\n\u25ba Generator is a monad with $unit(x) = single(x)$",
    "Monads and map\n\nmap can be defined for every monad as a combination of flatMap and unit:\n\n$$m.map(f) == m.flatMap(x => unit(f(x)))$$\n$$== m.flatMap(f andThen unit)$$\n\nNote: andThen is defined function composition in the standard library.\n\n```scala\nextension [A, B, C](f: A => B)\n  infix def andThen(g: B => C): A => C =\n    x => g(f(x))\n```",
    "Monad Laws\n\nTo qualify as a monad, a type has to satisfy three laws:\n\nAssociativity:\n\n$m.flatMap(f).flatMap(g) == m.flatMap(f(_).flatMap(g))$\n\nLeft unit\n\n$unit(x).flatMap(f) == f(x)$\n\nRight unit\n\n$m.flatMap(unit) == m$",
    "Checking Monad Laws\n\nLet's check the monad laws for Option.\n\nHere's flatMap for Option:\n\nextension [T](xo: Option[T])\n  def flatMap[U](f: T => Option[U]): Option[U] = xo match\n    case Some(x) => f(x)\n    case None => None",
    "Checking the Left Unit Law\n\nNeed to show: $ \\text{Some}(x). \\text{flatMap}(f) == f(x) $\n\n$ \\text{Some}(x). \\text{flatMap}(f) $\n\n$ == \\text{Some}(x) \\text{ match}$\n$ \\quad \\text{case Some}(x) => f(x) $\n$ \\quad \\text{case None} => \\text{None} $\n\n$ == f(x) $",
    "Checking the Right Unit Law\n\nNeed to show: $opt.flatMap(Some) == opt$\n\n$opt.flatMap(Some)$\n\n$== \\ opt \\ match$\n$\\ \\ \\ \\ \\ case \\ \\ Some(x) \\ => \\ Some(x)$\n$\\ \\ \\ \\ \\ case \\ \\ None \\ => \\ None$\n\n$== \\ opt$",
    "Checking the Associative Law\n\nNeed to show: opt.flatMap(f).flatMap(g)  == opt.flatMap(f(_).flatMap(g))\n\nopt.flatMap(f).flatMap(g)\n\n==  (opt match { case Some(x) => f(x) case None => None })\n     .match { case Some(y) => g(y) case None => None }\n\n==  opt match\n     case Some(x) =>\n          f(x) match { case Some(y) => g(y) case None => None }\n     case None =>\n          None match { case Some(y) => g(y) case None => None }",
    "==    opt match\n        case Some(x) =>\n            f(x) match { case Some(y) => g(y) case None => None }\n        case None => None\n\n==    opt match\n        case Some(x) => f(x).flatMap(g)\n        case None => None\n\n==    opt.flatMap(x => f(x).flatMap(g))\n\n==    opt.flatMap(f(_).flatMap(g))",
    "Significance of the Laws for For-Expressions\n\nWe have seen that monad-typed expressions are typically written as for expressions.\n\nWhat is the significance of the laws with respect to this?\n\n1. Associativity says essentially that one can \"inline\" nested for expressions:\n\nfor\n    y <- for x <- m; y <- f(x) yield y\n    z <- g(y)\nyield z\n\n== for x <- m; y <- f(x); z <- g(y)\nyield z",
    "Significance of the Laws for For-Expressions\n\n2. Right unit says:\n\n\\[\n\\text{for } x \\leftarrow m \\text{ yield } x\n\\]\n\n\\[\n== \\quad m\n\\]\n\n3. Left unit does not have an analogue for for-expressions.",
    "Eliminated Recursion! What about representing numbers?\n\nenum Expr\n    case C(c: BigInt)          // <-- to eliminate next\n    case N(name: String)\n    case IfNonzero(cond: Expr, trueE: Expr, falseE: Expr)\n    case Call(function: Expr, arg: Expr) \n    case Fun(param: String, body: Expr)\n    case Defs(defs: List[(String, Expr)], rest: Expr) // Done\n\nWe now make language smaller, but without losing expressive power!\nWe wish to show that we only need these three constructs:\n\nenum Expr\n    case N(name: String)\n    case Call(function: Expr, arg: Expr)\n    case Fun(param: String, body: Expr)\n\nThe higher-order language with only these three constructs is called lambda calculus.",
    "We defined twice like this:\n\n\\[ f = x \\Rightarrow f \\left( f \\left( x \\right) \\right) \\]\n\nMaybe we can use it to represent number two?\nWhat should we use to represent number three?\n\n\\[ f = x \\Rightarrow f \\left( f \\left( f \\left( x \\right) \\right) \\right) \\]\n\nWhat about zero?\n\n\\[ f = x \\Rightarrow x \\]\n\nSuch numbers, where $n$ becomes $n$-fold function application, are called Church numerals according to Alonzo Church, inventor of lambda calculus.\nIs there a function that computes addition? A composition of iterations of $f$:\n\n\\[ m \\Rightarrow n \\Rightarrow (f \\Rightarrow x \\Rightarrow m\\left( f \\left( n \\left( f \\left( x \\right) \\right) \\right) \\right) ) \\]",
    "Example of Evaluation of Two Plus Three\n\n(m => n => f => x => m f (n f x)) // plus\n(f => x => f (f x)) // two\n(f => x => f (f (f x))) // three\n\n~~>\n\nf => x =>\n\t((f => (x => (f (f (f x))))) f) (((f => x => (f (f x))) f) x)\n\nIf we apply the above term to some concrete F and X we would get call-by-value evaluation corresponding to:\n\n(((f => (x => (f (f (f x)))) F) (((f => x => (F (F x)))) F )) x)\n~~>\n(x => (F (F (F x)))) ((F (F x)))\n\nwe would evaluate three times F applied to X, then two more times F applied to result.",
    "enum Expr\n  case C(c: BigInt)       // OK\n  case N(name: String)\n  case IfNonzero(cond: Expr, trueE: Expr, falseE: Expr) // <--\n  case Call(function: Expr, arg: Expr)\n  case Fun(param: String, body: Expr)\n  case Defs(defs: List[(String, Expr)], rest: Expr) // OK\n\nWe wish to show that we only need these three constructs:\n\nenum Expr\n  case N(name: String)\n  case Call(function: Expr, arg: Expr)\n  case Fun(param: String, body: Expr)\n\nThe higher-order language with only these three constructs is called lambda calculus.",
    "How To Check If Numeral is Nonzero?\n\nGiven a numeral $n$, like one for two:\n\n$f => x => f (f x)$\n\nHow can we apply it to some expressions to get the effect of\n\n$ifNonzero\\ n\\ then\\ eTrue\\ else\\ eFalse$\n\nWe give to numeral a specifically crafted function as $f$ and a term as the initial value $x$.",
    "How To Check If Numeral is Nonzero?\n\nGiven a numeral $n$, like one for two:\n\n$f => x => f (f x)$\n\nHow can we apply it to some expressions to get the effect of\n\n\\texttt{ifNonzero n then eTrue else eFalse}\n\nWe give to numeral a specifically crafted function as $f$ and a term as the initial value $x$. When $n$ is zero (that is, $f \\Rightarrow x \\Rightarrow x$) we want to return \\texttt{eFalse}.",
    "How To Check If Numeral is Nonzero?\n\nGiven a numeral $n$, like one for two:\n\n\\[ f \\Rightarrow x \\Rightarrow f (f \\; x) \\]\n\nHow can we apply it to some expressions to get the effect of\n\n\\[ \\text{ifNonzero} \\; n \\; \\text{then} \\; eTrue \\; \\text{else} \\; eFalse \\]\n\nWe give to numeral a specifically crafted function as $f$ and a term as the initial value $x$. When $n$ is zero (that is, $f \\Rightarrow x \\Rightarrow x$) we want to return $eFalse$. Let $f$ be constant function that ignores its argument and returns $eTrue$. Thus, we can try:\n\n\\[ n \\; (arg \\Rightarrow eTrue) \\; eFalse \\]",
    "How To Check If Numeral is Nonzero?\n\nGiven a numeral $n$, like one for two:\n\n$f => x => f (f x)$\n\nHow can we apply it to some expressions to get the effect of\n\nifNonzero n then eTrue else eFalse\n\nWe give to numeral a specifically crafted function as $f$ and a term as the initial value $x$. When $n$ is zero (that is, $f  => x => x$) we want to return $eFalse$. Let $f$ be constant function that ignores its argument and returns $eTrue$. Thus, we can try:\n\n$n (\\text{arg} => eTrue) eFalse$\n\nUnfortunately, this always evaluates the false branch. To prevent that, encode IfNonzero as: \n\n$(n (\\text{arg} => (_ => eTrue) (_ => eFalse)) d$\n\nwhere $_$ is an arbitrary parameter and $d$ is any lambda term, e.g., $x => x$",
    "Take the proposed encoding of $\\text{IfNonzero}(n,{eTrue}, {eFalse})$:\n$$(n \\; (\\text{arg} => \\_ => {eTrue}) \\; (\\_ => {eFalse})) \\; d$$\n\nSuppose \\(n\\) is zero, \\(f \\implies x \\implies x\\). Then:\n$$(f \\implies x \\implies x) \\; (\\text{arg} => \\_ => {eTrue}) \\; (\\_ => {eFalse}) \\; d$$\n$$~~> (\\_ => {eFalse}) \\; d$$\n$$~~> {eFalse}$$\n\nSuppose \\(n\\) is one, \\(f \\implies x \\implies f \\; x\\). Then:\n$$(f \\implies x \\implies f \\; x) \\; (\\text{arg} => \\_ => {eTrue}) \\; (\\_ => {eFalse}) \\; d$$\n$$(\\text{arg} => \\_ => {eTrue}) \\; (\\_ => {eFalse}) \\; d$$\n$$~~> (\\text{arg} => {eTrue}) \\; (\\_ => {eFalse}) \\; d$$\n$$~~> {eTrue}$$\n\nSuppose \\(n\\) is, e.g., two, \\(f \\implies x \\implies f \\; (f \\; x)\\). Then:\n$$(f \\implies x \\implies f \\; (f \\; x)) \\; (\\text{arg} => \\_ => {eTrue}) \\; (\\_ => {eFalse}) \\; d$$\n$$(f \\implies x \\implies f \\; x) \\; (\\text{arg} => \\_ => {eTrue}) \\; ((\\text{arg} => \\_ => {eTrue}) \\; (\\_ => {eFalse})) \\; d$$\n$$(\\text{arg} => \\_ => {eTrue}) \\; ((\\text{arg} => \\_ => {eTrue}) \\; (\\_ => {eFalse})) \\; d$$\n$$(\\text{arg} => {eTrue}) \\; ((\\text{arg} => \\_ => {eTrue}) \\; (\\_ => {eFalse})) \\; d$$\n$$(\\text{arg} => {eTrue}) \\; {eTrue} \\; d$$\n$$~~> {eTrue}$$",
    "Automating Encoding of IfNonzero\n\n```\ndef mkIf(n: Expr, eTrue: Expr, eFalse: Expr): Expr = \n    Call(\n        Call(Call(n, Fun(\"arg\", Fun(\"foo\", eTrue))),\n             Fun(\"foo\", eFalse)),\n        Fun(\"x\", N(\"x\")))\n```",
    "Reduced to lambda calculus\n\n```\nenum Expr\n  case C(c: BigInt)                      // encoded\n  case N(name: String)\n  case IfNonzero(cond: Expr, trueE: Expr, falseE: Expr) // encoded\n  case Call(function: Expr, arg: Expr)\n  case Fun(param: String, body: Expr)\n  case Defs(defs: List[(String, Expr)], rest: Expr) // encoded\n```\n\nAll that is left is:\n\n```\nenum Expr\n  case N(name: String)\n  case Call(function: Expr, arg: Expr)\n  case Fun(param: String, body: Expr)\n```\n\nThe higher-order language with only these three constructs is called lambda calculus.",
    "Lambda Calculus Notation\n\nenum Expr\ncase N(name: String)\ncase Call(function: Expr, arg: Expr)\ncase Fun(param: String, body: Expr)\n\nA general-purpose computation model that can express recursion, numbers, lists and other data types. Standard notation in lambda calculus:\n\n| syntax tree  | our simple language | lambda calculus | common terminology |\n| ---          | ---                | ---             | ---                |\n| N(\"x\")       | x                  | x               | variable           |\n| Call(f, e)   | f e                | f e             | application        |\n| Fun(x, e)    | x => e             | $\\lambda x.e$   | abstraction        |\n\nWe have seen it work with call by value evaluation. Another common evaluation used in lambda calculus theory (and in Haskell) is call-by-name, which terminates on some of the programs for which call by value diverges.",
    "1 2 3\n\n$0.2$ $0.2$ $0.2$\n\n$0.1$ $0.1$",
    "EPFL\n\nA Closer Look At Lists\n\nPrinciples of Functional Programming",
    "Lists Recap\n\nLists are the core data structure we will work with over the next weeks.\n\nType: List[Fruit]\n\nConstruction:\n\nval fruits = List(\"Apple\", \"Orange\", \"Banana\")\nval nums = 1 :: 2 :: Nil\n\nDecomposition:\n\nfruits.head // \"Apple\"\nnums.tail // 2 :: Nil\nnums.isEmpty // false\n\nnums match\ncase x :: y :: _ => x + y // 3",
    "List Methods (1)\n\nSublists and element access:\n\nxs.length The number of elements of xs.\nxs.last The list\u2019s last element, exception if xs is empty.\nxs.init A list consisting of all elements of xs except the last one, exception if xs is empty.\nxs.take(n) A list consisting of the first n elements of xs, or xs itself if it is shorter than n.\nxs.drop(n) The rest of the collection after taking n elements.\nxs(n) (or, written out, xs.apply(n)). The element of xs at index n.",
    "List Methods (2)\n\nCreating new lists:\n\n$xs ++ ys$ \n  The list consisting of all elements of $xs$ followed by all elements of $ys$.\n\n$xs.reverse$ \n  The list containing the elements of $xs$ in reversed order.\n\n$xs.updated(n, x)$\n  The list containing the same elements as $xs$, except at index $n$ where it contains $x$.\n\nFinding elements:\n\n$xs.indexOf(x)$\n  The index of the first element in $xs$ equal to $x$, or $-1$ if $x$ does not appear in $xs$.\n\n$xs.contains(x)$\n  same as $xs.indexOf(x) >= 0$",
    "Implementation of last\n\nThe complexity of head is (small) constant time.\n\nWhat is the complexity of last?\n\nTo find out, let's write a possible implementation of last as a stand-alone function.\n\n```\ndef last[T](xs: List[T]): T = xs match\n  case List() => throw Error(\"last of empty list\")\n  case List(x) => x\n  case y :: ys => last(ys)\n```\n\nSo, last takes steps proportional to the length of the list xs.\n\n=> slow",
    "Exercise\n\nImplement $init$ as an external function, analogous to $last$.\n\n```scala\ndef init[T](xs: List[T]): List[T] = xs match\n  case List() => throw Error(\"init of empty list\")\n  case List(x) => List()\n  case y :: ys => y :: init(ys)\n```",
    "How can concatenation be implemented?\n\nLet\u2019s try by writing an extension method for ++:\n\n```\nextension [T](xs: List[T])\n  def ++ (ys: List[T]): List[T] = xs match\n    case Nil => ys\n    case x :: xs1 => x :: (xs1 ++ ys)\n```\nWhat is the complexity of concat?\n\nAnswer: O(xs.length)",
    "Implementation of reverse\n\nHow can reverse be implemented?\n\nLet\u2019s try by writing an extension method:\n\n\\[\n\\begin{align*}\n\\text{extension [T](xs: List[T])}\\\\\n\\indent \\text{def reverse: List[T] = xs match} \\\\\n\\indent \\indent \\text{case Nil => Nil} \\\\\n\\indent \\indent \\text{case y :: ys => ys.reverse ++ List(y)}\n\\end{align*}\n\\]\n\nWhat is the complexity of reverse?\n\nAnswer: $O(xs.length * xs.length)$\n\nCan we do better? (to be solved later).",
    "Exercise\n\nRemove the n' th element of a list xs. If n is out of bounds, return xs itself.\n\ndef removeAt[T](n: Int, xs: List[T]) = ???\n\nUsage example:\nremoveAt(1, List('a', 'b', 'c', 'd')) > List(a, c, d)\n\ndef removeAt[A](n: Int, xs: List[T]): List[T] = xs match\n  case Nil => Nil\n  case y::ys =>\n    if n == 0 then ys\n    else y::removeAt(n-1, ys)",
    "Exercise (Harder, Optional)\n\nFlatten a list structure:\n\n```scala\ndef flatten(xs: List[Any]): List[Any] = ???  // Remove embedded sublists\n```\n\n```scala\nflatten(List(List(1, 1), 2, List(3, List(5, 8))))\n> res0: List[Any] = List(1, 1, 2, 3, 5, 8)\n```\n\n```scala\ndef flatten(xs : List[Any]): List[Any] = xs match\n  case Nil => Nil\n  case y :: ys => flatten(y) ++ flatten(ys)\n  case _ => xs :: Nil  // input element xs is not a list!\n```",
    "101 Language of arithmetic and if expressions\n102 Absolute value and its desugaring\n103 Recursive functions implemented using substitutions\n104 Environment instead of substitutions\n105 Higher-order functions using substitutions\n106 Higher-order functions using environments\n107 Nested recursive definitions using environments",
    "Environments are often more efficient alternative to substitutions. Instead of copying body of function definition and replacing parameter names with argument constants, we do replacement lazily:\n\u25ba leave the body as is (no copying!)\n\u25ba record map from names to argument constants in the environment\n\u25ba when we find a name, look it up in the environment\n\nMoins co\u00fbte effective than substitutions.",
    "fact(3)\n  env: Map(n -> 3)\n  (if n then (* n (fact (- n 1))) else 1)       // body as declared\nfact(2)\n  env: Map(n -> 2)\n  (if n then (* n (fact (- n 1))) else 1)       // same\nfact(1)\n  env: Map(n -> 1)\n  (if n then (* n (fact (- n 1))) else 1)       // still same\nfact(0)\n  env: Map(n -> 0)\n  (if n then (* n (fact (- n 1))) else 1)       // again same!\n    1\n  1\n  2\n  6",
    "def evalE(e: Expr, env: Map[String, BigInt]): BigInt = e match \n  case C(c) => c\n  case N(n) => env(n)  // look up name in the environment\n  case BinOp(op, e1, e2) => \n    evalBinOp(op)(evalE(e1, env), evalE(e2, env))\n  case IfNonzero(cond, trueE, falseE) => \n    if evalE(cond, env) != 0 then evalE(trueE, env)\n    else evalE(falseE, env)\n  case Call(fName, args) =>\n    defs.get(fName) match \n      case Some(f) =>\n        val evaledArgs = args.map((e: Expr) => evalE(e,env))\n        // newEnv additionally maps parameters to arguments\n        val newEnv = env ++ f.params.zip(evaledArgs)\n        evalE(f.body, newEnv)",
    "Functions and Data\n\nPrinciples of Functional Programming",
    "In this section, we'll learn how functions create and encapsulate data structures.\n\nExample: Rational Numbers\n\nWe want to design a package for doing rational arithmetic.\n\nA rational number $\\frac{x}{y}$ is represented by two integers:\n\n- its numerator $x$, and\n- its denominator $y$.",
    "Rational Addition\n\nSuppose we want to implement the addition of two rational numbers.\n\n\\[\n\\text{def addRationalNumerator(n1: Int, d1: Int, n2: Int, d2: Int): Int}\n\\]\n\n\\[\n\\text{def addRationalDenominator(n1: Int, d1: Int, n2: Int, d2: Int): Int}\n\\]\n\nbut it would be difficult to manage all these numerators and denominators.\n\nA better choice is to combine the numerator and denominator of a rational number in a data structure.",
    "Classes\n\nIn Scala, we do this by defining a class:\n\n```scala\nclass Rational(x: Int, y: Int):\n  def numer = x\n  def denom = y\n```\n\nThis definition introduces two entities:\n\n- A new type, named Rational.\n- A constructor Rational to create elements of this type.\n\nScala keeps the names of types and values in different namespaces. So there\u2019s no conflict between the two entities named Rational.",
    "Objects\n\nWe call the elements of a class type objects.\n\nWe create an object by calling the constructor of the class:\n\nExample\nRational(1, 2)",
    "Objects of the class Rational have two members, numer and denom.\n\nWe select the members of an object with the infix operator \u2018.\u2019.\n\nExample\n\nval x = Rational(1, 2)  // x: Rational = Rational@2abe0e27 \nx.numer               // 1\nx.denom              // 2",
    "Rational Arithmetic\n\nWe can now define the arithmetic functions that implement the standard rules.\n\n$\\frac{n_1}{d_1} + \\frac{n_2}{d_2} = \\frac{n_1 d_2+n_2 d_1}{d_1 d_2}$\n\n$\\frac{n_1}{d_1} - \\frac{n_2}{d_2} = \\frac{n_1 d_2-n_2 d_1}{d_1 d_2}$\n\n$\\frac{n_1}{d_1} \\cdot \\frac{n_2}{d_2} = \\frac{n_1 n_2}{d_1 d_2}$\n\n$\\frac{n_1}{d_1} \\div \\frac{n_2}{d_2} = \\frac{n_1 d_2}{d_1 n_2}$\n\n$\\frac{n_1}{d_1} = \\frac{n_2}{d_2} \\iff n_1 d_2 = d_1 n_2$",
    "Implementing Rational Arithmetic\n\n```python\ndef addRational(r: Rational, s: Rational): Rational = \n  Rational(\n    r.numer * s.denom + s.numer * r.denom,\n    r.denom * s.denom\n  )\n\ndef makeString(r: Rational): String =\n  s\"${r.numer}/${r.denom}\"\n    \nmakeString(addRational(Rational(1, 2), Rational(2, 3)))  >  7/6\n\nNote: s\"...\"\" in makeString is an interpolated string, with values r.numer \nand r.denom in the places enclosed by ${...}.\n```",
    "Methods\n\nOne can go further and also package functions operating on a data abstraction in the data abstraction itself.\n\nSuch functions are called methods.\n\nExample\n\nRational numbers now would have, in addition to the functions numer and denom, the functions add, sub, mul, div, equal, toString.",
    "Here's a possible implementation:\n\n```\nclass Rational(x: Int, y: Int):\n  def numer = x\n  def denom = y\n\n  def add(r: Rational) =\n    Rational(numer * r.denom + r.numer * denom, \n      denom * r.denom)\n\n  def mul(r: Rational) = ...\n  ...\n\n  override def toString = s\"$numer/$denom\"\n```\n\nRemark: the modifier `override` declares that `toString` redefines a method that already exists (in the class java.lang.Object).",
    "Calling Methods\n\nHere is how one might use the new Rational abstraction:\n\nval x = Rational(1, 3)\nval y = Rational(5, 7)\nval z = Rational(3, 2)\nx.add(y).mul(z)",
    "1. In your worksheet, add a method neg to class Rational that is used like this:\n\n    x.neg            // evaluates to -x\n\n2. Add a method sub to subtract two rational numbers.\n\n3. With the values of x, y, z as given in the previous slide, what is the result of\n\n    $x - y - z$\n\n?",
    "1) def neg = Rational(-numer, denom)\n\n2) def sub(r: Rational) = add(r.neg)",
    "\\textbf{101} Language of arithmetic and \\textit{if} expressions  \n\\textbf{102} Absolute value and its \\textit{desugaring}  \n\\textbf{103} \\textit{Recursive} functions implemented using \\textit{substitutions}  \n\\textbf{104} \\textit{Environment} instead of substitutions  \n\\textbf{105} \\textit{Higher-order} functions using substitutions  \n\\textbf{106} \\textit{Higher-order} functions using environments  \n\\textbf{107} \\textit{Nested recursive} definitions using environments",
    "Higher-Order Functions Using Environments\n\nEnvironments are more efficient (and avoid variable capture more easily). How to use them when parameters can be functions?\n\nBefore higher-order functions, environment mapped names to integers. Now, it maps names to value, which may also be functions:\n\n```enum Value\n    case I(i: BigInt)\n    case F(f: Value => Value) // enum that includes functions.\n```\n\n```type Env = Map[String, Value]\n```\n\nWe represent function values of the language we are interpreting using functions in Scala. We say our interpreter is meta circular because we use features in meta language in which we write interpreter (Scala) to represent features of the language we are interpreting.",
    "I06: Environment-Based Interpreter is Very Concise!\n\ndef evalEnv(e: Expr, env: Map[String, Value]): Value = e match\n  case C(c) => Value.I(c)\n  case N(n) => env.get(n) match\n    case Some(v) => v\n    case None => evalEnv(defs(n), env)\n  case Binop(op, arg1, arg2) =>\n    evalBinOp(op)(evalEnv(arg1, env), evalEnv(arg2, env))\n  case IfNonzero(cond, trueE, falseE) =>\n    if evalEnv(cond, env) != Value.I(0) then evalEnv(trueE, env)\n    else evalEnv(falseE, env)\n  case Fun(n, body) => Value.F({(x: Value) =>\n    evalEnv(body, env + (n -> x)) // no danger of capture\n  })\n  case Call(fun, arg) => evalEnv(fun, env) match\n    case Value.F(f) => f(evalEnv(arg, env))",
    "Kernel Ridge Regression and the Kernel Trick\n\nNov 2, 2022\n\nEPFL",
    "Motivation\nIn our last lecture we formulated the optimization problem corresponding to SVMs. We then derived an alternative formulation using duality. We saw that in this alternative formulation the data only enters in the form of a \"kernel\" $K = XX^T$.\nThe aim of today is the following. First, we will discuss a second problem, namely ridge regression, that admits an alternative formulation that is \"kernelized,\" i.e., the alternative formulation depends on the data only via the kernel $K = XX^T$. Second, we will see that for any kernelized problem we can apply the kernel trick. This will allow us to use a significantly augmented feature vector without incurring extra costs. We will discuss what kernel functions are admissible for this trick and how to construct new kernel functions from old ones.\nEven though we present the kernel trick in the context of ridge regression it will hopefully be clear by the end that the same trick can be applied to any problem that can be brought into kernelized form.\n\nAlternative formulation of ridge regression\nRecall that ridge regression corresponds to the following optimization problem:\n\n$$\\min_{\\mathbf{w}} \\frac{1}{2N} \\|\\mathbf{y} - X\\mathbf{w}\\|^2 + \\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2.$$\n\nIt has the solution\n\n$$\\mathbf{w}^* = \\frac{1}{\\lambda} (X^TX + \\lambda ID)^{-1} X^T \\mathbf{y}.$$",
    "We claim that this solution can be written alternatively as\n$$\n\\mathbf{w}^{*}=\\frac{1}{\\lambda} \\mathbf{X}^{\\top}\\left(\\mathbf{X X}^{\\top}+\\lambda \\mathbf{I}_{N}\\right)^{-1} \\mathbf{y}.\n\\quad(1)\n$$\nThis second formulation can be proved using the following identity: let $\\mathbf{P}$ be an $N \\times M$ matrix and $\\mathbf{Q}$ be an $M \\times N$ matrix. Then, trivially,\n$$\n\\mathbf{P}(\\mathbf{Q P}+\\mathbf{I}_{M})=\\mathbf{P Q P}+\\mathbf{P}=(\\mathbf{P Q}+\\mathbf{I}_{N}) \\mathbf{P}.\n$$\nIf we now assume that $(\\mathbf{Q P}+\\mathbf{I}_{M})$ and $(\\mathbf{P Q}+\\mathbf{I}_{N})$ are invertible we have the identity\n$$\n(\\mathbf{P Q}+\\mathbf{I}_{N})^{-1} \\mathbf{P}=\\mathbf{P}(\\mathbf{Q P}+\\mathbf{I}_{M})^{-1}.\n$$\nTo derive from this general statement our alternative representation, let $\\mathbf{P}=\\mathbf{X}^{\\top}$ and $\\mathbf{Q}=\\frac{1}{\\lambda} \\mathbf{X}$. \n\nWhy is this alternative representation useful?\n\n1. Define $\\boldsymbol{\\alpha}^{*}=\\frac{1}{\\lambda}\\left(\\mathbf{X X}^{\\top}+\\lambda \\mathbf{I}_{N}\\right)^{-1} \\mathbf{y}$. Then we can write\n$$\n\\mathbf{w}^{*}=\\mathbf{X}^{\\top} \\boldsymbol{\\alpha}^{*}.\n\\quad(2)\n$$\nFrom this representation we see that $\\mathbf{w}^{*}$ lies in the column space of $\\mathbf{X}^{\\top},$ i.e., the space spanned by the feature vectors.\n\n2. The original formulation involves computation of order $O(D^{3}+N D^{2})$, while the second can be computed in time $O(N^{3}+D N^{2})$. Hence it depends on the size of $D$ and $N$ which of the two is more efficient.\n\n3. We will see that (1) and (2) are the crucial ingredients for the kernel trick to work.",
    "The representer theorem\n\nThe representer theorem generalizes this result: for a $ \\mathbf{w}^* $ minimizing the following function for any $ L_n $,\n\n$$ \\min_{\\mathbf{w}} \\frac{1}{N} \\sum_{n=1}^{N} L_n(\\mathbf{x}_n \\mathbf{w}, y_n ) + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|^2 $$\n\nthere exists $\\alpha^*$ such that $ \\mathbf{w}^* = \\mathbf{X}^T \\alpha^* $.\n\nSuch a general statement was originally proved by Sch\u00f6lkopf, Herbrich and Smola (2001).\n\nKernelized ridge regression\n\nLet us go back to ridge regression. The representer theorem allows us to write an equivalent optimization problem in terms of $\\alpha$:\n\n$$ \\mathbf{w}^* = \\arg\\min_{\\mathbf{w}} \\frac{1}{2N} \\|\\mathbf{y} - \\mathbf{Xw}\\|^2 + \\frac{\\lambda}{2}\\|\\mathbf{w}\\|^2 $$\n\n$$ \\alpha^* = \\arg \\min_\\alpha \\frac{1}{2}(\\mathbf{y}^T \\mathbf{y} - 2(\\mathbf{X} \\alpha)^T \\mathbf{y} + \\alpha^T \\mathbf{X}^T \\mathbf{X} \\alpha + \\lambda I_N \\alpha)^T \\mathbf{y} $$\n\nTo see that these two problems have equivalent solutions, note that if we take the gradient of the second expression we get $(\\mathbf{XX}^T + \\lambda I) \\alpha - \\mathbf{y}$. Setting this to 0 and solving for $\\alpha$ results in\n\n$$ \\alpha^* = \\frac{1}{\\lambda} (\\mathbf{y}^T \\mathbf{X}^T \\mathbf{X} + \\lambda I_N)^T \\mathbf{y}  $$\n\nIf we combine this with the representer theorem $ \\mathbf{w}^* = \\mathbf{X}^T \\alpha^* $ we find back the solution (1).",
    "As we discussed previously, depending on the $D$, the dimension of the feature space, and $N$, the number of samples, one or the other of the two formulations might be more efficient. But there is an arguably even more important reason why the second expression is of interest. In this second expression the data only enters in terms of the kernel matrix $\\mathbf{K} = \\mathbf{X} \\mathbf{X}^{\\top}$.\n\n**Kernel functions**\n\nRecall that the kernel is defined as\n$$\n\\mathbf{K} = \\mathbf{X} \\mathbf{X}^{\\top} =\n\\begin{bmatrix}\nx_1^{\\top} x_1 & x_1^{\\top} x_2 & \\cdots & x_1^{\\top} x_N \\\\\nx_2^{\\top} x_1 & x_2^{\\top} x_2 & \\cdots & x_2^{\\top} x_N \\\\\n \\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_N^{\\top} x_1 & x_N^{\\top} x_2 & \\cdots & x_N^{\\top} x_N\n\\end{bmatrix}\n$$\n\nFor reasons that will become clear shortly, we call this the linear kernel.\n\nAssume that we had first augmented the feature space to $\\phi(x)$. The associated kernel with basis functions $\\phi(x)$ would then be $\\mathbf{K} = \\Phi \\Phi^{\\top}$. Explicitly,\n\n$$\n\\mathbf{K} =\n\\begin{bmatrix}\n\\phi(x_1)^{\\top} \\phi(x_1) & \\phi(x_1)^{\\top} \\phi(x_2) & \\cdots & \\phi(x_1)^{\\top} \\phi(x_N) \\\\\n\\phi(x_2)^{\\top} \\phi(x_1) & \\phi(x_2)^{\\top} \\phi(x_2) & \\cdots & \\phi(x_2)^{\\top} \\phi(x_N) \\\\\n \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\phi(x_N)^{\\top} \\phi(x_1) & \\phi(x_N)^{\\top} \\phi(x_2) & \\cdots & \\phi(x_N)^{\\top} \\phi(x_N)\n\\end{bmatrix}\n$$\n\nWe have already discussed that sometimes it is useful to augment the feature space. This will lead to a more powerful model. Here is a link to a video explaining this point in more detail: https://www.youtube.com/watch?v=3ilCbRZPrZA",
    "The kernel trick\n\nThe big advantage of using kernels is that rather than first augmenting the feature space and then computing the kernel, we can do both steps together, and we can do it more efficiently. Let us discuss how this works.\nLet us define a \"kernel function\" $\\kappa (x,x')$ and let us compute the $(i,j)$-th entry of $K$ as $K_{ij} = \\kappa (x_i, x_j)$. For the right choice of kernel $\\kappa$, it turns out to be equivalent to first augmenting the features to some suitable $\\phi(x)$ and then computing the inner product\n$$\\phi (x)^\\top \\phi (x')$$\nin the augmented space. In other words, for the right choices we have\n$$\\kappa (x,x') = \\phi (x)^\\top \\phi (x').$$\nThis is probably best seen by looking at examples:\n1. To start trivially, if we pick the linear kernel $\\kappa (x,x') = x^\\top x'$, then the corresponding feature map is of course $\\phi (x') = x'$.\n2. Assume that $x \\in \\mathbb{R}$, i.e., x is a scalar. The kernel $\\kappa (x,x') = (xx')^2$ corresponds to $\\phi (x) = x^2$.\n3. Assume that $x \\in \\mathbb{R}^3$, i.e., $x$ is a vector of dimension 3. The kernel $\\kappa (x,x') = (x_1 x_1' + x_2 x_2' + x_3 x_3')^2$ corresponds to \n$$\\phi (x) = [x_1^2, x_2^2, x_3^2, \\sqrt{2} x_1 x_2, \\sqrt{2} x_1 x_3, \\sqrt{2} x_2 x_3 ].$$\n\nThis is an example of what is called a polynomial kernel.",
    "4. The kernel\n\n\\[ \\kappa(\\mathbf{x}, \\mathbf{x'}) = \\exp \\left[ -(\\mathbf{x} - \\mathbf{x'})^\\top (\\mathbf{x} - \\mathbf{x'}) \\right] \\]\n\ncorresponds to an infinite feature map! It is called the radial basis function (RBF) kernel. In order to look at this more in detail, consider the simple case where the $\\mathbf{x}$ and $\\mathbf{x'}$ are scalars. In this case we have the expansion\n\n\\[ K(x, x') = e^{-(x^2) - (x')^2} \\sum_{k=0}^\\infty \\frac{2^k (x')^k (x')^k}{k!} \\]\n\nWe see that we can think of this as the inner product of infinite-dimensional vectors whose k-th component, $k=0, 1, \\ldots$ is equal to\n\n\\[ e^{- (x')^2} \\frac{2^k}{\\sqrt{k!}} x^k \\quad \\text{and} \\quad  e^{- (x')^2} \\frac{2^k}{\\sqrt{k!}} (x')^k \\]\n\nrespectively. And although this is not obvious, let us state that this kernel cannot be represented as an inner product in a finite-dimensional space.\n\n5. You can find many further examples in Section 14.2 of Murphy's book.\n\n6. Building new kernels from old kernels.\n  \na) $\\kappa(x, x') = a\\kappa_1(x, x') + b\\kappa_2(x, x')$, for all $a, b \\geq 0$.\n\nProof. By assumption $\\kappa_1$ and $\\kappa_2$ are valid kernels. Hence there exist feature maps $\\phi_1$ and $\\phi_2$ so that\n\n\\[ \\kappa_1(x, x') = \\phi_1(x) \\phi_1(x'), \\]\n\n\\[ \\kappa_2(x, x') = \\phi_2(x) \\phi_2(x'). \\]",
    "Hence,\n\n\\[ \\kappa(\\mathbf{x}, \\mathbf{x}') = a\\phi_{1}(\\mathbf{x})^{T}\\phi_{1}(\\mathbf{x}') + b\\phi_{2}(\\mathbf{x})^{T}\\phi_{2}(\\mathbf{x}'). \\]\n\nThis can be represented as an inner product via the feature map\n\n\\[ (\\sqrt{a}\\phi_{1}(\\cdot), \\sqrt{b}\\phi_{2}(\\cdot)). \\]\n\nb) \\(\\kappa(\\mathbf{x}, \\mathbf{x}') = \\kappa_{1} (\\mathbf{x}, \\mathbf{x}')\\kappa_{2} (\\mathbf{x},\\mathbf{x}'). \\)\n\nProof. Let the two feature maps be \\(\\phi_{1}\\) and \\(\\phi_{2}\\). Assume that they are of dimensions \\(d_{1}\\) and \\(d_{2}\\). Then \\(\\phi\\) is a feature map of dimension \\(d_{1}d_{2}\\) of the form\n\n\\[ \\phi(\\mathbf{x})^{T} = (\\phi_{1}(\\mathbf{x})_{1}\\phi_{2}(\\mathbf{x})_{1}, \\cdots , \\phi_{1}(\\mathbf{x})_{1}\\phi_{2}(\\mathbf{x})_{d_{2}}, \\cdots , \\phi_{1}(\\mathbf{x})_{d_{1}}\\phi_{2}(\\mathbf{x})_{1}, \\cdots , \\phi_{1}(\\mathbf{x})_{d_{1}}\\phi_{2}(\\mathbf{x})_{d_{2}}). \\]\n\nc) \\(\\kappa(\\mathbf{x}, \\mathbf{x}') = \\kappa_{1} (f(\\mathbf{x}), f(\\mathbf{x}'))\\) for any \\(f\\) from the domain to itself.\n\nProof. Let \\(\\phi_{j}\\) be the feature map corresponding to \\(\\kappa_{j} (\\cdot , \\cdot)\\). Then by direct inspection we see that \n\\(\\phi_{j} (f(\\cdot )) = \\phi_{j} (f(\\cdot ))\\) is the feature map corresponding to \\(\\kappa_{j} (f(\\cdot ), f(\\cdot))\\). Indeed,\n\n\\[ \\phi_{1}(f(\\mathbf{x}))^{T}\\phi_{1}(f(\\mathbf{x}')) = \\kappa_{1}(f(\\mathbf{x}), f(\\mathbf{x}')) = \\kappa_{1}(\\mathbf{x}, \\mathbf{x}'). \\]",
    "d) $\\kappa (x, x') = f(x)f(x')$ for any real-valued $f$. Clearly, $\\phi(x) = f(x)$ will be the corresponding feature map.\n\nClassifying with the kernel K\n\nWe have seen so far how we can compute the optimal parameter vector $\\alpha$ using only the kernel (and not having to go to the extended feature space). We have also discussed that in some cases the feature space is in fact infinite. All this would not be useful if there was not also a way to do the prediction using only the kernel. Indeed this is possible. Recall that the classifier predicts $y = \\phi(x)^T \\mathbf{w}^*$ which, using (2), can be expressed as\n$$y = \\phi(x)^T \\phi(X)^T \\alpha = \\sum_{n=1}^{N} \\kappa (x, x_n) \\alpha_n.$$\n\nI.e., we can express the prediction in terms of the kernel function applied to the new feature vector and the data vector in the original space and do not need to go into the augmented space.\nFrom this expression we can also clearly see that although the classifier in the extended space $\\phi(x)$ is linear, it works at the decision regions in the original space $x$ it is non-linear.\n\nProperties of kernels: Mercer\u2019s Condition\n\nA natural question is the following: how can we ensure that there exists a $\\phi$ corresponding to a given kernel function $\\kappa$?",
    "I.e., how do we ensure that the kernel function is an inner-product in some feature space? \nMercer's condition states that this is true if and only if the following two conditions are fulfilled. In the following, given the kernel function $\\kappa$ and some arbitrary input set $\\{x_i\\}_{i=1}^n$, let $K$ be the associated kernel matrix, $K_{ij} = \\kappa(x_i, x_j)$.\n\n1. The kernel function $\\kappa$ must be symmetric, i.e. $\\kappa(x, x') = \\kappa(x', x)$; equivalently, the kernel matrix $K$ must be symmetric for all possible input sets.\n\n2. The kernel matrix $K$ must be positive semi-definite for all possible input sets.",
    "Machine Learning Course - CS-433\n\nNeural Nets - Training: SGD and Backpropagation\n\nNovember 09, 2022\n\nchanges by Nicolas Flammarion 2021/2020; changes by R\u00e9mi lepriol 2019; 2018; 2017; @R\u00fcdiger Urbanke 2016\nLast updated on: November 7, 2022",
    "Motivation\n\nRecall the structure of a neural network. For your convenience it is shown again in Figure 1. Assume that our task is regression. I.e., we have a training set $S_t = \\{(x_n, y_n)\\}$. Let $f(x)$ be the function that is represented by the nn (including the last layer). I.e., $f(x)$ is the output of the nn. Let us assume that we use our standard cost function\n\n\\[\nL = \\frac{1}{N} \\sum_{n=1}^{N} (y_n - f(x_n))^2.\n\\]\n\nWe might want to add a regularization term to avoid over-fitting, but this term is trivial to compute and to take into account. Therefore, we omit such a regularization term from our discussion in this lecture.",
    "Given our training set $St$, our task is to train the network to minimize the cost function. **Training** here means choosing the parameters of the net, namely the **weights** of the edges and the **bias terms** in order to minimize the cost function. Our go-to technique for training models is stochastic gradient descent. We have seen how it works for simple linear regression models but also for the matrix factorization problem. It is also a natural candidate for training neural nets and the current state-of-the-art. Contrary to some other optimization problems we encountered this problem is not convex. In fact, we expect it to have many local minima. We therefore have no guarantee that gradient descent will get close to an optimal solution for the training set.\n\nIn addition, we have to worry about **overfitting**. Here the news is better: SGD is known to be **stable** when applied to a NN. Informally this means that the outcome of running SGD will not differ dramatically if we replace a single sample from our training set. More precisely, assume that we run two versions of SGD on the same net and with the same training set, except a single sample that differs in the two training sets.\n\nAssume now that the net is initialized in the same state and that we make the same random choices in the two parallel versions. Then, as long as we do not run for too many rounds, (running a thorough the whole data a constant number over times is OK) the outcome of the two runs will differ only slightly. And, as a consequence, such a stable training algorithm is guaranteed not to overfit, i.e., the training error will be close to the true error.",
    "As always when dealing with gradient descent we compute the gradient of the cost function for a particular input sample (with respect to all weights of the net and all bias terms) and then we take a small step in the direction opposite to this gradient.\n\nAs we will see, computing the derivative with respect a particular parameter amounts to applying the chain rule of Calculus and is therefore familiar to all of us. So why discuss this matter?\n\nSince in general there are many parameters it would not be efficient to do this computation for each parameter individually. We therefore will discuss how to compute all the derivatives jointly in an efficient manner. The algorithm for doing so is very natural and it is called back propagation.\n\n\nCompact Description of Output\n\nLet us start by writing down the output as a function of the input explicitly in compact form. It is natural and convenient to describe the function that is implemented by each layer of the network separately at first. The overall function is then the composition of these functions.\nLet $\\mathbf{W}^{(l)}$ denote the weight matrix that connects layer $l-1$ to layer $l$. The matrix $\\mathbf{W}^{(1)}$ is of dimension $D \\times K$, the matrices $\\mathbf{W}^{(l)}, 2 \\leq l \\leq L$, are of dimension $K \\times K$, and the matrix $\\mathbf{W}^{(L+1)}$ is of dimension $K \\times 1$. The entries of each matrix are given by\n\n$$\nW_{i, j}^{(l)}=w_{i j}^{(l)}.\n$$",
    "where we recall that $w_{ij}^{(l)}$ is the weight on the edge that connects node $i$ on layer $l-1$ to node $j$ on layer $l$.\nFurther, let us introduce the bias vectors $b^{(l)}$, $1 \\le l \\le L+1$, that collect all the bias terms. All these vectors are of length $K$, except the term $b^{(L+1)}$ that is a scalar.\nWith this notation we can describe the function that is implemented by each layer in the form\n\n\\[ x^{(l)} = f^{(l)}(x^{(l-1)}) = \\phi((W^{(l)})^T x^{(l-1)} + b^{(l)}), \\tag{1} \\]\n\nwhere the (generic) activation function $\\phi$ is applied pointwise to the vector.\nThe overall function $y = f(x^{(0)})$ can then be written in terms of these functions as the composition\n\n\\[ f(x^{(0)}) = f^{(L+1)} \\circ \\ldots \\circ f^{(2)} \\circ f^{(1)}(x^{(0)}). \\]\n\n**Cost Function**\n\nThe cost function can be written as\n\n\\[ \\mathcal{L} = \\frac{1}{N} \\sum_{n=1}^N (y_n - f^{(L+1)} \\circ \\ldots \\circ f^{(2)} \\circ f^{(1)}(x_n))^2. \\]\n\nNote that this cost function is a function of all weight matrices and bias vectors and that it is a composition of all the functions describing the transformation at each layer.\nNote also that the specific form of the loss (squared loss, hinge loss,\u2026) does not really matter for the workings of the back propagation algorithm that we discuss. In the lectures of this week we stick to the square loss. Only the initialization of the back recursion changes if we pick a different loss function.",
    "The Backpropagation Algorithm\n\nIn SGD we compute the gradient of this function with respect \nto one single sample. Therefore, we start with the function\n\n\\[ L_n = (y_n - f^{(L+1)} \\circ \\cdots \\circ f^{(2)} \\circ f^{(1)}(x_n))^2. \\]\n\nRecall that our aim is to compute \n\n\\[ \\frac{\\partial L_n}{\\partial u_i^{(l)}}, \\quad i = 1, \\ldots, L + 1, \\]\n\\[ \\frac{\\partial L_n}{\\partial b_i^{(l)}}, \\quad l = 1, \\ldots, L + 1. \\]\n\nIt will be convenient to first compute two preliminary quan-\ntities. The desired derivatives are then easily expressed in \nterms of those quantities.\n\nLet\n\\[ z^{(l)} = (\\mathbf{W}^{(l)})^T x^{(l-1)} + b^{(l)},  \\]\no\u00f9  $x^{(0)} = x_n$, et $x^{(l)} = \\phi(z^{(l)})$. In words, $z^{(l)}$\nis the input at the l-th layer before applying the activation\nfunction. These quantities are easy to compute by a forward\npass in the network. More precisely, start with $x^{(0)} = x_n$, and \nthen apply this recursion for $ l = 1, \\ldots, L + 1$, first always\ncomputing $z^{(l)}$ via (2) and then computing $x^{(l)} = \\phi(z^{(l)})$.\nFurther, let\n\n\\[ \\delta_j^{(l)} = \\frac{\\partial L_n}{\\partial z_j^{(l)}}. \\]",
    "Let $\\delta^{(l)}$ be the corresponding vector at level $l$. Whereas the quantities $z^{(l)}$ were easily computed by a forward pass, the quantities $\\delta^{(l)}$ are easily computed by a backwards pass:\n$$\n\\delta_j^{(l)} = \\frac{\\partial C_n}{\\partial z_j^{(l)}} = \\sum_k \\frac{\\partial C_n}{\\partial z_k^{(l+1)}} \\frac{\\partial z_k^{(l+1)}}{\\partial z_j^{(l)}} = \\sum_k \\delta_k^{(l+1)} W_{jk}^{(l+1)} \\phi' (z_j^{(l)}).\n$$\nIn vector form we can write this as\n$$\n\\delta^{(l)} = (W^{(l+1)})^t \\odot \\phi' (z^{(l)}),\n$$\nwhere $\\odot$ denotes the Hadamard product (the pointwise multiplication of vectors).\n\nNow that we have both $z^{(l)}$ and $\\delta^{(l)}$ let us get back to our initial goal. Note that\n$$\n\\frac{\\partial C_n}{\\partial w_{ij}^{(l)}} = \\sum_k \\frac{\\partial C_n}{\\partial z_k^{(l)}} \\frac{\\partial z_k^{(l)}}{\\partial u_{ij}^{(l)}} = \\sum_k \\delta_k^{(l)} \\frac{\\partial z_k^{(l)}}{\\partial u_{ij}^{(l)}} = \\sum_k \\delta_k^{(l)} \\frac{\\partial}{\\partial u_{ij}^{(l)}} \\left( \\sum_j w_{ik}^{(l)} y_j^{(l-1)} \\right) = \\delta_i^{(l)} y_j^{(l-1)}.\n$$\nWhy could we drop the sum in the above expression? When we change the weight $w_{ij}^{(l)}$ then it only changes the sum $\\sum_j^{(l)}$. All other sums at level $l$ stay unchanged.\n\nIn a similar manner,\n$$\n\\frac{\\partial C_n}{\\partial b_j^{(l)}} = \\sum_k \\frac{\\partial C_n}{\\partial z_k^{(l)}} \\frac{\\partial z_k^{(l)}}{\\partial b_j^{(l)}} = \\sum_k \\delta_k^{(l)} \\frac{\\partial}{\\partial b_j^{(l)}} \\left( \\sum_i w_{ik}^{(l)} y_i^{(l-1)} + b_j^{(l)} \\right) = \\delta_1^{(l)} y_j^{(l-1)} = \\delta_i^{(l)} y_j^{(l-1)}.\n$$",
    "Summary of Backpropagation Algorithm for Computing the Derivatives\n\nWe are given a nn with $L$ hidden layers. All weight matrices $W(l)$ and bias vectors $b(l)$, $l = 1, \\cdots, L + 1$, are fixed. We are given in addition a sample $(x_n, y_n)$. We want to compute the derivatives\n$$\n\\frac{\\partial L_n}{\\partial W_{ij}(l)}, \\quad \\frac{\\partial L_n}{\\partial b_{j}(l)}, \\quad l = 1, \\cdots, L + 1,\n$$\nwhere\n$$\nL_n = (y_n - f^{(L+1)} \\circ \\cdots \\circ f^{(2)} \\circ f^{(1)}(x_n))^2.\n$$\n\nForward Pass: Set $x^{(0)} = x_n$. Compute for $l = 1, \\cdots, L + 1$,\n$$\nz^{(l)} = (W^{(l)})^T x^{(l-1)} + b^{(l)}, \\quad x^{(l)} = \\phi(z^{(l)}).\n$$\n\nBackward Pass: Set $\\delta^{(L+1)} = -2(y_n - x^{(L+1)})g'(z^{(L+1)})$. If we are using a loss other than the squared loss, this initialization changes and this is the only change. Also note that the expression $g'(.)$ refers to the derivative of the activation function used in the output layer. So if we are using a different activation function in the last layer (as we often do) use the appropriate derivative at this point. Compute for $l = L, \\cdots, 1$,\n$$\n\\delta^{(l)} = (W^{(l+1)}\\delta^{(l+1)}) \\odot g'(z^{(l)}).\n$$\n\nFinal Computation: For all parameters compute\n$$\n\\frac{\\partial L_n}{\\partial W_{ij}(l)} = \\delta^{(l)}_j x^{(l-1)}_i, \\quad \\frac{\\partial L_n}{\\partial b_{j}(l)} = \\delta^{(l)}_j.\n$$",
    "Now that we have the gradient with respect to all parameters, the SGD algorithm makes a small step in the direction opposite to the gradient, then picks a new sample $(x_n, y_n)$, and repeats.\n\nOne final note. In our next lecture we will encounter networks (convolutional neural nets) where several edges share the same weight or bias. The advantage of doing so is that the net has fewer parameters and so might be easier to train with a given amount of data. How do we proceed then. We can still compute the gradient in such scenarios using the backpropagation algorithm: Write down the network pretending that all the parameters are independent. Run the backpropagation algorithm. The gradient for a particular parameter for the model where some weights are equal is now just the sum of the gradients (of the model where weights are independent) of all the edges that share the same weight.",
    "Machine Learning Course - CS-433\n\nNeural Nets \u2013 Regularization,\nData Augmentation, and\nDropout\n\nNov 15, 2022\n\nchanges by Nicolas Flammarion 2021, 2020, changes by R\u00e9mi Leblond 2019,2018,2017;\n\u00a9Didier Urbano 2016\nLast updated on: November 14, 2022\n\nEPFL",
    "**Regularization**\n\nWe have seen that for standard regression/classification tasks it is common to add a regularization term when learning. The same is true for neural networks. E.g., we might want to add a term of the form\n$$\n\\frac{1}{2} \\sum_{l=1}^{L+1} \\mu^{(l)} \\| \\mathbf{W}^{(l)} \\|_F^2,\n$$\nwhere $\\mu^{(l)}$ is a non-negative constant that can depend on the layer. Note that it is common not to penalize the bias terms but only the weights. \n\nSuch a regularization term favors small weights and, combined with the right constants $\\mu^{(l)}$, can avoid overfitting. How does the gradient descent algorithm change if we add this form of regularization? Assume that we use the same constant in all layers, i.e., $\\mu^{(l)} = \\mu$. Let $\\Theta = \\{ \\mathbf{W} \\}$ be the weight of the edge going from node i at layer l - 1 to node j at layer l and let t be discrete time, increasing by one in each update step. We then get the update rule\n$$\n\\Theta[t+1] = \\Theta[t] - \\eta \\frac{\\partial}{\\partial \\Theta} \\left( \\mathcal{L} + \\frac{\\mu}{2} \\left| \\Theta \\right| \\right) \\quad \\text{step size} \\quad \\text{grad.} \\quad \\text{data/regularization}\n$$\n$$\n= (1-\\eta \\mu)  \\Theta[t] - \\eta \\nabla \\mathcal{L}.\n$$\nWe see that in one update step the weight is decreased by a factor $1-\\eta\\mu$ and in addition we add a small step in the\n\n1This discussion is not restricted to neural nets but apples generally. We just happen to discuss this topic in the context of neural nets.",
    "negative direction of the gradient. We say that regularization leads to weight decay.\n\nAnother popular method (Hinton et al, 2013) is not to put a penalty on the square of the $L_2$ norm of the weights, but rather ask that the weight vector must have an $L_2$ norm more than a constant, call it $r$. This can be easily incorporated into the gradient descent algorithm as follows. After each gradient step check whether the $L_2$ norm of the weight vector is above $r$ or not. If it is, rescale the whole weight vector so that it has $L_2$ norm equal to $r$. This rescaling operation is trivial for the $L_2$ norm. The resulting algorithm is called the projected gradient descent algorithm (since we project after the gradient step the weight vector back to the sphere of radius $r$ if necessary).\n\nAs a side remark - if we had added a regularization term which is the $L_1$ norm of the weight vector then this projection is not nearly as easy. But fortunately for neural nets the $L_2$ norm is the most useful regularization.\n\n## Dataset Augmentation\n\nData is scarce and valuable and the more data we have the better we can train. In some instances we can generate new data from the data we are given.\n\nConsider a classification task with training set $S_t = \\{(x_n, y_n)\\}$. Assume that there exists a transformation $\\tau : \\mathbb{R}^D \\rightarrow \\mathbb{R}^D$ that keeps the labels unchanged.\n\nE.g., consider a hand-writing recognition task. We are given small squares each containing a digit from 0 to 9. The absolute position of the digit inside the square and",
    "the exact orientation of the digit do not matter and can be changed without changing the label. We can therefore take the data we are given, create variants of it, and add it to the date. Figure 1 shows some characters from the MNIST data set. Figure 2 shows some rotated variants and Figure 3 shows some shifted variants. This way\n\nwe can significantly increase our data which helps in training. In addition, if we train our network on this augmented data set then the network will automatically learn to become invariant to these transformations.",
    "These transformations, if they exist, are very task specific. If we consider image recognition task some other possible transformations are cropping or resizing. More subtle, we can use the PCA and \"compress\" the image by only keeping the components corresponding to the largest singular values. This changes the photo globally but introduces only a minimal distortion (in the $L_2$ sense). In a similar sense, we can add some small amount of noise to our data. There is another way in which we can \"augment\" our data. Assume that we have several distinct but related tasks. In this case we can train a network jointly whose \"core\" is used jointly for all tasks and where only the last layer is task specific. This is shown in Figure 4. The idea here is that for related tasks the same features are useful for the task.\n\nDropout\n\nDropout is a method both to avoid overfitting as well as to do model averaging (Hinton et al, 2012). By now, many variants have been proposed. Here is the original version.",
    "Define the probability $p_i^{(l)}$. It is the probability of \"keeping\" the node $i$ in layer $l$. Typical values are $p_i^{(0)} = 0.8$ (i.e., we keep in expectation 80 percent of all input nodes) and $p_i^{(l)} = 0.5$ for $l \\ge 1$, (i.e., we keep in expectation 50 percent of all hidden nodes).\nAt every training step decide for each node $i$ at level $l$ according to the probability $p_i^{(l)}$ whether to keep this node or not. This defines a \"subnetwork.\" Run one step of SGD (or perhaps a minibatch) and update the weights. Iterate until training is done.\nFor the prediction phase several variants are possible. Either generate $K$ subnets in the same manner as before, predict for each and average the prediction. Alternatively use the whole network for the prediction. But in this case scale the output of node $i$ at level $l$ by the factor $p_i^{(l)}$. This guarantees that the expected input at each node stays the same as the expected input during training.\nThere are two benefits to this \"dropout\" procedure. First,",
    "it has been observed that this procedure limits overfitting. Intuitively, nodes cannot \u201crely\u201d on other nodes being present. Second, note that there is an exponential number of \u201csub-networks.\u201d This is shown in Figure 5 for a very small toy network. The effect of dropout is that we are performing an average over several (sub)networks. We either do this explicitly by running over several of them, computing the output, and then average. Or we do this implicitly by using the whole network but with reduced weights. We therefore get the advantage that comes with model averaging. Averaging over many models is a standard ML trick and it is called bagging. It typically leads to improved performance. But dropout is quite different from standard bagging since we do not train $K$ networks and then average. Rather, all these networks share the same weights. In fact, this characteristic seems to be an important component to explain their good performance.\nIn dropout we remove whole nodes. It is of course also possible to remove individual edges independently from each other.",
    "I do not see any worded content from the image nor any equations in math delimiters.",
    "Machine Learning Course - CS-433\n\nK-Means Clustering\n\nNov 23, 2022\n\nMartin Jaggi\nLast updated on: November 28, 2022\ncredits to Mohammad Emtiyaz Khan & R\u00fcdiger Urbanke",
    "Clustering\nClusters are groups of points whose inter-point distances are small compared to the distances outside the cluster.\n\nThe goal is to find \u201cprototype\u201d points $\\mu_1, \\mu_2, \\ldots, \\mu_K$ and cluster assignments $z_n \\in \\{1, 2, \\ldots, K\\}$ for all $n = 1, 2, \\ldots, N$ data vectors $x_n \\in \\mathbb{R}^D$.\n\nK-means clustering\nAssume $K$ is known.\n\n\\[\n\\min_{Z, \\mu} \\mathcal{L}(Z, \\mu) = \\sum_{n=1}^N \\sum_{k=1}^K z_{nk} \\|x_n - \\mu_k\\|_2^2\n\\]\n\ns.t. $\\mu_k \\in \\mathbb{R}^D, z_{nk} \\in \\{0, 1\\}, \\sum_{k=1}^K z_{nk} = 1,$\n\nwhere $Z = [z_{n1}, z_{n2}, \\ldots, z_{nK}]^T$\n$z = [z_1, z_2, \\ldots, z_N]^T$\n$\\mu = [\\mu_1, \\mu_2, \\ldots, \\mu_K]^T$\n\nIs this optimization problem easy?",
    "Algorithm: Initialize $\\mu_k$ $\\forall k$,\nthen iterate:\n\n1. For all $n$, compute $z_n$, given $\\mu$.\n2. For all $k$, compute $\\mu_k$, given $z$.\n\nStep 1: For all $n$, compute $z_n$, given $\\mu$.\n\n$$\nz_{nk} =\n\\begin{cases} \n1 & \\text{if } k = \\arg \\min_{j=1,2,...K} ||x_n - \\mu_j||^2_2 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\n\nStep 2: For all $k$, compute $\\mu_k$, given $z$.\nTake derivative w.r.t $\\mu_k$ to get:\n\n$$\n\\mu_k = \\frac{\\sum_{n=1}^N z_{nk} x_n}{\\sum_{n=1}^N z_{nk}}\n$$\n\nHence, the name \u2018K-means\u2019.",
    "Summary of K-means\nInitialize $\\mu_k$ $\\forall k$, then iterate:\n1. For all $n$, compute $z_n$ given $\\mu$.\n\\[ z_{nk} = \\begin{cases} \n1 & \\text{if } k = \\arg \\min_j \\|\\mathbf{x}_n - \\mu_j \\|^2_2 \\\\\n0 & \\text{otherwise} \n\\end{cases} \\]\n\n2. For all $k$, compute $\\mu_k$ given $z$.\n\\[ \\mu_k = \\frac{\\sum_{n=1}^{N} z_{nk} \\mathbf{x}_n}{\\sum_{n=1}^{N} z_{nk}} \\]\n\nConvergence to a local optimum is assured since each step decreases the cost (see Bishop, Exercise 9.1).",
    "Coordinate descent\nK-means is a coordinate descent algorithm, where, to find $\\min_{z,\\mu} L(z, \\mu)$, we start with some $\\mu^{(0)}$ and repeat the following:\n\n$$\nz^{(t+1)} := \\arg \\min_z L(z, \\mu^{(t)})\n$$\n\n$$\n\\mu^{(t+1)} := \\arg \\min_\\mu L(z^{(t+1)}, \\mu)\n$$",
    "Examples\n\nK-means for the \u201cold-faithful\u201d dataset (Bishop\u2019s Figure 9.1)",
    "Data compression for images (this is also known as vector quantization).\n\nProbabilistic model for K-means",
    "K-means as a Matrix Factorization\n\nRecall the objective\n\n\\[\n\\min_{z, \\mu} L(z, \\mu) = \\sum_{n=1}^{N} \\sum_{k=1}^{K} z_{nk} \\| x_n - \\mu_k \\|_2^2\n\\]\n\n\\[\n= \\| X^T - MZ^T \\|_{Frob}^2\n\\]\n\ns.t. $\\mu_k \\in \\mathbb{R}^D,$\n\n$z_{nk} \\in \\{0,1\\}, \\sum_{k=1}^{K} z_{nk} = 1.$\n\nIssues with K-means\n\n1. Computation can be heavy for large $N, D$ and $K$.\n\n2. Clusters are forced to be spherical (e.g. cannot be elliptical).\n\n3. Each example can belong to only one cluster (\"hard\" cluster assignments).",
    "Machine Learning Course - CS-433\n\nRegression\n\nSept 20, 2022\n\nMartin Jaggi \nLast updated on: September 20, 2022\ncredits to Mohammad Bashyar Khaza\n\nEPFL",
    "What is regression?\nRegression is to relate input variables to the output variable, to either predict outputs for new inputs and/or to understand the effect of the input on the output.\n\nDataset for regression\nIn regression, data consists of pairs $(x_n, y_n)$, where $y_n$ is the n\u2019th output and $x_n$ is a vector of $D$ inputs. The number of pairs $N$ is the data-size and $D$ is the dimensionality.\n\nExamples of regression",
    "Two goals of regression\n\nIn **prediction**, we wish to predict the output for a new input vector, e.g. what is the weight of a person who is 170 cm tall?\n\nIn **interpretation**, we wish to understand the effect of inputs on output, e.g. are taller people heavier too?\n\nThe regression function\n\nFor both the goals, we need to find a function that approximates the output \u201cwell enough\u201d given inputs.\n\n\\[ y_n \\approx f(x_n), \\ \\text{for all} \\ n \\]",
    "Additional Notes\n\nCorrelation $\\neq$ Causation\n\nRegression finds correlation not a causal relationship, so interpret your results with caution.\n\nThis image is taken from www.venganza.org. You can see many more examples at this page: Spurious correlations page.\n\nMachine Learning Jargon for Regression\n\nInput variables are also known as features, covariates, independent variables, explanatory variables, exogenous variables, predictors, regressors. Output variables are also known as target, label, response, outcome, dependent variable, endogenous variables, measured variable, regressands.",
    "Prediction vs Interpretation\n\nSome questions to think about: are these prediction tasks or interpretation tasks?\n\n1. What is the life-expectancy of a person who has been smoking for 10 years?\n\n2. Does smoking cause cancer?\n\n3. When the number of packs a smoker smokes per day doubles, their life span gets cut in half?\n\n4. A massive scale earthquake will occur in California within next 30 years.\n\n5. More than 300 bird species in North America could reduce their habitat by half or more by 2080.",
    "Machine Learning Course - CS-433\n\nBias-Variance Decomposition\n\nOct 12, 2022\n\nminor changes by Nicolas Flammarion 2021,2020, minor changes by  R\u00e9diger Urbanke 2019, changes by Martin Jaggi 2018, changes by R\u00e9diger Urbanke 2017 @Mohammad Emtiyaz Khan and R\u00e9diger Urbanke 2016\n\nLast updated on: October 9, 2022\n\nEPFL",
    "Motivation\n\nLast time we saw how to assess if a given function was good. In particular, we discussed how we can bound the difference between the true risk of the function and the empirical risk. We then used the same ideas and discussed how to choose the \u201cbest\u201d out of a finite number of models. This led us to the idea of splitting the data into a train set and a test set. Our motivation for the model selection problem was that typically we need to optimize hyper-parameters. E.g., in the ridge regression problem the hyper-parameter was $\\lambda$. These hyper-parameters often control the \u201ccomplexity\u201d of the class of models that we allow. \nToday we will focus on how the risk (true or empirical) behaves as a function of the complexity of the model class. This will lead to the important concept of the bias - variance trade-off when we perform the model selection. It will help us to decide how \u201ccomplex\u201d or \u201crich\u201d we should make our model.\nLet us discuss a very simple example. Consider linear regression with a one-dimensional input and using polynomial feature expansion. The maximum degree $d$ regulates the complexity of the class. We will see that the following is typically true.\nAssume that we only allow simple models, i.e., we restrain the degree to be small:\n\n- We then typically will get a large bias, i.e., a bad fit.\n- On the other hand the variance of $L_D(f_S)$ as a function of the random sample $S$ is typically small.",
    "We say that we have high bias but low variance.\nAssume that we allow complex models, i.e., we allow large degrees:\n- We then typically will find a model that fits the data very well. We will say that we have small bias.\n- But we likely observe that the variance of $L_D(fs)$ as a function of the random sample $S$ is large.\n\nWe say that we have low bias but high variance.\n\n**Data Generation Model**\n\nAssume that the data is generated as\n\\[ \ny=f(x)+ \\epsilon,\n\\]\nwhere $f$ is some (arbitrary and unknown) function and $\\epsilon$ is additive noise with distribution $\\mathcal{D}_e$ that is independent from sample to sample and independent from the data. Assume the noise has zero mean (otherwise this constant can be absorbed into $f$). Note that $f$ is in general not realizable, i.e., it is in general not in our model class. \nWe further assume that $x$ is generated according to some fixed but unknown distribution $\\mathcal{D}_x$. Finally, we assume that the loss function $\\ell(\\cdot, \\cdot)$ is the square loss. Let $\\mathcal{D}$ denote the joint distribution on pairs $(x,y)$.\n\n**Error Decomposition**\n\nAs always, we have given some training data $S_{train}$, consisting of i.i.d. samples according to $\\mathcal{D}$. Given our learning",
    "algorithm $\\mathcal{A}$, we compute the prediction function $f_{\\text{strain}} = \\mathcal{A}(\\text{Strain})$. We are ultimately interested in how the true error\n$$\\mathbb{E}_{x \\sim \\mathcal{D}}[(f(x) + \\epsilon - f_{\\text{strain}}(x))^2]$$\nbehaves as a function of the training set $\\text{Strain}$ and the complexity of the model class. But the decomposition we will discuss already applies \u201cpointwise\u201d, i.e., for a single sample $x$. It is therefore simpler if we fix $x_0$, and only consider\n$$(f(x_0) + \\epsilon - f_{\\text{strain}}(x_0))^2.$$\nWe imagine that we are running the experiment many times: we create $\\text{Strain}$, we learn the model $f_{\\text{strain}}$, and then we evaluate the performance by computing the square loss for this fixed element $x_0$. So let us look at the expected value of this quantity:\n$$\\mathbb{E}_{\\text{Strain} \\sim \\mathcal{D}^n, \\epsilon \\sim \\mathcal{D}_\\epsilon}[(f(x_0) + \\epsilon - f_{\\text{strain}}(x_0))^2].$$\nWe will now show that we can rewrite the above quantity as a sum of three non-negative terms and this decomposition",
    "has a natural interpretation. We write\n\n\\[\nE_{S_{\\text{train}} \\sim D, \\mathcal{E} \\sim \\mathcal{D}_{\\mathcal{E}}}\\left[(f(X_0) + \\varepsilon - f_{S_{\\text{train}}}(x_0))^2\\right]\n\\]\n\\[\n= E_{\\mathcal{E} \\sim \\mathcal{D}_{\\mathcal{E}}}[\\varepsilon^2] + E_{S_{\\text{train}} \\sim D}[(f(X_0) - f_{S_{\\text{train}}}(x_0))^2]\n\\]\n\\[\n= \\text{Var}_{\\mathcal{E} \\sim \\mathcal{D}_{\\mathcal{E}}}[\\varepsilon] + E_{S_{\\text{train}} \\sim D}[(f(X_0) - f_{S_{\\text{train}}}(x_0))^2]\n\\]\n\\[\n= \\text{Var}_{\\mathcal{E}[\\varepsilon]} \\text{noise variance} + \\left(f(x_0) - E_{S_{\\text{train}} \\sim D}[f_{S_{\\text{train}}}(x_0)]\\right)^2 \\text{bias}\n+ E_{S_{\\text{train}} \\sim D} \\left[\\left(E_{S_{\\text{train}}' \\sim D}[f_{S_{\\text{train}}'}(x_0)] - f_{S_{\\text{train}}}(x_0)\\right)^2\\right] \\text{variance}\n\\]\n\nNote that here $S'_{\\text{train}}$ is a second training set, also sampled from $D$ that is independent of the training set $S_{\\text{train}}$.",
    "Details:\nIn step (a), we omitted the third term\n\\[ \\mathbb{E}_{S_{train} \\sim \\mathcal{D}, \\varepsilon \\sim \\mathcal{D}_\\varepsilon} [2 \\varepsilon (f(x_0) - f_{S_{train}}(x_0))]. \\]\n\nBut since the noise $\\varepsilon$ is independent from $S_{train}$ we can first average over the noise, and by observing that the noise has mean zero, we see that this term is in fact zero.\n\nFurther, since the noise has zero mean, the second moment is equal to the variance. This explains step (b).\n\nIn step (c) we have added and subtracted the constant term\n\\[ \\mathbb{E}_{S_{train}}[f_{S_{train}}(x_0)] \\]\nto the expression and then expanded the square.\n\nThe expansion yields the two expressions which are stated (termed \u201cbias\u201d and \u201cvariance\u201d). In addition it yields the cross term (to save space we omit the factor 2 and the \u201ctrain\u201d subscript)\n\\[\n\\mathbb{E}_{S \\sim \\mathcal{D}} [(f(x_0) - \\mathbb{E}_{S}[f_{S}(x_0)]) \\cdot (\\mathbb{E}_{S}[f_{S}(x_0)] - f_{S}(x_0))] \n\\]\n\\[\n= (f(x_0) - \\mathbb{E}_{S}[f_{S}(x_0)]) \\cdot \\mathbb{E}_{S}[(\\mathbb{E}_{S}[f_{S}(x_0)] - f_{S}(x_0))] \n= (f(x_0) - \\mathbb{E}_{S}[f_{S}(x_0)]) \\cdot (\\mathbb{E}_{S}[\\mathbb{E}_{S}[f_{S}(x_0)] - \\mathbb{E}_{S}[f_{S}(x_0)]) \n= 0. \n\\]",
    "Interpretation of Decomposition\n\nEach of the three terms is non-negative. Hence each of them is a lower bound on the true error for the input $x_0$. The noise imposes a strict lower bound on what error we can achieve. This contribution is given by the term $V_{\\text{ar} F_{D_{L} E}}$.\n\nThe bias term is the square of the difference between the actual value $f(x_0)$ and the expected prediction $E_{S_{e}-D_{S F_{S(x_0)}}}$, where the expectation is over the training sets. (E.g. simple models can not fit well, so have a large bias)\n\nThe variance term is the variance of the prediction function. If we consider very complicated models then small variations in the data set can produce vastly different models and our prediction for an input $x_0$ will vary widely.\n\nExamples\n\nThe following four figures are taken from the book by James, Witten, Hastie, and Tibshirani (Introduction to Statistical Learning).\n\nThe first three pictures show three different functions each (the true function is the black curve). The first function has medium \u2018\u2018complexity\u2019\u2019, the second is very simple, and the third is the most complicated. In each case, three different predictions are done based on models of increasing complexity.",
    "FIGURE 2.9. Left: Data simulated from $f$, shown in black. Three estimates of $f$ are shown: the linear regression line (orange curve), and two smoothing spline fits (blue and green curves). Right: Training MSE (gray curve), test MSE (red curve), and minimum possible test MSE over all methods (dashed line). Squares represent the training and test MSEs for the five fits shown in the left-hand panel.\n\nFIGURE 2.10. Details are as in Figure 2.9, using a different true $f$ that is much closer to linear. In this setting, linear regression provides a very good fit to the data.",
    "The final figure shows the bias-variance decomposition for each of these three models as a function of increasing complexity.",
    "Additional Notes\n\nYou can find a very readable article about this topic by Scott Fortmann-Roe, here\nscott.fortmann-roe.com/docs/BiasVariance.html\nYou can also find a nice article about the double descent phenomenon by Mikhail Belkin et al, here\nhttps://www.pnas.org/content/116/32/15849.short",
    "Machine Learning Course - CS-433\n\nText Representation Learning\n\nDec 20, 2022\n\nMartin Jaggi\nLast updated on: December 20, 2022",
    "Motivation\nFinding numerical representations for words is fundamental for all machine learning methods dealing with text data.\n\nGoal: For each word, find mapping (embedding)\n\\[ w_j \\mapsto \\mathbf{w}_i \\in \\mathbb{R}^k \\]\n\nRepresentation should capture semantics of the word.\n\nConstructing good feature representations (= \\textit{representation learning}) benefits all ML applications.",
    "The Co-Occurence Matrix\n\nA big corpus of un-labeled text can be represented as the co-occurrence counts\n\n$$\nn_{ij} := \\# \\text{contexts where word } w_i \\text{ occurs together with word } w_j.\n$$\n\nNeeds definition of\n\n- Context e.g. document, paragraph, sentence, window\n- Vocabulary\n  \\[\n  \\mathcal{V} = \\{w_1, \\ldots, w_D\\}\n  \\]\n\nFor words $w_d = 1, 2, \\ldots, D$ and context words $w_n = 1, 2, \\ldots, N$, the co-occurence counts $n_{ij}$ form a very sparse $D \\times N$ matrix.",
    "Learning Word-Representations (Using Matrix Factorization)\n\nFind a factorization of the co-occurrence matrix!\nTypically uses log of the actual counts, i.e. $\\hat{x}_{dn} := \\log(x_{dn})$.\n\nWe will aim to find $\\mathbf{W}, \\mathbf{Z}$ s.t.\n$$\n\\mathbf{X} \\approx \\mathbf{W} \\mathbf{Z}^T.\n$$\n\nSo for each pair of words $(w_d, w_n)$, we try to \u2018explain\u2019 their co-occurrence count by a numerical representation of the two words - in fact by the inner product of the two feature vectors $\\mathbf{w}_d, \\mathbf{z}_n$:\n$$\n\\min_{\\mathbf{W}, \\mathbf{Z}} \\mathcal{L}(\\mathbf{W}, \\mathbf{Z}) := \\frac{1}{2} \\sum_{(d,n) \\in \\Omega} \\left[ \\hat{x}_{dn} - (\\mathbf{W Z}^T)_{dn} \\right]^2\n$$\n\nwhere $\\mathbf{W} \\in \\mathbb{R}^{D \\times K}$ and $\\mathbf{Z} \\in \\mathbb{R}^{N \\times K}$ are tall matrices, having only $K \\ll D, N$ columns.\nThe set $\\Omega \\subset [D] \\times [N]$ collects the indices of non-zeros of the count matrix $\\mathbf{X}$.\nEach row of those matrices forms a representation of a word ($\\mathbf{W}$) or a context word ($\\mathbf{Z}$) respectively.",
    "GloVe  \nThis model is called GloVe, and is a variant of word2vec.  \n  \nWeights $f_{dn}$: Give \u201cimportance\u201d of each entry. Choosing $f_{dn} = 1$ is ok. GloVe weight function:  \n$$f_{dn} = \\min \\{1, (n_{dn} / n_{\\text{max}})^{\\alpha}\\}, \\quad \\alpha \\in [0;1] \\quad \\text{e.g.} \\; \\alpha = \\frac{3}{4}$$  \n  \nChoosing $K$  \n$K$ e.g. 50, 100, 500",
    "Word Analogies\n\nNewspapers\n\n\\[\n\\begin{array}{|c|c|}\n\\hline\nNew York & New York Times \\\\\nSan Jose & San Jose Mercury News \\\\\nBaltimore & Baltimore Sun \\\\\nCincinnati & Cincinnati Enquirer \\\\\n\\hline\n\\end{array}\n\\]\n\nCities\n\n\\[\n\\begin{array}{|c|c|}\n\\hline\nBoston & Boston Celtics \\\\\nHouston & Houston Rockets \\\\\nNashville & Nashville Predators \\\\\n\\hline\n\\end{array}\n\\]\n\n\\[\n\\begin{array}{|c|c|}\n\\hline\nDetroit & Detroit Pistons \\\\\nToronto & Toronto Raptors \\\\\nOakland & Golden State Warriors \\\\\nMemphis & Memphis Grizzlies \\\\\n\\hline\n\\end{array}\n\\]\n\nCountries\n\n\\[\n\\begin{array}{|c|c|}\n\\hline\nAustria & Austrian Airlines \\\\\nBelgium & Brussels Airlines \\\\\nSpain & Spanair \\\\\nGreece & Aegean Airlines \\\\\n\\hline\n\\end{array}\n\\]\n\nCompanies\n\n\\[\n\\begin{array}{|c|c|}\n\\hline\nSteve Ballmer & Microsoft \\\\\nSamuel J. Palmisano & IBM \\\\\nWerner Vogels & Amazon \\\\\n\\hline\n\\]",
    "Training\n- Stochastic Gradient Descent (SGD)\n- Alternating Least-Squares (ALS)\n\nOpen questions:\n- Parallel and distributed training\n- Does regularization help?\n\nAlternative: Skip-Gram Model\n(Original word2vec)\n\nUses binary classification (logistic regression objective), to separate real word pairs $(w_c, w_n)$ from fake word pairs. Same inner product score = matrix factorization.\n\nGiven $w_c$, a context word $w_n$ is\n- real = appearing together in a context window of size 5\n- fake = any word $w'_n$ sampled randomly: Negative sampling (also: Noise Contrastive Estimation)",
    "Learning Representations of Sentences & Documents\n\nSupervised: For a supervised task (e.g. predicting the emotion of a tweet), we can use matrix-factorization (below) or convolutional neural networks (see next weeks).\n\nUnsupervised:\n- Adding or averaging (fixed, given) word vectors\n- Training word vectors such that adding/averaging works well\n- Direct unsupervised training for sentences (appearing together with context sentences) instead of words",
    "FastText\nMatrix factorization to learn document/sentence representations (supervised).\n\nGiven a sentence $s_n = (w_1, w_2, \\ldots, w_m)$, let $\\mathbf{x}_n \\in \\mathbb{R}^{|V|}$ be the bag-of-words representation of the sentence.\n\n\\[\n\\min_{\\mathbf{W}, \\mathbf{Z}} \\mathcal{L}(\\mathbf{W}, \\mathbf{Z}) := \\sum_{s_n \\in \\text {sentence}} f(y_n \\mathbf{WZ}^T \\mathbf{x}_n)\n\\]\n\nwhere $\\mathbf{W} \\in \\mathbb{R}^{1 \\times K}$, $\\mathbf{Z} \\in \\mathbb{R}^{|V| \\times K}$ are the variables, and the vector $\\mathbf{x}_n \\in \\mathbb{R}^{|V|}$ represents our $n$-th training sentence.\nHere $f$ is a linear classifier loss function, and $y_n \\in \\{ \\pm 1 \\}$ is the classification label for sentence $\\mathbf{x}_n$.",
    "Language Models  \n\nSelfsupervised training:  \n\nCan a model generate text? - train classifier to predict the continuation (next word) of given text  \n\n- Multi-class:  \n  Use soft-max loss function with a large number of classes  \n  $D = \\text{vocabulary size}$  \n\n- Binary classification:  \n  Predict if next word is real or fake (i.e. as in word2vec)  \n\nImpressive recent progress using large models, such as transformers  \n(e.g. GPT-2, GPT-3, chatGPT  \nhttps://transformer.huggingface.co/doc/gpt2-large, https://chat.openai.com/ )",
    "Arithmetic:\n\nReasoning:\n\nI got curious about this and tested ChatGPT on last year's exam from our ML course at EPFL (github.com/epfml/ML_course). Chain-of-thought evaluation with a majority vote over 5 trials gives 10/20\n\nlink: chatGPT on ML course exam",
    "Further Pointers\n\n1. word2vec:\ncode: code.google.com/p/word2vec/\npaper:\n\u201cDistributed representations of words and phrases and their compositionality\u201d - T Mikolov, I Sutskever, K Chen, GS Corrado, J Dean. NIPS 2013\n\n2. GloVe:\ncode and vectors: nlp.stanford.edu/projects/glove/\npaper:\n\u201cGloVe: Global Vectors for Word Representation\u201d - Pennington, J., Socher, R., Manning, C. D. EMNLP 2014\n\n3. FastText & sent2vec:\ncode: github.com/facebookresearch/fastText\npapers: \n\u201cBag of Tricks for Efficient Text Classification\u201d - Joulin, A., Grave, E., Bojanowski, P., Mikolov, T. - EC-ACL, 2017.\n\u201cEnriching Word Vectors with Subword Information\u201d - Bojanowski, P., Grave, E., Joulin, A., Mikolov, T. - TACL, 2017.\n\u201cUnsupervised Learning of Sentence Embeddings using Compositional n-Gram Features\u201d - Pagliardini, M., Gupta, P., Jaggi, M. NAACL 2018.\n\n4. Write with transformers:\ncode and demo: transformer.huggingface.co/doc/gpt2-large\n\n5. ChatGPT\ndemo: chat.openai.com/",
    "Machine Learning Course - CS-433\n\nLeast Squares\n\nOct 4, 2022\n\nMartin Jaggi\nLast updated on: October 3, 2022\ncredits to Mohammad Emtiyaz Khan & R\u00fcdiger Urbanke\n\nEPFL",
    "Motivation\nIn rare cases, one can compute the optimum of the cost function analytically. Linear regression using a mean-squared error cost function is one such case. Here the solution can be obtained explicitly, by solving a linear system of equations. These equations are sometimes called the normal equations. This method is one of the most popular methods for data fitting. It is called least squares.\n\nTo derive the normal equations, we first show that the problem is convex. We then use the optimality conditions for convex functions (see the previous lecture notes on optimization). I.e., at the optimum parameter, call it $\\mathbf{w}^*$, it must be true that the gradient of the cost function is 0. I.e.,\n\n$$\\nabla \\mathcal{L}(\\mathbf{w}^*) = 0.$$\n\nThis is a system of $D$ equations.",
    "Normal Equations\n\nRecall that the cost function for linear regression with mean-squared error is given by\n\n$$\\mathcal{L}(\\mathbf{w}) = \\frac{1}{2N} \\sum_{n=1}^N (y_n - \\mathbf{x}_n^\\top \\mathbf{w})^2 = \\frac{1}{2N} (\\mathbf{y} - \\mathbf{Xw})^\\top (\\mathbf{y} - \\mathbf{Xw}),$$\n\nwhere\n\n$$\n\\mathbf{y} = \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_N\n\\end{bmatrix}, \\quad\n\\mathbf{X} = \\begin{bmatrix}\nx_{11} & x_{12} & \\cdots & x_{1D} \\\\\nx_{21} & x_{22} & \\cdots & x_{2D} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{N1} & x_{N2} & \\cdots & x_{ND}\n\\end{bmatrix}.\n$$\n\nWe claim that this cost function is convex in the $\\mathbf{w}$. There are several ways of proving this:\n\n1. Simplest way: observe that $\\mathcal{L}$ is naturally represented as the sum (with positive coefficients) of the simple terms $(y_n - \\mathbf{x}_n^\\top \\mathbf{w})^2$. Further, each of these simple terms is the composition of a linear function with a convex function (the square function). Therefore, each of these simple terms is convex and hence the sum is convex.",
    "2. Directly verify the definition, that for any $\\lambda \\in [0,1]$ and $\\mathbf{w},\\mathbf{w'}$,\n$$\n\\mathcal{L}(\\lambda\\mathbf{w} + (1 - \\lambda)\\mathbf{w'}) - (\\lambda\\mathcal{L}(\\mathbf{w}) + (1 - \\lambda)\\mathcal{L}(\\mathbf{w'})) \\leq 0.\n$$\nComputation: LHS =\n$$\n-\\frac{1}{2N}\\lambda (1 - \\lambda) \\| \\mathbf{X}(\\mathbf{w} - \\mathbf{w'}) \\|_2^2,\n$$\nwhich indeed is non-positive.\n\n3. We can compute the second derivative (the Hessian) and show that it is positive semidefinite (all its eigenvalues are non-negative). For the present case a computation shows that the Hessian has the form\n$$\n\\frac{1}{N}\\mathbf{X}^T \\mathbf{X}.\n$$\nThis matrix is indeed positive semidefinite since its non-zero eigenvalues are the squares of the non-zero singular values of the matrix $\\mathbf{X}$.",
    "Now where we know that the function is convex, let us find its minimum. If we take the gradient of this expression with respect to the weight vector $\\mathbf{w}$ we get\n\n$$\n\\nabla \\mathcal{L}(\\mathbf{w}) = - \\frac{1}{N} \\mathbf{X}^T (\\mathbf{y} - \\mathbf{X}\\mathbf{w}).\n$$\n\nIf we set this expression to 0 we get \nthe normal equations for linear regression,\n\n$$\n\\mathbf{X}^T (\\mathbf{y} - \\mathbf{X}\\mathbf{w}) = 0.\n$$",
    "Geometric Interpretation\n\nThe error is orthogonal to all columns of $X$.\nThe span of $X$ is the space spanned by the columns of $X$. Every element of the span can be written as $u = Xw$ for some choice of $w$. Which element of $span(X)$ shall we take? The normal equations tell us that the optimum choice for $u$, call it $u^*$, is that element so that $y - u^*$ is orthogonal to $span(X)$. In other words, we should pick $u^*$ to be equal to the projection of $y$ onto $span(X)$.\n\nThe following figure illustrates this:",
    "Least Squares\n\nThe matrix $\\mathbf{X}^\\top \\mathbf{X} \\in \\mathbb{R}^{D \\times D}$ is called the Gram matrix. If it is invertible, we can multiply the normal equation by the inverse of the Gram matrix from the left to get a closed-form expression for the minimum:\n\\[ \\mathbf{w}^* = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}. \\]\n\nWe can use this model to predict a new value for an unseen datapoint (test point) $\\mathbf{x}_m$:\n\\[ \\hat{y}_m = \\mathbf{x}_m^\\top \\mathbf{w}^* = \\mathbf{x}_m (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}. \\]\n\nInvertibility and Uniqueness\n\nNote that the Gram matrix $\\mathbf{X}^\\top \\mathbf{X} \\in \\mathbb{R}^{D \\times D}$ is invertible if and only if $\\mathbf{X}$ has full column rank, or in other words $\\text{rank}(\\mathbf{X}) = D$.\n\nProof: To see this assume first that $\\text{rank}(\\mathbf{X}) < D$. Then there exists a non-zero vector $\\mathbf{v}$ so that $\\mathbf{X} \\mathbf{v} = \\mathbf{0}$. It follows that $\\mathbf{v}^\\top \\mathbf{X}^\\top \\mathbf{X} \\mathbf{v} = \\|\\mathbf{X} \\mathbf{v}\\|^2$. This implies that $\\mathbf{Xv} = \\mathbf{0}$, i.e., $\\text{rank}(\\mathbf{X}) < D$.",
    "Rank Deficiency and Ill-Conditioning\n\nUnfortunately, in practice, $X$ is often rank deficient.\n\n- If $D > N$, we always have rank$(X) < D$ (since row rank = col. rank)\n- If $D \\leq N$, but some of the columns $x_d$ are (nearly) collinear, then the matrix is ill-conditioned, leading to numerical issues when solving the linear system.\n\nCan we solve least squares if $X$ is rank deficient? Yes, using a linear system solver.\n\nSummary of Linear Regression\n\nWe have studied three types of methods:\n\n1. Grid Search\n2. Iterative Optimization Algorithms\n(Stochastic) Gradient Descent\n3. Least squares\nclosed-form solution, for linear MSE",
    "Additional Notes\n\nClosed-form solution for MAE\n\nCan you derive closed-form solution for 1-parameter model when using MAE cost function?\nSee this short article: http://www.johnmyleswhite.com/notebook/2013/03/22/modes-medians-and-means-an-unifying-perspective/.\n\nImplementation\n\nThere are many ways to solve a linear system, but using the QR decomposition is one of the most robust ways. Matlab's backslash operator and also NumPy's linalg package implement this in just one line:\n\n$w = \\text{np.linalg.solve}(X, y)$\n\nFor a robust implementation, see Sec. 7.5.2 of Kevin Murphy's book.",
    "Machine Learning Course - CS-433\n\nClassification\n\nOct 18, 2022\n\nMinor changes by Nicola Flammarion 2020, 2021; changes by R\u00e9mi Lepriol 2019, 2018, 2017, 2016; Mohamed Ishteyak Khan 2015\nLast updated on: October 17, 2022",
    "Classification\n\nSimilar to regression, classification relates the input variable $x$ to the output variable $y$, but now $y$ can only take on discrete values. We say that $y$ is a categorical variable.\n\nBinary classification\n\nWhen $y$ can only take on two values, it is called binary classification. Sometimes we refer to the two discrete values abstractly as $y \\in \\{C_1, C_2\\}$. The $C_i$ are called class labels or simply classes. Other times it is more conveniently to assume that $y \\in \\{-1, +1\\}$ or $y \\in \\{0, 1\\}$. Note that even the class labels are real values, there is typically no ordering implied between the two classes.\n\nMulti-class classification\n\nIn a multi-class classification, $y$ can take on more than two values, i.e., $y \\in \\{C_0, C_1, \\dots, C_{K-1} \\}$ for a $K$-class problem. Again, even though there is in general no ordering among these classes, we sometimes use the labels $y \\in \\{0, 1, 2, \\dots, K-1\\}$.\n\nExamples of classification problems\n\nA credit card service must be able to determine whether or not a requested transaction is fraudulent. They might have at their disposal the users IP address (if the transaction",
    "happens on the web), past transaction history, and perhaps some other features.\n\nAn example from the book _Elements of Statistical Learning_ by Hastie, Tibshirani, and Friedman is shown below. We have at our disposal the annual incomes and monthly credit card balances of a number of individuals. The individuals who defaulted on their credit card payments are shown in orange, and those who did not default are shown in blue.\n\nTo consider another example, a person arrives at the emergency room with a set of symptoms that could possibly be attributed to one of three medical conditions. Which of the three conditions does the individual have?\n\n**Classifier**\n\nA classifier will divide the input space into a collection of regions belonging to each class. The boundaries of these re",
    "gions are called decision boundaries. A classifier can be linear or nonlinear. This distinction is less strict than it might seem at first. E.g., if you look at the classifier in the right-hand side of \"Figure 4.1\" you will see that the decision regions are non-linear (not straight lines). But in fact the classifier that led to these region is linear \u2013 we added some non-linear features to the original feature vector (think polynomial basis) before performing the linear classification. The decision boundaries appear non-linear since the plot is made in the original feature space and not the extended feature space.\n\nWhat is the aim of classification?\n\nIn some situations we are interested in classification in itself. This means, we are constructing a predictor based on a training set and are interested in applying this predictor to \"new\" data. Consider e.g. the example of the credit card company that wants to predict if a customer will default or not.\n\nBut in some instances we are interested in more. We would like to \"understand\" the cause. Think e.g. of risk prediction. Not only are we interested to know if a subject will but we would like to understand why somebody is at risk. So we are interested in the \"interpretation\" of the predictor. In particular for this second task it is important to have simple models and to have means of eliminating the features that do not contribute significantly to the prediction.\nConsider \"Figure 4.12\". In this data set various risk factors are given for a particular heart disease. These risk factors are blood pressure (sbp), tobacco usage, family history, obesity,",
    "alcohol consumption, and age. For each pair of these risk factors the figure shows how the cases (people who have the disease) separate from the controls (people who do not have the disease). Such plots can help to decide which risk factors should be included in a model and which might have little predictive power.",
    "Classification as a special case of regression\n\nFrom the very definition we see that classification is a _special case_ of regression. It is a special case since the output is restricted to a small discrete set. So it might appear that there is not much new and that we should simply apply our",
    "standard regression techniques to this special case. \nE.g., we can assign $y = 0$ for $C_1$ and $y = 1$ for $C_2$ and, given a training set $S_{\\text{train}}$, we can use (regularized) least- squares to learn a prediction function $f_{\\text{sin}}(x)$ for this regression problem. To convert the regression into a classification it is then natural to decide on class $C_1$ if $f_{\\text{sin}}(x) < 0.5$ and $C_2$ if $f_{\\text{sin}}(x) > 0.5$.\n\nIn the figure below this approach is applied to the credit-card default problem. To keep things simple we use as feature vector the balance (as we have seen in a previous plot the second feature (the income) does not contain much information). We think of $y = 0$ as \"no default\" and $y = 1$ as \"default\". The dots we see correspond to the various data points and all dots are either on the line $y = 0$ or $y = 1$. The horizontal axis corresponds to the input $x$, the balance.\n\nIn the figure the output $y$ is labeled as probability. This is just a convenient way of interpretation. Since the desired label $y$ is either 0 or 1 we can think of $y$ as the probability of a default.\n\nSo let us now run a regression on the training data $S_{\\text{train}}$. To keep things simple we run a linear regression and learn the linear function $f_{\\text{sin}}(x)$. The result is the blue curve that we indicated.\n\nWe might want to interpret the value $f_{\\text{sin}}(x)$ as the probability of a default and then assign a label depending on whether this \"probability\" is smaller or larger than 0.5. Of course, this \"probability\" can be negative or be larger than 1 so such an interpretation has to be taken with a grain of salt.",
    "Why classification is not just a special case of regression\n\nIt is not hard to see that this method can lead to questionable results. Even if the cases and controls are well separated, the general \u201cposition\u201d of the line will depend crucially on how many points are in each class and where these points lie. E.g., if we add a few points with \\( y = 1 \\) and a very large balance this will shift the curve significantly even though only a few points changed. This is clearly not a desirable property. Why does this happen? The squared loss function that we used for regression is not a good match to our objective. We would like that the fraction of misclassified cases is small. But the mean-squared error is only very loosely related to this objective. In particular, the mean-squared error counts positive and negative deviations from the class label equally bad, although only one of them can potentially lead to a misclassification. If we do have a very small mean-squared error then indeed we can guarantee a small classification error",
    "but the opposite is not true \u2013 a regression function can have\narbitrarily large mean-squared error even though the fraction\nof misclassified cases is arbitrarily small. We therefore might\nhave to work \u201cmuch harder\u201d than we should in bringing down\nthe mean-squared error and so to have a guarantee on the\nmisclassification error.\nBased on the above observation, we see that classification\nis not just a special form of regression with a simple loss\nfunction like the mean-squared error.\n\nSome basic ideas of how to perform\nclassification\n\nMany different approaches have been developed over the\nyears of how to efficiently perform classification. Our aim\nright now is not to give an exhaustive account of all possible\ntechniques. Rather, let us quickly discuss some basic ideas.\nWe will come back and discuss those in more detail in later\nlectures.\n\nNearest Neighbor\nIn some cases it is reasonable to postulate that inputs that\nare \u201cclose\u201d are also likely to have the same label attached.\nHere \u201cclose\u201d might e.g. be measured by the Euclidean dis-\ntance. If we believe that this assumption is good, then, giv-\nen a input $x$ and a training set $S_{train}$, we can look for that point\n$x^*$ which is closest to $x$ and an element of $S_{train}$ and then\noutput $y^*$, the label attached to $x^*$.",
    "The good point about such a classifier is that it might work well even in cases where the decision boundaries are very irregular (see the Figure 2.3 below). But, as we will discuss in a later lecture, such a scheme fails miserably in high-dimensions since in this case the geometry renders the notion of \"close by\" meaningless.\n\nThere are many natural generalizations of this concept. Instead of using a single neighbor we can use lets say the $k$ nearest neighbors or we can take a weighted linear combination of elements in our neighborhood. The latter idea leads to smoothing kernels.\n\nLinear decision boundaries\n\nOne starting point is to assume that decision boundaries are linear (hyperplanes). Consider e.g. a binary classification problem and look at schemes where the boundary between",
    "the two classes is a hyperplane. We can ask how to pick this boundary. To keep things simple, assume that there exists a \"separating hyperplane\" i.e., a hyperplane so that no point in the training set is misclassified. \nIn general, there might be many hyperplanes that do the trick (assuming there is at least one). So which one should we pick? \nOne idea is to pick a hyperplane so that the decision has as much \"robustness/margin\" with respect to the training set as is possible. I.e., if we slightly change the training set by \"wiggling\" the inputs we would like that the number of misclassifications stays low.\nIn the figure below (taken from Wikipedia) we see that $H_1$ does not separate the data, but $H_2$ and $H_3$ do. Between $H_2$ and $H_3$, $H_3$ is preferable, since it has a larger \"margin.\"\nThis idea will lead us to support vector machines (SVM) as well as logistic regression.",
    "Non-linear decision boundaries\n\nIn many cases linear decision boundaries will not allow us to separate the data and non-linearities are needed. One option is to augment the feature vector with some non-linear functions. (The kernel trick is a method of doing this in an efficient way. We will learn about this at a later stage.) Another way is to find an appropriate non-linear transform of the input so that the transformed input is then linearly separable. This is what is done when we are using neural networks.\n\nOptimal classification for known generating model\n\nIt is instructive to think about how one could classify in an optimal fashion, i.e., how one could minimize the probability of misclassification, if the distribution of the generating model was known. To be concrete, assume that we know the joint distribution\n\n$p(x, y)$\n\nand that $y$ takes on elements in a discrete set $\\mathcal{Y}$. Given the \"observation\" (input $x$), let $\\hat{y}(x)$ be our estimate of the class label. What is the optimum choice for this function? Note that our estimate is only a function of the input $x$. Further, for a given input $x$, the probability that the \"correct\" label is $y$ is $p(y \\mid x)$, according to our model. So if our estimate is $\\hat{y}(x)$ then we will be correct a fraction $p(\\hat{y}(x) \\mid x)$ of the time. We conclude that if we want to maximize the probability of guessing the correct label then we should choose",
    "the decision rule\n\n\\[\n\\hat{y}(x) = \\arg \\max_{y \\in \\mathcal{Y}} p(y \\mid x).\n\\]\n\nThis is called the maximum a-posteriori (MAP) criterion since we maximize the posterior probability (it is called posterior probability, since it is the probability of a class label after we have observed the input $ \\mathbf{x} $). This classifier is also called the Bayes classifier.\nThe probability of a correct guess is then the average (over all inputs $ \\mathbf{x} $) of this probability, i.e.,\n\n\\[\n\\mathbb{P} \\{ \\hat{y}(\\mathbf{x}) = y \\} =\\int p(\\mathbf{x}) p( \\hat{y}(\\mathbf{x}) \\mid \\mathbf{x}) d\\mathbf{x}.\n\\]\n\nIn practice we do not know the joint distribution $ p(\\mathbf{x}, y) $. But we could use such an approach by using the data itself to learn the distribution (perhaps by assuming that the distribution is Gaussian and then just fitting the parameters from the data).",
    "Machine Learning Course - CS-433\n\nNeural Nets - Convolutional Nets\n\nNov 15, 2022\n\nchanges by Nicolas Flammarion 2022, 2020; changes by B\u00e9riger Urbanke 2019,2018,2017; @B\u00e9riger Urbanke 2016 Last updated on: November 14, 2022",
    "Basic Structure of Convolutional Nets\n\nRecall that for standard neural network every node at level $l$ is connected to every node at level $l-1$. The advantage of this structure is that it is very general and powerful. The disadvantage is that such a network has a large number of parameters and so generally lots of data is needed to train it.\n\nIn some scenarios it is intuitive that \u201clocal\u201d processing of data should suffice. E.g., consider an audio stream given by samples $x^0[n]$. It is natural to process such a stream by running it through a linear time-invariant filter, whose output, call it $x^1[n]$, is given by the convolution of the input $x^0[n]$ and the filter $f[n]$,\n\n$$\nx^1[n] = \\sum_k f[k] x^0[n-k].\n$$\n\nThe filter $f[n]$ is often \u201clocal\u201d, i.e., $f[k] = 0$ for $|k| \\ge K$. Much of signal processing is based on this type of operation. By choosing an appropriate type of filter we can bring out various aspects of the underlying signal. E.g., we can smooth features by averaging or we can enhance differences between neighboring elements by taking a so-called \u201chigh-pass\u201d filter.\n\nWe have essentially the same scenario if we think of a picture. Now the signal $x^0[n,m]$ is two-dimensional and the convolution takes the form\n\n$$\nx^1[n,m] = \\sum_{k,l} f[k,l] x^0[n-k, m-l].\n$$",
    "As before, we can take filters $f[n, m]$ that are \u201clocal\u201d i.e., only have non-zero coefficients for small values of $|n|$ and $|m|$. \n\nThere are two important aspects about this structure. First, the output $x^{(1)}$ at position [n, m] only depends on the value of the input $x^{(0)}$ at positions close to [n, m]. If we use this in a NN then we no longer get a fully connected network but the structure is much more sparse and local. This implies that we have significantly fewer parameters to estimate. Second, this structure implies that we should use the same filter (e.g., not only the same connection-pattern but also the same weights) at every position! This is called weight sharing. Weight sharing drastically reduces the number of parameters further. \n\nFigure 1 shows two layers of a very small NN where we see the difference between a fully connected network and one where connections are sparse and local.  \n\nWhy is it meaningful to use the same filter at every position in the network? Consider e.g. a photo. Photos are inherently \u201cshift invariant.\u201d We can imagine that there is an essentially infinite-sized photo in reality and we are seeing a small portion of it. The portion we are seeing is more or less random and so the exact position of any object in this photo is more or less random as well. It therefore makes sense that we treat each position essentially equally. \n\nLayout\n\nIt is common to lay out the data in a convolutional network according to its \u201cnatural\u201d layout. E.g., if the input is a photo",
    "then it is natural to use a 2D layout, whereas if the data is naturally one-dimensional then it makes sense to use a 1D layout.\n\nHandling of Borders\n\nConsider a 2D case. Assume that we have an input of dimension $N_1 \\times N_2$ and a kernel $f[l,m]$ so that $|f[m,l]| = 0$ if $|l| \\geq K_1$ or $|m| \\geq K_2$. There are several natural ways of dealing with the boundary.\nThe first is to pad the original input data with zeros at the boundary. More precisely, instead of considering the input",
    "of size $N_1 \\times N_2$, consider the input to be of size $(N_1 + 2(K_1 - 1)) \\times (N_2 + 2(K_2 - 1))$ where the \"center piece\" is the original data and there is an additional boundary of width $K_1 - 1$ and $K_2 - 1$ respectively which is set to 0. If we now perform the convolution then the output will again be of size $N_1 \\times N_2$. For obvious reasons this is called zero padding.\n\nThe second option is to compute an output which is only of size $(N_1 - 2(K_1 - 1)) \\times (N_2 - 2(K_2 - 1))$, i.e., to perform the convolution only for positions so that the whole filter lies inside the original data. This is called valid padding. Figure 2 shows this second method.",
    "Multiple Channels\n\nAssume we start with picture, i.e., a 2D structure. It is common to not only compute the output of a single filter but to use multiple filters. The various outputs are called channels. This introduces some additional parameters into the model.\nIf we add several channels we do not end up with a 2D output in the next level but in fact with a 3D output. We proceed in the same fashion in each further stage, computing several channels per input layer in the previous stages. In this manner, we will get more and more channels as we get deeper and deeper into the network. On the other hand the \u201csize\u201d of each picture typically gets smaller and smaller as we proceed through the layers, either due to the handling of the boundary or because we might perform subsampling. The whole structure then looks a little bit like a pyramid. It gets thinner towards the top but the sections become longer and longer (more and more channels). This is shown in Figure 3.\n\nTraining\n\nAs we discussed, there are two aspects that make CNN special. First, only some of the edges are present. This means that the weight matrices are sparse and this does not require any change in the learning steps when we use SGD and backpropagation.\nSecond, weight sharing is used, i.e., many edges use weights that are the same. As we already mentioned in the previous",
    "lecture, with a small modification the back propagation algorithm can still be used to train a CNN with weight sharing: run backpropagation ignoring that some weights are shared, considering each weight on each edge to be an independent variable. Once the gradient has been computed for this network with independent weights, sum up the gradients of all edges that share the same weight. This gives the gradient for the network with weight sharing.\n\nTo see that this is the correct thing to do, consider a simple example. Let $f(x, y, z)$ be a function from $\\mathbb{R}^3 \\rightarrow \\mathbb{R}$. Let $g(x, y) = f(x, y, x)$. In words, $z$ is no longer an independent variable but we set $z = x$. If we now want to compute the gradient\n\n$$\n\\left( \\frac{\\partial g(x, y)}{\\partial x} \\quad \\frac{\\partial g(x, y)}{\\partial y} \\right)\n$$",
    "then we can compute this by first computing\n\\[\n\\left( \\frac{\\partial f(x,y,z)}{\\partial x}\\frac{\\partial f(x,y,z)}{\\partial z} \\right)\n\\]\nand then realizing that\n\\[\n\\left( \\frac{\\partial g(x,y,z)}{\\partial x}\\frac{\\partial g(x,y,z)}{\\partial y} \\right) = \\left( \\frac{\\partial^2 f(x,y,z)}{\\partial x \\partial y} \\frac{\\partial^2 f(x,y,z)}{\\partial z}\\bigg \\vert_{x,y} \\frac{\\partial^2 f(x,y,z)}{\\partial y^2} \\bigg \\vert_{x,y,z} \\right)\n\\]\n\nFFT\nThe convolutional structure can be used in order to compute the output of a CNN very efficiently. Whether this is more efficient than computing the output by directly implementing the sum depends on the size of the filter/kernel.\nTo keep things simple, assume that our data layout is one-dimensional and that each layer is connected via a convolution where we use zero-padding at the boundaries. Let us consider the first layer to be specific. We then have\n\\[\nx^{(1)}[n] = \\sum_k f[k] x^{(0)} [n - k].\n\\]\n\nAssume that $\\left| f[k] \\right| = 0$ for $k \\notin \\{0, \\ldots K - 1 \\}.$ I.e., the filter has at most K non-zero coefficients. And assume that the signal $x^{(0)}[n]$ has length N. Zero-pad both the signal and the filter to the median of length $L$, where $L \\geq N + K -1.$ More precisely, for the filter the first $K$ positions are the non-zero positions of the original filter and the remaining $L - K$ are",
    "zeros. For the signal the first $N$ positions are the non-zero coefficients of the signal and the remaining $L - N$ are zeros. Call the resulting quantities $\\tilde{f}$ and $\\tilde{x}$ respectively. Compute the cyclic convolution of these two signals, i.e., compute\n$$\n\\tilde{x}^{(1)}[n] = \\sum_{k=0}^{L-1} f[k] \\tilde{x}^{(0)}[n - k \\mod L].\n$$\n\nThis convolution is just like the regular one except that we compute indices modulo $L$. A quick check shows that $\\tilde{x}^{(1)}[n]$ (where we used zero-padding to deal with the boundary) and $\\tilde{x}^{(1)}[n]$ are identical for the first $N - K + 1$ positions. But this cyclic convolution can be computed by transforming both the signal as well as the filter into the Fourier domain, multiplying the two, and then converting the result back. This in turn can be accomplished efficiently by means of the Fast Fourier Transform (FFT) in $c \\log_2 (L)$ operations, where $c$ is a small constant.\n\nMore precisely, for a signal $x[n]$ of length $L$, its discrete Fourier Transform (DFT) (also of length $L$) and its inverse are given by\n$$\n\\tilde{x}[k] = \\sum_{n=0}^{L-1} x[n]e^{-j \\frac{2\\pi}{L}kn},\n$$\nand\n$$\nx[n] = \\frac{1}{L} \\sum_{k=0}^{L-1} \\tilde{x}[k]e^{j \\frac{2\\pi}{L}kn}.\n$$",
    "Machine Learning Course - CS-433\n\nLogistic Regression\n\nOct 19, 2022\n\nminor changes by Nicolas Flammarion 2020, 2021, 2022; changes by R\u00fcdiger Urbanke 2019, 2018, 2017, 2016; \u00a9Mohammad Emtiyaz Khan 2015\n\nLast updated on: October 17, 2022\n\nEPFL",
    "Logistic regression\n\nRecall that in the previous lecture we discussed what happens if we treat binary classification as regression with lets say $y = 0$ and $y = 1$ as the two possible (target) values and then decide on the label by looking if the predicted value is smaller or larger than 0.5.\n\nWe have also discussed that it is tempting to interpret the predicted value as probability.\nBut there are problems: (i) the predicted values are in general not in $[0,1]$; further, (ii) very large ($y \\gg 1$) or very small ($y \\ll 0$) values of the prediction will contribute to the error if we use the squared loss, even though they indicate that we are very confident in the resulting classification.\nIt is therefore natural that we transform the predictions that take values in $(-\\infty, \\infty)$ into a true probability by applying an appropriate function. There are several possible such functions. The logistic function\n\n$$\n\\sigma (z) := \\frac{e^{z}}{1+e^{z}}\n$$\n\nis a natural and popular choice, see the next figure.",
    "Consider the binary classification case and assume that our two class labels are $\\{0, 1\\}$. We proceed as follows. Given a training set $S_{\\text{train}}$ we learn a weight vector $\\mathbf{w}$ (we will discuss how to do this shortly) and a \"shift\" (scalar) $w_0$. Given a \"new\" feature vector $\\mathbf{x}$, we predict the (posterior) probability of the two class labels given $\\mathbf{x}$ by means of\n\\[\np(1 \\mid \\mathbf{x}, \\mathbf{w}) = \\sigma(\\mathbf{x}^T \\mathbf{w} + w_0),\n\\]\n\\[\np(0 \\mid \\mathbf{x}, \\mathbf{w}) = 1 - \\sigma(\\mathbf{x}^T \\mathbf{w} + w_0).\n\\]\n\nNote that we predict a real value (a probability) and not a label. This is the reason it is called logistic regression. But typically we use logistic regression as the first step of a classifier. In the second step we quantize the value to a binary value, typically according to whether the predicted probability is larger than $0.5$ or not.\n\nThis can lead to overflows. One work around is to implement this function by first checking the value of $a$ and by treating large (in magnitude) values separately.",
    "ability is smaller or larger than 0.5.\nSo very large and very small (large negative) values of $\\mathbf{X}^{T} w + w_0$ correspond to probabilities $p(1 \\mid \\mathbf{x}, w)$ very close to 1 and 0, respectively.\nThe following figure visualizes the probabilities obtained for a 2-D problem (taken from KPM Chapter 7). More precisely, this is a case with two features and hence two weights that we learn. We see the effect of changing the weight vector on the resulting probability function.\nIt is easy to see what the roles of $w$ and $w_0$ are. The vector $w$ is orthogonal to the \u201csurface of transition\u201d and the $w_0$ allows us to shift the transition point along the vector $w$. E.g., if $w = (1,0)$ and $w_0 = 0$ then the transition between the two levels happens at the $x_1 = 0$ plane. By scaling $w$ we can make the transition faster or slower and by changing $w_0$ we can shift the decision region along the $w$ vector.",
    "At this point it is hopefully clear how we use logistic regression to do classification. To repeat, given the weight vector $\\mathbf{w}$ we predict the probability of the class label 1 to be $p(1 \\,|\\, \\mathbf{x}, \\mathbf{w}) = \\sigma(\\mathbf{ x} ^T \\mathbf{ w} + w_0)$ and then quantize. What we need to discuss next is how we learn the model, i.e., how we find a good weight vector $\\mathbf{w}$ given some training set $S_{\\text{train}}$.\n\nA word about notation\n\nIn the beginning of this course we started with an arbitrary feature vector $\\mathbf{x}$. We then discussed that often it is useful to add the constant 1 to this feature vector and we called the resulting vector $\\mathbf{\\hat{x}}$. We also discussed that often it is useful to add further features and we called then the resulting vec-",
    "tor $\\phi(x)$. Note that in particular for the logistic regression it is crucial that we have the constant terms contained in $x$ since this allows us to \"shift\" the decision region.\n\nWe will assume from now on that the vector $\\mathbf{x}$ always contains the constant term as well as any further features we care to add. This will save us from a flood of notation.\nHence, from now on we no longer need the extra term $w_0$ but the term $\\mathbf{x}^T\\mathbf{w}$ suffices since it contains already the constant.\n\nTraining\n\nAs always we assume that we have our training set $S_\\text{train}$, consisting of iid samples $\\{(x_n, y_n)\\}_{n=1}^N$ sampled according to a fixed but unknown distribution $\\mathcal{D}$.\nExploiting that the samples $(x_n, y_n)$ are independent, the probability of $\\mathbf{y}$ (vector of all labels) given $\\mathbf{X}$ (matrix of all inputs) and $\\mathbf{w}$ (weight vector) has a",
    "simple product form:\n\n\\[ \np(y | \\mathbf{X}, \\mathbf{w}) = \\prod_{n=1}^{N} p(y_n|x_n) \n\\]\n\n\\[\n= \\prod_{n=1}^{N} p(y_n = 1|x_n) \\prod_{n:y_n=0} p(y_n = 0|x_n) \n\\]\n\n\\[\n= \\prod_{n=1}^{N} \\sigma(x_n^T \\mathbf{w})^{y_n} [1 - \\sigma(x_n^T \\mathbf{w})]^{1-y_n} \n\\]\n\nIt is convenient to take the logarithm of this probability to bring it into an even simpler form. In addition we add a minus sign to the expression. In this way our objective will be to minimize the resulting cost function (rather than maximizing it). This is consistent with our previous examples, where we always minimized the cost function. We call the resulting cost function \\(\\mathcal{L}(\\mathbf{w})\\),\n\n\\[\n\\mathcal{L}(\\mathbf{w}) = -\\frac{1}{N} \\sum_{n=1}^{N} y_n \\ln{\\sigma(x_n^T \\mathbf{w})} + (1 - y_n)\\ln{[1 - \\sigma(x_n^T \\mathbf{w})]}\n\\]\n\n\\[\n= \\frac{1}{N} \\sum_{n=1}^{N} [ \\ln{[1 + \\exp(x_n^T \\mathbf{w}})] - y_n x_n^T \\mathbf{w}]\n\\]\n\nIn the last step we have used the specific form of the logistic function \\(\\sigma(x)\\) to bring the cost function into a nice form.",
    "Before we continue note the following. In principle we should have written down the likelihood of the data $(y, \\mathbf{X})$ given the parameter $\\mathbf{w}$, i.e., $p(y, \\mathbf{X} \\mid \\mathbf{w})$. But\n\\[ p(y, \\mathbf{X} \\mid \\mathbf{w}) = p(\\mathbf{X} \\mid \\mathbf{w}) p(y \\mid \\mathbf{X}, \\mathbf{w}) = p(\\mathbf{X}) p(y \\mid \\mathbf{X}, \\mathbf{w}), \\]\nwhere in the second step we have made the natural assumption that the $\\mathbf{X}$ data does not depend on the parameter we choose in our model. Note that this is an assumption and part of our model. But now note that the factor $p(\\mathbf{X})$ is a constant wrt to the choice of $\\mathbf{w}$, and hence plays no role when we apply the maximum likelihood criterion.\n\nMaximum likelihood criterion\n\nRecall what we did so far. Under the assumption that the samples are independent we have written down the likelihood of the data given a particular choice of weights $\\mathbf{w}$. We then choose the weights $\\mathbf{w}$ that maximize this likelihood. Equivalently, we choose the weights that maximize the log-likelihood. This is called the maximum-likelihood criterion. In a final reformulation, we added a negative sign to bring the cost function to our standard form and called it $\\mathcal{L} (\\mathbf{w})$. In this form,",
    "we are looking for the weights $\\mathbf{w}$ that minimize $\\mathcal{L}(\\mathbf{w})$. In formulae, we choose the weight $\\mathbf{w}^*$, so that\n\n$$\n\\mathbf{w}^* = \\arg \\min_{\\mathbf{w}} \\mathcal{L}(\\mathbf{w}).\n$$\n\nAs we discussed in that context of the probabilistic interpretation of the least squares problem, one justification of the maximum-likelihood criterion is that, under some mild technical conditions, it is consistent. I.e., if we assume that the data was generated according to a model in this class and we have i.i.d. samples and we use this procedure to estimate the underlying parameter, then our estimate will converge to the true parameter if we get more and more data. Of course, in practice the data is unlikely being generated in this way and there might not be any probabilistic model underlying it. But nevertheless, this gives our method a theoretical justification.\n\n**Conditions of optimality**\n\nAs we want to minimize $\\mathcal{L}(\\mathbf{w})$, let us look at the stationary points of this function by computing the gradient, setting it to zero, and solving for $\\mathbf{w}$. Note",
    "that\n$$\n\\frac{\\partial \\ln[1 + \\exp(x)]}{\\partial x} = \\sigma(x).\n$$\n\nTherefore\n$$\n\\nabla \\mathcal{L}(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{x}_n (\\sigma(\\mathbf{x}_n^{\\top} \\mathbf{w}) - y_n)\n$$\n$$\n= \\frac{1}{N} \\mathbf{X}^{\\top} [\\sigma(\\mathbf{Xw}) - \\mathbf{y}].\n$$\n\nRecall that by our convention the matrix $\\mathbf{X}$ has $N$ rows, one per input sample. Further, $\\mathbf{y}$ is the column vector of length $N$ which represents the $N$ labels corresponding to each sample.\nTherefore, $\\mathbf{Xw}$ is a column vector of length $N$. The expression $\\sigma(\\mathbf{Xw})$ means that we apply the function $\\sigma$ to each of the $N$ components of $\\mathbf{Xw}$. In this manner we can express the gradient in a compact manner.\n\nThere is no closed-form solution for this equation. Let us therefore discuss how to solve this equation in an iterative fashion by using gradient descent or the Newton method.\n\nConvexity\n\nSince we are planning to iteratively minimize our cost function, it is good to know that this cost func-",
    "Lemma. The cost function\n$$\nL(\\mathbf{w}) = \\frac{1}{N} \\sum_{n=1}^{N} \\ln(1 + \\exp(\\mathbf{x}_n^\\top \\mathbf{w})) - y_n \\mathbf{x}_n^\\top \\mathbf{w}\n$$\nis convex in the weight vector $\\mathbf{w}$.\n\nProof. Recall that the sum (with non-negative weights) of any number of (strictly) convex functions is (strictly) convex. Note that $L(\\mathbf{w})$ is the sum of $2N$ functions. $N$ of them have the form $-y_n \\mathbf{x}_n^\\top \\mathbf{w}$, i.e., they are linear in $\\mathbf{w}$ and a linear function is convex. Therefore it suffices to show that the other $N$ functions are convex as well. Let us consider one of those. It has the form $\\log(1 + \\exp(\\mathbf{x}^\\top \\mathbf{w}))$. Note that $\\ln(1 + \\exp(z))$ is convex \u2013 it has first derivative $\\sigma(z)$ and second derivative \n$$\n\\frac{\\partial^2 \\ln(1 + \\exp(z))}{\\partial z^2} = \\frac{\\partial \\sigma(z)}{\\partial z} = \\sigma(z)(1 - \\sigma(z)),\n$$\nwhich is non-negative.\n\nThe proof is complete by noting that ln(1+exp($\\mathbf{x}^\\top \\mathbf{w}$)) is the composition of a linear function with a convex function, and is therefore convex.\n\nNote: Alternatively, to prove that a function is convex (strictly convex) we can check that the Hessian\n",
    "(matrix consisting of second derivatives) is positive semi-definite (positive definite). We will do this shortly.\n\nGradient descent\n\nAs we have done for other cost functions, we can apply a (stochastic) gradient descent algorithm to minimize our cost function. E.g., for the batch version we can implement the update equation\n$$\n\\mathbf{w}^{(t+1)} := \\mathbf{w}^{(t)} - \\gamma(t) \\nabla \\mathcal{V}(\\mathbf{w}^{(t)}),\n$$\nwhere $\\gamma(t) > 0$ is the step size and $\\mathbf{w}^{(t)}$ is the sequence of weight vectors.\n\nNewton's method\n\nThe gradient method is a first-order method, i.e., it only uses the gradient (the first derivative). We get a more powerful optimization algorithm if we also use the second order terms. Of course there is a trade-off. On the one hand we need fewer steps to converge if we use second order terms, on the other hand every iteration is more costly. Let us describe now a scheme that also makes use of second order terms. It is called Newton's method.",
    "Hessian of the Log-Likelihood\n\nLet us compute the Hessian of the cost function $\\mathcal{L}(\\mathbf{w})$, call it $\\mathbf{H}(\\mathbf{w})$. What is the Hessian? If $\\mathbf{w}$ has $D$ components then this is the $D \\times D$ symmetric matrix with entries\n$$\nH_{i,j} = \\frac{\\partial^2 \\mathcal{L}(\\mathbf{w})}{\\partial w_i \\partial w_j};\n$$\nRecall that the cost function $\\mathcal{L}(\\mathbf{w})$ is a sum of $N$ terms, all of the same form. So let us first compute the Hessian corresponding to one such term. We already computed the gradient of one such term and got\n$$\nx_n \\left( \\sigma (\\mathbf{x}_n^T \\mathbf{w}) - y_n \\right).\n$$\nRecall, that this gradient is a vector of length $D$ (the dimension of the feature vector $\\mathbf{x}$ and hence also the dimension of the weight vector) where the i-th component is the derivative of $\\mathcal{L}(\\mathbf{w})$ with respect to $w_i$. If you look at the above expression you see that this gradient is equal to $\\mathbf{x}$ (a vector) times the scalar $\\left( \\sigma (\\mathbf{x}_n^T \\mathbf{w}) - y_n \\right)$. Note that x does not depend on $\\mathbf{w}$ and neither does $y_n$. The only dependence on $\\mathbf{w}$ is in the term $\\sigma (\\mathbf{x}_n^T \\mathbf{w})$. Therefore, the Hessian associated to one term will be\n$$\nx_n (\\nabla \\sigma (\\mathbf{x}_n^T \\mathbf{w}))^T.\n$$",
    "We have already seen that $\\sigma'(x) = \\sigma(x)(1 - \\sigma(x))$. Therefore, by the chain rule one such term gives rise to the Hessian\n\n$$\\mathbf{x}_n \\mathbf{x}_n^T \\sigma(\\mathbf{x}_n^T \\mathbf{w})(1 - \\sigma(\\mathbf{x}_n^T \\mathbf{w})).$$\n\nIt remains to do the sum over all $N$ samples. Rather than just summing, let us put this again in a compact form by using the data matrix $\\mathbf{X}$. We get\n\n$$\\mathbf{H}(\\mathbf{w}) = \\frac{1}{N} \\mathbf{X}^T \\mathbf{S} \\mathbf{X},$$\n\nwhere $\\mathbf{S}$ is a $N \\times N$ diagonal matrix with diagonal entries\n\n$$S_{nn} := \\sigma(\\mathbf{x}_n^T \\mathbf{w})[1 - \\sigma(\\mathbf{x}_n^T \\mathbf{w})].$$\n\nNote that the diagonal entries of $\\mathbf{S}$ are non-negative. Hence $\\mathbf{H}(\\mathbf{w})$ is non-negative definite. This gives us an alternative proof that our original cost function is convex.\n\n**Newton\u2019s Method**\n\nGradient descent uses only first-order information and takes steps in the direction opposite to the gradient. This makes sense since the gradient points in the direction of increasing function values and we want to minimize the function.",
    "*Newton's method* uses second-order information and takes steps in the direction that minimizes a quadratic approximation. More precisely, it approximates the function locally by a quadratic form and then moves in the direction where this quadratic form has its minimum. The update equation is of the form\n$$\n\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} - \\gamma^{(t)} (\\mathbf{H}^{(t)})^{-1} \\nabla \\mathcal{L}(\\mathbf{w}^{(t)}).\n$$\nWhere does this update equation come from? Recall that the Taylor series approximation of a function (up to second order terms) around a point $\\mathbf{w}^*$ has the form\n$$\n\\mathcal{L}(\\mathbf{w}) \\approx \\mathcal{L}(\\mathbf{w}^*) + \\nabla \\mathcal{L}(\\mathbf{w}^*)^{\\top} (\\mathbf{w} - \\mathbf{w}^*)\n+ \\frac{1}{2} (\\mathbf{w} - \\mathbf{w}^*)^{\\top} \\mathbf{H}(\\mathbf{w}^*)(\\mathbf{w} - \\mathbf{w}^*).\n$$\nThe right-hand side is a local approximation of $\\mathcal{L}(\\mathbf{w})$. Assume that we take the right-hand side to be an exact representation of our cost function. We want to minimize this function. So let us look where the right-hand side takes its minimum value. If we think that this approximation is reasonably good, then it makes sense to move the new weight vector to the position of this minimum.\nLet us take the gradient of the right-hand side and",
    "set it to zero. We get\n$$\\nabla L(w^*) + H(w^*)(w - w^*) = 0.$$\nSolving for $w$ gives us $w = w* - H(w*)^{-1}\\nabla L(w*)$. This corresponds exactly to the stated update equation, except that in this update we have an extra step size $\\gamma$. Why do we need this factor?\nRecall that the right-hand side is only an approximation. Caution therefore dictates that we only move part of the way to the indicated minimum.\n\nRegularized Logistic Regression\n\nAlthough the cost-function for logistic regression is lower bounded by 0 we suggest if the data is linearly separable. In this case there is no finite-weight vector w which gives us this minimum cost function and if we continue to run the optimization the weights will tend to infinity.\nTo avoid this problem, as for standard regression problems, we can add a penalty term. E.g., we consider the cost function\n$$\\arg \\min_w - \\frac{1}{N} \\sum_{n=1}^N \\ln p(y_n | x_n, w) + \\frac{\\lambda}{2} ||w||^2.$$\n\nWhen the data is linearly separable, even if the gradient descent algorithm is not converging to a",
    "finite-weight vector, the direction in which the iterates are diverging to infinity is still very informative: the predictor converges to the direction of the max-margin solution. You can find a very interesting and related article by Nati Srebro here https://www.jmlr.org/papers/volume19/18-188/18-188.pdf",
    "Machine Learning Course - CS-433\n\nGeneralization, Model Selection, and Validation\n\nOct 11, 2022\n\nminor changes by Nicolas Flammarion 2021, 2020, minor changes by Martin Jaggi 2019, changes by Martin Jaggi 2018, 2016, changes by Volkan Cevher 2019, 2017 @Mohamed\n\nLecture Notes 2017\nLast updated on: October 9, 2022\n\nEPFL",
    "Motivation\n\nAssume that your friend has trained a model on some data and now claims to have found the \u201cperfect\u201d regression function $f$. How can you verify this claim and have confidence that $f$ will have good performance? This leads us to the question of generalization and validation.\n\nAs a second motivation consider the following problem. We have seen in ridge regression that the regularization parameter $\\lambda > 0$ can be tuned to reduce overfitting by reducing model complexity,\n$$\n\\min_{\\mathbf{w}} \\frac{1}{2N} \\sum_{n=1}^{N} \\left( y_n - \\mathbf{x}_n^\\top \\mathbf{w} \\right)^2 + \\lambda \\| \\mathbf{w} \\|^2\n$$\nThe parameter $\\lambda$ is a hyper-parameter.\n\nIn a similar manner, we can enrich the model complexity, by augmenting the feature vector $\\mathbf{x}$. E.g., consider a polynomial feature expansion. Here the degree $d$ is a hyperparameter.\n\nTo see a final example consider neural nets. Here we have tens or hundreds of hyperparameters: architecture, width, depth, type of the network etc.\n\nIn all these cases we are faced with the same problem: how do we choose these hyperparameters? This is the model selection problem.",
    "Data Model and Learning Algorithm\n\nIn order to give a meaningful answer to the above questions we first need to specify our data model.\n\nWe assume that there is an (unknown) underlying distribution $\\mathcal{D}$, with range $\\mathcal{X} \\times \\mathcal{Y}$. The data set we see, call it $S$, consists of independent samples from $\\mathcal{D}$:\n\\[ S = \\{(x_n, y_n) : 1 \\leq n \\leq N\\} \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{D}^N \\]\n\nThe learning algorithm takes the data and outputs a model within the class of models that it is given. Often this is done by optimising a cost function. We have seen that we can use e.g. (stochastic) gradient descent or least-squares for the ridge-regression model as an efficient way of implementing this learning. Write $f_S = A(S)$, where $A$ denotes the learning algorithm.\n\nIf we want to indicate that $f_S$ also depends on parameters of the model, e.g., the $\\lambda$ in the ridge regression model, we can add a subscript to write $f_{S, \\lambda}$.\n\nTrue Error, Empirical Error, and Training Error\n\nGiven a model $f$, how can we assess if $f$ is any good? We should compute the expected error over all samples chosen according to $\\mathcal{D}$, i.e., we should \n\\[ L_{\\mathcal{D}}(f) = \\mathbb{E}_{\\mathcal{D}}[\\ell(y, f(x))], \\]\nwhere $\\ell(\\cdot, \\cdot)$ is our loss function. E.g., for ridge regression \n\\[ \\ell(y, f(x)) = \\frac{1}{2} (y - f(x))^2. \\]",
    "The quantity $L_D(f)$ has many names: (true/expected) (risk/loss/error). This is the quantity we are fundamentally interested in, but we cannot compute it since $\\mathcal{D}$ is not known. But we are given some data $S$. It is therefore natural to compute the equivalent empirical quantity\n$$\nL_S(f) = \\frac{1}{|S|} \\sum_{(x_n,y_n) \\in S} \\ell(y_n,f(x_n)). \\tag{1}\n$$\n\nThis is called the (empirical) (risk/loss/error). \n\nThere is one added complication. Assume that we are given the data $S$. If we first learn the model from $S$, i.e. we compute $f_S = \\mathcal{A}(S)$ and then we compute the empirical risk of $f_S$ using the same data $S$ then in fact we are computing \n$$\nL_S(f_S) = \\frac{1}{|S|} \\sum_{(x_n,y_n) \\in S} \\ell(y_n,f_S(x_n)).\n$$\n\nThis is called the training (risk/loss/error) and we have already discussed in previous lectures that this training error might not be representative of the error we see on \"fresh\" samples.\n\nThe reason that $L_S(f_S)$ might not be close to $L_D(f_S)$ is of course overfitting.\n\nSo let us summarize. If somebody hands us a function $f$ then we call the true risk $L_D(f)$ associated to $f$, but we cannot in general compute it. If we have some data $S$ that was not used to determine $f$ then we can compute the empirical risk of $f$ with respect to $S$. This is denoted by $L_S(f)$. We will shortly distinguish this from the quantity $L_S(f_S)$. And if $S$ was used to learn $f$, then we denote it by $f_S$ and call the resulting empirical error the training error, $L_S(f_S)$.",
    "Splitting the Data and Test Error\n\nBefore we go on and explore the relationship between the true risk and the empirical risk, let us first see how we can address the potential overfitting problem that occurs if we train and test the model on the same data.\nProblem: Validating model on the same data subset we trained it on!\nFix: Split the data into a training and a test set (a.k.a. validation set), call them $S_{train}$ and $S_{test}$ respectively. We apply the learning algorithm $\\mathcal{A}$ to the training set $S_{train}$ and compute the function $f_{S_{train}}$. We then compute the error on the test set, i.e.,\n$$\nL_{S_{test}} (f_{S_{train}} )= \\frac{1}{|S_{test}|} \\sum_{(x_n, y_n ) \\in S_{test}} \\ell (y_n, f_{S_{train}} (x_n ))\n$$\nThis is called the (test/validation) (risk/loss/error). Since $S_{test}$ is a \u201cfresh\u201d sample we can hope that $L_{S_{test}} (f_{S_{train}} )$ is close to the quantity $L_{\\mathcal{D}} (f_{S_{train}} )$. \n\nBut we payed a price. We had to split the data and now have less data both for the learning as well as the evaluation (test) task. \n\u201cCross validation\u201d as described below is more efficient in using data, but hard to analyze.\n\nTrue Error, Test Error, and Generalization Error\n\nWe now get back to our original question. Assume that we have a model $f$, and that our loss function $\\ell ( \u22c5 , \u22c5 )$ is bounded,",
    "lets say in $[a,b]$. We are given a test set $S_{test}$ chosen i.i.d. from the underlying distribution $D$ (and this test set was not used to train the model). The test/empirical error is\n\n$$ L_{S_{test}}(f) = \\frac{1}{|S_{test}|} \\sum_{(x_i,y_i) \\in S_{test}} \\ell(y_i, f(x_i)). $$\n\nThe true error is\n\n$$ L_D(f) = E_{(x,y) \\sim D} [\\ell(y, f(x))]. $$\n\nHow far are these apart? This is called the generalization error and it is given by\n\n$$ |L_D(f) - L_{S_{test}}(f)|. $$\n\nFirst note that in expectation they are the same, i.e.,\n\n$$ L_D(f) = E_{S_{test} \\sim D} [L_{S_{test}}(f)], \\tag{2} $$\n\nwhere the expectation is over the samples of the test set. But we need to worry about the variation. We claim that\n\n$$ P \\left[ |L_D(f) - L_{S_{test}}(f)| \\geq \\sqrt{\\frac{(b-a)^2 \\ln(2/\\delta)}{2|S_{test}|}} \\right] \\leq \\delta. \\tag{3} $$\n\nInsights: The error decreases as $O(1/\\sqrt{|S_{test}|})$ with the number test points. The more data points we have therefore, the more confident we can be that the empirical loss we measure is close to the true loss. If we want $\\delta$ to be smaller we only need to increase the size of the test set slightly. \n\nProof of (3):",
    "Since we assumed that each data sample $(x_n, y_n)$ in the test set $S_{test}$ is chosen independently, the associated losses $\\{l_{y_n, f(x_n)}\\}$, given a fixed model $f$, are also i.i.d. random variables, taking values in $[a, b]$ by assumption. Call each such loss $\\Theta_n$. The expected value of $\\Theta_n = l(y_n, f(x_n))$ is equal to the true loss\n\\[ \nL_D(f) = \\mathbb{E}[l(y_n, f(x_n))].\n\\]\n\nThe empirical loss on the other hand is equal to the average of |$S_{test}$| such i.i.d. values. \nWe want to know the chance that the empirical loss $L_{S_{test}}(f)$ deviates from its true value by more than a given constant $\\epsilon$. This is a classical problem addressed in the following lemma.\n\n**Lemma 0.1** (Hoeffding\u2019s inequality). Let $\\Theta_1, \\ldots, \\Theta_N$ be a sequence of i.i.d. random variables with mean $\\mathbb{E}[\\Theta]$ and range $[a, b]$. Then, for any $\\epsilon > 0$,\n\\[\nP\\left[ \\left| \\frac{1}{N} \\sum_{n=1}^N \\Theta_n - \\mathbb{E}[\\Theta] \\right| \\geq \\epsilon \\right] \\leq 2e^{-2N\\epsilon^2/(b-a)^2}.\n\\]\n\nUsing Lemma 0.1 let us show (3). Equating $2e^{-2|S_{test}|\\epsilon^2/(b-a)^2}$ with $\\delta$ we get that $\\epsilon = \\sqrt{\\frac{(b-a)^2 \\ln(2/\\delta)}{2|S_{test}|}}$.\n\n**How to Use This Bound**\n\nLet us summarize. Assume at first that somebody hands you a function $f$ and you have a data set $S$. Then you can assert",
    "that\n$$\n\\mathbb{P} \\left[ L_D(f) > L_S(f) + \\sqrt{\\frac{(b-a)^2 \\ln(2/\\delta)}{2|S|}} \\right] \\leq \\delta.\n$$   \n\nIn words, we can compute a probabilistic upper bound on the true risk since both $L_S(S)$ as well as the error term can be computed with the data at hand.   \nIn the more general case, we are given a data set $S$ and we want to first learn a function and then compute an upper bound on the true risk of the learned function. In this case we should split $S$ into $S = S_{train} \\cup S_{test}$. We then let $f_{S_{train}} = \\mathcal{A}(S_{train})$. Then we can assert that\n$$\n\\mathbb{P} \\left[ L_D(f_{S_{train}}) > L_{S_{test}}(f_{S_{train}}) + \\sqrt{\\frac{(b-a)^2 \\ln(2/\\delta)}{2|S_{test}|}} \\right] \\leq \\delta.\n$$   \nSo also in this case do we get a a computable probabilistic upper bound. In the second case we pay a price for splitting the data and the bound will in general be less tight.\n\nModel selection\n\nLet us now get to our second, related, problem. We are looking for a way to select the hyperparameters of our model, like the parameter $\\lambda$ for the ridge regression problem.   \nWe split out data into a training set $S_{train}$ and a validation set $S_{test}$ and with the former having been generated independently and assumed generated from the same unknown distribution $\\mathcal{D}$. We have in addition a set of values of a parameter of the model, e.g., the parameter $\\lambda$ in the ridge    \n",
    "regression problem. Let these values be \u03bb_k, k = 1, . . . , K. To keep things simple we assume that K is some finite value. We run the learning algorithm K times on the same training set $S_{train}$ to compute the K prediction functions $f_{S_{train},\u03bb_k}$. For each such prediction function we compute the test error $L_{S_{test}} (f_{S_{train},\u03bb_k})$. We then choose that value of the parameter \u03bb which gives us the smallest such test error.\n\nIn the figure below, we plot the test error (red) as well as the training error (blue) for many values of \u03bb (grid search).\n\nThe same procedure can is applied to select other model hyperparameters, such as the degree in case of a polynomial feature expansion.\n\nModel Selection Based on Test Error\n\nIf for all models $f_{S_{train},\u03bb}$ the test error was exactly equal to the true error then it makes sense that we pick the best of these models. But we have seen that even if we compare the",
    "test to the true error of a single function in general there is a difference (the generalization error). And in the model selection problem we use the same test set $K$ times to compute the test error for each of the $K$ models. How confident can we be that the suggested procedure gives us meaningful results? This is a slight extension of our previous analysis.\nAssume hence that we have $K$ models $fk$ given as candidates, $k = 1,..., K$. Again assume that our loss function $l(.,.)$ is bounded in $[a, b]$. Given a test set $S_{test}$ chosen i.i.d. from $\\mathcal{D}$, what is the maximum generalization error, i.e., what is the maximum difference between the true error and the test error?\n\nSimilarly as in the case of a single model (3), we claim that we can now bound the maximum deviation for all $K$ candidates, by\n\n\\[\n\\mathbb{P}\\left[\\max_k \\left| L_{\\mathcal{D}}(f_k) - L_{S_{test}}(f_k) \\right| \\geq \\sqrt{\\frac{(b - a)^2 \\ln \\frac{2K}{\\delta}}{2|S_{test}|}} \\right] \\leq \\delta.\n\\]\n\n(4)\n\nInsights: The error decreases as $\\mathcal{O}(1/{\\sqrt{|S_{test}|}})$ with the number test points. Now that we test $K$ hyper-parameters, our error only goes up by a very small factor which is proportional to $\\ln(K)$. So we can test many different models without incurring a large penalty.\nThe proof of this statement follows (3), which has answered the special case of $K = 1$.\n\nFor a general $K$, if we check the deviations for $K$ models and ask for the probability that at least one such model",
    "we get a deviation of at least $\\epsilon$ then by the union bound this probability is at most $K$ times as large as in the case where we are only concerned with a single instance. I.e., the upper bound becomes $2K e^{-2|S_{\\text{test}}|\\epsilon^2/(\\delta^2(b - a)^2)}$. Hence, equating now $2K e^{-2|S_{\\text{test}}|\\epsilon^2/(\\delta^2(b - a)^2)}$ with $\\delta$ we get that\n\n$$\n\\epsilon = \\sqrt{\\frac{(b - a)^2 \\ln(2K / \\delta)}{2|S_{\\text{test}}|}}\n$$\n\nas stated. Let\n\n$$\nk^* = \\arg \\min_{k} L_D(f_k).\n$$\n\nIn words, $f_{k^*}$ is that function that has the smallest true risk. Further, let\n\n$$\n\\hat{k} = \\arg \\min_{k} L_{S_{\\text{test}}}(f_k).\n$$\n\nIn words, $f_{\\hat{k}}$ is that function that has the smallest empirical risk. Then a little thought shows that\n\n$$\n\\mathbb{P}\\left[L_D(f_{\\hat{k}}) > L_D(f_{k^*}) + 2 \\sqrt{\\frac{(b - a)^2 \\ln(2K / \\delta)}{2|S_{\\text{test}}|}}\\right] \\le \\delta. \\tag{5}\n$$\n\nIn words, if we choose the \"best\" function according to the empirical risk then its true risk is not too far away from the true risk of the optimal choice.\n\nExtension to Infinitely Many Model Choices The basic idea of this bound can be carried over to the case where we have infinitely many models. In this case a more sophisticated concept, called the VC-dimension, is used: as long as we have models with a finite VC-dimension then the bound we can show has the same form, with $K$ replaced by the VC dimension.",
    "Cross-validation\n\nSplitting the data once into two parts (one for training and one for testing) is not the most efficient way to use the data. Cross-validation is a better way.\n\nK-fold cross-validation is a popular variant. Randomly partition the data into $K$ groups. Now train $K$ times. Each time leave out exactly one of the $K$ groups for testing and use the remaining $K-1$ groups for training. Average the $K$ results.\n\nNote: Have used all data for training, and all data for testing, and used each data point the same number of times.\n\nnum 1\n\nrun 1\n\nrun 2\n\nrun 3\n\nrun 4\n\nCross-validation returns an unbiased estimate of the generalization error and its variance.",
    "Additional Notes\n\nProof of Lemma 0.1\n\nInstead of considering the setup in the lemma we can equivalently assume that $E[\\Theta] = 0$ and that the $\\Theta_n$ take values in $[a, b]$, where $a \\le 0 \\le b$. We will show that\n\n\\[P\\{\\frac{1}{N}\\sum_{n=1}^N \\Theta_n \\ge \\epsilon\\} \\le e^{-2N\\epsilon^2/(b-a)^2}.\\]\n\nThis, together with the equivalent bound\n\n\\[P\\{\\frac{1}{N}\\sum_{n=1}^N \\Theta_n \\le -\\epsilon\\} \\le e^{-2N\\epsilon^2/(b-a)^2}\\]\n\nwill prove the claim. We have\n\n\\[P\\{\\frac{1}{N}\\sum_{n=1}^N \\Theta_n \\ge \\epsilon\\} = P\\{e^{t \\sum_{n=1}^N \\Theta_n} \\ge e^{tN \\epsilon}\\}\\]\n\n\\[\\le \\min_{s>0}E[e^{t \\sum_{n=1}^N \\Theta_n}]e^{-tN\\epsilon}\\]\n\n\\[\\le \\min_{s>0}\\prod_{n=1}^N E[e^{t\\Theta_n}]e^{-tN\\epsilon}\\]\n\n\\[\\le \\min_{s>0}E[e^{t\\Theta}]^Ne^{-tN\\epsilon}\\]\n\n\\[\\le \\min_{s>0}(E[e^{tb}]^N e^{-tN\\epsilon}, E[e^{ta}]^N e^{-tN\\epsilon})\\]\n\n\\[\\le \\min_{s>0}(e^{tNb}e^{-tN\\epsilon}, e^{tNa} e^{-tN\\epsilon})\\]\n\n\\[= e^{-N\\epsilon^2/(b-a)^2}\\cdot e^{-2N\\epsilon^2/(b-a)^2}.\\]\n\nHere, step (a) follows from the Markov inequality. In step (b) we have used the fact that the random variables $\\Theta_n$, and",
    "hence the random variables $e^{sX_i}$ are independent so that the expectation of the product is equal to the product of the expectations. Finally, in step (c) we have used the so-called Hoeffding lemma. It states that for any random variable $X$, with $\\mathbb{E}[X] = 0$ and $X \\in [a, b]$ we have\n$$\n\\mathbb{E}[e^{sX}] \\le e^{s^2(b-a)^2/8}.\n$$\n\nTo give a rough outline, consider the convex function $e^{sx}$, $s \\ge 0$. In the range $[a, b]$ it is upper bounded by the chord (the line that is equal to the function at the two boundaries)\n$$\ne^{sx} \\le \\frac{x-a}{b-a} e^{sb} + \\frac{b-x}{b-a} e^{sa}.\n$$\n\nIf we now take the expectation with respect to $X$ and recall that $\\mathbb{E}[X] = 0$ by assumption then we get\n$$\n\\mathbb{E}[e^{sX}] \\le \\frac{b}{b-a} e^{sa} - \\frac{a}{b-a} e^{sb} \\le e^{s^2(b-a)^2/8}.\n$$\n\nThe last step on the right requires several steps but this is now a pure calculus problem and we skip the details.\n",
    "Machine Learning Course - CS-433\n\nGenerative Models\n\nDec 6, 2022\n\nMartin Jaggi\nLast updated on: December 6, 2022\ncredits to Tatjana Chavdarova and Lars Otsdal\n",
    "Motivation\n\nGenerative models model a probability distribution over a set of random variables either explicitly or implicitly. In the latter case, we do not have direct access to the underlying probability distribution, but we can sample according to it.\n\nGenerative Adversarial Networks (GANs, Goodfellow et al. [2014]) are a family of implicit generative algorithms that are fast to sample from. Contrary to single-objective minimization $f:\\mathcal{X} \\to \\mathbb{R}$, The optimization of a GAN is formulated as a differentiable two-player game where the generator $G$ with parameters $\\theta$, and the discriminator $D$ with parameters $\\varphi$, aim at minimizing their own cost function $\\mathcal{L}^G$ and $\\mathcal{L}^D$, respectively, as follows:\n\n$$\n\\theta^* \\in \\arg \\min_{\\theta \\in \\Theta} \\mathcal{L}^G (\\theta; \\varphi)\n$$\n\n$$\n\\varphi^* \\in \\arg \\min_{\\varphi \\in \\Phi} \\mathcal{L}^D (\\theta; \\varphi)\n$$\n\n(2P-G)\n\nWhen $\\mathcal{L}^G = - \\mathcal{L}^D$ the game is called a zero-sum game and (2P-G) is a minimax problem.",
    "Generative Models\n\nGiven a data sample $x$, a discriminative model aims at predicting its label $y$, hence it models the posterior distribution $p(y|x)$. Generative models instead model the distribution $p(x)$ defined over the datapoints $x$. Depending on the type of the generative model we can either evaluate the probability assigned to each datapoint, or sample according to it.\n\nTaxonomy. The following figure depicts the taxonomy of the existing generative methods that are based on maximum likelihood:\n\nThe explicit density generative methods generally model the distribution that describes the probability that the model assigns to each datapoint, while the implicit density generative methods can be further categorized as (i) direct or models, and (ii) cascaded models. Finally, the category containing the flexible density generative models instead provides a way to draw samples.\n\nApplications. Due to the outstanding suitability of the raw data of real-world tasks, a great effort has been dedicated by the research community to designing generative models that are able to model such data distributions in the unusable space. Generative models have been shown useful in a wide range of applications such as data augmentation, e.g., generative adversarial networks [Sutton and Barton, 2018] where aganist as alternative options of outcomes, e.g. to generate diverse samples. Also, generative models are key towards enabling stable training in parametric (Grey et al., 2019) among others.",
    "2-Player vs. Single-objective minimization\n\n1. Standard supervised learning: convex objective\n\n2. Minmax: convex-concave objective\n\n$\\min_{\\theta} \\max_{\\varphi} L(\\theta, \\varphi)$\n\nWe would like to converge to a point called Nash equilibrium (NE). In the context of game theory, NE is a combination of strategies from which, no player has an incentive to deviate unilaterally.",
    "Differential Nash Equilibrium\n\nMore formally, a Nash equilibrium for a continuous game is defined as a point $(\u03b8^*, \u03c6^*)$ where:\n\n$$\n\\mathcal{L}(\u03b8^*, \u03c6) \\leq \\mathcal{L}(\u03b8^*, \u03c6^*) \\leq \\mathcal{L}(\u03b8, \u03c6^*) \\quad \\forall\u03b8, \u03c6.\n$$\n(NE)\n\nSuch points are (locally) optimal for both players with respect to their own decision variable, i.e. no player has the incentive to unilaterally deviate from it.\nIn machine learning we are interested in differential games where $\\mathcal{L}$ is twice differentiable, in which case such NE needs to satisfy slightly stronger conditions. A point $(\u03b8^*, \u03c6^*)$ is a Differential Nash Equilibrium (DNE) of a zero-sum game if:\n\n$$\n\u2207_\u03b8 \\mathcal{L}(\u03b8^*, \u03c6^*) = || \u2207_\u03c6 \\mathcal{L}(\u03b8^*, \u03c6^*) || = 0,\\\\\n\u2207_\u03b8^2 \\mathcal{L}(\u03b8^*, \u03c6^*) \u227d 0, \\quad and \\\\\n\u2207_\u03c6^2 \\mathcal{L}(\u03b8^*, \u03c6^*) \u227c 0.\n$$\n(DNE)\n\nwhere $A \u227d 0$ and $A \u227c 0$ iff A is positive definite and negative definite, respectively*.",
    "Generative Adversarial Networks\n\n1. The discriminator \"distinguishes\" real vs. fake samples:\n\n$$\nD: x \\rightarrow y \\in [0, 1]\n$$\n\n$$\np_z \\text{ known \"noise\" distribution, e.g., } \\mathcal{N}(0, 1)\n$$\n\n$$\np_x \\text{ the real data distribution}\n$$\n\n$$\nD \\text{ mapping } D: x \\rightarrow y \\in [0, 1], \\text{where } y \\text{ is an estimated probability that } x \\sim p_x\n$$\n\n2. The generator aims at fooling the discriminator that its samples are real:\n\n$$\nG \\text{ mapping } G: z \\rightarrow x, \\text{ such that if } z \\sim p_z, \\text{ then hopefully } x \\sim p_x\n$$\n\n$$\np_g \\text{ the \"fake\" data distribution}\n$$",
    "3. Objective.\n\n$$\\min_G \\max_D \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text {data}}}\\left[\\log D(\\mathbf{x})\\right] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}\\left[\\log(1 - D(G(\\mathbf{z})))\\right]$$\n\n- Loss for $D$: distinguish between $\\mathbf{x} \\sim p_{\\text{data}}$ and $\\mathbf{x} \\sim p_g$ (binary classification):\n$$\\mathcal{L}_{\\mathrm{D}}(G, D) = \\max_D \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}} \\left[ \\log D(\\mathbf{x}) \\right] + \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} \\left[ \\log (1 - D(G(\\mathbf{z}))) \\right]$$\n\n- Loss for $G$: fool $D$ that $G(\\mathbf{z}) \\sim p_{\\text{data}}$\n$$\\mathcal{L}_{\\mathrm{G}}(G, D) = \\min_G \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}}\\left[\\log(1 - D(G(\\mathbf{z})))\\right]$$\n(in practice) \n$$ \\max_G \\mathbb{E}_{\\mathbf{z} \\sim p_{\\mathbf{z}}} \\left[ \\log (D(G(\\mathbf{z}))) \\right]$$\n\n4. Theoretical Solution: The optimum is reached when $p_g = p_\\text {data}$ and the optimal value is $- \\log 4$ (proof in function space, see next slides).",
    "KL and JS divergences\n\nBefore proving that at the equilibrium of the above GAN framework $p_g = p_d$ we need to define some measures of similarity between two probability distributions: The KL and JS divergences.\n\nThe Kullback-Leibler (KL) divergence is defined as:\n\\[ D_{KL}(p\\|p_d) := \\int_x \\log \\left( \\frac{p_d(x)}{p_g(x)} \\right) p_d(x) \\, dx . \\]\n\nKL is also called relative entropy, as it measures how one probability distribution is different from a \u201creference\u201d probability distribution, and it is asymmetric.\n\nThe Jensen-Shannon (JS) divergence is defined as:\n\\[ D_{JS}(p\\|q) := \\frac{1}{2} D_{KL} \\left( p \\left\\| \\frac{p+q}{2} \\right. \\right) + \\frac{1}{2} D_{KL} \\left( q \\left\\| \\frac{p+q}{2} \\right. \\right) . \\]\n\nNote that contrary to the KL divergence defined above, the JS divergence is symmetric.",
    "The GAN framework: Equilibrium at $p_g = p_d$\n\nIn the following, we\u2019ll assume the neural network models G and D have infinite capacity, so can represent any probability distribution. We will study the convergence of the loss function in the space of probability density functions.\n\nThe discriminator maximizes:\n\n$$\nL(G, D) = \\int p_d(x) \\log (D(x)) \\, dx \\\\\n+ \\int p_g (z) \\log (1 - D(G(z))) \\, dz \n= \\int p_d(x) \\log (D(x)) + p_g(x) \\log (1 - D(x)) \\, dx \n$$\n\nWhere we used $x = G(z)$, and $p_g$ is the distribution of $x$.\n\nThe above integrand can be written as: $f(y) = a \\log y + b \\log (1 - y)$. To solve for its critical points: $f'(y) = 0$ when $\\frac{a}{y} - \\frac{b}{1 - y} = 0$ gives $y = \\frac{a}{a+b}$. Moreover, if $a, b \\neq 0$ we obtain that $d^2 = a \\frac{1}{y^2} + b \\frac{1}{(1-y)^2} = 0$ is a maximum as $f''(\\frac{a}{a+ b}) < 0$. \n\nHence, optimal discriminator $D^*$ is: \n$$ \nD^*(x) = \\frac{p_d(x)}{p_d(x) + p_g(x)} \n$$",
    "By replacing the optimal discriminator in the above objective, we obtain that the generator minimizes:\n$$\\mathcal{L}(G, D^*) = \\mathbb{E}_{p_d} [\\log D^*(x)] + \\mathbb{E}_{p_g} [\\log(1 - D^*(x))]$$\n$$= \\mathbb{E}_{p_d} [\\log \\frac{p_d(x)}{p_d(x) + p_g(x)}] + \\mathbb{E}_{p_g} [\\log \\frac{p_g(x)}{p_d(x) + p_g(x)}]$$\n$$= \\log 4 + D_{KL}(p_d \\| \\frac{p_d + p_g}{2}) + D_{KL}(p_g \\| \\frac{p_d + p_g}{2})$$\n$$= \\log 4 + 2 \\cdot D_{JS}(p_d \\| p_g)$$\nwhere to obtain the third expression we used the definition of logarithm:\n$$\\log 2 + \\log \\left(\\frac{p_d(x)}{p_g(x) + p_d(x)}\\right)$$\n$$= \\log 2 - \\log \\left(\\frac{p_g(x) + p_d(x)}{p_d(x)}\\right)$$\n$$= \\log 2 - \\log \\left(2 \\cdot \\frac{p_g(x) + p_d(x)}{p_d(x) + p_g(x)}\\right)$$\n$$= \\log 2 - \\log 2 + \\log \\left(\\frac{p_d(x)}{p_d(x) + p_g(x)}\\right)$$\n\nAbove, $D_{KL}$ and $D_{JS}$ again denote the Kullback-Leibler and the Jensen-Shannon divergences (see previous slides).\nThe optimum is reached when $p_g = p_d$ (note $D^* = \\frac{1}{2}$), and the optimal value is $-\\log 4$.",
    "Drawback of using JS divergence for GANs\n\nExample: Let us consider two probability distributions defined on $\\mathbb{R}$: $P: \\delta_0(x)$ and $Q: \\delta_{\\theta}(x)$.\n\nNote that when the supports of the two distributions are disjoint ($\\theta \\ne 0$), we obtain $D_{KL}(P||Q) = +\\infty$, and $D_{JS}(P||Q) = \\log 2$, both yielding non-smooth gradient, making gradient-based methods hard to use [Arjovsky et al., 2017].",
    "Wasserstein Distance\n\nThe previous example motivates the use of the Wasserstein distance (aka Earth mover's distance) in the context of GANs, described next.\n\nWasserstein-1 distance is defined as: \n\n\\[ D_W (p_{\\theta}, p_g) = \\inf_{\\pi \\in \\Pi (p_{\\theta}, p_g)} \\mathbb{E}_{(x,y) \\sim \\pi} [\\| x - y \\|], \\] \n\nwhere $\\Pi (p_{\\theta}, p_g)$ is the set of all possible point probability distributions between $p_{\\theta}$ and $p_g$, whose marginals are $p_{\\theta}$, $p_g$ respect.\n\nIntuitively, the two distributions can be viewed as a mass on each point. The goal is to move these masses so that one distribution can be transformed into the other. As there are infinitely many ways of doing so, $D_W (p_{\\theta}, p_g)$ is the minimum cost we need to spend. The cost is the amount of mass that has to be transported times the distance it has to be moved.\n\nNote that in the above example $D_W (\\delta(x), \\delta(y)) = \\| x - y \\|$ and it provides \"usable\" gradient. However, $D_W$ does not scale with the dimension- ality of the input random variables, as the number of states of the joint probability distribution grows exponentially. Fortunately, it can be alternatively formalized (see next slide).",
    "Wasserstein GAN\n\nDef. $f : \\mathbb{R} \\to \\mathbb{R}$ is called $k$-Lipschitz continuous if $\\exists k \\in \\mathbb{R}$ s.t.\n\\[ |f(x_1) - f(x_2)| \\leq k|x_1 - x_2|, \\quad \\forall x_1, x_2. \\]\n\nThe so called Wasserstein GAN [WGAN, Arjovsky et al., 2017, Gulrajani et al., 2017] replaces the JS divergence with the Wasserstein distance. As the Wasserstein distance is intractable for Deep Neural Nets, WGANs make use of the so called Kantorovich-Rubinstein duality theorem, which tells us that:\n\\[ W(\\mu_p, \\mu_g) = \\sup_{f : ||f||_L \\leq 1} \\mathbb{E}_{\\mathbf{x} \\sim \\mu_p} [f(\\mathbf{x})] - \\mathbb{E}_{\\mathbf{z} \\sim p_z} [f(g(\\mathbf{z}))], \\]\n\nwhere the supremum is over 1-Lipschitz functions $f : \\mathcal{X} \\to \\mathbb{R}$. Its derivation is out of the scope of this course (if interested see proof sketch in the Appendix).\nIn the context of GANs, $f$ is the function represented by the discriminator (called critic in WGAN), yielding:\n\n\\[ \\min_G \\max_{D \\in \\mathcal{D}} \\mathbb{E}_{\\mathbf{x} \\sim p_r} [D(\\mathbf{x})] - \\mathbb{E}_{\\mathbf{z} \\sim p_z} [D(g(\\mathbf{z}))], \\]\n\nwhere $\\mathcal{D}$ is the set of 1-Lipschitz functions.\n",
    "Some GAN variants with Lipschitz Discriminator\n\nThe constraint that the discriminator should be 1-Lipschitz can be enforced in several ways. The table below summarizes some of the GAN variants which enforce such constraint.\n\nWGAN [Arjovsky et al., 2017] uses straightforward weight clipping. [Gulrajani et al., 2017] point out that this may lead to optimization difficulties, and proposed adding an extra penalty term to the training loss of the Discriminator, which penalizes gradients whose norm is higher than 1. As enforcing this for any input is intractable, this is done by considering a line between real and generated points, characterized by an interpolating scheme. [Kodali et al., 2017] also penalizes gradient whose norm is tighter than 1 while considering samples in a region around real data points. Note that DRAGAN & WGAN-GP can automatically enforce the constraints on appropriate regions without dependence on an additional sampler $\\pi_{a}$ (as the loss includes gradient penalty). Miyato et al., 2018 make use of another popular interpretation of the 1-Lipschitz function called Wasserstein-$2$ (as opposed to Wasserstein-$1$ that we have studied so far), and use SVS, a SOTA spectral norm based method instead. The spectral norm of a matrix being its largest singular value, it can be implemented efficiently to the effect that it is no longer hard to use the gradient based optimization approaches to train models. Gulrajani et al., 2017 also presents another variant which combines two discriminators, one of which estimates the largest singular value. In upcoming models with higher resolution images, this has the advantage of tieing the complexity with universal gradient based method rather than any specified sampler $\\pi_{a}$. In a long-run, beside finding theoretical backing, one of the good way to analyze some GAN variants and theirs success could be the convergence of GAN objectives with 1-Lipschitz functions.\n\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\n\\text {Method/Algorithm} & \\mathcal{D}(s) / \\mathcal{G}(s) & \\text {Means of enforcing Lipschitz constraint} \\\\\n\\hline\n\\text {WGAN [Arjovsky et al., 2017]} & \\mathcal{D} & \\text {Gradient clipping} \\\\\n\\hline\n\\text {WGAN-GP [Gulrajani et al., 2017]} & \\mathcal{D}_{1}, \\mathcal{D}_{2} & \\text {Gradient penalty-based norm constraint} \\\\\n\\hline\n\\text {DRAGAN [Kodali et al., 2017]} & \\mathcal{D}_{1}, \\mathcal{D}_{2} & \\text {Gradient penalty based norm constraint but initialized via separate interpolation} \\\\\n\\hline\n\\text {SN-GAN [Miyato et al., 2018]} & \\mathcal{D} & \\text {Spectral norm using Power iteration} \\\\\n\\hline\n\\text {WGAN-div [Gulrajani et al., 2017]} & \\mathcal{D}_{1}, \\mathcal{D}_{2} & \\text {Spectral norm using two power iteration} \\\\\n\\hline\n\\end{array}\n\\]",
    "Alternating-GAN algorithm\n\nIn practice, $G$ and $D$ are parametrized models (typically neural networks), and are optimized with gradient based methods.\n\n$G$: deep neural network $G(z; \\theta)$ with parameters $\\theta$\n\n$D$: deep neural network $D(x; \\varphi)$ with parameters $\\varphi$\n\nIn most GAN implementations $G$ and $D$ have different losses $\\mathcal{L}^G$ and $\\mathcal{L}^D$, resp. In the following, we present the most commonly used algorithm for training GANs.\n\nAlgorithm 1 alternating-GAN Input: dataset $\\mathcal{D}$, known distribution $p_z$, learning rate $\\eta$, generator loss $\\mathcal{L}^G$, discriminator loss $\\mathcal{L}^D$.\n\nInitialize: $\\theta, \\varphi, D, G$\nfor $t = 1$ to $T$ do\n  $\\quad x \\sim p_{\\mathcal{D}}$ (sample real data)\n  $\\quad z \\sim p_z$ (sample noise from $p_z$)\n  $\\quad \\varphi \\gets \\varphi - \\eta \\nabla_{\\varphi} \\mathcal{L}^D (D, G, x, z)$ (update $D$)\n  $\\quad \\theta \\gets \\theta - \\eta \\nabla_{\\theta} \\mathcal{L}^G (D, G, x, z)$ (update $G$)\nend for\nOutput: $\\varphi$\n\nFor simplicity, in Alg.1 we used gradient descent, however in practice GANs are often optimized using Adam [Kingma and Ba, 2015], and developing well performing minimax optimization methods is an active research area.\n\n*Although we minimize both the losses, this notation guarantees the zero-sum game, as the latter holds even $\\mathcal{L}^G = -\\mathcal{L}^D = -\\mathcal{L}$.",
    "**Conditional GAN \u2013 (CGAN)**\n\nMany applications require generative model of a conditional probability distribution (e.g. \u201cin-painting\u201d, segmentation, predicting the next frame of a video etc.). GANs can also generate samples of conditional distribution, called Conditional GAN (CGAN) [Mirza and Osindero, 2014]. In CGANs both the Generator and the Discriminator are conditioned during training by some additional information, typically the class labels (but could also be images e.g. auto-generated edges of an image, conditioning on non-occluded portion so as to generate the occluded part of the image etc.).\n\nWhen conditioning on the class labels, typically one-hot vector representation of the class labels is used (empirically shown to perform better).",
    "GAN architectures for images\n\nIn the context of images synthesis, [Radford et al., 2015] propose specific architectures of the two models, named Deep Convolutional GANs = DCGAN. Notably, the generator uses transposed convolutional layer (a.k.a. fractionally strided convolutions), also informally called \u201cDeconvolution layers\u201d (wrongfully). Simplest way to explain these is that they \u201cswap\u201d the forward and the backward passes of a convolution layer: the forward transposed convolution operation can be thought of as the gradient of some convolution with respect to its input, which is usually how transposed convolutions are also implemented in practice.",
    "Image to image translation\n\nImage Ground truth Output\nImage Ground truth Output\n\nIsola et al. (2016). (C)GAN: automatically detected edges $\\rightarrow$ handbag.\n\nInput Output Input Output Input Output Input Output\n\n\nIsola et al. (2016). generalization of the (C)GAN model trained on edges $\\rightarrow$ photos (see previous figure) to human-drawn sketches.",
    "Conditional Generation of Images\n\n\"A Style-Based Generator Architecture for Generative Adversarial Networks\", CVPR 2019, https://arxiv.org/abs/1812.04948",
    "CycleGAN\n\n$G$ and $F$ contain two mapping functions $G : X \\rightarrow Y$ and $F : Y \\rightarrow X$, and associated adversarial discriminators $D_Y$ and $D_X$. D_Y encourages $G$ to translate $X$ into outputs indistinguishable from domain $Y$, and vice versa for $D_X$. To further regularize the mappings, we introduce two cycle consistency losses that capture the intuition that if we translate from one domain to the other and back again we should arrive where we started: $F(G(X)) \\approx X$ and $G(F(Y)) \\approx Y$. We include these two losses in our full objective in addition to the adversarial losses for each mapping: \n\n$$\\mathcal{L}(G, F, D_X, D_Y) = \\mathcal{L}_{\\text{GAN}}(G, D_Y, X, Y) + \\mathcal{L}_{\\text{GAN}}(F, D_X, Y, X) + \\lambda \\mathcal{L}_{\\text{cyc}}(G, F)$$\n\nwhere\n\n$$\\mathcal{L}_{\\text{cyc}}(G, F) = \\mathbb{E}_{x \\sim p_{\\text{data}}(x)}[\\|F(G(x)) - x\\|_1] + \\mathbb{E}_{y \\sim p_{\\text{data}}(y)}[\\|G(F(y)) - y\\|_1]$$",
    "GAN generated images\n\n512\u00d7512 samples from the class-conditional BigGAN [Brock et al., 2019].",
    "Diffusion models\n\nDiffusion models are another class of generative models that have gained popularity in recent years, both for their enhanced performance and implementation in AI image generators like DALL-E 2, Stable Diffusion, and MidJourney. Unlike GANs, which train two separate models for data generation and discrimination, Diffusion Models work by progressively adding noise to input data and training one single model to estimate the added noise and recover the data.\n\nThe figure above from Ho et al. [2020] describes the steps of the diffusion process, where $x_1, \\dots, x_T$ are latent representations of the input data $x_0$ that shares its dimensions. The forward process (right to left in the image above) consists of a Markov chain that adds Gaussian noise $q$ with a variance $\\beta_t$ to each latent $x_{t-1}$:\n\n$$q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_t \\mathbb{I}).$$\n\nThe reverse process (left to right in the image above) learns the transitions of the Markov chain through the noise distribution $p$, where:\n\n$$p_\\theta (x_{t-1} | x_t) = \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t)).$$",
    "A model is trained to estimate the added noise at each step of the process, and a simple L2 loss function compares the predicted noise to the actual added noise. Then, data can be generated starting from random inputs by modeling the noise at each step and subtracting it from the image. Instead of starting from a purely random image, DALL-E 2 begins by embedding the inputted text and transforming it into an image, which is then decoded using a Diffusion model. The text embedding simply provides additional information to condition the input of the Diffusion model. Here are some examples of transformed text provided by Ramesh et al. [2022]:",
    "Applications of GANs and Diffusion Models\n\n- Generating images;\n- edges to realistic photos [Isola et al., 2017];\n- old gray-scale images to RGB\n- Semi supervised learning;\n- Text-to-image generation;\n- Super resolution;\n- Image editing;\n- Image Inpainting (filling gaps);\n- Adversarial examples (Defense Vs. Attack of classifiers);\n- Videos (generation/prediction);\n- Domain-transfer;\n- Audio;\n- Tabular data;\n- Also: physics, games... \n\nGANs and diffusion models have also been used for other data modalities: For raw-waveform audio synthesis, examples include WaveGAN [Donahue et al., 2019] and MelGAN [Kumar et al., 2019], among others. For generating realistic tabular data, see e.g. [Kotenikov et al., 2022].",
    "Summary\n\nWe have studied:\n\n1. Zero-sum games & its solution\n\n2. Generative Adversarial Networks\nPlayers (generator & discriminator), Objectives, Solution & Algorithm\n\n3. KL and JS divergences and Wasserstein distance\nGANs, WGANs\n\n4. Some GAN variants (CGAN & CycleGAN) & applications of (C)GANs\n\n5. Diffusion models & applications",
    "Additional Notes\n\n(optional material)\n\nAppendix A: Wasserstein Distance\n\nContinuous probability distributions\nThe Wasserstein distance between two probability distributions $\\mu$ and $\\nu$ is defined as:\n$$\nW(\\mu, \\nu) = \\inf_{\\gamma \\in \\Pi(\\mu, \\nu)} \\int \\|x-y\\| d \\gamma(x, y), \\quad (1)\n$$\nEquation (1) assumes continuous distributions $\\mu$ and $\\nu$. If we use the Euclidean distance we have:\n$$\nW(\\mu, \\nu) = \\inf_{\\gamma \\in \\Pi(\\mu, \\nu)} \\int \\|x-y\\| d \\gamma(x, y) = \\mathbb{E}_{x,y \\sim \\gamma} [\\|x - y\\|]. \\quad (2)\n$$\n\nDiscrete probability distributions\nLet's consider two discrete distributions $P_X, P_Y$, with $s$ states each: $x_i$ and $y_i, i = 1 \\ldots s$. This gives: \n$$\nW(P_X, P_Y) = \\min_{\\gamma \\in \\Pi(P_X, P_Y)} \\sum_{i,j} \\|x_i - y_j\\| \\gamma_{ij}, \\quad (3)\n$$\nwhere with $\\langle, \\rangle$ we denote some kind of element-wise multiplication, and $\\gamma \\in \\mathbb{R}^{s \\times s}$ is the joint probability and $D \\in \\mathbb{R}^{s \\times s}$ is the Euclidean distance between both $x_i, y_j i = 1 \\ldots s, j = 1 \\ldots s$. \n\nKantorovich-Rubinstein duality principle\nFrom Kantorovich-Rubinstein duality [Villani, 2008]:\n$$\nD_{W}(P_{x}, P_{g}) = \\frac{1}{L} \\sup_{1/L \\leqslant k \\leqslant K} \\mathbb{E}_{x \\sim P_{x}} [f(x)] - \\mathbb{E}_{z \\sim P_{g}} [f(x)]\n$$",
    "Villani [2008] gives the following intuitive interpretation of the above\nKantorovich duality principle. Namely, if our goal is to transfer a huge amount of mass distributed over certain area, to a different distinct area, we would like to minimize the cost for transport, thus we have an inf\nover the implied cost. Suppose we have a middle-man who offers to handle the problem for us, by claiming that he will not charge us more than the actual transport cost (thus $ \\varphi(x) - \\psi(y) \\leq c(x,y))$. Then, our initial problem is in fact equal to the one of the middle-man trying to maximize his profit. His profit on the other hand is defined as a price for loading goods: $ c(x) $ and a price for unloading them at destination $ \\psi(y)$. Naturally, he aims at maximizing his profit (thus the sup). Note however that the middle man is ready to give financial compensations for some places, in the form of negative prices.\nProof sketch. See [Villani, 2008] for full formal proof.\n$x$ cont. r.v.\n$ \\mu$ distribution of $x$\n$ \\nu$ target distribution\n$c(.)$ cost, e.g. $\\ell_p$ norm\n$$ \nD_{\\mu, \\nu}^{p} = \\inf_{{\\gamma \\in \\Pi(\\mu,\\nu)}} \\int \\int c(x, y) d \\gamma(x, y) \n= \\sup_{{(\\varphi,\\psi)~:~ \\varphi(x) - \\psi(y) \\leq c(x,y)}} \\int \\psi(y) d \\nu - \\int \\varphi(x) d \\mu\n$$\nwhere $ \\varphi(y) - \\psi(y) \\leq d(x, y)$, and $\\Pi$ is set of all non-negative Borel measures, whose marginals are f, $\\int \\gamma = \\nu$ and $\\int \\gamma = \\mu$.",
    "$D_{\\omega}(r,y) = \\inf \\int \\int c(x,y) d \\pi (x,y)$\n\n$= \\inf \\int \\int c(x,y) d x (y) + \\left\\{ \\begin{array}{ll}\n0 & \\text { if } y \\in x \\\\\n\\infty & \\text { otherwise }\n\\end{array}\\right.$\n\n$= \\inf \\int \\int c(x,y) d x (y)+ \\sup_{\\varphi \\in C_{c}} \\int \\varphi(y) d y - \\int \\varphi(y)[x(y)](r,y) dy \\right]$\n\n$= \\inf \\sup_{(\\varphi,\\psi)} \\int \\varphi(y) d u - \\int \\varphi(x) d (x | x (y) - c(r,y) - c(\\psi(y,x)) \\, dy, ps)$\n\n$= \\sup_{\\varphi} \\int \\varphi(y) d y - \\inf_{x}\\left[\\int x(y)-c(x,y) - (\\epsilon \\varphi)(y,x) - c(r,y)] \\right]$\n\n$= \\sup_{\\varphi} \\bart z(y) d y - \\inf_{x}\\left[\\int y(y) - \\epsilon\\right[x(y)]$\n\n$= \\sup_{x \\le x,} \\int \\varphi(y)d y - \\inf_{x}\\left[\\int\\left[\\varphi(y) - c(r,X) \\right]d y\\right]$\n\n$= \\int \\varphi(y)d y - \\epsilon[\\int \\left[ c(y) < c(y)-c(x,y)]$",
    "References\n\nMartin Arjovsky, Soumith Chintala, and L\u00e9on Bottou. Wasserstein generative adversarial networks. In ICML, 2017.\n\nAndrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity natural image synthesis. In ICLR, 2019.\n\nChris Donahue, Julian McAuley, and Miller Puckette. Adversarial audio synthesis. In ICLR, 2019.\n\nIan Goodfellow. NIPS 2016 tutorial: Generative adversarial networks. arXiv:1701.00160, 2016.\n\nIan Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, 2014.\n\nSamuel Greydanus, Misko Dzamba, and Jason Yosinski. Hamiltonian neural networks. In NeurIPS, 2019.\n\nIshaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C. Courville. Improved training of wasserstein GANs. In NIPS, 2017.\n\nJonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising Diffusion Probabilistic Models. In Advances in Neural Information Processing Systems, volume 33, pages 6840-6851, 2020.\n\nPhillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros. Image-to-image translation with conditional adversarial networks. In CVPR, 2017.\n\nDiederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n\nNaveen Kodali, Jacob D. Abernethy, James Hays, and Zsolt Kira. How to train your DRAGAN. arXiv:1705.07215, 2017.",
    "Akim Kotelnikov, Dmitry Baranchuk, Ivan Rubachev, and Artem Babenko. Tabddpm: Modelling tabular data with diffusion models. arXiv preprint arXiv:2209.15421, 2022.\n\nK. Kumar, Rithesh Kumar, T. D. Bossa\u0300\u0131re, L. Gestin, Wei Zhen Toh, J. Sotelo, A. D. Brebisson, Yoshua Bengio, and Aaron C. Courville. Melgan: Generative adversarial networks for conditional waveform synthesis. In NeurIPS, 2019.\n\nThanard Kurutach, Aviv Tamar, Ge Yang, Stuart J. Russell, and Pieter Abbeel. Learning plannable representations with causal infogan. In NeurIPS, 2018.\n\nMehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv:1411.1784, 2014.\n\nTakero Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. In ICLR, 2018.\n\nAlec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv:1511.06434, 2015.\n\nAditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-Shot Text-to-Image Generation with CLIP. April 2022. arXiv:2204.06125 [cs].\n\nRichard S. Sutton and Andrew G. Barto. Reinforcement Learning: An Introduction. 2018. ISBN 0262039249.\n\nCe\u0301dric Villani. Optimal Transport: Old and New. Springer, 2009 edition, September 2008. ISBN 3540710493.\n\nJun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In ICCV, 2017.",
    "Machine Learning Course - CS-433\n\nUnderfitting and Overfitting\n\nOct 4, 2022\n\nMartin Jaggi\nLast updated on: October 3, 2022\ncredits to Mohammad Emtiyaz Khan & R\u00fcdiger Urbanke",
    "Motivation\n\nModels can be too limited or they can be too rich. In the first case we cannot find a function that is a good fit for the data in our model. We then say that we underfit. In the second case we have such a rich model family that we do not just fit the underlying function but we in fact fit the noise in the data as well. We then talk about an overfit. Both of these phenomena are undesirable. This discussion is made more difficult since all we have is data and so we do not know a priori what part is the underlying signal and what part is noise.\n\nUnderfitting with Linear Models\n\nIt is easy to see that linear models might underfit. Consider a scalar case as shown in the figure below.\n\nThe solid curve is the underlying function and the circles are the actual data. E.g., we assume that there is a scalar function $g(x)$ but that we do not observe $g(x_n)$ directly but only a noisy version of it, $y_n = g(x_n) + Z_n,$ where $Z_n$ is",
    "the noise. The noise might be due for example to some measurement inaccuracies. The $y_n$ are shown as blue circles. If our model family consists of only linear functions of the scalar input $x$, i.e., $\\mathcal{F} = \\{f_w(x) = wx\\}$, where $w$ is a scalar constant (the slope of the function), then it is clear that we cannot match the given function accurately, regardless of how many samples we get and how small the noise is. We therefore will underfit.\n\n**Extended/Augmented Feature Vectors** From the above example it might seem that linear models are more likely to be overfit. But in fact, linear models are highly prone to overfitting, much more so than complicated models like neural nets.\nSince linear models are inherently not very rich the following is a standard \u201ctrick\u201d to make them more powerful. In order to increase the representational power of linear models we typically \u201caugment\u201d the input. E.g., if the input (features) is one-dimensional we might add a polynomial basis (of arbitrary degree $M$),\n$$ \\phi(x_n) := [1, x_n, x_n^2, x_n^3, \\dots, x_n^M] $$\nso that we end up with an extended feature vector. We then fit a linear model to this extended feature vector $\\phi(x_n)$:\n$$ y_n \u2248 w_0 + w_1x_n + w_2x_n^2 + \\ldots + w_Mx_n^M = (\\phi(x_n)^T \\mathbf{w}). $$",
    "Overfitting with Linear Models\n\nIn the following four figures, circles are data points, the green line represents the \u201ctrue function\u201d, and the red line is the model. The parameter $M$ is the maximum degree in the polynomial basis.\n\nFor $M = 0$ (the model is a constant) the model is underfitting and the same is true for $M = 1$. For $M = 3$ the model fits the data fairly well and is not yet so rich as to fit in addition the small \u201cwiggles\u201d caused by the noise. But for $M = 9$ we now have such a rich model that it can fit every single data point and we see severe overfitting taking place. What can we do to avoid overfitting? If you increase the amount of data (increase $N$, but keep $M$ fixed), overfitting",
    "might reduce. This is shown in the following two figures where we again consider the same model complexity $M = 9$ but we have extra data ($N = 15$ or even $N = 100$).\n\nA Word About Notation\n\nIf it is important to distinguish the original input $x$ from the augmented input then we will use $\\phi (x)$ to denote this augmented input vector. But we can consider this augmentation as part of the pre-processing, and then we might simply write $x$ to denote the input. This will save us a lot of notation.\n\nAdditional Materials\n\nRead about overfitting in the paper by Pedro Domingos (Sections 3 and 5 of \u201cA few useful things to know about machine learning\u201d).",
    "Machine Learning Course - CS-433\n\nOptimization\n\nSep 21+27, 2022\n\nMartin Jaggi\nLast updated on September 21, 2022\ncredits to Muhammad Burak Yavuz Khan\n\nEPFL",
    "Learning / Estimation / Fitting\n\nGiven a cost function $L(w)$, we wish to find $w^*$ which minimizes the cost:\n\n$$\\min_{w} L(w) \\quad \\text{subject to} \\quad w \\in \\mathbb{R}^D$$\n\nThis means the learning problem is formulated as an optimization problem.\n\nWe will use an optimization algorithm to solve the problem (to find a good $w$).\n\nGrid Search\n\nGrid search is one of the simplest optimization algorithms. We compute the cost over all values w in a grid, and pick the best among those.\n\nThis is brute-force, but extremely simple and works for any kind of cost function when we have very few parameters and the cost is easy to compute.",
    "For a large number of parameters $D$, however, grid search has too many \u201cfor-loops\u201d, resulting in an exponential computational complexity:\n\nIf we decide to use 10 possible values for each dimension of $\\mathbf{w}$, then we have to check $10^D$ points. This is clearly impossible for most practical machine learning models, which can often have $D \\approx$ millions of parameters. Choosing a good range of values for each dimension is another problem.\n\nOther issues: No guarantee can be given that we end up close to an optimum.",
    "Optimization Landscapes\n\nA vector $\\mathbf{w}^*$ is a local minimum of $\\mathcal{L}$ if it is no worse than its neighbors; i.e. there exists an $\\epsilon > 0$ such that,\n$$\\mathcal{L}(\\mathbf{w}^*) \\le \\mathcal{L}(\\mathbf{w}), \\quad \\forall \\mathbf{w} \\text{ with } \\|\\mathbf{w} - \\mathbf{w}^*\\| < \\epsilon$$\n\nA vector $\\mathbf{w}^*$ is a global minimum of $\\mathcal{L}$ if it is no worse than all others,\n$$\\mathcal{L}(\\mathbf{w}^*) \\le \\mathcal{L}(\\mathbf{w}), \\quad \\forall \\mathbf{w} \\in \\mathbb{R}^D$$\n\nA local or global minimum is said to be strict if the corresponding inequality is strict for $\\mathbf{w} \\neq \\mathbf{w}^*$.",
    "Smooth Optimization\n\nFollow the Gradient\n\nA gradient (at a point) is the slope of the tangent to the function (at that point). It points to the direction of largest increase of the function.\n\nFor a 2-parameter model, MSE($w$) and MAE($w$) are shown below.\n(We used $y_i = w_0 + w_1 x_i$ with $y^* = [2, -1.5, -8]$ and $x^* = [-1, 1, -1]$).",
    "Definition of the gradient:\n\n$\\nabla \\mathcal{L}(\\mathbf{w}) := \\begin{bmatrix}\n\\frac{\\partial \\mathcal{L}(\\mathbf{w})}{\\partial w_1}, \\ldots, \\frac{\\partial \\mathcal{L}(\\mathbf{w})}{\\partial w_D}\n\\end{bmatrix}^\\top$\n\nThis is a vector, $\\nabla \\mathcal{L}(\\mathbf{w}) \\in \\mathbb{R}^D$.\n\nGradient Descent\nTo minimize the function, we iteratively take a step in the (opposite) direction of the gradient\n\n$\\mathbf{w}^{(t+1)} := \\mathbf{w}^{(t)} - \\gamma \\nabla \\mathcal{L}(\\mathbf{w}^{(t)})$\n\nwhere $\\gamma > 0$ is the step-size (or learning rate). Then repeat with the next $t$.\n\nExample: Gradient descent for 1-parameter model to minimize MSE:\n\n$w_0^{(t+1)} := (1 - \\gamma)w_0^{(t)} + \\gamma y$\n\nwhere $y := \\sum_n y_n / N$. When is this sequence guaranteed to converge?",
    "Gradient Descent for Linear MSE\n\nFor linear regression\n$$\n\\mathbf{y} = \\begin{bmatrix}\ny_1 \\\\\ny_2 \\\\\n\\vdots \\\\\ny_N\n\\end{bmatrix},\n\\mathbf{X} = \\begin{bmatrix}\nx_{11} & x_{12} & \\dots & x_{1D} \\\\\nx_{21} & x_{22} & \\dots & x_{2D} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nx_{N1} & x_{N2} & \\dots & x_{ND}\n\\end{bmatrix}\n$$\n\nWe define the error vector $\\mathbf{e}$:\n$$\n\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\mathbf{w}\n$$\nand MSE as follows:\n$$\n\\mathcal{L}(\\mathbf{w}) := \\frac{1}{2N} \\sum_{n=1}^{N} (y_n - \\mathbf{x}_n^T \\mathbf{w})^2\n= \\frac{1}{2N}\\mathbf{e}^T \\mathbf{e}\n$$\nthen the gradient is given by\n$$\n\\nabla \\mathcal{L}(\\mathbf{w}) = -\\frac{1}{N}\\mathbf{X}^T \\mathbf{e}\n$$\n\nComputational cost. What is the complexity (# operations) of computing the gradient?\n\na) starting from $\\mathbf{w}$ and\n\nb) given $\\mathbf{e}$ and $\\mathbf{w}$?",
    "Variant with offset. Recall: Alternative trick when also incorporating an offset term for the regression:\n\\[ \ny = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_N \\end{bmatrix} \\quad \\tilde{X} = \\begin{bmatrix} 1 & x_{11} & x_{12} & \\cdots & x_{1D} \\\\ 1 & x_{21} & x_{22} & \\cdots & x_{2D} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & x_{N1} & x_{N2} & \\cdots & x_{ND} \\end{bmatrix}\n\\]\n\nStochastic Gradient Descent\n\nSum Objectives. In machine learning, most cost functions are formulated as a sum over the training examples, that is\n\\[\n\\mathcal{L}(w) = \\frac{1}{N} \\sum_{n=1}^N \\mathcal{L}_n(w),\n\\]\nwhere $\\mathcal{L}_n$ is the cost contributed by the n-th training example.\n\nQ: What are the $\\mathcal{L}_n$ for linear MSE?\n\nThe SGD Algorithm. The stochastic gradient descent (SGD) algorithm is given by the following update rule, at step t:\n\\[ \nw^{(t+1)} := w^{(t)} - \\gamma \\nabla \\mathcal{L}_n(w^{(t)}).\n\\]",
    "Theoretical Motivation.  Idea: Cheap but unbiased estimate of the gradient! \n\nIn expectation over the random choice of $n$, we have: \n\\[\nE [\\nabla L_n (w)] = \\nabla L (w)\n\\]\nwhich is the true gradient direction. \n(check!)\n\nMini-batch SGD. There is an intermediate version, using the update direction being \n\\[\ng := \\frac{1}{|B|} \\sum_{n \\in B} \\nabla L_n (w^{(t)})\n\\]\nagain with \n\\[\nw^{(t+1)} := w^{(t)} - \\gamma g . \n\\]\n\nIn the above gradient computation, we have randomly chosen a subset $B \\subseteq [N]$ of the training examples. For each of these selected examples $n$, we compute the respective gradient $\\nabla L_n$, at the same current point $w^{(t)}$.",
    "The computation of $g$ can be parallelized easily. This is how current deep-learning applications utilize GPUs (by running over $|B|$ threads in parallel).\n\nNote that in the extreme case $B := [N]$, we obtain (batch) gradient descent, i.e. $\\mathbf{g} = \\nabla \\mathcal{L}$.\n\nSGD for Linear MSE\n\nSee Exercise Sheet 2.\n\nComputational cost. For linear MSE, what is the complexity (# operations) of computing the stochastic gradient? (using only $|B| = 1$ data examples)",
    "Non-Smooth Optimization\n\nAn alternative characterization of convexity, for differentiable functions is given by\n\\[\n\\mathcal{L}(u) \\geq \\mathcal{L}(w) + \\nabla \\mathcal{L}(w)^{\\top} (u - w) \\quad \\forall u, w\n\\]\nmeaning that the function must always lie above its linearization.\n\nSubgradients\n\nA vector $g \\in \\mathbb{R}^D$ such that\n\\[\n\\mathcal{L}(u) \\geq \\mathcal{L}(w) + g^{\\top} (u - w) \\quad \\forall u\n\\]\nis called a subgradient to the function $\\mathcal{L}$ at $w$.\n\nThis definition makes sense for objectives $\\mathcal{L}$ which are not necessarily differentiable (and not even necessarily convex).\n\nIf $\\mathcal{L}$ is convex and differentiable at $w$, then the only subgradient at $w$ is $g = \\nabla \\mathcal{L}(w)$.",
    "Subgradient Descent\n\nIdentical to the gradient descent algorithm, but using a subgradient instead of gradient. Update rule\n\n\\[ \\mathbf{w}^{(t+1)} := \\mathbf{w}^{(t)} - \\gamma \\mathbf{g} \\]\n\nfor $\\mathbf{g}$ being a subgradient to $\\mathcal{L}$ at the current iterate $\\mathbf{w}^{(t)}$.\n\nExample: Optimizing Linear MAE\n\n1. Compute a subgradient of the absolute value function \n\n\\[ h : \\mathbb{R} \\to \\mathbb{R} , h(e) := |e|. \\]\n\n2. Recall the definition of the mean absolute error:\n\n\\[ \\mathcal{L}(\\mathbf{w}) = \\text{MAE}(\\mathbf{w}) := \\frac{1}{N} \\sum_{n=1}^{N} |y_n - f_{\\mathbf{w}}(\\mathbf{x}_n)| \\]\n\nFor linear regression, its (sub)gradient is easy to compute using the chain rule. Compute it! \n\nSee Exercise Sheet 2.",
    "Stochastic Subgradient Descent\n\nStochastic SubGradient Descent (still abbreviated SGD commonly).\n\nSame, g being a subgradient to the randomly selected $L_n$ at the current iterate $w^{(t)}$.\n\n*Exercise:* Compute the SGD update for linear MAE.",
    "Constrained Optimization\n\nSometimes, optimization problems come posed with additional constraints:\n\\[ \\min_w \\mathcal{L}(w), \\text{ subject to } w \\in \\mathcal{C}. \\]\n\nThe set \\( \\mathcal{C} \\subseteq \\mathbb{R}^D \\) is called the constraint set.\n\nSolving Constrained Optimization Problems\n\nA) Projected Gradient Descent\n\nB) Transform it into an unconstrained problem",
    "Convex Sets\n\nA set $C$ is convex \\textit{iff} the line segment between any two points of $C$ lies in $C$, i.e., if for any $\\mathbf{u}, \\mathbf{v} \\in C$ and any $\\theta$ with $0 \\leq \\theta \\leq 1$, we have\n$$\n\\theta \\mathbf{u} + (1 - \\theta) \\mathbf{v} \\in C.\n$$\n\nProperties of Convex Sets\n\n* Intersections of convex sets are convex\n* Projections onto convex sets are \\textit{unique}. (and often efficient to compute)\n  Formal definition:\n  $$\n  \\mathcal{P}_C(\\mathbf{w}') := \\text{arg} \\min_{\\mathbf{w} \\in C} \\|\\mathbf{v} - \\mathbf{w}\\|.\n  $$",
    "Projected Gradient Descent\n\nIdea: add a projection onto $C$ after every step:\n\\[ P_C(\\mathbf{w'}) := \\arg \\min_{\\mathbf{v} \\in C} \\|\\mathbf{v} - \\mathbf{w'}\\|. \\]\n\nUpdate rule:\n\\[ \\mathbf{w}^{(t+1)} := P_C \\left(\\mathbf{w}^{(t)} - \\gamma \\nabla \\mathcal{L}(\\mathbf{w}^{(t)}) \\right). \\]\n\nProjected SGD. Same SGD step, followed by the projection step, as above. Same convergence properties.\n\nComputational cost of projection? Crucial!",
    "Turning Constrained into Unconstrained Problems\n(Alternatives to projected gradient methods)\n\nUse penalty functions instead of directly solving $\\min_{\\mathbf{w} \\in \\mathcal{C}} L(\\mathbf{w})$.\n\n- \"brick wall\" (indicator function)\n\\[ I_{\\mathcal{C}}(\\mathbf{w}) = \\begin{cases} \n0 & \\mathbf{w} \\in \\mathcal{C} \\\\ \n\\infty & \\mathbf{w} \\notin \\mathcal{C} \n\\end{cases} \\]\n\\[\n\\Rightarrow \\min_{\\mathbf{w} \\in \\mathbb{R}^D} L(\\mathbf{w}) + I_{\\mathcal{C}}(\\mathbf{w})\n\\]\n(disadvantage: non-continuous objective)\n\n- Penalize error. Example:\n\\[ \\mathcal{C} = \\{ \\mathbf{w} \\in \\mathbb{R}^D \\ | \\ A\\mathbf{w}=\\mathbf{b} \\} \\]\n\\[\n\\Rightarrow \\min_{\\mathbf{w} \\in \\mathbb{R}^D} L(\\mathbf{w}) + \\lambda \\| A\\mathbf{w} - \\mathbf{b} \\|^2\n\\]\n\n- Linearized Penalty Functions\n(see Lagrange Multipliers)",
    "Implementation Issues\n\nFor gradient methods:\n\nStopping criteria: When $\\nabla \\mathcal{L}(w)$ is (close to) zero, we are (often) close to the optimum value.\n\nOptimality: If the second-order derivative is positive (positive semi-definite to be precise), then it is a (possibly local) minimum. If the function is also convex, then this condition implies that we are at a global optimum. See the supplementary section on Optimality Conditions.\n\nStep-size selection: If $\\gamma$ is too big, the method might diverge. If it is too small, convergence is slow. Convergence to a local minimum is guaranteed only when $\\gamma < \\gamma_{\\text{min}}$ where $\\gamma_{\\text{min}}$ is a fixed constant that depends on the problem.",
    "Line-search methods: For some objectives $L$, we can set step-size automatically using a line-search method. More details on \u201cback-tracking\u201d methods can be found in Chapter 1 of Bertsekas\u2019 book on \u201cnonlinear programming\u201d.\n\nFeature normalization and pre-conditioning: Gradient descent is very sensitive to ill-conditioning. Therefore, it is typically advised to normalize your input features. In other words, we pre-condition the optimization problem. Without this, step-size selection is more difficult since different \u201cdirections\u201d might converge at different speed.",
    "Non-Convex Optimization\n\nReal-world problems are not convex!\n\nAll we have learnt on algorithm design and performance of convex algorithms still helps us in the non-convex world.",
    "Additional Notes\n\nGrid Search and Hyper-Parameter Optimization\nRead more about grid search and other methods for \u201chyperparameter\u201d setting:\nen.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search.\n\nComputational Complexity\nThe computation cost is expressed using the big-O notation. Here is a definition taken from Wikipedia. Let $f$ and $g$ be two functions defined on some subset of the real numbers. We write $f(x) = O(g(x))$ as $x \\to \\infty$, if and only if there exists a positive real number $M$ and a real number $x_0$ such that $|f(x)| \\leq q(g(x))$, $\\forall x > x_0$.\n\nPlease read and learn more from this page in Wikipedia:\nen.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Matrix_algebra.\n\n- What is the computational complexity of matrix multiplication?\n  \n- What is the computational complexity of matrix-vector multiplication?\n\nOptimality Conditions\nFor a convex optimization problem, the first-order necessary condition says that at an optimum the gradient is equal to zero.\n$$\n\\nabla C(w^*) = 0 \\tag{1}\n$$\n\nThe second-order sufficient condition ensures that the optimum is a minimum (not a maximum or saddle-point) using the Hessian matrix,\n",
    "which is the matrix of second derivatives:\n\n$$\n\\mathbf{H}(\\mathbf{w}^*) = \\frac{\\partial^2 L(\\mathbf{w}^*)}{\\partial \\mathbf{w} \\partial \\mathbf{w}^\\top}\n$$\n\nis positive semi-definite. \n$$\n(2)\n$$\n\nThe Hessian is also related to the convexity of a function: a twice-differentiable function is convex if and only if the Hessian is positive semi-definite at all points.\n\nSGD Theory\n\nAs we have seen above, when $N$ is large, choosing a random training example $(x_n, y_n)$ and taking an SGD step is advantageous:\n\n$$\n\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} - \\gamma^{(t)} \\nabla_{w} L_n(\\mathbf{w}^{(t)})\n$$\n\nFor convergence, $\\gamma^{(t)} \\rightarrow 0$ \"appropriately\". One such condition called the Robbins-Monroe condition suggests to take $\\gamma^{(t)}$ such that:\n\n$$\n\\sum_{t=1}^{\\infty} \\gamma^{(t)} = \\infty, \\quad \\sum_{t=1}^{\\infty} (\\gamma^{(t)})^2 < \\infty \n$$\n$$\n(3)\n$$\n\nOne way to obtain such sequences is $\\gamma^{(t)} = 1/(t + 1)^r$ where $r \\in (0.5, 1)$.",
    "More Optimization Theory\nIf you want, you can gain a deeper understanding of several optimization methods relevant for machine learning from this survey:\nConvex Optimization: Algorithms and Complexity\n- by S\u00e9bastien Bubeck\n\nAnd also from the book of Boyd & Vandenberghe\n(both are free online PDFs)\n\nExercises\n1. Chain-rule\n\n    If it has been a while, familiarize yourself with it again.\n\n2. Revise computational complexity (also see the Wikipedia link in Page 6 of lecture notes).\n\n3. Derive the computational complexity of grid-search, gradient descent and stochastic gradient descent for linear MSE (# steps and cost per step).\n\n4. Derive the gradients for the linear MSE and MAE cost functions.\n\n5. Implement gradient descent and gain experience in setting the step-size.\n\n6. Implement SGD and gain experience in setting the step-size.",
    "Machine Learning Course - CS-433\n\nGaussian Mixture Models\n\nNov 29, 2022\n\nMartin Jaggi\nLast updated on: November 28, 2022\ncredits to Mohammad Emtiyaz Khan & R\u00fcdiger Urbanke\n\nEPFL",
    "Motivation\nK-means forces the clusters to be spherical, but sometimes it is desirable to have elliptical clusters. Another issue is that, in K-means, each example can only belong to one cluster, but this may not always be a good choice, e.g. for data points that are near the \"border\". Both of these problems are solved by using Gaussian Mixture Models.\n\nClustering with Gaussians\nThe first issue is resolved by using full covariance matrices $\\Sigma_k$ instead of isotropic covariances.\n$$p(X|\\mu, \\Sigma, z) = \\prod_{n=1}^{N}\\prod_{k=1}^{K}[\\mathcal{N}(x_n|\\mu_{k}, \\Sigma_{k})]^{r_{nk}}$$\n\nSoft-clustering\nThe second issue is resolved by defining $z_n$ to be a random variable. Specifically, define $z_n \\in \\{1, 2, \\cdots, K\\}$ that follows a multinomial distribution.\n$$p(z_n = k) = \\pi_k \\text{ where } \\pi_k > 0, \\forall k \\text{ and } \\sum_{k=1}^{K}\\pi_k = 1$$",
    "This leads to soft-clustering as opposed to having \u201chard\u201d assignments.\n\nGaussian mixture model\nTogether, the likelihood and the prior define the joint distribution of Gaussian mixture model (GMM):\n\n\\[ p(X, z | \\mu, \\Sigma, \\pi) \\]\n\\[ = \\prod_{n=1}^{N} p(x_n | z_n, \\mu, \\Sigma) p(z_n | \\pi) \\]\n\\[ = \\prod_{n=1}^{N} \\prod_{k=1}^{K} [\\mathcal{N}(x_n | \\mu_k, \\Sigma_k)]^{z_{nk}} \\prod_{k=1}^{K} [\\pi_k]^{z_{nk}} \\]\n\nHere, \\( x_n \\) are observed data vectors, \\( z_n \\) are latent unobserved variables, and the unknown parameters are given by \\( \\theta := \\{\\mu_1, \\ldots, \\mu_K, \\Sigma_1, \\ldots, \\Sigma_K, \\pi \\} \\).",
    "Marginal likelihood\n\nGMM is a latent variable model with $z_n$ being the unobserved (latent) variables. An advantage of treating $z_n$ as latent variables instead of parameters is that we can marginalize them out to get a cost function that does not depend on $z_n$, i.e. as if $z_n$ never existed.\n\nSpecifically, we get the following marginal likelihood by marginalizing $z_n$ out from the likelihood:\n\n$$p(x_n|\\mathbf{\\Theta}) = \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(x_n|\\mu_k, \\mathbf{\\Sigma}_k)$$\n\nDeriving cost functions this way is good for statistical efficiency. Without a latent variable model, the number of parameters grows at rate $O(N)$. After marginalization, the growth is reduced to $O(D^2 K)$ (assuming $D, K \\ll N$).",
    "Maximum likelihood\n\nTo get a maximum (marginal) likelihood estimate of $\\theta$, we maximize the following:\n$$ \n\\max_{\\theta} \\sum_{n=1}^{N} \\log \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(x_n | \\mu_k, \\Sigma_k) \n$$\nIs this cost convex? Identifiable? Bounded?",
    "Machine Learning Course - CS-433\n\nCost Functions\n\nSept 22, 2022\n\nMartin Jaggi\nLast updated on September 21, 2022\ncredits to Muhammad Bastiyari Khan",
    "Motivation\nConsider the following models.\n\n1-parameter model: $y_n \\approx w_0$\n2-parameter model: $y_n \\approx w_0 + w_1 x_{n1}$\n\nHow can we estimate (or guess) values of $w$ given the data $D$?\n\nWhat is a cost function?\nA cost function (or energy, loss, training objective) is used to learn parameters that explain the data well. The cost function quantifies how well our model does - or in other words how costly our mistakes are.\n\nTwo desirable properties of cost functions\nWhen the target $y$ is real-valued, it is often desirable that the cost is symmetric around 0, since both positive and negative errors should be penalized equally.\n\nAlso, our cost function should penalize \"large\" mistakes and \"very-large\" mistakes similarly.",
    "Statistical vs computational trade-off\n\nIf we want better statistical properties, then we have to give-up good computational properties.\n\nMean Square Error (MSE)\n\nMSE is one of the most popular cost functions.\n\n$$\\text{MSE}(\\mathbf{w}) := \\frac{1}{N} \\sum_{n=1}^{N} \\left[ y_n - f_w(x_n) \\right]^2$$\n\nDoes this cost function have both mentioned properties?\n\nAn exercise for MSE\n\nCompute MSE for 1-param model:\n\n$$\\mathcal{L}(w_0) := \\frac{1}{N} \\sum_{n=1}^{N} \\left[ y_n - w_0 \\right]^2$$\n\n\\[\n\\begin{array}{ccccccc}\nn & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\\\\ny_1 = 1 & y_2 = 3 & y_3 = 2 & y_4 = 4 & y_5 = 3 & y_6 = 1 & y_7 = 0 \\\\\n\\text{MSE}(w) \\cdot N  &  &  &  &  &  &  &  \\\\\ny = 20 \\\\\n\\frac{y}{5} = 20 & & & & & & \\\\\n\\text{MSE}(w) \\cdot N & \\\\\n\\end{array}\n\\]\n\nSome help: \\(1^2 = 361, 18^2 = 324, 17^2 = 289, 16^2 = 256, 15^2 = 225, 14^2 = 196, 13^2 = 169\\)",
    "Outliers\n\nOutliers are data examples that are far away from most of the other examples. Unfortunately, they occur more often in reality than you would want them to!\n\nMSE is not a good cost function when outliers are present.\n\nHere is a real example on speed of light measurements\n\nHandling outliers well is a desired statistical property.",
    "Mean Absolute Error (MAE)\n\n$MAE(\\mathbf{w}) := \\frac{1}{N} \\sum_{n=1}^{N} |y_{n} - f_{\\mathbf{w}}(x_{n})|$\n\nRepeat the exercise with MAE.\n\n\\[\n\\begin{array}{c|ccccccc}\n & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\\\ \\hline\ny_1 = 1 & & & & & & & \\\\\ny_2 = 2 & & & & & & & \\\\\ny_3 = 3 & & & & & & & \\\\\ny_4 = 4 & & & & & & & \\\\\n & & & & & & & \\\\\nMAE(\\mathbf{w}) \\cdot N & & & & & & & \\\\\n & & & & & & & \\\\\ny_5 = 20 & & & & & & & \\\\\n & & & & & & & \\\\\nMAE(\\mathbf{w'}) \\cdot N & & & & & & & \\\\\n\\end{array}\n\\]\n\nCan you draw MSE and MAE for the above example?",
    "Convexity\nRoughly, a function is convex iff a line segment between two points on the function\u2019s graph always lies above the function.\n\nA function $h(\\mathbf{u})$ with $\\mathbf{u} \\in \\mathbb{R}^D$ is convex, if for any $\\mathbf{u}, \\mathbf{v} \\in \\mathbb{R}^D$ and for any $0 \\leq \\lambda \\leq 1$, we have:\n$$ h(\\lambda \\mathbf{u} + (1 - \\lambda) \\mathbf{v}) \\leq \\lambda h(\\mathbf{u}) + (1 - \\lambda) h(\\mathbf{v}) $$\n\nA function is strictly convex if the inequality is strict.\n\nImportance of convexity\nA strictly convex function has a unique global minimum $\\mathbf{w}^*$. For convex functions, every local minimum is a global minimum.\n\nSums of convex functions are also convex. Therefore, MSE combined with a linear model is convex in $\\mathbf{w}$.\n\nConvexity is a desired computational property.",
    "Can you prove that the MAE is convex? (as a function of the parameters $\\mathbf{w} \\in \\mathbb{R}^D$, for linear regression $f_\\mathbf{w}(\\mathbf{x}) = f(\\mathbf{x}, \\mathbf{w}) := \\mathbf{x}^T \\mathbf{w}$)\n\nComputational VS statistical trade-off\n\nSo which loss function is the best?\n\nIf we want better statistical properties, then we have to give up good computational properties.",
    "Additional Reading\n\nOther cost functions\nHuber loss\n\n\\( Huber(e) := \\begin{cases} \\frac{1}{2}e^2, & \\text{if } |e| \\leq \\delta \\\\ \\delta |e| - \\frac{1}{2}\\delta^2, & \\text{if } |e| > \\delta \\end{cases} \\)\n\nHuber loss is convex, differentiable, and also robust to outliers. However, setting $\\delta$ is not an easy task.\n\nTukey's bisquare loss (defined in terms of the gradient)\n\n\\( \\frac{\\partial L}{\\partial e} := \\begin{cases} e (1 - e^2 / \\delta^2)^2, & \\text{if } |e| \\leq \\delta \\\\ 0, & \\text{if } |e| > \\delta \\end{cases} \\)\n\nTukey\u2019s loss is non-convex, but robust to outliers.\n\nAdditional reading on outliers\n- Wikipedia page on \u201cRobust statistics\u201d.\n- Repeat the exercise with MAE.\n- See 2.4 of Kevin Murphy\u2019s book for an example of robust modeling.\n\nNasty cost functions: Visualization\nSee Andrej Karpathy\u2019s Tumblr post for many cost functions gone \u201cwrong\u201d for neural networks. http://lossfunctions.tumblr.com/.",
    "Machine Learning Course - CS-433\n\nRegularization:\nRidge Regression and Lasso\n\nOct 5, 2022\n\nMartin Jaggi\nLast updated on: October 3, 2022\ncredits to Mohammad Emtiyaz Khan & R\u00fcdiger Urbanke\n\nEPFL",
    "Motivation\nWe have seen that by augmenting the feature vector we can make linear models as powerful as we want. Unfortunately this leads to the problem of overfitting. Regularization is a way to mitigate this undesirable behavior.\nWe will discuss regularization in the context of linear models, but the same principle applies also to more complex models such as neural nets.\n\nRegularization\nThrough regularization, we can penalize complex models and favor simpler ones:\n\n$$\n\\min_w \\mathcal{L}(w) + \\Omega(w)\n$$\n\nThe second term $\\Omega$ is a regularizer, measuring the complexity of the model given by $w$.",
    "\\[ L_2 \\text{-Regularization: Ridge Regression} \\]\n\nThe most frequently used regularizer is the standard Euclidean norm ($L_2$-norm), that is\n\\[\n\\Omega(\\mathbf{w}) = \\lambda ||\\mathbf{w}||_2^2\n\\]\nwhere \n\\[ \n||\\mathbf{w}||_2^2 = \\sum w_i^2. \n\\]\nHere the main effect is that large model weights $w_i$ will be penalized (avoided), since we consider them \u201cunlikely\u201d, while small ones are ok. When $\\mathcal{L}$ is MSE, this is called ridge regression:\n\n\\[\n\\min_{\\mathbf{w}} \\frac{1}{2N} \\sum_{n=1}^N  \\left[ y_n - \\mathbf{x}_n^\\top \\mathbf{w} \\right]^2 + \\lambda ||\\mathbf{w}||_2^2\n\\]\n\nLeast squares is a special case of this: set $\\lambda = 0$.\n\n\\textbf{Explicit solution for w:} Differentiating and setting to zero:\n\\[\n\\mathbf{w}_{\\text{ridge}} = \\left( \\mathbf{X}^\\top \\mathbf{X} + \\lambda I \\right)^{-1} \\mathbf{X}^\\top \\mathbf{y}\n\\]\n(here for simpler notation $\\frac{\\lambda}{2N} = \\lambda$)",
    "Ridge Regression to Fight Ill-Conditioning\n\nThe eigenvalues of $(X^{\\top}X + \\lambda I)$ are all at least $\\lambda$ and so the inverse always exists. This is also referred to as lifting the eigenvalues.\n\nProof: Write the Eigenvalue decomposition of $X^{\\top}X$ as $USU^{\\top}$. We then have\n\n\\[\nX^{\\top}X + \\lambda I = USU^{\\top} + \\lambda I \n= U[S + \\lambda I]U^{\\top}.\n\\]\n\nWe see now that every Eigenvalue is \u201clifted\u201d by an amount $\\lambda$.\n\nHere is an alternative proof. Recall that for a symmetric matrix $A$ we can also compute eigenvalues by looking at the so-called Rayleigh ratio, \n\n\\[\nR(A, \\mathbf{v}) = \\frac{\\mathbf{v}^{\\top}A\\mathbf{v}}{\\mathbf{v}^{\\top}\\mathbf{v}}.\n\\]\n\nNote that if $\\mathbf{v}$ is an eigenvector with eigenvalue $\\lambda$ then the Rayleigh coefficient indeed gives us $\\lambda$. We can find the smallest and largest eigenvalue by minimizing and maximizing this coefficient. But note that if we apply this to the symmetric matrix $X^{\\top}X + \\lambda I$ then for any vector $\\mathbf{v}$ we have \n\n\\[\nR(X^{\\top}X + \\lambda I, \\mathbf{v}) = \\frac{\\mathbf{v}^{\\top}(X^{\\top}X + \\lambda I) \\mathbf{v}}{\\mathbf{v}^{\\top}\\mathbf{v}} = \\frac{\\mathbf{v}^{\\top}X^{\\top}X\\mathbf{v}}{\\mathbf{v}^{\\top}\\mathbf{v}} + \\lambda \\frac{\\mathbf{v}^{\\top}\\mathbf{v}}{\\mathbf{v}^{\\top}\\mathbf{v}} \\geq \\lambda.\n\\]",
    "$L_1$-Regularization: The Lasso\n\nAs an alternative measure of the complexity of the model, we can use a different norm. A very important case is the $L_1$-norm, leading to $L_1$ regularization. In combination with the MSE cost function, this is known as the Lasso:\n\n\\[\n\\min \\frac{1}{2N} \\sum_{n=1}^{N} [y_n - \\mathbf{x}_n^T \\mathbf{w}]^2 + \\lambda \\| \\mathbf{w} \\|_1\n\\]\n\nwhere\n\n\\[\n\\| \\mathbf{w} \\|_1 := \\sum_i |w_i|\n\\]",
    "The figure above shows a \"ball\" of constant $L_1$ norm. To keep things simple assume that $\\mathbf{X}^\\mathbf{T} \\mathbf{X}$ is invertible. We claim that in this case the set\n\\[\n\\{\\mathbf{w} : \\| \\mathbf{y} - \\mathbf{Xw} \\|^2 = \\alpha \\}\n\\]\n(1)\nis an ellipsoid and this ellipsoid simply scales around its origin as we change $\\alpha$. We claim that for the $L_1$-regularization the optimum solution is likely going to be sparse (only has few non-zero components) compared to the case where we use $L_2$-regularization.",
    "Why is this the case? Assume that a genie tells you the $L_1$-norm of the optimum solution. Draw the L1-ball with that norm value (think of 2D to visualize it). So now you know that the optimal point is somewhere on the surface of this \u201cball\u201d. Further you know that there are ellipsoids, all with the same mean and rotation that defines the equal error surfaces incurred by the first term. The optimum solution is where the \u201csmallest\u201d of these ellipsoid just touches the $L_1$-ball. Due to the geometry of this ball this point is likely to be on one of the \u201ccorner\u201d points. In turn, sparsity is desirable, since it leads to a \u201csimple\u201d model.\n\nHow do we see the claim that (1) describes and ellipsoid? First look at $a = ||Xw||^2 = w^T X^T X w$. This is a quadratic form. Let $A = X^T X$. Note that $A$ is a symmetric matrix and by assumption it has full rank. If $A$ is a diagonal matrix with strictly positive elements $a_i$ along the diagonal then this describes the equation\n\\[\n\\sum_i a_i w_i^2 = \\alpha,\n\\]\nwhich is indeed the equation for an ellipsoid. In the general case, A can be written as (using the SVD) $A = U B U^T$, where $B$ is a diagonal matrix with strictly positive entries. This then corresponds to an ellipsoid with rotated axes. If we now look at $a = ||y - X w||^2$, where $y$ is in the column space of $X$ we can write it as $a = ||X(w_o - w)||^2$ for a suitable chosen $w_o$ and so this corresponds to a shifted ellipsoid. Finally if we write $y$ = $Xy_1 + y_\\bot$ = $y_1 + y_\\bot$, where $y_1$ is the component of $y$ that lies in the subspace spanned by the columns of $X$ and $y_\\bot$ is the component that",
    "is orthogonal. In this case\n\n\\[\n\\alpha = \\|y - Xw\\|^2\n= \\|y_1 + y_\u22a5 - Xw\\|^2\n= \\|y_\u22a5\\|^2 + \\|y_1 - Xw\\|^2\n= \\|y_\u22a5\\|^2 + \\|X(w_0 - w)\\|^2.\n\\]\n\nHence this is then equivalent to the equation $\\|X(w_0-w)\\|^2 = \\alpha - \\|y_\u22a5\\|^2$, proving the claim. From this we also see that if $X^TX$ is not full rank then what we get is not an ellipsoid but a cylinder with an ellipsoidal cross-section.",
    "Additional Notes\n\nOther Types of Regularization\n\nPopular methods such as shrinkage, dropout and weight decay (in the context of neural networks), early stopping of the optimization are all different forms of regularization.\n\nAnother view of regularization: The ridge regression formulation we have seen above is similar to the following constrained problem (for some $\\tau > 0$).\n\n\\[ \\min_{\\mathbf{w}} \\frac{1}{2N} \\sum_{i=1}^N (y_i - \\mathbf{x}_i^\\top \\mathbf{w})^2, \\quad \\text{such that } \\|\\mathbf{w}\\|_2^2 \\leq \\tau \\]\n\nThe following picture illustrates this.\n\nFigure 1: Geometric interpretation of Ridge Regression. Blue lines indicating the level sets of the MSE cost function.",
    "For the case of using $L_1$ regularization (known as the Lasso, when used with MSE) we analogously consider\n\\[ \\min_{\\mathbf{w}} \\frac{1}{2N} \\sum_{n=1}^N (y_n - \\mathbf{x}_n^T \\mathbf{w})^2, \\quad \\text{such that } \\|\\mathbf{w}\\|_1 \\le \\tau \\]\n\nThis forces some of the elements of $\\mathbf{w}$ to be strictly 0 and therefore enforces sparsity in the model (some features will not be used since their coefficients are zero).\n\n- Why does $L_1$ regularizer enforce sparsity? \\textit{Hint: Draw the picture similar to above, and locate the optimal solution.}\n\n- Why is it good to have sparsity in the model? Is it going to be better than least-squares? When and why?",
    "Ridge Regression as MAP estimator\n\nRecall that classic least-squares linear regression can be interpreted as the maximum likelihood estimator:\n\n$$\n\\mathbf{w}_{\\mathrm{ML}} = \\underset{\\mathbf{w}}{\\arg \\min} - \\log p(\\mathbf{y}, \\mathbf{X} \\mid \\mathbf{w})\n$$\n$$\n= \\underset{\\mathbf{w}}{\\arg \\min} - \\log p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) p(\\mathbf{X})\n$$\n$$\n= \\underset{\\mathbf{w}}{\\arg \\min} - \\log p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) - \\log p(\\mathbf{X})\n$$\n$$\n= \\underset{\\mathbf{w}}{\\arg \\min} - \\log p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w})\n$$\n$$\n= \\underset{\\mathbf{w}}{\\arg \\min} - \\log \\left[ \\prod_{i=1}^{N} p(y_i \\mid \\mathbf{x}_i, \\mathbf{w}) \\right]\n$$\n$$\n= \\underset{\\mathbf{w}}{\\arg \\min} - \\log \\left[ \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi} \\sigma} \\exp \\left( -\\frac{1}{2\\sigma^2} (y_i - \\mathbf{x}_i^{\\top} \\mathbf{w})^2 \\right) \\right]\n$$\n$$\n= \\underset{\\mathbf{w}}{\\arg \\min} - \\log \\left[ \\left( \\frac{1}{\\sqrt{2\\pi} \\sigma} \\right)^N \\exp \\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i - \\mathbf{x}_i^{\\top} \\mathbf{w})^2 \\right) \\right]\n$$\n$$\n= \\underset{\\mathbf{w}}{\\arg \\min} \\frac{1}{2\\sigma^2} \\sum_{i=1}^{N} (y_i - \\mathbf{x}_i^{\\top} \\mathbf{w})^2\n$$\n$$\n= \\underset{\\mathbf{w}}{\\arg \\min} \\sum_{i=1}^{N} (y_i - \\mathbf{x}_i^{\\top} \\mathbf{w})^2\n$$\n\nIn step (a) on the right we wrote down the negative of the log of the likelihood. The maximum likelihood criterion choses that parameter $\\mathbf{w}$ that maximizes this quantity (i.e., maximizes the likelihood). In step (b) we factored the likelihood. The usual assumption is that the choice of the input samples, $\\mathbf{X}$, does not depend on the model parameter (which only infuences the output given the input. Hence, in step (c) we removed the conditioning. Since the factor $p(\\mathbf{X})$ does not depend on $\\mathbf{w}$, i.e. is constant w.r.t to $\\mathbf{w}$ we can remove it. This is done in step (d). In step (e) we used the assumption that the samples are i.i.d. In step (f) we then used our assumption that the samples have the form $y_i = \\mathbf{w}^{\\top} \\mathbf{x}_i + Z_{i}$,",
    "where $Z_n$ is a Gaussian noise with mean zero and variance $\\sigma_z$. The rest is calculus.\n\nRidge regression has a very similar interpretation. Now we start with the posterior $p(w|X, y)$ and chose that parameter w that maximizes this posterior. Hence this is called the maximum-a-posteriori (MAP) estimate. As before, we take the log and add a minus sign and minimize instead. In order to compute the posterior we use Bayes law and we assume that the components of the weight vector are i.i.d Gaussians with mean zero and variance $\\lambda$:\n\\[\nw_{ridge} = \\arg \\min_w - \\log p(w|X, y)\n\\]\n(a) $\\rightarrow \\arg \\min_w - \\log \\frac{p(y, X|w)p(w)}{p(y, X)}$\n\\[\n= \\arg \\min_w - \\log p(y, X|w)p(w)\n\\]\n(b) $\\rightarrow \\arg \\min_w - \\log p(y, X|w) - \\log p(w)\n\\]\n(c) $\\rightarrow \\arg \\min_w - \\log p(y|X, w)p(X|w) - \\log p(w)\n\\]\n= $\\arg \\min_w - \\log p(y|X, w) - \\log p(w)$\n= $\\arg \\min_w - \\left[ \\log \\prod_{n=1}^N p(y_n|x_n, w) \\right] - \\log \\left[ \\prod_{i=1}^M p(w_i) \\right]$\n\\[\n= \\arg \\min_w - \\left[ \\sum_{n=1}^N \\log p(y_n|\\mathbf{x}_n, w) \\right] - \\left[ \\sum_{i=1}^M \\log p(w_i) \\right]\n\\]\n= $\\arg \\min_w \\sum_{n=1}^N - \\log \\left[ \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left( - \\frac{(y_n - \\mathbf{x}_n^T w)^2}{2 \\sigma^2} \\right) \\right]$\n\\[\n\\quad \\quad \\quad \\quad \\quad \\quad + \\sum_{i=1}^M - \\log \\left[ \\frac{1}{\\sqrt{2 \\pi} \\lambda} \\exp \\left( - \\frac{w_i^2}{2 \\lambda} \\right) \\right]\n\\]\n= $\\arg \\min_w \\sum_{n=1}^N \\left[ \\frac{(y_n - \\mathbf{x}_n^T w)^2}{2 \\sigma^2} + \\frac{1}{2} \\log(2 \\pi \\sigma^2) \\right]$\n\\[\n \\quad \\quad \\quad \\quad \\quad \\quad + \\sum_{i=1}^M \\left[ \\frac{w_i^2}{2 \\lambda} + \\frac{1}{2} \\log (2 \\pi \\lambda) \\right]\n\\]\n= $\\arg \\min_w \\frac{1}{2 \\sigma^2} \\sum_{n=1}^N (y_n - \\mathbf{x}_n^T w)^2 + \\frac{1}{2 \\lambda} \\sum_{i=1}^M w_i^2$\n\\[\n= \\arg \\min_w \\frac{1}{2 \\sigma^2} \\sum_{n=1}^N (y_n - \\mathbf{x}_n^T w)^2 + \\frac{1}{2 \\lambda} \\|w\\|^2\n\\]\n\nIn step (a) we used Bayes' law. In step (b) and (c) we eliminated quantities that do not depend on $w$.",
    "Machine Learning Course - CS-433\n\nNeural Nets \u2013 Some Popular Activation Functions\n\nNovember 09, 2022\n\nchanges by Nicola Piatkowski 2012,2013, changes by B\u00fcdiger Urbanke 2019,2018,2017, (B\u00fcdiger Urbanke 2016\nLast updated on: November 7, 2022",
    "Motivation\n\nThere are many activation functions that are being used in practice. Let us list here some of them and briefly discuss their merits.\n\nSigmoid\n\nWe start with the sigmoid $\\phi(x)$, which we have encountered already several times. Just to summarize, it is defined by\n\n$$\\phi(x) = \\frac{1}{1+e^{-x}}$$\n\nand a plot is shown in Figure 1. Note that the sigmoid is always positive (not really an issue) and that it is bounded. Further, for $|x|$ large, $\\phi'(x) \\sim 0$. This can cause the gradient to become very small (which is known as the \u201cvanishing gradient problem\u201d), sometimes making learning slow.",
    "Tanh\n\nVery much related to the sigmoid is tanh$(x)$. It is defined by\n\n$$\n\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} = 2\\phi(2x) - 1,\n$$\n\nand a plot is shown in Figure 2. Note that tanh$(x)$ is \"balanced\" (positive and negative) and that it is bounded. But it has the same problem as the sigmoid function, namely for $|x|$ large, tanh$(x) \\sim 0$. As mentioned, this can cause the gradient to become very small, sometimes making learning slow.\n\nRectified linear Unit \u2013 ReLU\n\nVery popular is the rectified linear unit (ReLU) $(x)_+$ that we have also seen already. To recall, it is defined by\n\n$$\n(x)_+ = \\max\\{0, x\\},\n$$\n\nand a plot is shown in Figure 3. Note that the ReLU is",
    "always positive and that it is unbounded. One nice property of the ReLU is that its derivative is 1 (and does not vanish) for positive values of $x$ (it has 0 derivative for negative values of $x$ though).\n\nLeaky ReLU\n\nIn order to solve the 0-derivative problem of the ReLU (for negative values of $x$) one can add a very small slope $\\alpha$ in the negative part. This gives rise to the leaky rectified linear unit (LReLU). It is defined by\n$$f(x) = \\max\\{\\alpha x, x\\}$$\nand a plot is shown in Figure 4. The constant $\\alpha$ is of course a hyper-parameter that can be optimized.\n\nMaxout\n\nThe maxout generalizes ReLU and LReLU. It is defined by\n$$f(x) = \\max\\{x^Tw_1 + b_1, \\ldots, x^Tw_k + b_k\\}$$",
    "and a plot is shown in Figure 5. The constants in this function are of course parameters that can be chosen for the particular application. Note that this activation function is quite different from the previous cases. In the previous cases we computed a weighted sum and then applied the activation function to it, whereas here we compute two or more different weighted sums and then choose the maximum.",
    "max$\\{ x_1 - 0.5 x_2 + 1, -2 x_1 + x_2 - 2 \\}$",
    "Machine Learning Course - CS-433\n\nMaximum Likelihood\n\nOct 5, 2022\n\nMartin Jaggi\nLast updated on: October 3, 2022\ncredits to Muhammad Burayya Khan & R\u00fcdiger Urbanke\n\nEPFL",
    "Motivation\n\nIn the previous lecture 3a we arrived at the least-squares problem in the following way: we postulated a particular cost function (square loss) and then, given data, found that model that minimizes this cost function. In the current lecture we will take an alternative route. The final answer will be the same, but our starting point will be probabilistic. In this way we find a second interpretation of the least-squares problem.",
    "Gaussian distribution and independence\n\nRecall the definition of a Gaussian random variable in $\\mathbb{R}$ with mean $\\mu$ and variance $\\sigma^2$. It has a density of\n$$\np(y \\mid \\mu, \\sigma^2) = \\mathcal{N}(y \\mid \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left[ {-\\frac{(y - \\mu)^2}{2 \\sigma^2}} \\right].\n$$\n\nIn a similar manner, the density of a Gaussian random vector with mean $\\mu$ and covariance $\\Sigma$ (which must be a positive semi-definite matrix) is\n$$\n\\mathcal{N}(y \\mid \\mu, \\Sigma) = \\frac{1}{\\sqrt{(2 \\pi)^d \\det (\\Sigma)}} \\exp \\left[ -\\frac{1}{2} (y - \\mu)^{\\top} \\Sigma^{-1} (y - \\mu) \\right].\n$$\n\nAlso recall that two random variables $X$ and $Y$ are called independent when $p(x, y) = p(x)p(y)$.",
    "A probabilistic model for least-squares\n\nWe assume that our data is generated by the model,\n\n\\[ y_n = \\mathbf{X}_n \\mathbf{w} + \\epsilon_n, \\]\n\nwhere the \\(\\epsilon_n\\) (the noise) is a zero-mean Gaussian random variable with variance \\(\\sigma^2\\) and the noise that is added to the various samples is independent of each other, and independent of the input. Note that the model w is unknown. Therefore, given \\(N\\) samples, the likelihood of the data vector \\(\\mathbf{y} = (y_1, \\cdots, y_N)\\) given the input \\(\\mathbf{X}\\) (each row is one input) and the model \\(\\mathbf{w}\\) is equal to\n\n\\[ p(\\mathbf{y}|\\mathbf{X}, \\mathbf{w}) = \\prod_{n=1}^N p(y_n|\\mathbf{X}_n, \\mathbf{w}) = \\prod_{n=1}^N \\mathcal{N}(y_n | \\mathbf{X}_n \\mathbf{w}, \\sigma^2). \\]\n\nThe probabilistic view point is that we should maximize this likelihood over the choice of model \\(\\mathbf{w}\\). I.e., the \"best\" model is the one that maximizes this likelihood.",
    "Defining cost with log-likelihood\n\nInstead of maximizing the likelihood, we can take the logarithm of the likelihood and maximize it instead. Expression is called the log-likelihood (LL).\n\n\\[\n\\mathcal{L}_{LL}(\\mathbf{w}) := \\log \\, p(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w}) = -\\frac{1}{2\\sigma^2} \\sum_{n=1}^{N} (y_n - \\mathbf{x}_n^\\top \\mathbf{w})^2 + \\text{cnst}.\n\\]\n\nCompare the LL to the MSE (mean squared error)\n\n\\[\n\\mathcal{L}_{LL}(\\mathbf{w}) = -\\frac{1}{2\\sigma^2} \\sum_{n=1}^{N} (y_n - \\mathbf{x}_n^\\top \\mathbf{w})^2 + \\text{cnst}\n\\]\n\n\\[\n\\mathcal{L}_{MSE}(\\mathbf{w}) = \\frac{1}{2N} \\sum_{n=1}^{N} (y_n - \\mathbf{x}_n^\\top \\mathbf{w})^2\n\\]",
    "Maximum-likelihood estimator (MLE)\n\nIt is clear that maximizing the LL is equivalent to minimizing the MSE:\n\n$$\\arg \\min_{\\mathbf{w}} L_{\\text{MSE}}(\\mathbf{w}) = \\arg \\max_{\\mathbf{w}} L_{\\text{LL}}(\\mathbf{w}).$$\n\nThis gives us another way to design cost functions.\n\nMLE can also be interpreted as finding the model under which the observed data is most likely to have been generated from (probabilistically). This interpretation has some advantages that we discuss now.",
    "Properties of MLE\n\nMLE is a sample approximation to the expected log-likelihood:\n\\[ \\mathcal{L}_{\\mathcal{L}}(\\mathbf{w}) \\approx \\mathbb{E}_{p(y|\\mathbf{x}, \\mathbf{w})} [\\log p(y|\\mathbf{x}, \\mathbf{w})] \\]\n\nMLE is consistent, i.e., it will give us the correct model assuming that we have a sufficient amount of data. (can be proven under some weak conditions)\n\n\\[ \\mathbf{w}_{\\text{MLE}} \\xrightarrow{p} \\mathbf{w}_{\\text{true}} \\quad \\text{in probability} \\]\n\nThe MLE is asymptotically normal, i.e.,\n\\[ (\\mathbf{w}_{\\text{MLE}} - \\mathbf{w}_{\\text{true}}) \\xrightarrow{d} \\frac{1}{\\sqrt{N}} \\mathcal{N} (\\mathbf{w}_{\\text{MLE}} | \\mathbf{0}, \\mathbf{F}^{-1} (\\mathbf{w}_{\\text{true}})) \\]\n\nwhere\n\\[ \\mathbf{F}(\\mathbf{w}) = -\\mathbb{E}_{p(y|\\mathbf{x})} \\left[ \\frac{\\partial^2 \\mathcal{L}}{\\partial \\mathbf{w} \\partial \\mathbf{w}} \\right] \\]\nis the Fisher information.\n\nMLE is efficient, i.e., it achieves the Cramer-Rao lower bound.\n\n\\[ \\text{Covariance} (\\mathbf{w}_{\\text{MLE}}) = \\mathbf{F}^{-1} (\\mathbf{w}_{\\text{true}}) \\]",
    "Another example\n\nWe can replace Gaussian distribution by a Laplace distribution.\n\n$$\np(y_n \\mid x_n, \\mathbf{w}) = \\frac{1}{2b} e^{-\\frac{1}{b} \\lvert y_n - x_n^T \\mathbf{w} \\rvert}\n$$",
    "Machine Learning Course - CS-433\n\nUnsupervised Learning\n\nNov 23, 2022\n\nMartin Jaggi\nLast updated on: November 28, 2022\ncredits to Mohammad Emtiyaz Khan & R\u00fcdiger Urbanke\n\nEPFL",
    "Unsupervised learning\n\nHow can systems learn when there are no labels available? How to learn a meaningful internal representation for data examples? I.e., to represent them in a way that reflects the semantic structure of the overall collection of input patterns? This question is the central focus of unsupervised learning.\n\nIn unsupervised learning, our data consists only of features (or inputs) $x_1, x_2, \\ldots, x_N$, vectors in $\\mathbb{R}^D$, and there are no outputs $y_n$ available.\n\nUnsupervised learning seems to play an important role in how living beings learn. Variants of it seem to be more common in the brain than supervised learning.\n\nTwo main directions in unsupervised learning are\n\n* representation learning and\n\n* density estimation & generative models",
    "Examples\n\nExamples for Representation Learning\n\nGiven ratings of movies and viewers, we use matrix factorization to extract useful features (see e.g. Netflix Prize).\n\nLearning word-representations using matrix-factorizations, \\texttt{word2vec} (Mikolov et al. 2013).",
    "Given voting patterns of regions across Switzerland, we use PCA to extract useful features (Etter et al. 2014).",
    "PCA Example 2: Genes mirror geography\n\nNature 2008, http://dx.doi.org/10.1038/nature07331",
    "Examples for Clustering",
    "Clustering more than two million biomedical publications (Kevin Boyack et.al.  2011)\n\nClustering articles published in Science (Blei & Lafferty 2007)",
    "Unsupervised Representation Learning & Generation\n\nHow does it work?\nDefine an unsupervised or self-supervised loss function, for\n\n- Compression & Reconstruction\n  (e.g. Auto-Encoder)\n\n- Consistency & Contrastive Learning\n  (e.g. Noise-contrastive estimation)\n\n- Generation\n  (e.g. Auto-Encoder, Gaussian Mixture Model)",
    "Examples:\n(G = can be used as a generative model)\n\nAuto-Encoders (G)\nInvertible networks, learned compression, normalizing flows\n\nRepresentation Learning\ne.g. images, text, time-series, video. Combining unsupervised representation learning (pre-training) with supervised learning\n\nLanguage Models & Sequence Models (G)\ntext generation, or sequence continuation, BERT\nvideo, audio & timeseries (auto-regressive, contrastive, ...)\n\nGenerative Adversarial Networks (GAN) (G)\nsee also predictability minimization",
    "- Contrastive image-language pretraining (CLIP)\n  learns a joint representation space for images and text using contrastive learning\n\n- Diffusion models (G)\n  new state-of-the-art in image generation; these models can be adapted to generate images from text prompts (e.g., DALL-E 2, Stable Diffusion, Midjourney)",
    "Machine Learning Course - CS-433\n\nLinear Regression\n\nSept 20, 2022\n\nMartin Jaggi\nLast updated on: September 20, 2022\ncredits to Muhammad Farisyar Khan\n\nEPFL",
    "1 Model: Linear Regression\n\nWhat is it?\n\nLinear regression is a model that assumes a linear relationship between inputs and the output.\n\nWhy learn about linear regression?\n\nPlenty of reasons: simple, easy to understand, most widely used, easily generalized to non-linear models. Most importantly, you can learn almost all fundamental concepts of ML with regression alone.",
    "Simple linear regression\n\nWith only one input dimension, we get simple linear regression.\n\\[ y_n \\approx f(\\mathbf{x}_n) := w_0 + w_1 x_{n1} \\]\nHere, $\\mathbf{w} = (w_0, w_1)$ are the two parameters of the model. They describe $f$.\n\nMultiple linear regression\n\nIf our data has multiple input dimensions, we obtain multivariate linear regression.\n\\[ y_n \\approx f(\\mathbf{x}_n) \\]\n\\[ := w_0 + w_1 x_{n1} + \\ldots + w_D x_{nD} \\]\n\\[ = w_0 + \\mathbf{x}_n^{\\top} \\begin{pmatrix} w_1 \\\\ \\vdots \\\\ w_D \\end{pmatrix} \\]\n\\[ =: \\mathbf{x}_n^{\\top} \\tilde{\\mathbf{w}} \\]\nNote that we add a tilde over the input vector, and also the weights, to indicate they now contain the additional offset term (a.k.a. bias term).",
    "Learning / Estimation / Fitting\nGiven data, we would like to find \n$\\mathbf{w} = [w_0, w_1, \\ldots, w_D]$. This is called learning or estimating the parameters or fitting the model. \nTo do so, we need an optimization algorithm, which we will discuss in the chapter after the next. \n\nAdditional Notes\nAlternative when not using an 'offset' term\nAbove we have used $D + 1$ model parameters, to fit data of dimension $D$. An alternative also often used in practice, in particular for high-dimensional data, is to ignore the offset term $w_0$.\n\n$$y_n \\approx f(\\mathbf{x}_n) = w_1 x_{n1} + \\ldots + w_D x_{nD} = \\mathbf{x}_n \\mathbf{w}$$\n\nin this case, we have just $D$ parameters to learn, instead of $D + 1$.\n\nAs a warning, you should be aware that for some machine learning models, the number of weight parameters (elements of $\\mathbf{w}$) can in general be very different from $D$ (being the dimension of the input data). For an ML model where they do not coincide, think for example of a neural network (more details later).",
    "Matrix multiplication\n\nTo go any further, one must revise matrix multiplication. Remember that multiplication of $M \\times N$ matrix with a $N \\times D$ matrix results in a $M \\times D$ matrix. Also, two matrices of size $M \\times N_1$ and $N_2 \\times M$ can only be multiplied when $N_1 = N_2$.\n\nThe $D > N$ Problem\n\nConsider the following simple situation: You have $N = 1$ and you want to fit $y_1 \\approx w_0 + w_1 x_1$, i.e. you want to find $w = (w_0, w_1)$ given one pair $(y_1, x_1)$. Is it possible to find such a line?\n\nThis problem is related to something called $D > N$ problem (in statistics typically named $p > n$). It means that the number of parameters exceeds number of data examples. In other words, we have more variables than we have data information. For many models, such as linear regression, this makes the task under-determined. We say that the model is over-parameterized for the task.\n\nUsing regularization is a way to avoid the issue described, which we will learn later.",
    "Machine Learning Course - CS-433\n\nNearest Neighbor Classifiers and the Curse of Dimensionality\n\nOct 26th, 2022\n\nminor changes by Nicolas Flammarion 2021,2022; changes by Holger Fr\u00f6hlich 2019,2018,2017,2016; G\u00f6khan Muzaffer Baykal Haas 2015\nLast updated on: October 24, 2022",
    "### Classification example\n\nIn many cases a linear model is not optimal.\n\nA classification example in two dimensions. The classes are coded as a binary variable (BLUE = 0, ORANGE = 1), and then fit by linear regression. The line is the decision boundary defined by $x^T \\hat{\\beta} = 0.5$. The orange shaded region denotes that part of input space classified as ORANGE, while the blue region is classified as BLUE.\n\nThe K-nearest-neighbor classifier/regressor is an entirely different way of performing classification/regression. It performs best if we are working in low dimensions and if we have reason to believe that points $(x, y)$ that are \u201cclose\u201d in input have similar labels/values.",
    "$k$-Nearest Neighbor ($k$-NN)\n\nAssume that $S_{train}$ is our training data. We are given a \"fresh\" input $\\mathbf{x}$ and want to make a prediction (regression). A natural k-NN prediction for $\\mathbf{x}$ is,\n\n$$f_{S_{train}, k}(\\mathbf{x}) = \\frac{1}{k} \\sum_{\\mathbf{x}_n \\in nbbs_{S_{train}, k}(\\mathbf{x})} y_n,$$\n\nwhere $nbbs_{S_{train}, k}(\\mathbf{x})$ is the set of $k$ input points in $S_{train}$ that are closest to $\\mathbf{x}$. There are many possible variants. E.g., instead of taking the empirical average we could weigh individual samples the heavier the closer they are to $\\mathbf{x}$.\n\nFor the classification problem it is natural to output that label that appears the most frequently,\n\n$$f_{S_{train}, k}(\\mathbf{x}) = \\text{majority element}\\{y_n : \\mathbf{x}_n \\in nbbs_{S_{train}, k}(\\mathbf{x})\\}.$$\n\nFor the binary case it is good to pick $k$ to be odd so that there is a clear winner. For the simplest case of $k = 1$ we return the label of the closest neighbor.\nFigures \"2.3\" and \"2.2\" show this rule applied to a binary classification problem with $k = 1$ an $k = 15$.",
    "Bias-variance revisited\n\nNote that if we pick a large value of $k$ then we are smoothing/averaging over a large area. In the extreme case where",
    "$k$ is equal to the size of the training data our prediction will become a constant. Therefore \u2014 large $k$ equals simple model, small $k$ equals complex model.\n\nHence, if we pick $k$ small we expect a small bias but large variance and if we pick $k$ large we expect a large bias but small variance. Figure \u201c2.4\u201d shows the test error as a function of the complexity of the model. It shows the usual \u201cU\u201d shaped curve. The left part of the figure corresponds to large $k$ (small complexity) and the right part corresponds to small $k$ (large complexity). On the left the test error is large due to a model that is too simple (too much averaging), whereas on the right it is large due to a large variance.\n\nFigure 2.4. Misclassification curves for the simulation example used in Figures 2.1, 2.2, and 2.3. A simple learning sample of size $10,000$ was used, and the test sample has a size of $10,000$. The orange curves are the test and the blue are training errors for $k$-nearest-neighbor designs. Both axes are counts of error regressions and the solid line and the blue squares at three degrees of freedom. The purple line is the optimal Bayes error rate.",
    "Curse of dimensionality\n\nAccording to Pedro Domingos: \u201cIntuition fails in high dimensions\u201d. This is also known as the curse of dimensionality (Bellman, 1961).\nClaim 1: \u201cGeneralizing correctly becomes exponentially harder as the dimensionality grows because fixed-size training sets cover a dwindling fraction of the input space.\u201d\nTo see this, assume that our data is uniformly distributed in the box $[0,1]^d$. Take the point at the center of this box, i.e., the point $\\left(\\frac{1}{2}, \\ldots, \\frac{1}{2}\\right)$, and draw a (small) box around it of side length $r$. What fraction of the total volume does this smaller box cover? It is $r^d$. Therefore, in expectation a fraction $r^d$ of the data lies in this small box. Let the desired fraction be $\\alpha$. Then for $\\alpha = 0.01 \\text{ in 10 dimensions, we need } r \\approx 0.63$ and if we want to capture a fraction 0.1 of the data then we need $r = 0.8 \\text{ (recall the large box has a side length of only 1)}$. So we need to explore almost the whole range in each dimension!",
    "We will see shortly that as a result we have to scale the number of samples exponentially in the dimension if we want our risk to stay constant.\nClaim 2: In high-dimension, data-points are far from each other. Consequently, \"as the dimensionality increases, the choice of nearest neighbor becomes effectively random.\" Consider again $N$ data points uniformly distributed in the box $[0,1]^d$. We consider a nearest-neighbor estimate at the point $(\\frac{1}{2}, \\ldots , \\frac{1}{2})$. Assume that we center around this point a box of side-length $r$. How large do we have to pick $r$ so that the chance that at least one point falls into this smaller box is $\\frac{1}{2}$?\nWe claim that\n\\[ r = \\left(1 - \\frac{1}{2^{1/N}}\\right)^{1/d} \\]\nFor $N = 500, d = 10$, this number is 0.52. So the box has to have a side length of half the one of the large box before we can hope to find a neighbor inside it.\nTo see this claim, what is the chance that a random sample inside the big box is not inside this small box? This probability is $1 - r^d$, since the small box covers a fraction $r^d$ of the volume of the big box. Therefore, the chance that none of $N$ i.i.d. samples fall inside the small box is equal to $(1 - r^d)^N$. We want this probability to be $\\frac{1}{2}$ (we are looking for the median). Solving for $r$ confirms the above claim.",
    "Analysis of nearest neighbor rule\n\nOur aim is to analyze the simplest setting. We consider the nearest neighbor classifier and we will compare its performance to the optimal (Bayes) classifier. This will confirm our intuition about the curse of dimensionality and tell us how good this classifier performs compared to the best we can hope for. In particular, if we have plenty of data we will see a simple and pleasing connection.\n\nHere is our set-up. We assume that $\\mathbf{x}$ takes values in $\\mathcal{X} = [0,1]^d$ and that $Y = \\{0,1\\}$ (binary classification). We assume further that there is some unknown distribution $\\mathcal{D}$ on $\\mathcal{X} \\times Y$ from which samples are drawn. Our training set $S_{train}$ will consist of $N$ i.i.d. samples. Associated to the distribution $\\mathcal{D}$ is the conditional probability\n\n$$ \\Pr\\{Y = 1 \\mid \\mathbf{x}\\}. $$\n\nTo ease our notation, let us introduce\n\n$$ \\eta(\\mathbf{x}) = \\Pr\\{Y = 1 \\mid \\mathbf{x}\\}. $$\n\nIn words, $\\eta(\\mathbf{x})$ is the conditional probability that the label is 1 given that the input is $\\mathbf{x}$.\nIf we knew the distribution $\\mathcal{D}$ (and hence $\\eta(\\mathbf{x})$) we would employ the classifier $f$ which outputs\n\n$$ f_\\star(\\mathbf{x}) = \\mathbf{1}\\{\\eta(\\mathbf{x}) \\ge \\frac{1}{2}\\}. $$\n\nThis is the Bayes classifier (also called maximum a posteriori or MAP classifier). It has the smallest probability of misclassification of any classifier, namely\n\n$$ L(f_\\star) = \\mathbb{E}_{\\mathbf{x}}[\\min\\{\\eta(\\mathbf{x}), 1 - \\eta(\\mathbf{x})\\}]. $$",
    "It is instructive to compare the classification error of our nearest neighbor classifier to this optimal classifier. \nIt is clear that we cannot hope to perform well if there is no correlation between the \u201cposition\u201d $\\mathbf{x}$ and the associated label. E.g., consider the case where the label $y$ is chosen randomly and independently from $\\mathbf{x}$. It is then of no help to know the labels of points close by. So we need to make a suitable assumption regarding $D$. Here is one way of doing this. We demand that the distribution $D$ is such that for some constant $c$ we have\n\n$$\n|\\eta(\\mathbf{x}) - \\eta(\\mathbf{x}')| \\leq c |\\mathbf{x} - \\mathbf{x}'|,\n$$\n\nwhere on the right we have the Euclidean distance. In words, we ask that the conditional probability $P[y = 1 \\mid \\mathbf{x}]$ (seen as a function of $\\mathbf{x}$) is Lipschitz continuous with Lipschitz constant $c$. This seems a reasonable assumption: If we move a point only slightly, we want that the probability (this point will have to have an associated label $y = 1$ only varies slightly as well).\n\nLet $\\mathcal{L}(f_D)$ denote the risk (classification error) for this setting assuming that we use the Bayes classifier and let $\\mathcal{L}(f_{S,nn})$ denote for this setting if we use the nearest neighbor classifier.\n\nLemma.\n\n$$\n\\mathbb{E}_{S \\sim D^m} [\\mathcal{L}(f_{S,nn})] \\leq 2 \\mathcal{L}(f_D) + c \\mathbb{E}_{S \\sim D^m} [\\| \\mathbf{x} - \\text{nbh}_{S,nn}(\\mathbf{x}) \\|]\n$$\n$$\n\\leq 2 \\mathcal{L}(f_D) + 4cv D_m^{- 1/d}.\n$$\n\nBefore we see where this bound comes from, let us interpret this result. We see that the risk of the nearest neighbor",
    "classifier is upper bounded by twice the risk of the optimal classifier plus a \u201cgeometric\u201d term. This term is the average distance of a randomly chosen point to the nearest point in the given training set times the Lipschitz constant $c$.\n\nIt is very natural to have this second term present. Our assumption was that nearby points are likely to be on the same label. So it is reasonable to expect in the bound a term that depends on the average distance.\n\nSo let us discuss what happens in certain limiting cases. Assume at first that we have a fixed dimension and that the size of the training data tends to infinity. Then the second term on the right will converge to zero and we see that in this case we have a risk that is mixed to twice the Bayes risk. So if we have plenty of data then we are doing well!\n\nOn the other hand, if we fix the size of the data, namely $N$, but increase the dimension we see from the bound that very quickly we should expect a large error. The second term on the right is proportional to $1/N$ to the power $1/(d+1)$ (there is an extra term $\\sqrt{d/\\alpha}$ in the bound but this is relatively minor and hence let us ignore it). More precisely, in order to keep the second term on the right constant, let\u2019s say $c, \\alpha << 1$, we need to let $N$ grow like $(1/\\alpha)^{d+1}$, i.e., exponential in the dimension. This is another way of seeing the curse of dimensionality.\n\nNote that the nearest neighbor rule is an interpolating classification method (since the training labels are predicted at the training points, it obtains zero classification error on the training data). Thus the previous result is going against the common belief that interpolating classifiers are not gen",
    "eralizing and will alway lead to overfitting. However this method is still not consistent (when the number of training data is going to infinity, the difference between its classification error and the Bayes risk, i.e., the minimal risk possible, is not going to zero) and saturates at twice the Bayes risk. Interested readers can read the following paper of Belkin (https://arxiv.org/pdf/1806.05161.pdf) where related classification rules are shown to be nearly consistent.\n\nProof. Let us now explain how to derive such a bound. We follow the proof in Chapter 19 of the \u201cUnderstanding Machine Learning\u201d book. You can find a more detailed explanation there.\n\nWe start with the second inequality. How do we bound $\\mathbb{E}_{S_{\\text{train}},x \\sim p}\\|k - nb h_{S_{\\text{train}}}(x)\\|$ by $4\\sqrt{dN^{-d/k}}$? Take the unit cube $[0,1]^d$. Recall that this is the space of inputs. Cut this \u201clarge\u201d cube into small little cubes of side length $c$. Consider now what happens when we want to predict a label for a \u201cfresh\u201d input. \n\nConsider the cube which contains x. If we are lucky, the same cube also contains elements from the training set $S_{\\text{train}}$. In this case x has a neighbor in $S_{\\text{train}}$ at distance at most $c$. This is good since by our assumption a short distance leads to good predictions. But if x lies in a cube which contains no such element from the training data, then its nearest neighbor might be much further, at worst a distance $\\sqrt{d}$. In this case the prediction is probably not very reliable. \n\nWhat is the chance that a randomly chosen point x ends up in a specific box and this box does not have a training point in there?",
    "If the probability of $x$ landing in a particular box $i$ is lets say $P_i$, then the chance that none of the $N$ training symbols are in box $i$ is $(1 - P_i)^N$. This is the main step in this proof. We do not know the distribution $D$ and hence cannot determine the probabilities $P_i$. But it turns out that this is not important. No matter how the probability is distributed over the boxes we are fine. The reason is simple. If $P_i$ is large (i.e., this case happens often) we are fine since then it is very likely that we also have at least one training point in this box. But if $P_i$ is small (and hence also the probability that we have a training point in there is small) we are fine since by definition this does not happen very often.\n\nThe rest is calculus, carefully choosing the right scaling for $\\epsilon$ in order to get a good bound.\n\nIt still remains to explain the term $2L(f_i)$. Consider the following experiment. We are given two points $x$ and $x'$, both elements of $[0,1]^d$. Assign to these points two labels $y$ and $y'$ according to the distribution $\\eta(x)$. What is the chance that these two labels are not the same? We claim that\n\n\\[\nP[y \\neq y'] \\leq 2\\eta(x)(1 - \\eta(x)) + c||x - x'||.\n\\]\n\nThis is easily explained. Assume at first that we draw the two labels $y$ and $y'$ independently but according to the same conditional probability $\\eta(x)$. In this case the probability that the two labels are different is exactly equal to $2\\eta(x)(1-\\eta(x))$.\nBut according to our model we draw the label for $x$ according to the conditional probability $\\eta(x)$ and the label for $x'$ independently is not known and will be interpreted in the conditional probability $\\eta(x')$. These two quantities are in general not the same. But",
    "we have \n\\[\n\\eta(x)(1 - \\eta(x')) + \\eta(x')(1 - \\eta(x)) \\le 2\\eta(x)(1 - \\eta(x)) + (2\\eta(x) - 1)(\\eta(x) - \\eta(x')) \\le 2\\eta(x)(1 - \\eta(x)) + |\\eta(x) - \\eta(x')| \\le 2\\eta(x)(1 - \\eta(x)) + c||x - x'||.\n\\]\n\nConsider now the following experiment. Draw a set $S_\\text{train}$ according to the distribution $D$ but hide the labels $y_n$ and only reveal the inputs $x_n$. Then draw one more \u201cfresh\u201d sample $(x, y)$ but hide also in this case the label $y$ and only reveal $x$. Find the point in $S_\\text{train}$ that is closest to $x$, call it $nbh_{S_\\text{train},K}(x)$. Now reveal the label $y$ associated to $x$ as well as the label $y_{nbh_{S_\\text{train},K}(x)}$ associated to this closest point $nbh_{S_\\text{train},K}(x)$. What is the probability that these two labels do not agree?\n\nThis is exactly the risk $\\mathbb{E}_{S_\\text{train}}[L(S_\\text{train})]$. And according to (1) we can bound this probability by averaging the right hand side over all choices of $x$ and $nbh_{S_\\text{train},K}(x)$. The average of the term $2\\eta(x)(1 - \\eta(x))$ is upper bounded by $2L(f_1)$ since $2\\eta(x)(1 - \\eta(x)) \\le 2\\min\\{\\eta(x), 1 - \\eta(x)\\}$. And the average of the term $c||x - x'||$ is $c \\mathbb{E}_{S_\\text{train} \\sim D}[||x - nbh_{S_\\text{train},K}(x)||]$.",
    "Machine Learning Course - CS-433\n\nAdversarial ML\n\nNov 16, 2022\n\nSmall changes by Nicolas Flammarion 2021/2020, small changes by Martin Jaggi 2019.\nR\u00fcdiger Urbanke 2019\n\nLast updated on: November 14, 2022\n\nEPFL",
    "Introduction\n\nSome ML tasks are inherently difficult. E.g., consider the examples in Figure 1. Even humans might not be able to classify all examples correctly. So we would not be surprised to see NNs struggle in such cases. But typically this is where they shine, having a performance on par or perhaps even surpassing humans. But to date, NNs (or other classifiers for that matter) are not as robust in their decisions as humans and can be easily tricked by adversarially chosen perturbations of the input, even if the perturbations are small. This can lead to problems.\n\nIn the sequel it might be good to have a concrete example in mind. E.g., think of self-driving cars. And we will assume that we are using NNs. But the basic principle applies to a much wider setting.\nSo consider a self-driving car. Such a device hopefully will be able to recognize and correctly interpret street signs with very high probability. If the ML algorithm that performs",
    "this task can be easily tricked by slightly manipulating the input then insurance companies might not be happy!!\n\nThe Basic Attack using Back Propagation\n\nSo let us look at the simplest instance. Assume that we have trained a binary classifier $f : X \\rightarrow \\{\\pm 1\\}$ given some training set $\\mathcal{S} = \\{(x_n, y_n)\\}_{n=1}^N$. There is an underlying data distribution $\\mathcal{D}$ that is unknown to us. Assume that we have trained the network well and that it has a small true risk, i.e., \n$$\n\\mathcal{L}(f) = \\mathbb{E}_{(x,y)\\sim\\mathcal{D}}[1\\{f(x)\\neq y\\}] \\leq \\delta,\n$$\nwhere $\\delta > 0$ is a small number. We are happy.\n\nBut assume now that an adversary were allowed to manipulate, i.e., change, the input $x$ slightly. How much worse can the risk be made? If we put no restriction on the \u201cpower\u201d of the adversary then clearly she can increase the risk at will. So let us say that the adversary can change the given input $x$ to $\\tilde{x}$, but that we require that $\\|\\tilde{x} - x\\| \\leq \\epsilon$ for some small $\\epsilon > 0$. What norm shall we pick? This depends on the",
    "application and it is part of what is called the threat model. We will get back to this point later. It is customary in the literature to pick either $\\ell_1$, $\\ell_2$, or $\\ell_{\\infty}$. We can now define the adversarial risk, call it $\\mathcal{R}(f, \\epsilon)$, as \n$$\n\\mathcal{R}(f, \\epsilon) = \\mathbb{E}_{(\\mathbf{x}, y) \\sim \\mathcal{D}} \\left[ \\max_{\\|\\delta\\| \\leq \\epsilon} \\mathbb{1}_{\\{f(\\mathbf{x} + \\delta) \\neq y \\}} \\right].\n$$\nIn words, for every input $\\mathbf{x}$ the adversary can find the worst perturbation allowed by the norm constraint. Depending on whether you are interested in \u201cbreaking\u201d the classifier or try to make it robust we are faced with numerous questions. Here are some in no particular order. \n\n1. How do we find adversarial perturbations efficiently?\n\n2. In order to find those perturbations, what access to the classifier do we need?\n\n3. By how much worse can we make the risk?\n\n4. Are there measures we can take to make a given classifier more robust?\n\n5. Are there particular ways to train the classifier to make it robust?\n\nWe will explore some of these questions in the following sections.\n\nWhite Box Attacks\n\nSo assume that we are given a binary classifier $f$. To be concrete let us assume that it is implemented by a NN. We",
    "have complete access to the NN and are given an input $\\mathbf{x}$. How do we find an adversarial perturbation $\\hat{\\mathbf{x}}$ so that $\\|\\mathbf{x} - \\hat{\\mathbf{x}}\\| \\le \\epsilon$? You will explore this in the exercise session. Here is a the basic idea.\n\nIf $\\mathbf{x}$ does not classify correctly then we are done - we can just set $\\hat{\\mathbf{x}} = \\mathbf{x}$. So we might as well assume that it does indeed classify $\\mathbf{x}$ correctly. To be specific, assume that the data is separable in principle, i.e., that there exists a \"ground truth\" encoded by the function $h : \\mathcal{X} \\rightarrow \\{\\pm 1\\}$. In other words, the correct label is non-probabilistic and is given by $h(\\mathbf{x})$. Further assume that $f(\\mathbf{x})$ has the form\n$$\nf(\\mathbf{x}) = \n\\begin{cases} \n1, & 0 \\le g(\\mathbf{x}) \\le 1, \\\\\n-1, & 0 \\le g(\\mathbf{x}) < \\frac{1}{2},\n\\end{cases}\n\\eqno{(1)}\n$$\nwhere $g : \\mathcal{X} \\rightarrow [0,1]$ represents the probability that $y = 1$ given the input, i.e., we assume that, like in logistic regression, we first compute a probability and then we quantize. Of course $g(\\mathbf{x})$ depends on all the weights and parameters within the NN but we omit this dependence in our notation since in this (expose) context we are interested only in variations to the changes in the input rather than changes in the parameters.\n\nWhy do we assume that $g$ has this form? We will use gradient descent in order to find adversarial perturbations. For this to work we need to function $g$ to be smooth. We will therefore use $g$ rather than the original $f$.\n\nUsing the backpropagation algorithm we can efficiently compute $\\nabla g(\\mathbf{x})$. Note that this is the gradient with respect to changes in the input rather than changes in the parameters.",
    "Hence\n\n$$h(x) \\nabla_x g(x)$$\n\nis a vector of length $D$ (the dimension of the input space) which is positive in positions where an increase in that input makes the prediction more correct (increases the probability of the correct label) and negative where an increase in that dimension makes the prediction less correct.\nAssume that we are allowed to move the point $x$ to a new point $\\tilde{x}$, with the restriction that $\\|\\tilde{x} - x \\|_2 \\leq \\epsilon$. Note that we have assumed an $\\ell_2$ constraint. Our aim is to make the prediction as bad as possible. This means that we would like to decrease the probability of the correct label as much as possible.\nIf $\\epsilon$ is small then it makes sense to assume that the change in the probability is given by the first order change, i.e., that it is well predicted by the gradient. Given our \u201cbudget\u201d in terms of $\\ell_2$ the optimum move is then to move in the opposite direction of the gradient, i.e., to define\n\n$$\\tilde{x} = x - \\epsilon h(x) \\frac{\\nabla_x g(x)}{\\|\\nabla_x g(x)\\|_2}.$$\n\nIf, for a particular $x$, we manage to \u201cflip\u201d the probability using a move that is bounded by $\\epsilon$ then we have found an adversarial example. In general, we might not want to take a single step but rather only move partially in this direction and then iterate this process.\n\n1. Mathematically speaking this corresponds to the following. We are given a fixed vector $v$ of unit norm (in the $\\ell_2$ sense). Then the inner product $v^T w$ takes its maximum when $w$ is identical in choosing $v$ as this. This can be seen e.g. by the Cauchy Schwartz inequality $v^T w \\leq \\| w \\| \\| v \\|$.",
    "The above attack is known as a \"white box\" attack \u2013 we have access to the details of the algorithm.\nHere is a good problem to think about. Assume that we are given as above the gradient $\\nabla_x g(x)$. What is the locally optimal move if our constraint is $\\|\\tilde{x} - x\\|_1 \\leq \\varepsilon$ or $\\|\\tilde{x} - x\\|_{\\infty} \\leq \\varepsilon$ instead of the $l_2$ constraint we used above?\n\nBlack Box Attacks\n\nIn the above attack we needed access to the NN that implemented the prediction in order to compute the gradients. In general it is a good idea in anything involving security to assume that the adversary has this level of access. Assume e.g., autonomous cars. Typically those are sold in large quantities and it will not be difficult for an adversary to get a hold of one of those boxes.\nBut even if we limit the adversary it turns out that similar attacks can still be carried out. Those are typically known as \"black box\" attacks. In such attacks we assume that he can observe the input output relationship but we cannot look inside the box.\nEarly on in the development of adversarial machine learning researchers showed that adversarial attacks could be constructed by presenting access to the algorithm or bypassing access by making the attacks (e.g., by adding some small amount of noise to the input before passing it through the network or by adding noise to the output). But it has been shown that all such approaches can be easily broken and that black box access is enough.\nIn the simplest case assume the previous setting and assume",
    "further that we have access to the \"unquantized\" output $g(x)$. Assume that we want to compute the derivative with respect to the $i$-th input component. We can do this numerically by asking for the input output pairs for both $x$ and $x$ which is equal to $x$, except in the $i$-th component, where it is slightly perturbed.\n\nBut what can we do if we only see the quantized output, i.e., the decision. In this case we cannot compute the derivative. An ingenious approach for this case is the following. Given black box access to $f$ create a new set of samples $S = \\{ (x, f(x)) \\}$ by computing many input-output pairs. Given $S$ train a new NN. This new NN does not have to have the same structure (depth, width, activation function etc) as the original one. Now run a white box attack on the newly-trained NN. Those adversarial direction that are found in this way often also cause trouble for the original network. If we assume that we have a sufficiently large number of examples so that we can learn $f$ perfectly then this is perhaps not so surprising. But this approach seems to work also in cases where the number of samples we have at our disposal is quite reasonable.\n\nAdversarial Attacks on Physical Objects\n\nSo far in our discussion we have assumed that we are given an input and that we are finding an adversarial perturbation. But there exist much more interesting and potentially more dangerous threats. Let us go back to the example of a self-driving car. The car presumably has a camera (or multiple cameras). Assume that the car approaches an in",
    "tersection and sees a traffic sign. Perhaps this traffic sign is a stop sign. How can the adversary perturb the input. Perhaps the adversary can \u201chack\u201d the car itself. But a much simpler attack is to perturb the actual physical stop sign. Is it possible to change the stop sign slightly so that a human will still recognize it as a stop sign but that the car will likely mistake it for a different sign? Note that this is quite more complicated than our original set-up. We are not given a particular input $x$ but a whole family of such inputs, and the family comes about since the car might approach the same stop sign from various slightly different angles, distances, and under slightly different ambient lighting conditions. And we would like the same attack (the same physical manipulation of this stop sign) to work under a broad set of those conditions. Even in this case it has been shown that adversarial changes can be found! This is quite non-trivial! Figure 2 shows what a perturbed stop sign might look like. Note that for a human the change is visible but it is unlikely that it will cause confusion.\n\nWhy Some ML Algorithms Might Not Be Robust \u2014 Non-Robust Features\n\nThe following example illustrates one reason why a ML algorithm might learn a classification rule that has low standard risk but high adversarial risk.\nThis is a toy example, but the basic idea is sound: the ML algorithm might rely on a large set of \u201cnon-robust\u201d features that can be easily tricked by perturbations.",
    "Consider a binary classification task. We have $y \\in \\{\\pm1\\}$. Let $\\mathbf{x}$ be the input vector. Assume that after applying a suitable transform we get the new input vector $\\mathbf{x}$ that has the following simple structure.\n\nWe have $\\mathbf{x} = (x_1, \\dots, x_D)$, where $x_i = a_iy + Z_i$, $i = 1, \\ldots, D$, where $Z_i$ is Gaussian zero-mean and unit-variance noise which is independent for each component. Further, $a_1 = 1$ and for $i = 2, \\ldots, D$, we have $a_i = \\sqrt{\\frac{\\log(D)}{D-1}}$. The exact values for $a_i$ are not so important and are chosen simply for convenience. What is important is that the first component contains a strong signal component, whereas the other features have a very weak such component. Strong versus weak is with respect to the strength of the noise that is added (zero-mean Gaussian of unit variance). We will say that the first feature is robust whereas the other features are not robust.\n\nTo summarize, each of the $D$ components is a scaled and",
    "noisy version of the label and all components represent conditionally independent observations. Further, the first component contains a strong signal component. The remaining $D-1$ features contain extremely weak signal components but there are many of them (we assume that $D$ is large). Finally, assume that we are given the prior on the label $p(y)$ and that it is uniform.\nAssume at first that we are interested in the best classifier without adversarial perturbations, i.e., the classifier with the smallest possible risk (error probability). This is the Bayes classifier, i.e., we should compute the posterior probability and then choose that label that maximizes the posterior:\n\n$$\\text{argmax}_{\\hat{y} \\in \\{\\pm1\\}} p(\\hat{y} | x) = \\text{argmax}_{\\hat{y} \\in \\{\\pm1\\}} \\frac{p(x | \\hat{y}) p(\\hat{y})}{p(x)} = \\text{argmax}_{\\hat{y} \\in \\{\\pm1\\}} p(x | \\hat{y}).$$\n\nIn the last step we have used the fact that under our model the observations are conditionally independent so that we get a product of the probabilities and that we have a uniform",
    "prior. This can further be simplified to\n\n$$\\text{argmax}_{\\mathbf{y} \\in \\{\\pm1\\}} p(\\mathbf{y} | \\mathbf{x}) = \\text{argmax}_{\\mathbf{y} \\in \\{\\pm1\\}} \\prod_{i=1}^d p(x_i | \\hat{y})$$\n\n$$= \\text{argmax}_{\\mathbf{y} \\in \\{\\pm1\\}} \\prod_{i=1}^d p(x_i | \\hat{y})$$\n\n$$= \\text{argmax}_{\\mathbf{y} \\in \\{\\pm1\\}} \\sum_{i=1}^d \\log p(x_i | \\hat{y})$$\n\n$$= \\text{argmax}_{\\mathbf{y} \\in \\{\\pm1\\}} \\sum_{i=1}^d \\log \\frac{1}{\\sqrt{2 \\pi} \\sigma_{\\hat{y}}} e^{-\\frac{(x_i - \\hat{\\mu}_{\\hat{y}})^2}{2 \\sigma^2_{\\hat{y}}}}$$\n\n$$= \\text{argmin}_{\\mathbf{y} \\in \\{\\pm1\\}} \\sum_{i=1}^d (x_i - y_j a_i)^2$$\n\n$$= \\text{argmin}_{\\mathbf{y} \\in \\{\\pm1\\}} \\sum_{i=1}^d (x_i^2 - 2 x_i y_j a_i + y_j^2 a_i^2)$$\n\n$$= \\text{argmax}_{\\mathbf{y} \\in \\{\\pm1\\}} \\sum_{i=1}^d x_i a_i$$\n\nRecall that we observe $\\mathbf{x}$ which is the vector $\\mathbf{y} (a_1 = 1, a_2 = \\sqrt{\\frac{\\log(D)}{D-1}}, \\ldots, a_D = \\sqrt{\\frac{\\log(D)}{D-1}})$ under Gaussian noise with i.i.d zero-mean components and unit variance in each dimension. Therefore the expression that we maximize over $\\hat{y}$ above is equal to\n\n$$\\hat{y} y_j (\\sum_{i=1}^D a_i^2) + \\hat{y} \\sum_{i=1}^D a_i Z_i = d \\hat{y}(1 + \\log(D)) + \\hat{y} Z_i$$",
    "where $Z$ is a Gaussian noise with variance $\\left(\\sum_{i=1}^{D} a_i^2\\right) = 1 + \\log(D)$. Scaling everything by $1 / (1 + \\log(D))$, we see that this is equivalent to observing the signal $y = \\pm 1$ under a zero-mean Gaussian noise with variance $1 / (1 + \\log(D))$. Hence as $D$ grows the variance tends to zero and our error probability will go to zero as well. In other words, if we train our ML algorithm well then we can hope to get close to zero standard risk when the dimension $D$ grows.\n\nBut assume now that we allow the adversary to move the point $x$ into $\\hat{x}$ and that our norm is $\\ell_{\\infty}$ with $\\epsilon = 2 \\sqrt{\\log D} / \\sqrt{D}$. In this case the adversary can do the following. She can first make an optimal decision based on the observation. As we have seen, with high probability she will know the correct label. She can then move each of the non-robust features $i = 2, \\ldots, D$ into the wrong direction by an amount $2 \\sqrt{\\log D} / \\sqrt{D - 1}$. This means that she can in effect flip the non-robust features. She can also move the first component somewhat but this has almost no effect. If we ignore the movement of the first component (as we see that with this change the classifier will misclassify every single sample with high probability!)\n\nIn summary, we have seen an example where the zero standard risk is essentially zero but the adversarial risk of the same classifier is almost 1. This is as bad as it gets, but we have seen that this is due to the fact that the classifier relied heavily on many very weak features that the adversary could perturb.\n\nCould we have constructed a more robust classifier? Yes, certainly, but at a price. Assume that we build a classifier based on the first feature only. The best classifier in this case",
    "is again a Bayes classifier. A little bit of thought shows that it is given by simply taking the sign of $x_1$. What is the risk of this classifier? We have a label that is either $+1$ or $-1$. We add a zero-mean unit-variance Gaussian random variable to it and ask what is the probability that this noise changes the sign. A little bit of thought shows that the incurred error probability in this case is equal to\n\n$$\n\\frac{1}{\\sqrt{2\\pi}} \\int_1^{\\infty} e^{-\\frac{t^2}{2}} dt \\sim 0.16.\n$$\n\nIn words, this classifier incurs a standard risk of about sixteen percent. This is much higher than the standard risk of essentially zero we saw above. But in this case, the risk almost does not change if we consider the adversarial setting since in our threat model we allow the adversary to move each component by only a very small amount. So we see in this model a trade-off between a small standard risk and a small adversarial risk. We cannot get both.\nThe above example might look a little constructed and also it might not be clear how much of this is due to the fact that we allow the adversary to change the components in an $\\ell_{\\infty}$ sense. Indeed, it is more challenging to find simple examples if the threat model consists of changes in $\\ell_2$. But similar ideas still apply.\nThe idea for the above model and further details came from the paper \"Robustness May Be at Odds with Accuracy,\" by Tsipras, Dimitris, Santurkar, Shibani, Engstrom, Logan, Turner, Alexander, and Madry, Aleksander.",
    "Why Some ML Algorithms Might Not Be Robust \u2013 The Curse of Dimensionality \u2013 Again!\n\nLet us talk about a simple setting to see why in high dimensions adversarial examples cannot be completely avoided. We consider a binary classification example. Let us assume that $X = \\mathbb{R}^{500}$, i.e., $D = 500$. Our data is perfectly separable. For $y = -1$ the data is distributed uniformly on the surface of a $p$ sphere of radius 1 and for $y = 1$ the data is uniformly distributed on the surface of a sphere of radius 1.3. Both classes have equal size.\n\nIn the paper \"The Relationship Between High-Dimensional Geometry and Adversarial Examples,\" by Justin Gilmer, Luke Metz, Fartash Faghri, Samuel S. Schoenholz, Maithra Raghu, Martin Wattenberg, and Ian Goodfellow the authors performed the following experiment.\n\nThey took a 2-hidden layer NN with ReLU activation functions and 500 nodes per hidden layer. They then trained with 50 million samples using SGD. The network trained very well, giving no error on 20 million test samples. Despite this, they were easily able to find adversarial examples by moving the samples by a small amount (on the order of $1/\\sqrt{D}$)!\n\nLet us now discuss how this is an essentially unavoidable consequence of working in very high dimension.\n\nConsider a classifier $f$ that has a small but non-zero error probability. Consider test samples that are very close. Where $(x, y)$ is such that $||x||_2 = 1$ and $y = -1$ but $f(x) = 1$. I.e., these are points lying on the inner sphere but that are classified",
    "as belonging to the outer sphere. Let $E$ be the set of such points that are misclassified.\n\nFor a reason that will become clear hopefully soon, assume that this set forms a spherical cap in the $e_i$ direction, i.e., these are the points $x$ of the form $\\|x\\|_2 = 1$ and $x_i \\geq \\alpha$ for some appropriate constant $\\alpha$. Without loss of generality we can assume that the error probability, call it $p$, fulfills $0 \\leq p \\leq \\frac{1}{2}$ so that $\\alpha \\geq 0$.\n\nGiven $p$ what is the value of $\\alpha$ that gives us $p$ (recall that we assume a uniform distribution of the data on the sphere)? This amounts to computing the surface area of the spherical cap, dividing it by the surface area of the whole sphere and equating this ratio to $p$. Recall that the sphere has radius 1.\n\nIf we are using our low-$D$ intuition we might think that as $p$ varies from 0 to $\\frac{1}{2}$, $\\alpha$ will vary from 1 to 0. But in fact, we will see now that $\\alpha$ is of order $\\frac{1}{\\sqrt{D}}$ and that $p$ only modulates the constant in front of this expression! This means that as $D$ becomes large, the spherical cap extends almost completely down to the equator. In other words, almost all the mass is at the equator. As a consequence, adversarial examples are essentially unavoidable -- if we randomly pick a point, it likely is very close to the equator. And such a point is hence very likely $\\frac{1}{\\sqrt{D}}$-close to a point that $f$ misclassifies. In other words, it is easy to find small adversarial moves that will cause this point to be misclassified!\n\nIt remains to clarify two things. First, let us check for the example above that indeed the spherical cap almost extends all the way down to the equator when $D$ is large and the error probability is non-zero. Second, why did we assume",
    "that the error set forms a spherical cap?\n\nTo answer the first question we will take a convenient shortcut. In principle the area of a spherical cap is explicitly known. But the expression is somewhat unwieldy. But note the following. Picking a point uniformly at random on a sphere of radius 1 in $D$-dimensional real space is almost the same as picking a Gaussian vector with iid zero-mean components of variance $\\sigma^2 = 1/D$. Such a vector will be spherically symmetric and it will have a norm very close to 1.\n\nBut for the latter model it is very easy to assess the probability that this vector extends beyond a positive number $\\beta$ in the first component. This probability is given by\n\n$$\\int_\\beta^\\infty \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{\\frac{-x^2}{2\\sigma^2}} dx = p.$$\n\nOne way to express this is to define\n\n$$Q(x) = \\int_x^\\infty \\frac{1}{\\sqrt{2\\pi}} e^{\\frac{-y^2}{2}} dy.$$\n\nE.g., $Q(1) = 0.16$, i.e., the probability that a zero-mean unit-variance Gaussian has a value larger than 1 is about 16 percent. With this function we get the expression\n\n$$Q(\\beta/\\sigma) = p.$$\n\nSince $\\sigma = \\frac{1}{\\sqrt{D}}$, we see from this expression that $\\beta$ must be of the form $\\alpha/\\sqrt{D}$, as claimed. More precisely,\n\n$$\\beta = Q^{-1}(p)/\\sqrt{D}.$$",
    "To answer the second question consider the following. You likely know that, in any dimension and for a fixed volume, the body that has the smallest surface area is the sphere. This is a famous so-called isoperimetric inequalities. Many such isoperimetric inequalities exist. The version we need is the following. Consider a sphere in $D$ dimension and a subset $E$ on the surface of this sphere of a fixed size. Now add to this subset all points on the sphere that have distance no more than a $\\varepsilon$ away from this set $E$. What is the smallest this set can be? It turns out that the answer is that the resulting set is the smallest if we start with a spherical cap! Applied to our problem this means that by assuming that the misclassified set was a spherical cap we in fact compute a lower bound on the adversarial misclassification rate!\n\nConstructing a Robust Classifier from Scratch \u2013 Adversarial Training\n\nSo far we have assumed that we are given a classifier and we discussed what might happen if we allow adversarial changes to the input. But we can take a more pro-active approach. First, we can include the aim for adversarial robustness in the training phase. This is what we discuss now. Second, given a classifier we can ask if we can modify it to make it more robust. We will briefly discuss this second approach in the next section. In practice we might want to apply both techniques. We will be very brief. \n\nThe approach taken in the paper \u201cTowards Deep Learning Models Resistant to Adversarial Attacks\u201d by Madry, Alek-",
    "sander, Makelov, Aleksandar, Schmidt, Ludwig, Tsipras, Dimitris, and Vladu is the following perhaps most natural idea. \nRather than minimizing the usual cost function \n\n\\[\n\\min_\\Theta \\left[ L(f) = \\mathbb{E}_{(x,y)\\sim\\mathcal{D}} l(f_\\Theta(x),y) \\right]\n\\]\n\nover all parameters $\\Theta$ of the model, why not directly minimize what matters, namely \n\n\\[\n\\min_\\Theta \\left[ R(f, \\epsilon) = \\mathbb{E}_{(x,y)\\sim\\mathcal{D}_\\epsilon} \\left[ \\max_{\\| x^{\\prime} - x \\| \\le \\epsilon} \\mathbf{1}\\{ f(x^{\\prime})\\ne y )\\right] \\right] .\n\\]\n\nThis leads to a min-max formulation. As written, this function is not easy to optimize for several reasons. The first is that it is not smooth (due to the indicator function). Therefore let us instead look at the problem\n\n\\[\n\\min_\\Theta \\left[ \\mathbb{E}_{(x,y)\\sim\\mathcal{D}} \\left[ \\max_{\\| x^{\\prime} - x \\| \\le \\epsilon} \\left( \\frac{1}{2} - y g (x^{\\prime} - \\frac{1}{2})   \\right) \\right] .\n\\]\n\nHere we assumed that we dealt with a binary classification problem, i.e., $y \\in \\{ \\pm1\\}$ and that the classifier $f(x)$ has the form (1) so that $f(x) = y g(x) - \\frac{1}{2})$ is the predicted probability of the incorrect label. Now we are dealing with a smooth function.\n\nNext, we do not have access to the distribution but instead we have a sample $S$. Therefore the equivalent problem is \n\n\\[\n\\min_\\Theta \\frac{1}{N} \\sum_{n=1}^N \\left[ \\max_{\\| x_n^{\\prime} - x_n \\| \\le \\epsilon} \\left( \\frac{1}{2} y_n g ( x_n^{\\prime} - \\frac{1}{2} ) \\right) \\right] .\n\\]\n\nIt is still not completely obvious how to minimize this. It turns out that the following is correct. Compute for each $x_n",
    "the worst perturbation $\\tilde{x}_n$. Then take the gradient of this expression and move towards the negative gradient direction. Of course, this is computationally intensive since for each sample and each iteration we need to find the worst-case perturbation.\n\nLet us apply this algorithm to our example with one robust and many non-robust features. To keep things simple let us assume that we even know that the optimum classifier is of the form as discussed, i.e., we first form the sum $\\sum_{i=1}^D a_i x_i$ and then take the sign, but we do not know what the best constants $a_i$ are that we should use. Hence, we are led to the optimization task\n\n\\[\n\\max_{\\lambda} \\frac{1}{N} \\sum_{i=1}^N \\min_{\\|\\delta_{x_n}\\|_k \\leq \\epsilon} y_n \\left( \\sum_{i=1}^D \\tilde{x}_i a_i + \\lambda \\left( \\sum_{i=1}^D a_i^2 - 1 - \\log(D) \\right) \\right),\n\\]\n\nwhere $\\epsilon = \\sqrt{\\frac{\\log(D)}{D-1}}$ and where we added the term $\\lambda \\left( \\sum_{i=1}^D a_i^2 -1 - \\log(D) \\right)$ in order to limit the scale of the coefficients. \n\nAssume at first that we started with the optimum obtained for the non-adversarial setting, i.e., $a_1 = 1$ and $a_i = \\alpha = \\sqrt{\\frac{1}{D - 1}}$. And now let us do one gradient step. The adver- sary will move all features in the \u201cincorrect direction\u201d by an amount $\\alpha$. This will leave the robust features essentially unchanged but will \u201cflip\u201d all non-robust features. The gradient will then have the value\n\n\\[\n\\begin{aligned}\n    (1 - 2\\alpha + 2\\lambda) + \\mathcal{N}(0,\\sigma^2) &= 1, \\quad i = 1, \\\\\n    - \\alpha(1 - 2\\lambda) + \\mathcal{N}(0, \\sigma^2) &= \\frac{1}{N}, \\quad i = 2, \\ldots, D.\n\\end{aligned}\n\\]",
    "and we will walk a little bit into the direction of this gradient (in the current setting we want to maximize and not to minimize the given expression). If $N$ is large then the additional noise is negligible and the direction will become deterministic. Further, think of $\\lambda$ as small. We see that the non-robust features will move towards zero.\nIndeed, if we consider as a second example the case where we set $\\alpha_i = 0, i = 2, \\cdots, D$, and pick $\\alpha_1$ to be positive, we see that this is a fixed point of the adversarial training algorithm. This training algorithm is called adversarial training.\n\nMaking an Existing Classifier Robust \u2013 Randomized Smoothing\n\nIn some instances we might be handed a classifier that has small standard risk but might be prone to adversarial errors and are asked to make it more robust rather than learning a new classifier from scratch. To date the perhaps most promising idea of accomplishing this is randomized smoothing.\n\nLet $f$ be the given classifier. Assume that it maps $\\mathbb{R}^D$ to $\\mathcal{Y}$, the set of labels. From this we derive the smoothed classifier, call it $g$. This new smoothed classifier $g$ maps an input $x$ to that class $c$ that is most likely returned by $f$ if presented with input $x + Z$, where $Z$ is a vector of iid zero mean random Gaussian variables with a variance of 2 per component. This idea was introduced by Lecuyer, M., A. et al., Y., Geambasu, R., Hsu, D., and Jana, S. in the paper entitled \u201cCertified robustness to adversarial examples with",
    "differential privacy\". It was shown to work well for various test data sets like ImageNet. There are several variants of this. E.g., rather than using this probabilistic definition us- ing Gaussians we could average over a ball of radius $\\sqrt{D\\sigma}$ (with a uniform distribution). The effect would be more or less the same. This resulting training algorithm variants are called robust training.\nThe basic idea why this adds robustness is the following. Consider e.g. the binary case. Take a point $x$ and consider the original classifier $f$. Lets say that the label $y = 1$ is much more likely to be returned by $f$ if we give it the point $x + z$ than the label $y = -1$. Now consider what happens if we give $f$ the label $x+z$ instead, where $\\left \\| x - x' \\right \\|_2 \\leq \\sigma$ for some not too large $\\sigma$. Since the resulting points in the two cases are picked with a probability that is not too different it is intuitive that in average we are still more likely to return $y = 1$ rather than $y = -1$. E.g. we make the center point biased for points not too far away. Let us make this precise. Consider first the case of $D = 1$, i.e., we are operating on a line. On the line each point $x$ has a label $f(x) \\in \\{ \\pm 1 \\}$ attached to it. For a point at a line neighbor- p = $\\mathbb{E}[1{(f{xi} = i)}]$. Let us assume that $\\frac{1}{2} < p < 1$. This means that \"more\" of the points in the neighborhood of $x$ are given the label $y = 1$ than the label $y = -1$. Consider now $\\overline{p} = \\mathbb{E}[1{(f{x + 2} = 1)}]| \\left \\| x - x' \\right \\|_2 \\leq \\sigma$. Assume e.g. all the point $x$ is moved to the right from $x$. The small can $\\overline{p}$. \nA little bit of thought shows that the worst case is if all the points that were originally labeled $y = -1$ were on the right of the point $x$ in the tail of the Gaussian.",
    "More precisely, the worst case happens if all the point to the left of $x + \\sigma Q^{-1}(1-p)$ are labeled $y = 1$ and all points to the right of this point are labeled $y = -1$. How far can we then move $\\tilde{x}$ to the right away from $x$ so that still the majority of the points is labeled $y = 1$. We see that we can move it at most by $\\sigma Q^{-1}(1-p)$. This is pleasing. The larger $p$, i.e., the more biased the original average was, the more we are adversarially robust.\nThis was in 1-D. But exactly the same happens in any dimension since the noise is Gaussian with iid components. Hence, no matter what direction we are considering, in this direction we are dealing with a Gaussian with zero mean and variance $\\sigma^2$.\nSo why not choose a very large $\\sigma$ so that we get a very large robustness radius? The averaging (smoothing) will in general increase the standard risk and it can do so considerably. I.e., there might be a considerable price to pay for the added robustness.",
    "Machine Learning Course - CS-433\n\nExponential Families and Generalized Linear Models\n\nOct 25nd, 2022",
    "Motivation\n\nLet us go back to regression. Consider the very simple one-dimensional example in Fig. 1. The horizontal axis represents the input $x$ and the vertical axis the output $y$. Our aim is to find a model for this data. It is very natural in this case that we try a linear model: $y = wx + w_0 + Z$. I.e., we model the data as a line plus noise. Perhaps the most natural choice for the noise is a zero-mean Gaussian with some variance $\\sigma^2$. As we discussed, this leads to least squares, assuming that we think of the data samples as independent and that we maximize the likelihood. This is what is typically meant when people talk about linear models (of course the data could be higher dimensional).\nNow consider the data given in Fig. 2. In this case a linear",
    "model would not be a good fit. We have seen how we can get around this problem. Just add some additional features, e.g., $x^2$ and $x^3$. If we now use again a linear model, but in the extended feature space then we should be able to model the data well. So the idea was to augment or transform the feature space.\n\nBut this is not the only option we have. Note that in the example above the linear model predicts the mean of a distribution from which we then assume the data was sampled. Explicitly, we had $y = xw_1 + w_0 + Z$, where $xw_1 + w_0$ is the prediction of the linear model and represents the mean (i.e., the putatively \u201ctrue\u201d value for this data point) and then we get a noisy version as a sample. Here is now the extra degree of freedom we have: Instead of using the linear model to predict the mean of the distribution we can use it to predict",
    "a different quantity.\n\nWe have already seen an example when we talked about logistic regression. Consider the data given in Fig 3, where all the y values are in $\\{0, 1\\}$. This might correspond to a binary classification problem. Recall that in logistic regression we model the probability of the two classes $\\{0, 1\\}$ given the data $\\mathbf{x}$ by\n\n$$\np(y = 1|\\eta) = \\sigma(\\eta),\n$$\n\n$$\np(y = 0|\\eta) = 1 - \\sigma(\\eta),\n$$\n\nwhere $ \\eta$ as a shorthand for $ \\mathbf{x}^\\top \\mathbf{w}$. This can be written compactly as\n\n$$\np(y|\\eta) = \\frac{e^{\\eta y}}{1 + e^\\eta} = \\exp [\\eta y - \\log (1 + e^\\eta)].\n$$",
    "where $y \\in \\{0, 1\\}$. Note that linear model predicts $\\eta, \\eta = \\mathbf{x}^T w$, and that $\\eta$ is not the mean of the distribution. Rather, $\\eta$ is related to the mean $\\mu$ by the non-linear relation $\\eta = \\ln \\frac{\\mu}{1-\\mu}$ or $\\mu = \\sigma(\\eta)$. This relation between the parameter we predict by the linear model and the mean is called the link function. It is exactly this nonlinear link function that makes it possible to use a linear model in this context.\n\nOutline\n\nAs you can see, we rewrote this distribution used in logistic regression in a very specific form. Our aim for today will be to generalize this form. We will see that there are many other distributions that can be written in this form. This will lead us to the class of distributions known as exponential families. We will first spend some time to talk about this family. We will see that many distributions (but not all) fit into this framework and that distributions in this family have many nice properties. We will only discuss some of these properties. Exponential families are also those distributions that have maximum entropy given some moment constraints and are not extremal also in other contexts. You are likely going to come across this family in other courses, and you will definitely see them if later on you will work in this area. As a second step we then discuss how exponential families can be used in the context of ML. In essence, the different families then use different link functions, i.e., different relationships between the parameter that the linear model predicts and the mean of the distribution. And this degree of freedom can be useful when we are trying to find a good",
    "model for a given set of data.\n\nIn the subsequent discussion we consider various exponential families and then compute the corresponding link functions. But conceptually it can also be fruitful to think in the reverse way. What should the relationship be between the parameter that the linear model predicts and the mean of the distribution in order to fit the data well. I.e., perhaps we start with a desired link function and then find the exponential family that gives us this relationship.\n\nExponential family \u2013 Definition\n\nLet $y$ be a scalar and $\\eta$ be a vector. We will say that a distribution belongs to the exponential family if it can be written in the form\n\n$$\np(y|\\eta) = h(y) \\exp \\left[ \\eta^T \\phi(y) - A(\\eta) \\right]. \\tag{1}\n$$\n\nLet us look at the various components of this distribution. The parameter vector $\\eta$ is often referred to as the natural or canonical parameter. The quantity $\\phi(y)$ is in general a vector and it is called a sufficient statistics. Why is $\\phi(y)$ called a sufficient statistics? Assume that we are given independent samples from this distribution. We do know $\\phi(y)$ and $h(y)$ but we do not know the parameter $\\eta$. It turns out that in order to optimally estimate $\\eta$ given these samples all we need is the empirical average of the $\\phi(y)$. In other words, $\\phi(y)$ contains all the relevant information.\n\nNote that the expression in (1) is non-negative if $h(y) \\geq 0$. So we only need to ensure that it is properly normalized, i.e.,",
    "we require that\n\n\\[\n\\int_y h(y) \\exp \\left[ \\eta^\\top \\Phi(y) - A(\\eta) \\right] dy| = 1.\n\\]\n\nRewriting this we see that\n\n\\[\n\\int_y h(y) \\exp \\left[ \\eta^\\top \\Phi(y) \\right] dy| = e^{A(\\eta)}.\n\\]\n\nWe see from the last expression that the only role of $A(\\eta)$ is to ensure a proper normalization. $A(\\eta)$ is sometimes called the cumulant and some times it is called the log partition function. We will see shortly that despite the fact that $A(\\eta)$ is only there for normalization purposes it plays a crucial role and contains valuable information.\n\nIf you look at the definition of the exponential family, you will see that we have several \"degrees of freedom\" to define an element of the family. We can choose the factor $h(y)$, we can choose the vector $\\Phi(y)$, and we can choose the parameter $\\eta$. For every choice we will get an element of the exponential family. The term $A(\\eta)$ is then determined for each such choice and ensures that the expression is properly normalized as discussed. Of course it can happen that for some parameters $\\eta$, $h(y) \\exp \\left[ \\eta^\\top \\Phi(y) \\right]$ is such that we cannot normalize the expression because the integral is infinity. E.g., set $h(y) = 1$, $\\Phi(y) = y^2$ and $\\eta = 1$. We will exclude such parameters by only looking at the set of parameters\n\n\\[\nM := \\left\\{ \\eta : \\int_y h(y) \\exp \\left[ \\eta^\\top \\Phi(y) \\right] dy < \\infty \\right\\}.\n\\]",
    "As a final remark concerning $A(\\eta)$ note that from (2) we have\n\n\\[\nA(\\eta) = \\ln \\left[ \\int_y h(y) \\exp \\left[ \\eta \\, \\Phi(y) \\right] dy \\right]. \\tag{3}\n\\]\n\nExponential family -- Examples\n\nLet us look at a few examples which are probably familiar to you but you might not have seen them written in this form. \n**Example**: We claim that the Bernoulli distribution is a member of the exponential family. We write\n\n\\[\np(y|\\mu) = \\mu^y (1 - \\mu)^{1-y}, \\text{ where } \\mu \\in (0, 1)\n\\]\n\n\\[\n= \\exp \\left[ \\left( \\ln \\frac{\\mu}{1 - \\mu} \\right) y + \\ln(1 - \\mu) \\right]\n\\]\n\n\\[\n= \\exp \\left[ \\eta \\Phi(y) - A(\\eta) \\right].\n\\]\n\nMapping this to (1) we see that\n\n\\[\n\\Phi(y) = y,\n\\]\n\n\\[\n\\eta = \\ln \\frac{\\mu}{1 - \\mu},\n\\]\n\n\\[\nA(\\eta) = \\ln(1 - \\mu) = \\ln(1 + e^\\eta),\n\\]\n\n\\[\nh(y) = 1.\n\\]\n\nIn this case $\\Phi(y)$ is a scalar, reflecting the fact that this family only depends on a single parameter. In fact, we have a 1-1 relationship between $\\eta$ and $\\mu$,\n\n\\[\n\\eta = g(\\mu) = \\ln \\frac{\\mu}{1 - \\mu} \\quad \\implies \\quad \\mu = g^{-1}(\\eta) = \\frac{e^\\eta}{1 + e^\\eta}.\n\\]",
    "As we mentioned in the very beginning, this function \\( g \\) is known as the link function (it links the mean of \\( \\phi(y) \\) to the parameter \\( \\eta \\). \nNote that this is exactly the same distribution that we encountered when we discussed logistic regression.\nExample: Consider the Poisson distribution with mean \\( \\mu \\). \nWe have, for \\( y \\in \\mathbb{N} \\),\n\n\\[ p(y|\\mu) = \\frac{\\mu^y e^{-\\mu}}{y!} \\]\n\n\\[ = \\frac{1}{y!} e^{y \\ln(\\mu) - \\mu } \\]\n\n\\[ = \\frac{1}{y!} e^{y g(\\eta)-A(g(\\eta ))}, \\]\n\nwhere \\( h(y) = 1/y! \\), \\( \\phi(y) = y\\), \\( \\eta = g(\\mu) = \\ln(\\mu) \\), and \\( \\mu = g^{-1}(\\eta) = e^\\eta \\). Here again, \\( g(y) \\) links the mean to the parameter \\( \\eta\\).\n\nExample: The Gaussian distribution with mean \\( \\mu \\) and variance \\( \\sigma^2 \\) as parameters is also a member of the exponential family. We write\n\n\\[ p(y|\\mu) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}}, y, \\mu \\in \\mathbb{R}, \\sigma^2 \\in \\mathbb{R}^+ \\]\n\n\\[ = \\exp\\left( \\frac{ \\mu/\\sigma^2, -1/(2\\sigma^2)^T (y,y^T) - \\mu^2}{2\\sigma^2} - \\frac{1}{2}\\ln(2\\pi\\sigma^2) }  \\right). \\]",
    "Mapping this again to (1) we see that\n\n$$\n\\Phi(y) = (y, y^2)^T\n$$\n$$\n\\eta = (\\eta_1, \\eta_2) = (\\mu/\\sigma^2, \\eta_2 = -1/(2\\sigma^2))^T,\n$$\n$$\nA(\\eta) = \\frac{\\eta_1^2}{4\\eta_2} + \\frac{1}{2} \\ln (2\\pi/2),\n$$\n$$\n\\Lambda = 2 \\eta_2 = - \\frac{1}{\\sigma^2}, \\quad 2A = \\frac{\\eta_1^2}{2\\eta_2} - \\frac{1}{2} \\ln (-\\eta_2/\\pi),\n$$\n$$\nh(y) = 1.\n$$\n\nNote that this time $\\Phi(y)$ is a vector of length two, reflecting the fact that the distribution depends on two parameters. In fact, we have the 1-1 relationship between $\\eta = (\\eta_1, \\eta_2)$ and $(\\mu, \\sigma^2)$.\n\n$$\n\\eta_1 = \\frac{\\mu}{\\sigma^2}, \\eta_2 = \\frac{-1}{2\\sigma^2} \\Longrightarrow \\mu = \\frac{\\eta_1}{2\\eta_2} = \\frac{1}{2\\eta_2}.\n$$\n\nBasic Properties\n\nConvexity of $A(\\eta)$\n\nLemma. The cumulant $A(\\eta)$ is convex as a function of $\\eta$ on $M$ (the set of parameters $\\eta$ where the cumulant is finite).\n\nProof. Let $\\eta_1$ and $\\eta_2$ be two parameters in $M$. Define $\\eta = \\lambda \\eta_1 + (1 - \\lambda)\\eta_2$. We start with (2) and apply H\u00f6elder\u2019s inequality. Recall that H\u00f6elder\u2019s inequality reads $\\|fg\\|_1 \\leq \\|f\\|_p\\|g\\|_q$, where $p, q \\in [1, \\infty]$ and $1/p +1/q = 1$. Here,\n\n$$\n\\|f\\|_p = \\left( \\int |f(y)|^p dy\\right)^{1/p} .\n$$",
    "You might not have seen Hoelder's inequality before, but you surely have seen the special case when $p = q = 2$. In this case you get the Cauchy-Schwarz inequality.\nLet us go back to the proof. Pick $p = \\frac{1}{\\lambda}$ and $q = \\frac{1}{(1-\\lambda)}$. Then $p, q \\in [1, \\infty]$ and $\\frac{1}{p} + \\frac{1}{q} = \\lambda + (1 - \\lambda) = 1$. We have\n\\[\ne^{A(\\eta)}\n= \\int_y h(y) \\exp \\left[\\eta^\\top \\phi(y) \\right] dy\n= \\int_y \\left(h(y)^{\\lambda} \\exp \\left[\\lambda \\eta^\\top \\phi(y) \\right] \\right) \\left(h(y)^{1-\\lambda}\\exp \\left[(1-\\lambda)\\eta^\\top \\phi(y) \\right] \\right) dy\n\\leq \\left(\\int_y h(y) \\exp \\left[\\eta^\\top \\phi(y) \\right] dy\\right)^{\\lambda} \\left(\\int_y h(y)\\exp \\left[\\eta^\\top \\phi(y) \\right] dy\\right)^{1 - \\lambda}\n= e^{\\lambda A(\\eta_1) + (1-\\lambda)A(\\eta_2)}.\n\\]\nTaking the log of this chain proves the claim,\n\\[\nA(\\eta) \\leq \\lambda A(\\eta_1) + (1 - \\lambda)A(\\eta_2).\n\\]\n\nDerivatives of $A(\\eta)$ and moments\nAnother useful property is that the gradient and Hessian (first and second derivatives) of $A(\\eta)$ are related to the mean and the variance of $\\phi(y)$.\n\nLemma.\n\\[\n\\nabla A(\\eta) = \\mathbb{E}[\\phi(y)].\n\\]\n\\[\n\\nabla^2 A(\\eta) = \\mathbb{E}[\\phi(y)\\phi(y)^\\top] - \\mathbb{E}[\\phi(y)]\\mathbb{E}[\\phi(y)]^\\top.\n\\]",
    "Note that this in particular shows that the Hessian of $A(\\eta)$ is a covariance matrix and hence is positive semi-definite. This gives us a second proof that $A(\\eta)$ is convex.\nBefore we prove this, let us check this for our two running examples. Recall that for the Bernoulli distribution $\\phi(y)$ is a scalar, namely $y$. So in this case the first derivative should be the mean of the Bernoulli distribution and the second derivative the variance. Let us verify this. We get\n\\[\n\\frac{dA(\\eta)}{d\\eta} = \\frac{d\\ln(1+e^\\eta)}{d\\eta} = \\frac{e^\\eta}{1+e^\\eta} = \\sigma(\\eta) = \\mu,\n\\]\n\\[\n\\frac{d^2A(\\eta)}{d\\eta^2} = \\frac{d \\sigma(\\eta)}{d\\eta} = \\sigma(\\eta)(1-\\sigma(\\eta)) = \\mu(1-\\mu),\n\\]\nwhich confirms the claim.\nFor the Gaussian distribution our vector $\\phi(y)$ is of the form $(y, y^2)^T$. So the first derivative (gradient) should give us the mean and the second moment of the Gaussian. The second derivative should give us the variance of various moments of $y$. We get\n\\[\n\\frac{\\partial A(\\eta)}{\\partial \\eta_1} = \\frac{\\partial(-\\frac{\\eta_2}{4\\eta_1} - \\frac{1}{2}\\ln(-\\pi/\\eta_1))}{\\partial \\eta_1} = \\frac{\\eta_2}{2\\eta_1^2} = \\mu,\n\\]\n\\[\n\\frac{\\partial A(\\eta)}{\\partial \\eta_2} = \\frac{\\partial(-\\frac{\\eta_2}{4\\eta_1})}{\\partial \\eta_2} = -\\frac{1}{4\\eta_1} = \\frac{1}{2\\eta_1^2} = 2\\mu = \\mu^2 + \\sigma^2,\n\\]\nwhich are exactly the expected value and the second moment of $y$, as claimed. To do one more computation, let us",
    "compute\n$$\\frac{\\partial^2 A(\\eta)}{\\partial \\eta_1^2} = \\frac{\\partial (\\frac{-\\mu_1}{\\partial \\eta_1})}{\\partial \\eta_1} = \\frac{1}{2 \\eta_2} = \\sigma^2,$$\nwhich is the variance of $y$, again as expected.\n\nProof. Let us just write down the proof regarding the first derivative. The proof for the second derivative proceeds in a similar fashion. We have\n$$\\nabla A(\\eta) = \\nabla \\ln\\left[ \\int h(y) \\exp[\\eta^T \\phi(y)] dy \\right]$$\n$$= \\frac{\\int h(y) y \\exp[\\eta^T \\phi(y)] dy}{\\int h(y) \\exp[\\eta^T \\phi(y)] dy} $$\n$$= \\frac{\\int h(y) \\exp[\\eta^T \\phi(y)] \\phi(y) dy}{\\int h(y) \\exp[\\eta^T \\phi(y)] dy} $$\n$$= \\exp[A(\\eta)]$$\n$$= \\frac{\\int h(y) \\exp[\\eta^T \\phi(y) - A(\\eta)] \\phi(y) dy}{E[\\phi(y)]}.$$\n\nIn the second step we have exchanged the derivative with the integral. Note that the exchange of differentiation and integration is permitted if the resulting integral is finite (which it is in our case).\n\nLink function\n\nAs we have seen already in two specific cases (Bernoulli and Poisson), there is a relationship between the \"mean\" $\\mu = :$",
    "$\\mathbb{E}[\\phi(y)]$ and $\\eta$ defined using a so-called link function $g$.\n\n$$\n\\eta = g(\\mu) \\Longleftrightarrow \\mu = g^{-1}(\\eta).\n$$\n\nFor the Gaussian, we started with the parameters $(\\mu, \\sigma^2)$ and we have seen that there is a 1-1 relationship to the vector $(\\eta_1, \\eta_2)$. But we could have started with the parameters $(\\mu, \\mu^2 + \\sigma^2)$ (which now corresponds to $\\mathbb{E}[\\phi(y)] = [\\mathbb{E}[y], \\mathbb{E}[y^2]]^T$ instead). And again we would have found that there is a 1-1 relationship between $\\mathbb{E}[\\phi(y)]$ and the vector $\\eta$. For a list of such link functions for various distributions see the chapter on \"Generalized Linear Model\" in the KPM book.\n\nApplications in ML\n\nLet us now look at two applications of exponential families in ML.\n\nMaximum Likelihood Parameter Estimation\n\nAssume that we have a set of samples $\\{y_n\\}_{n=1}^N$. We assume that these are independent samples from some distribution. Further, we assume that they come from some exponential family with a given $h(y)$ and sufficient statistics $\\phi(y)$ but with an unknown parameter $\\eta$. We simply want to find that element of this family of distributions that is closest. Our aim is thus to estimate the parameter $\\eta$. We use our maximum likelihood",
    "principle to find this parameter. Hence we minimize\n\n$$\nL(\\eta) = -\\frac{1}{N} \\ln(p(\\mathbf{y}|\\eta)) \\\\\n= -\\frac{1}{N} \\sum_{n=1}^{N} \\left[ \\ln(h(y_n)) - \\eta \\Phi(y_n) + A(\\eta) \\right].\n$$\n\nWe see that this is a convex function in $\\eta$ since $A(\\eta)$ is a convex function. Further, if we assume that we can determine the link function we can derive the solution in an explicit form by taking the gradient and setting it to zero:\n\n$$\n\\nabla \\mathcal{L}(\\eta) = -\\left(\\frac{1}{N} \\sum_{n=1}^{N} \\Phi(y_n) \\right) + \\mathbb{E}(\\phi(y)) = 0.\n$$\n\nThis equation makes sense intuitively. It says that we should pick $\\eta$ in such a way that the expected value of the sufficient statistics is equal to its empirical value! In formula,\n\n$$\n\\eta = g\\left(\\frac{1}{N} \\sum_{n=1}^{N} \\Phi(y_n) \\right).\n$$\n\nWe now see the justification for why we called $\\Phi(y)$ a sufficient statistics.\n\n**Generalized Linear Models**\n\nGiven an element from the exponential family with a scalar $g(y)$, we can construct this from a data model by assuming that a sample $(\\mathbf{x}, \\mathbf{y})$ follows the distribution\n\n$$\np(y \\, | \\, \\mathbf{x}, \\mathbf{w}) = h(y)e^{\\psi(\\mathbf{w}) \\cdot \\lambda(x^T\\mathbf{w})-A(x^T \\mathbf{w})}.\n$$",
    "We call such a model a \\emph{generalized linear model.} Just note: \nIf we had chosen $\\mathbf{w}$ to be a matrix instead of a vector then \nwe could build generalized linear models using exponential \nfamilies with non-scalar parameters. Not much changes. To \nkeep things simple we stick to the scalar case. \nIt is a generalization of the data model we used for logistic \nregression. As we will now discuss, for such a model the \nmaximum likelihood problem is particularly easy to solve. \nAssume that we have given a training set $S_{train}$ consisting of \n$N$ independent samples $(\\mathbf{x}_n,y_n)$. Assume further that we fit \na generalized linear model to this data. This means that we \nassume that samples obey a distribution of the form \n\\[\np(y_n \\mid \\mathbf{x}_n, \\mathbf{w}) = h(y_n)e^{\\eta_n\\phi(y_n)-A(\\eta_n)}\n\\]\nwith $\\eta_n = \\mathbf{x}_n^T\\mathbf{w}$. Given $S_{train}$, we then write down the likeli-\nhood and look for that weight vector that maximizes this \nlikelihood.\nIn more detail, we consider the cost function \n\\[\nL(\\mathbf{w}) = - \\frac{1}{N} \\sum_{n=1}^N \\ln p(y_n \\mid \\mathbf{x}_n, \\mathbf{w})\n\\]\n\\[\n= - \\frac{1}{N} \\sum_{n=1}^N \\left[\\ln (h(y_n)) + \\mathbf{x}_n^T \\mathbf{w} \\phi(y_n) - A(\\mathbf{x}_n^T \\mathbf{w}) \\right]\n\\]\n\nWe want to minimize this cost function (we added a minus \nsign). First, note that this cost function is convex, hence a \ngreedy algorithm should work well.",
    "Let us take the gradient of this expression. We get\n$$\\nabla_w L(w) = - \\frac{1}{N} \\sum_{n=1}^N x_n \\phi(y_n) - x_n g^{-1}(x_n^T w).$$\n\nwhere we used the fact that\n$$\\nabla A(\\eta) = g^{-1}(\\eta).$$\n\nIf we set this equation to zero we get the condition of optimality. In particular, if we rewrite this sum by using our matrix notation we get\n$$\\nabla L(w) = \\frac{1}{N} X^T \\left[ g^{-1} (Xw) - \\phi(y) \\right] = 0,$$\n\nwhere, as before, the scalar functions $(g^{-1}$ and $\\phi)$ are applied to each vector component-wise.\nTo compare, for the case of the logistic regression we got the equation\n$$\\nabla L(w) = \\frac{1}{N} X^T \\left[ \\sigma (Xw) - y \\right] = 0.$$\n\nAs we have discussed, for the logistic case (Bernoulli distribution) we have the relationship $g^{-1} = \\sigma$, which confirms that our previous derivation was just a special case.\nNote also that we have already shown that $A(x^T w)$ is a convex function $(A$ is convex and $A^{-1}(x^T w)$ is the composition of a linear function with a convex function). Therefore $L(w)$ is convex (the $\\phi$ can be constant or linear), just as we have seen for the logistic regression. As a consequence, greedy iterative algorithms like gradient descent with $y$ an optimum weight vector w are expected to work well in this context.",
    "Machine Learning Course - CS-433\n\nMatrix Factorizations\n\nDec 14, 2022\n\nMartin Jaggi\nLast updated on: December 13, 2022\ncredits to Muhammad Imran Khan\n\nEPFL",
    "Motivation\nIn the Netflix prize, the goal was to predict ratings of users for movies, given the existing ratings of those users for other movies. We are going to study the method that achieved the best error (for a single method).\n\nThe Movie Ratings Data\nGiven items (movies) $d=1, 2, \\ldots, D$ and users $n=1, 2, \\ldots, N$, we define $\\mathbf{X}$ to be the $D \\times N$ matrix containing all rating entries. That is, $X_{dn}$ is the rating of $n$-th user for $d$-th item.\n\nNote that most ratings $X_{dn}$ are missing and our task is to predict those missing ratings accurately.",
    "Prediction Using a Matrix Factorization\n\nWe will aim to find $W$, $Z$ s.t.\n\n\\[ X \\approx WZ^T. \\]\n\nSo we hope to \u2018explain\u2019 each rating $x_{dn}$ by a numerical representation of the corresponding item and user - in fact by the inner product of an item feature vector with the user feature vector.\n\n\\[ \\min_{W,Z} \\mathcal{L}(W, Z) := \\frac{1}{2} \\sum_{(d,n) \\in \\Omega} \\left[ x_{dn} - (WZ^T)_{dn} \\right]^2 \\]\n\nwhere $W \\in \\mathbb{R}^{D \\times K}$ and $Z \\in \\mathbb{R}^{N \\times K}$ are tall matrices, having only \n$K \\ll D, N$ columns.\nThe set $\\Omega \\subset [D] \\times [N]$ collects the indices of the observed ratings of the input matrix $X$.\n\nEach row of those matrices is the feature representation of an item\n(row of $W$) or a user (row of $Z$) respectively.\n\nIs this cost jointly convex w.r.t. $W$ and $Z$? Is the model identifiable? Can we incorporate side-information on users or items?",
    "Choosing $K$\n\n$K$ is the number of latent features.\n\nRecall that for K-means, $K$ was the number of clusters. (Similarly for GMMs, $K$ was the number of latent variable dimensions).\n\nLarge $K$ facilitates overfitting.\n\nRegularization\n\nWe can add a regularizer and minimize the following cost:\n$$\n\\frac{1}{2} \\sum_{(d,n) \\in \\Omega} [x_{dn} - (WZ)_{dn}]^2 + \\frac{\\lambda_w}{2} \\|W\\|_{\\text{Frob}}^2 + \\frac{\\lambda_z}{2} \\|Z\\|_{\\text{Frob}}^2\n$$\n\nwhere $\\lambda_w$, $\\lambda_z > 0$ are scalars.",
    "Stochastic Gradient Descent (SGD)\n\nThe training objective is a sum over $|\\Omega|$ terms (one per rating):\n$$\n\\sum_{(d,n) \\in \\Omega} \\frac{1}{2} \\left[ x_{dn} - (\\mathbf{WZ}^\\top)_{dn} \\right]^2\n$$\n\nDerive the stochastic gradient for $\\mathbf{W}, \\mathbf{Z}$, given one observed rating $(d,n) \\in \\Omega$.\n\nFor one fixed element $(d,n)$ of the sum, we derive the gradient entry $(d',k)$ for $\\mathbf{W}$, that is $\\frac{\\partial}{\\partial w_{d',k}} f_{dn} (\\mathbf{W,Z})$, and analogously entry $(n',k)$ of the $\\mathbf{Z}$ part:\n$$\n\\frac{\\partial}{\\partial w_{d',k}} f_{dn} (\\mathbf{W,Z}) \n= \n\\begin{cases} \n- \\left[ x_{dn} - (\\mathbf{WZ}^\\top)_{dn} \\right] z_{n,k} & \\text{if } d' = d \\\\\n0 & \\text{otherwise} \n\\end{cases}\n$$\n\n$$\n\\frac{\\partial}{\\partial z_{n',k}} f_{dn} (\\mathbf{W,Z}) \n= \n\\begin{cases} \n- \\left[ x_{dn} - (\\mathbf{WZ}^\\top)_{dn} \\right] w_{d,k} & \\text{if } n' = n \\\\\n0 & \\text{otherwise} \n\\end{cases}\n$$",
    "Alternating Least-Squares (ALS)\n\nFor simplicity, let us first assume that there are no missing ratings, that is $\\Omega = [D] \\times [N]$. Then\n\\[ \\frac{1}{2} \\sum_{d=1}^D \\sum_{n=1}^N \\left[z_{dn} - (\\mathbf{WZ})_{dn}\\right]^2 \n= \\frac{1}{2} \\| \\mathbf{X} - \\mathbf{WZ} \\|_\\text{Frob}^2 .\\]\n\nWe can use coordinate descent to minimize the cost plus regularizer:\nWe first minimize w.r.t. $\\mathbf{Z}$ for fixed $\\mathbf{W}$ and then minimize $\\mathbf{W}$ given $\\mathbf{Z}$.\n\n\\[ \\mathbf{Z}^\\top := (\\mathbf{W}^\\top \\mathbf{W} + \\lambda_z I_K)^{-1} \\mathbf{W}^\\top \\mathbf{X} \\]\n\\[ \\mathbf{W}^\\top := (\\mathbf{Z} \\mathbf{Z}^\\top + \\lambda_w I_K)^{-1} \\mathbf{Z} \\mathbf{X}^\\top \\]\n\nWhat is the computational complexity? How can you decrease the cost when $N$ and $D$ are large?",
    "ALS with Missing Entries\n\nCan you derive the ALS updates for the more general setting, when only the ratings $(d,n) \\in \\Omega$ contribute to the cost, i.e.\n\\[\n\\frac{1}{2} \\sum_{(d,n) \\in \\Omega} \\left[ x_{dn} - (WZ^T)_{dn} \\right]^2\n\\]\n\n_Hint:_ Compute the gradient with respect to each group of variables, and set to zero.",
    "Machine Learning Course - CS-433\n\nSupport Vector Machines\n\nNov 1, 2022\n\nchanges by Nicolas Flammarion 2021,2020, changes by Martin Jaggi 2019, changes by R\u00fcdiger Urbanke 2019, changes by Martin Jaggi 2018, 2017 \u00a9Mohamed Elrhayeb Khan 2015\n\nLast updated on: October 31, 2022",
    "Motivation\n\nLet us re-consider binary classification with data pairs $(x_n, \\tilde{y}_n)$, $\\tilde{y}_n \\in \\{0, 1\\}$. We use here the notation $\\tilde{y}_n$ to denote variables that take values in $\\{0, 1\\}$ since soon we will transform our labels to take values in $\\{\\pm1\\}$ and we want to avoid confusion. As we had discussed, if we use least squares (not recommended!) and ignore right now any potential regularization term this lead us to the minimization\n$$\n\\min_w \\frac{1}{N} \\sum_{n=1}^N (\\tilde{y}_n - x_n^Tw)^2.\n$$\n\nIf instead we use logistic regression and optimize the log-likelihood, we solve\n$$\n\\min_w \\frac{1}{N} \\sum_{n=1}^N \\log(1 + e^{x_n^Tw}) - \\tilde{y}_n x_n^Tw.\n$$\n\nIn the following it will be slightly more convenient to assume that $y_n \\in \\{\\pm1\\}$, where we have the mappings $0 \\leftrightarrow -1$ and $1 \\leftrightarrow 1$. We can write this compactly as $y_n = 2\\tilde{y}_n - 1$ or equivalently, $\\tilde{y}_n = \\frac{1}{2}(y_n + 1)$.\n\nConsider first the least squares problem. Assume, as always, that the feature vector contains the constant feature and that this is component 0. Define $w = (\\bar{w} + e_0)$, where $e_0$ is the vector of length $D$ (the dimension of the feature vector) that has a 1 at component 0 and 0 at all other components. Note that this defines a one-to-one mapping between $w$ and",
    "$\\mathbf{w}$. We then have\n\\[4\\sum_{n=1}^{N}(y_{n}-\\mathbf{x}_{n}^\\top\\mathbf{w})^{2}=4\\sum_{n=1}^{N}\\left(\\frac{1}{2}(y_{n}+1)-\\frac{1}{2}\\mathbf{x}_{n}^\\top(\\mathbf{w}+\\mathbf{e}_{0})\\right)^{2}\\]\n\\[=\\sum_{n=1}^{N}\\left((y_{n}+1)-\\mathbf{x}_{n}^\\top(\\mathbf{w}+\\mathbf{e}_{0})\\right)^{2}\\]\n\\[=\\sum_{n=1}^{N}(y_{n}-\\mathbf{x}_{n}^\\top\\mathbf{w})^{2}\\]\n\\[(a)=\\sum_{n=1}^{N}(1-y_{n}\\mathbf{x}_{n}^\\top\\mathbf{w})^{2}\\]\n\\[=\\sum_{n=1}^{N}\\text{MSE}(\\mathbf{x}_{n}^\\top\\mathbf{w},y_{n}),\\]\n\nwhere\n\\[\\text{MSE}(z,y)=(1-yz)^{2}.\\]\n\nIn step (a) we have used the fact that $y_{n}\\{\\pm1\\}$ so that $y_{n}^{2}=1.$\nIn a similar manner, for logistic regression we have\n\\[\\sum_{n=1}^{N}\\log(1+e^{z})-y_{n}\\mathbf{x}_{n}^\\top\\mathbf{w}=\\sum_{n=1}^{N}\\log(1+e^{-y_{n}\\mathbf{x}_{n}^\\top\\mathbf{w}})\\]\n\\[=\\sum_{n=1}^{N}\\text{LogisticLoss}(\\mathbf{x}_{n}^\\top\\mathbf{w},y_{n}),\\]\n\nwhere\n\\[\\text{LogisticLoss}(z,y)=\\log(1+e^{-yz}).\\]",
    "This is most easily seen by checking the two cases $\\hat{y}_n = 0 \\Leftrightarrow y_n = -1$ and $\\hat{y}_n = 1 \\Leftrightarrow y_n = 1$ separately. \nNote that above, $z$ is the prediction based on the given data point and $y$ is the label associated to the data point. We get support vector machines (SVMs), if instead we use the loss\n \n$$\\text{Hinge}(x, y) = [1 - yz]_+ = \\max \\{0, 1 - yz \\},$$\n\nand add a regularization term.\n\nSupport Vector Machine\n\nAs just mentioned, SVMs correspond to the following optimization problem:\n\n$$\\min_{\\mathbf{w}} \\frac{1}{N} \\sum_{n=1}^{N} [1 - y_n \\mathbf{x}_n^T \\mathbf{w}]_+ + \\frac{\\lambda}{2} ||\\mathbf{w}||^2.$$\n\nThe next figure compares the cost functions of the mean-squared loss, the logistic loss, and the hinge loss. Note that\n\nfor least squares we incur a cost whenever we fail to represent the desired value exactly and the cost is symmetric around ",
    "the target value. For logistic regression we always incur a cost but the cost is asymmetric \u2013 it becomes smaller the further we are \u201con the right side\u201d and it becomes larger the further we are \u201con the wrong side.\u201d The hinge loss acts differently. Once we are \u201csufficiently far\u201d on the right side we no longer pay a cost. But if we are not yet far enough on the correct side or if we are on the wrong side we do pay a cost and the cost increases linearly the further we are away.\n\nIn the figure below you see a region in pink. This region is called the \u201cmargin.\u201d It is defined as follows: Take the normal vector \n\n$\\mathbf{x}$ \n\nso that \n\n$|\\mathbf{x}^T\\mathbf{w}| \\leq 1$\n\n. This is the margin. Note that the margin does not only depend on the direction of the vector $\\mathbf{w}$ but also its norm. In fact the total width of the margin is equal to $2/\\|\\mathbf{w}\\|$.\n\nIf you are looking for an interpretation: It is the region where our prediction is not yet sufficiently \u201cconfident\u201d (assuming that we get the sign right). The intuition is strongest if we\n\nlook at the case of separable data. This is shown in the following two figures (left with a large margin and therefore small $\\|\\mathbf{w}\\|$, and right with small margin that corresponds",
    "to a large $\\|w\\|$. Assume that $\\lambda$ is small so that the cost function is dominated by the sum over the hinge losses on the left. What will the optimal $w$ look like in this case? It is clear that we want the following:\n\n1. A separating hyperplane.\n\n2. A scaling of $w$ so that no point of the data is in the margin.\n\n3. That separating hyperplane and scaling for which the margin is the largest.\n\nConditions (1) and (2) ensure that there is no cost incurred in the first expression (the sum over the terms $[1-y_n x_n^T w]_+$). Since by assumption that $\\lambda$ is small this is the dominant term, we cannot hope to do better than having this term to be 0. The condition (3) ensures that we have the minimum possible cost associated for the regularization term, i.e. the minimal possible normed squared $\\|w\\|^2$. Geometrically",
    "this corresponds to a hyperplane with maximal \u201cspacing\u201d to the left and right, i.e., a hyperplane with maximal margin \\( \\text{(corresponding to the figure on the left).} \\)\n\nNOTE: We have introduced our formulation of SVMs for the general case where the data is not necessarily linearly separable. This is sometimes called the soft-margin formulation. The hard-margin formulation concerns the case where the data is linearly separable and where we insist that the decision region is given in terms of a separating hyperplane. In this case the formulation would require us to find a separating hyperplane with minimal \\( \\|\\mathbf{w}\\|^2 \\). In other words, the optimal solution is a separating hyperplane with maximal margins. And in this case there must be some feature vectors which lie exactly on the boundaries (otherwise we could enlarge the margin, contradicting optimality). These feature vectors \u201csupport\u201d the boundaries and hence the name \u201csupport vector.\u201d For the soft-margin case this interpretation is only approximately true as we have explained in the previous paragraphs.\n\n### Optimization\n\nNow where we have established what function we are optimizing, let us look at the question how we can optimize it efficiently.\n\nNote that the function is convex and has a subgradient",
    "(in $w$):\n\n\\[\n\\min_{w} \\frac{1}{N} \\sum_{n=1}^{N} [1 - y_n x_n^T w]_+ + \\frac{\\lambda}{2} ||w||^2\n\\]\n\nWe can therefore use SGD with subgradients. This is good news!\n\nDuality: The big picture\n\nWe have just seen that we can use SGD in order to find the optimal parameters for the SVM. We will now discuss an alternative but equivalent formulation via the concept of duality. In some cases this leads to a more efficient implementation. But perhaps more importantly, once we have derived this alternative representation it will point us naturally to a more general formulation. This is called the kernel trick. We will explicitly discuss this technique in a separate lecture.\n\nLet us say that we are interested in minimizing a function $\\mathcal{L}(w)$. Assume that we can define an auxiliary function $G(w, \\alpha)$ so that\n\n\\[\n\\mathcal{L}(w) = \\max_{\\alpha} G(w, \\alpha).\n\\]\n\nWe can therefore solve our original problem by solving\n\n\\[\n\\min_{w} \\max_{\\alpha} G(w, \\alpha).\n\\]\n\nWe call this the primal problem. In some cases it might be much easier to find\n\n\\[\n\\max_{\\alpha} \\min_{w} G(w, \\alpha).\n\\]",
    "We call this the dual problem. This leads us naturally to the following questions:\n\n1. How do we find a suitable $G(\\mathbf{w}, \\boldsymbol{\\alpha})$?\n\n2. When is it OK to switch $\\min_{\\mathbf{w}}$ and $\\max_{\\boldsymbol{\\alpha}}$?\n\n3. When is the dual easier to optimize than the primal?\n\nQ1: How do we find a suitable $G(\\mathbf{w}, \\boldsymbol{\\alpha})$? There is a general theory on this topic (see e.g., Bertsekas' \"Nonlinear Programming\" for more formal details). But rather than talk about this in the abstract, let us look at our specific problem. We have\n\n$[z]_+ = \\max\\{0, z\\} = \\max_{\\alpha \\in [0,1]} \\alpha z.$\n\nTherefore,\n\n$[1 - y_n \\mathbf{x}_n^T \\mathbf{w}]_+ = \\max_{\\alpha_n \\in [0,1]} \\alpha_n (1 - y_n \\mathbf{x}_n^T \\mathbf{w}).$\n\nSo we can rewrite the SVM problem as:\n\n\\[\n\\min_{\\mathbf{w}} \\max_{\\alpha_n \\in [0,1]} \\frac{1}{N} \\sum_{n=1}^N \\alpha_n (1 - y_n \\mathbf{x}_n^T \\mathbf{w}) + \\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2.\n\\]\n\nNote that $G(\\mathbf{w}, \\boldsymbol{\\alpha})$ is convex in $\\mathbf{w}$ and linear, hence concave, in $\\boldsymbol{\\alpha}$.\n\nQ2: When is it OK to switch $\\min$ and $\\max$?",
    "Note that it is always true that\n\n\\[\n\\max_\\alpha \\min_\\mathbf{w} G(\\mathbf{w}, \\alpha) \\leq \\min_\\mathbf{w} \\max_\\alpha G(\\mathbf{w}, \\alpha).\n\\]\n\nThis is easy to see:\n\n\\[\n\\min_\\mathbf{w} G(\\mathbf{w}, \\alpha) \\leq G(\\mathbf{w}, \\alpha) \\quad \\forall \\mathbf{w}, \\alpha \\Longleftrightarrow\n\\]\n\\[\n\\max_\\alpha \\min_\\mathbf{w} G(\\mathbf{w}, \\alpha) \\leq \\max_\\alpha G(\\mathbf{w}, \\alpha) \\quad \\forall \\mathbf{w} \\Longleftrightarrow\n\\]\n\\[\n\\max_\\alpha \\min_\\mathbf{w} G(\\mathbf{w}, \\alpha) \\leq \\min_\\mathbf{w} \\max_\\alpha G(\\mathbf{w}, \\alpha).\n\\]\n\nWe get equality if $G(\\mathbf{w}, \\alpha)$ is a continuous function that is convex in $\\mathbf{w}$, concave in $\\alpha$, and the domain of $\\mathbf{w}$ and $\\alpha$ are both compact and convex. I.e., in this case we have\n\n\\[\n\\min_\\mathbf{w} \\max_\\alpha G(\\mathbf{w}, \\alpha) = \\max_\\alpha \\min_\\mathbf{w} G(\\mathbf{w}, \\alpha).\n\\]",
    "In other words, we get equality if we have functions that look like saddles as in the previous figure. For SVMs the condition is fulfilled and we can switch the min and max. This leads to the following formulation\n\n$$\n\\max_{\\alpha \\in [0,1]^N} \\min_{\\mathbf{w}} \\frac{1}{N} \\sum_{n=1}^N \\alpha_n (1 - y_n \\mathbf{x}_n \\mathbf{w}) + \\frac{\\lambda}{2} ||\\mathbf{w}||^2.\n$$\n(1)\n\nTaking the derivative w.r.t. $\\mathbf{w}$ we get\n\n$$\n\\nabla_\\mathbf{w} G(\\mathbf{w}, \\alpha) = - \\frac{1}{N} \\sum_{n=1}^N \\alpha_n y_n x_n + \\lambda \\mathbf{w}.\n$$\n\nEquating this to 0, we can explicitly solve for $\\mathbf{w}$ for any given $\\alpha$. We get\n\n$$\n\\mathbf{w}(\\alpha) = \\frac{1}{\\lambda} \\sum_{n=1}^N \\alpha_n y_n x_n = \\frac{1}{\\lambda} \\mathbf{X}^T \\mathbf{Y} \\alpha,\n$$\n\nwhere $\\mathbf{Y} := \\text{diag}(y)$. Plugging this $\\mathbf{w} = \\mathbf{w}(\\alpha)$ back into the saddle-point formulation (1), gives rise to the following dual optimization problem:\n\n$$\n\\max_{\\alpha \\in [0,1]^N} \\frac{1}{N} \\sum_{n=1}^N \\alpha_n (1 - \\frac{1}{\\lambda N} \\alpha^T \\mathbf{X}^T \\mathbf{Y} \\alpha) + \\frac{1}{2} \\frac{1}{\\lambda^2} \\alpha^T \\mathbf{X}^T \\mathbf{Y X Y} \\alpha ||\\frac{1}{\\lambda} \\mathbf{X}^T \\mathbf{Y} \\alpha||^2 \\Rightarrow\n\n$$\n\\max_{\\alpha \\in [0,1]^N} \\alpha^T \\mathbf{1} - \\frac{1}{2 \\lambda N^2} \\alpha^T \\mathbf{Y} \\mathbf{X} \\mathbf{X}^T \\mathbf{Y} \\alpha\n$$\n\nQ3: When is the dual easier to optimize than the primal, and why?\n",
    "(1) The dual is a differentiable (but constrained) quadratic problem.\n\nmax $\\limits_{\\alpha \\in [0,1]^P}$ $ \\alpha^T1 - \\frac{1}{2 \\lambda}\\alpha^T Q \\alpha $,\n\nwhere $\\mathbf{Q} := \\text{diag}(y)XX^T\\text{diag}(y)$. Optimization is easy by using coordinate descent, or more precisely coordinate ascent since this is a maximization problem. Crucially, this method will be changing only one $\\alpha_n$ variable a time.\n\n(2) Note that in the dual formulation the data only enters in the form $\\mathbf{K} := XX^T$. This product $XX^T$ is called the \"kernel.\" We hence often say that this formulation is kernelized. As we will discuss in the next lecture, this has a very pleasing consequence.\n\n(3) The solution $\\alpha$ is typically sparse, and is non-zero only for the training examples that are instrumental in determining the decision boundary.\n\nRecall how the parameters $\\alpha_n$ were introduced:\n\n$[1 - y_n \\mathbf{x}_n^T \\mathrm{w}]_+= \\max_{\\alpha_n \\in [0,1]} \\alpha_n (1 - y_n \\mathbf{x}_n^T\\mathbf{w})$\n\nFrom this formulation we can see that there are three distinct cases we should consider:\n\na) Examples that lie on the correct side and outside the margin. For those $1 - y_n \\mathbf{x}_n^T \\mathbf{w} < 0$. Hence, $\\alpha_n = 0$.",
    "b) Examples that lie on the correct side and just \u201con the margin\u201d. I.e., for those we have $1 - y_n \\mathbf{x}_n^\\top \\mathbf{w} = 0$. Therefore $\\alpha_n \\in [0, 1]$.\n\nc) Examples that lie strictly inside the margin, or on the wrong side. I.e., for those we have $1 - y_n \\mathbf{x}_n^\\top \\mathbf{w} > 0$. Therefore $\\alpha_n = 1$.\n\nWe call the $\\mathbf{x}_n$ for which $\\alpha_n = 0$ non-support vectors, the $\\mathbf{x}_n$ for which $\\alpha_n \\in (0, 1)$ essential support vectors and bound support vectors when $\\alpha_n = 1$. The above consideration explains why we expect most $\\alpha_n$ to be zero.\n\nCoordinate Descent\n\nGoal: Find $\\alpha^\\star \\in \\mathbb{R}^N$ maximizing or minimizing $g(\\alpha)$.\n\nYet another optimization algorithm?\n\nIdea: Update one coordinate at a time, while keeping others fixed.\n\ninitialize $\\alpha^{(0)} \\in \\mathbb{R}^N$ \n\nfor $t = 0 : \\text{maxIter}$ do",
    "sample a coordinate $n$ randomly from $1, \\ldots, N$.\n\noptimize $g$ w.r.t. that coordinate:\n$$u^* \\leftarrow \\arg \\min_{u \\in \\mathbb{R}} g(\\alpha_1^{(t)}, \\ldots, \\alpha_{n-1}^{(t)}, u, \\alpha_{n+1}^{(t)}, \\ldots, \\alpha_N^{(t)})$$\n\nupdate\n$$\\alpha_n^{(t+1)} \\leftarrow u^*$$\n$$\\alpha_{n'}^{(t+1)} \\leftarrow \\alpha_{n'}^{(t)} \\text{ for } n' \\ne n \\text{ (unchanged)}$$\n\nend for\n\nIssues with SVM\n\n- There is no obvious probabilistic interpretation of SVM.\n\n*The pseudocode here is for coordinate descent, that is to minimize a function. For the equivalent problem of maximizing (coordinate ascent), either change this line to arg max, or use the arg min of minus the objective function.",
    "- Extension to multi-class is non-trivial (see Section 14.5.2.4 of KPM book).",
    "Machine Learning Course - CS-433\n\nNeural Nets \u2013 Basic Structure\n\nNovember 8, 2022\n\nchanges by Nicolas Flammarion 2019-2020, changes by B\u0151ltiger Urbanke 2019,2018,2017, @B\u0151ltiger Urbanke 2016\nLast updated on: November 7, 2022\n\nEPFL",
    "Outline\n\nWe started this course with a basic setup. We are given a training set $S_t = \\{(y_n, \\mathbf{x}_n)\\}$ and our aim is classification. We have seen that simple linear classification schemes like logistic regression\n\n$$\np(y \\mid \\mathbf{x}^\\top \\mathbf{w}) = \\frac{e^{\\mathbf{x}^\\top \\mathbf{w}}}{1 + e^{\\mathbf{x}^\\top \\mathbf{w}}}\n$$\n\ncan some times work very well but they have their limits. The key to improving such schemes is to add well chosen features to the original data vector. E.g., assume that our data is two-dimensional, where all data with label $y = 0$ lies inside the unit circle and all data with label $y = 1$ lies outside the unit circle. A linear scheme, limited to the original input, cannot classify this data well. But if we add the features $x_1^2 + x_2^2$ and the constant to the input then the linear classification becomes trivial.\n\nIn \"real\" applications we are faced with the problem that we do not know a priori what features are useful. One option is to add many polynomial features. E.g., we could add all polynomials of degree two or some fourier feature vector. But this quickly becomes computationally infeasible and can also lead to overfitting.\n\nOne way to address the computational issue is to use the \"kernel trick.\" Alternatively, we can add more domain relevant features but have them designed by a domain experts. But would it not be nice if we could learn the features of the data in the same way as we learn the weights of the linear classifier? This is what neural networks allow us to do.",
    "There is currently a lot of excitement about neural networks and its many applications. At the end of this short tutorial you will unlikely be able to program a neural net to play Go like a grandmaster. Many small tricks and lots of patience and computing power are needed to train neural nets for complicated tasks. But you will be able to write small scripts to solve standard handwriting recognition challenges. We will focus on basic questions.\nWe highly recommend the web tutorial by Michael Nielsen, neuralnetworksanddeeplearning.com and we will follow it in many aspects.\n\nThe Basic Structure\n\nLet us look at the structure of a neural network. It is shown in Figure 1. This is a neural net with one input layer of size $D$, $L$ hidden layers of size $K$, and one output layer. It is a feedforward network: the computation performed by the network starts with the input from the left and flows to the right. There is no feedback loop.\nAs always, we assume that our input is a D-dimensional vector. We see that there is a node drawn in Figure 1 for each of the $D$ components of $x$. We denote these nodes by $x_j^{(0)}$, where the superscript $(0)$ specifies that this is the input layer.\nThe same network can be used for regression as well as classification. The only difference will be in the output layer. Let us discuss the exact computation that is performed by these networks. We already described the input layer. Let us now look at the hidden layers. Let us assume that there are",
    "$K$ nodes in each hidden layer, where $K$ is a hyper-parameter that has to be chosen by the user and can/should be optimized via validation. There is no reason that all hidden layers should have the same size but we will stick to this simple model. How many layers are there typically? Not long ago, typical networks might have had just one or a few hidden layers. Modern applications have \u201cdeep\u201d nets with sometimes hundreds of layers. Training such deep nets poses new and challenging problems and we will have more to say about this later.\n\nEach node in the hidden layer $l$, $l = 1, \\ldots, L$, is connected to all the nodes in the previous layer via a weighted edge. We denote the edge from node $i$ in layer $l - 1$ to the node $j$ in layer $l$ by $w_{ij}^l$. The super-script $(l)$ indicates that these are the weights of edges that lead to layer $l$.",
    "The output at the node $j$ in layer $l$ is denoted by $x_j^{(l)}$ and it is given by\n\\[ \nx_j^{(l)} = \\phi \\left( \\sum_i w_{ji}^{(l)} x_i^{(l-1)} + b_j^{(l)} \\right). \n\\]\n\nIn words, in order to compute the output we first compute the weighted sum of the inputs and then apply a function $\\phi$ to this sum.\n\nA few remarks are in order. The constant term $b_j^{(l)}$ is called the bias term and is a parameter like any of the weights $w_{ji}^{(l)}$. The learning part will consist of choosing all these parameters appropriately for the task. The function $\\phi(\\cdot)$ is called the activation function. Many possibilities exist for choosing this function and we will explore some choices later on. For now, let us just mention one of the most popular ones, namely the sigmoid function $\\phi(z) = \\frac{1}{1+e^{-z}}$. We have encountered this function already. It is the same as the logistic function. For future reference, Figure 2 shows a plot of this function. Note that the function is increasing from 0 to 1 and that for very small (negative) and very large (positive) values of the argument the function is very flat. As we will discuss, this will cause troubles when training the net since the derivative will vanish there.\n\nIt is crucial that this function is non-linear. Why is this? Assume otherwise in which the neural-net would just be a highly factorized linear transformation of the input data and there would be no gain compared to standard linear regression/classification. Although it is possible to choose different activation functions for different nodes, it is common to choose the same function within the network.",
    "To connect back to our previous discussion we can decompose the neural network into two parts. The first part comprises the input layer and all the $L$ hidden layers. The task of this part of the net is to transform the original input into a more suitable representation. In other words, this part of the net represents a function from $R^D$ to $R^K$. It performs the task that typically was done by domain experts, namely finding suitable features of the input. We will soon discuss what functions such a network can implement. We will see that this simple structure can approximate any continuous function arbitrarily closely provided only that we allow $K$ to be sufficiently large.\n\nNow that we have (hopefully) a suitable representation of the data, the final layer performs the desired ML task. This means that it is either our trusted linear regressor or perhaps a linear classifier. Presumably at this point the regression/classification task is easy. So a simple linear regres-",
    "sor/classifier suffices.",
    "Machine Learning Course - CS-433\n\nNeural Nets \u2013 Representation Power\n\nNovember 8, 2022\n\nchanges by Nicolas Flammarion 2018-2020, changes by R\u00fcdiger Urbanke 2019,2018,2017, @R\u00fcdiger Urbanke 2016 Last updated on: November 7, 2022",
    "Motivation\n\nIn the last lecture we introduced the basic structure of a neural net. It is shown in Figure 1. Recall that we can split this network into two parts. The first part comprises the input layer and all the $L$ hidden layers. The task of this part of the net is to transform the original input into a more suitable representation. In other words, this part of the net represents a function from $\\mathbb{R}^D$ to $\\mathbb{R}^K$. The second part, represented by the final layer performs the actual ML task (regression or classification).\n\nWe will now focus on the first part. We will ask: How \"powerful\" are neural nets? More precisely, what functions $f(x)$ can they represent, or better, what functions can they approximate? We will see that even relatively simple nets (with at most two hidden layers) are capable of approximating any",
    "continuous function arbitrarily closely on a bounded domain, assuming only that we allow a large number of nodes and arbitrary weights and biases.\n\nWe will not take a rigorous approach. Rather, we will follow the lead of Michael Nielsen and give a heuristic but rather convincing argument which shows why neural nets are so expressive.\n\nIf you are interested in a rigorous approach we recommend that you read either \u201cApproximation by superposition of a sigmoidal function\u201d by Cybenko (1989), or \u201cUniversal approximation bounds for superpositions of a sigmoidal function\u201d by Barron (1993). Both of these papers deal with networks with a single layer and sigmoids as approximation functions. Since then, many further approximation results for various network structures, activation functions, and approximation measures have been derived.\n\nBefore we get into our heuristic argument let us state the main theorem of the paper by Barron. This gives you a flavor of what kind of results can be proved.",
    "Lemma. Let $f : \\mathbb{R}^D \\rightarrow \\mathbb{R}$ be a function such that\n\n\\[\n\\int_{\\mathbb{R}^D} |\\omega||\\hat{f}(\\omega)|d\\omega \\leq C,\n\\]\n\nwhere\n\n\\[\n\\hat{f}(\\omega) = \\int_{\\mathbb{R}^D} f(x)e^{-j\\omega^T x}dx\n\\]\n\nis the Fourier transform of $f(x)$.\nThen for all $n \\geq 1$, there exists a function $f_n$ of the form\n\n\\[\nf_n(x) = \\sum_{j=1}^n c_j \\phi(\\mathbf{x}^T \\mathbf{w}_j + b_j) + c_0,\n\\]\n\ni.e., a function that is representable by a NN with one hidden layer with $n$ nodes and \"sigmoid-like\" activation functions so that\n\n\\[\n\\int_{|x| \\leq r} (f(x) - f_n(x))^2 dx \\leq \\frac{(2Cr)^2}{n}.\n\\]\n\nDiscussion: First note that the condition on the Fourier transform is a \"smoothness condition.\" E.g., functions so that $\\int_{\\mathbb{R}^D} |\\omega||f(\\omega)| < \\infty$ can be shown to be continuously differentiable.\nSecond note that the lemma only guarantees a good approximation in a bounded domain. The larger the domain, the more nodes we need in order to approximate a function to the same level (see the term $r$, where $r$ is the radius of the ball where we want the approximation to be good, in the upper bound).",
    "Third, this is an approximation \"in average\", more precisely in $L_2$-norm. We will mostly discuss approximations in this sense but come back to this point at the end.\nFourth, the approximation $f_n$ with $n$ terms corresponds exactly to our model of a neural net with one hidden layer containing $n$ nodes and sigmoids as activation functions.\nFifth, the theorem applies to all activation functions that are \"sigmoid-like,\" i.e., all activation functions whose left limit is $0$, whose right limit is $1$, and that are sufficiently smooth. In words the lemma says that a sufficiently \"smooth\" function can be approximated by a neural net with one hidden layer and the approximation error goes down like one over the number of nodes in the hidden layer. Note that this is a very fast convergence.\n\n\\textbf{Approximation in Average}\n\nWe will now give a very simple and intuitive explanation why neural nets with a sigmoid as activation function and at most two hidden layers have already a large expressive power. This explanation will not be rigorous and it will fall far short of the stated lemma by Barron which proves that in fact we only need one hidden layer and not too many hidden nodes. We will search for an approximation \"in average\", i.e., an approximation so that the integral over the absolute value of the difference is arbitrarily small.",
    "Functions $\\mathbb{R} \\to \\mathbb{R}$\n\nWe start with a scalar function $f(x)$ on a bounded domain. Recall that if this function is continuous then it is Riemann integrable, i.e., it can be approximated arbitrarily closely by \u201cupper\u201d and \u201clower\u201d sums of rectangles, see Figure 2. Of course, we might need a lot of such rectangles to approximate the area with an error of at most $\\epsilon$, but for every $\\epsilon > 0$ we can find such an approximation.\nWe will now show that if we do not limit the weights $\\theta$, then with two hidden nodes (of a neural network with one hidden layer) we can construct a function which is arbitrarily close to a given rectangle. But since, as we have just seen, a finite number of rectangles suffices to approximate a bounded continuous function arbitrarily closely, it follows that with a finite number of hidden nodes of a neural network with one hidden layer we can approximate any such function arbitrarily closely (in the sense that the integral of the absolute value",
    "The following idea is taken from the tutorial by Michael Nielsen, http://neuralnetworksanddeeplearning.com.\n\nLet $\\phi(z) = \\frac{1}{1+e^{-z}}$ be the sigmoid function. We have encountered it already in the last lecture. But here it is again in Figure 3.\n\nConsider the function $f(x) = \\phi(w(x - b))$, where $w$ is the weight of a particular edge and $-wb$ is the bias term. Note that if $w \\ge 0$ then $f(x)$ is an increasing function that increases smoothly from 0 to 1. Further, the \"transition\" happens at the spot $x = b$, i.e., at this value of $x$ the function has the value $\\frac{1}{2}$. The transition is the faster the larger we choose the weight $w$. In fact, if we set $b = 0$ so that the transition from 0 to 1 happens at $x = 0$, then the derivative of the function at 0 is $w/4$. In other words, the width of the transition is of order $4/w$.\n\nTherefore, if we want to create a rectangle that jumps from 0 to 1 at $x = a$ and jumps back to 0 at $x = b, a < b$, then",
    "we can accomplish this by taking\n$$\\phi(w(x - a)) - \\phi(w(x - b)), \\tag{1}$$\nand taking $w$ to be very large. This is shown in Figure 4 where the three figures correspond to $w = 10, 20$ and $50$, respectively and $a = -3$ and $b = 5$. We see that for large values of $w$ the result is barely distinguishable from a true rectangle.\n\nNote that equation (1) has a very simple representation in form of a neural net. This is shown in Figure 5. There is one input node which contains the value $x$. This value is",
    "multiplied by some large weight (in the figure it is 50) and it is then forwarded to the two hidden nodes. One of these hidden nodes has a bias of 150 the other one has a bias of $-250$, so that the sums at these two hidden nodes are $50(x+3)$ and $50(x-5)$, respectively. Each node applies the sigmoid function and forwards the result to the output layer. The edge from the top hidden node to the output has weight $1$ and the one from the bottom hidden node to the output has weight $-1$. The output node adds the two results and the result is $\\sigma(50(x+3)) - \\sigma(50(x-5))$, which is approximately a unit-height rectangle from $-3$ to $5$. If we want a rectangle of height $h$, use the weights $h$ and $-h$ in the second layer instead of the weights $1$ and $-1$. \n\nIt is hopefully clear at this point why any continuous function on a bounded domain can be approximated via a neural network with one hidden layer. Let us summarize in telegram style: Take the function. Approximate it in the Riemann sense. Approximate each of the rectangles in the Riemann sum by means of two rectangles in the hidden layer of a neural net. Compute the sum (with appropriate sign) of all the hidden layers at the output node. If we are using a Riemann sum with $K$ rectangles we get therefore a neural network approximation with one hidden layer containing $2K$ nodes. \n\nA few remarks are in order: \n\n1. The same intuition applies to many activation functions. All we have used is that the activation function has left limit 0 and right limit 1, just like for Barron's result. \n\n2. Whereas Barron's result gave us a strong bound on",
    "the number of required nodes, our intuitive explanation gave us no bound.\n\n3. The above approximation only works if we allow the weights to become arbitrarily large. Of course, very large weights would likely cause problems in practice. It is also not clear why we should need them. There is no fundamental reason why we should first approximate rectangles very precisely which then in turn approximate a continuous function.\n\n**Functions $\\mathbb{R}^D \\rightarrow \\mathbb{R}$**\n\nSo far we have talked about a real function of a single variable. What about functions over $\\mathbb{R}^D$? We will see that the same principle applies but we will need one major idea: the extra idea that is needed to extend the above scheme from one to several dimensions is already present in $\\mathbb{R}^2$. We will therefore stick to this case. You should have no trouble figuring out how to extend it to $\\mathbb{R}^D$.\n\nAs before, it will suffice if we can show how to approximate any two-dimensional rectangle. In fact, all we need are two-dimensional rectangles that are parallel to the two axes. Let the two inputs/axes be $x_1$ and $x_2$, represented by two nodes in the input layer. Assume that we want to represent a rectangle of height 1 that extends from $a_1$ to $b_1$, $a_1 < b_1$, on the $x_1$ axis and from $a_2$ to $b_2$, $a_2 < b_2$, on the $x_2$ axis. Consider the ray in Figure 1.6 It represents a rectangle that goes from $a_1$ to $b_1$ in the direction of the $x_1$ axis but is unbounded in the $x_2$ direction. The function it represents is",
    "shown Figure 7.\n\nLet us add to this rectangle another one that is unbounded in the $x_1$ direction but extends from $a_2$ to $b_2$ in the direction of the $x_2$ axis. The corresponding neural net is shown in Figure 8 and the plot of the corresponding function is shown in Figure 9. This is close to what we want. In the region where we want the function to be 1 it is in fact close to 2 since we have there the sum of two functions, each of height 1. A trivial scaling by a factor 1/2 would bring it to the desired value in this region. But unfortunately we still have in addition the two \u201carms\u201d that extend to infinity along each axis. Those have height 1.\nBut those additional unwanted \u201carms\u201d are easily suppressed. Just apply the sigmoid function with some large weight and bias, lets say $3/2$, to the node that sums up the two rectangles. A plot of the resulting function is shown in Figure 10. So instead of being the output node, as it was before, this",
    "node now becomes a hidden node, forming one extra layer of hidden nodes. With this we have created the desired 2-dimensional rectangle. We can approximate any sufficiently smooth 2-dimensional function on a bounded domain by using a suitable number of those and adding them at the output node.\n\n**Point-wise Approximations and other Activation Functions**\n\nSo far we have considered approximations \"in average\". I.e., we have seen for Barron's result that the $L_2$ norm can be made arbitrarily small. And for our intuitive derivation we took the Riemann integral as a starting point, i.e., we considered the $L_1$ norm. We can also ask if a point-wise approximation with vanishing",
    "error is possible, i.e., we can consider the L\u221e norm. Further, we have limited our discussion so far to \"sigmoid-type\u201d activation functions, i.e., activation functions whose left limit is 0 and whose right limit is 1. So let us now look at point-wise approximations with an activation function that is the rectified linear function,\n\n\\[\n(x)_+ = \\max\\{0, x\\}.\n\\]\n\nMany other combinations (approximation criterion and activation function) are of course possible and have been considered. Let \\(f(x)\\) be a continuous function on a bounded domain. Without loss of generality we can assume that this domain is \\([0, 1]\\), rescaling and shifting the x-axis if necessary. The classical Stone-Weierstrass theorem says that for every \\(\\epsilon > 0\\), there exists a polynomial \\(p(x)\\) so that for all \\(x \\in [0, 1]\\),\n\n\\[\n|f(x) - p(x)| < \\epsilon .\n\\]",
    "But such a function $f(x)$ can also be approximated in $L_\\infty$ norm by even simpler functions, namely continuous piecewise- linear functions, see Shektman, 1982. Let $q(x)$ be a continuous piecewise-linear function. Then it has the form\n\n\\[ \nq(x) = \\sum_{i=0}^m (a_i x + b_i)_{[r_i \\leq x < r_{i+1}} \n\\]\n\nwhere $0 = r_0 < r_1 < \\cdots < r_m = 1$ is a suitable partition of $[0, 1]$. Note that continuity imposes the constraints\n\n\\[ \na_{i+1} r_{i+1} + b_{i+1} = a_i r_{i+1} + b_i \\ , i = 1, \\cdots, m - 1. \n\\]\n\nFor our purpose it is more convenient to write in the al-",
    "The function $\\phi(w(g(x_1, x_2) - 3/2))$ where $g(x_1, x_2)$ is the function shown in Figure 9. This is now a good approximation of the desired rectangle.\n\n$q(x) = \\hat{a}_1 x + \\hat{b}_1 + \\sum_{i=2}^m \\hat{a}_i(\\hat{x} - \\hat{b}_i).$\n\nHere, $\\hat{a}_1 = a_1$ and $\\hat{b}_1 = b_1$ and for $i = 2, \\cdots, m$, the remaining parameters can be computed via the relations\n\\[\na_i = \\sum_{j=1}^i \\hat{a}_j,\n\\]\n\\[\nb_i = \\hat{b}_{i-1}.\n\\]\n\nEach term in the sum on the right corresponds to one node in a hidden layer with input $x$, bias $- \\hat{b}_i$, and activation function $(x^+).$ The bias term $\\hat{b}_1$ can be absorbed into the bias term of the output node. This leaves the term $\\hat{a}_1 x$.",
    "term can also be represented by a node in the hidden layer with activation function $(x)_+$ by choosing $x_0 = 0$, since we only need this representation to be correct in the range $[0, 1]$. So this shows that we can approximate any continuous function on a bounded domain by a neural net with one hidden layer in the $L_\\infty$ norm to arbitrary precision.\n\nWe have only considered the one-dimensional case. But it turns out that a similar scheme works also for higher dimensions. We skip the details.",
    "Machine Learning Course - CS-433\n\nSVD and PCA\n\nDec 7, 2022\n\nMartin Jaggi\nLast updated on: December 6, 2022\ncredits to Mohammad Emtiyaz Khan & R\u00fcdiger Urbanke\n\nEPFL",
    "Motivation\n\nPrincipal component analysis (PCA) is a popular method for dimensionality reduction. The idea is simple. Given the data matrix, we are looking for a linear mapping of the $D$-dimensional input into a $K$-dimensional space, $K \\leq D$, that \u201cbest\u201d represents the original data. In other words, we \u201ccompress\u201d the data with as small as possible distortion. There is also a second interpretation of the PCA. We are looking for a linear transformation of the $D$-dimensional input into a $K$-dimensional space, $K \\leq D$, that has maximum variance. This can also be phrased probabilistically, as asking for a linear transform that \u201cdecorrelates\u201d the input data. We will see that all these questions lead to the same answer and that this answer can be computed from the data matrix $\\mathbf{X}$ via the so-called singular value decomposition (SVD). PCA has strong connections to matrix factorizations, some of which we\u2019ve already seen. In all our subsequent discussion, $\\mathbf{X}$ is the $D \\times N$ data matrix, whose $N$ columns represent the input datapoints in $D$-dimensional space.\n\nSVD\n\nWe start with the singular value decomposition (SVD). Recall that any $D \\times N$ matrix $\\mathbf{X}$ can be written in the form\n\n$$\\mathbf{X} = \\mathbf{U} \\mathbf{S} \\mathbf{V}^\\top$$\n\nFor simplicity in the following we assume that $D < N$.",
    "is an arbitrary choice, but by consistently sticking with this convention it will make it easier to tell the dimensions apart. Here, $U$ is of size $D \\times D$ and $V$ is of size $N \\times N$ and both matrices are unitary\\footnote{Our notation assumes that the matrix is real-valued. In this case all of the matrices in the SVD are also real-valued and $U$ and $V$ are said to be orthogonal meaning that their inverse is their transpose. We use the term unitary in a more general sense that the matrix is unitary. In this case the transpose operator is supposed to be interpreted as the usual transpose for real-valued matrices and as $U^{*}$ for complex-valued matrices. The end result is that our formulas still hold regardless of whether $U$ and $V$ as unitary even though we assume that they are real-valued}, i.e.,\n\n\\[ UU^T = U^T U = I_{DxD}, \\]\n\\[ VV^T = V^T V = I_{NxN} \\]\n\nRecall that the condition $UU^T = I_{D \\times D}$ means that the matrix $U$ has orthonormal (i.e., orthogonal and norm 1) rows and that $U^T = U^{-1}$. But if $UU^T = I_{D \\times D}$ then also $U^TU = U^{-1}U = I_{D \\times D}$ so that also the columns of $U$ are orthonormal. Therefore, requiring that a square matrix is unitary is the same as requiring that it has orthonormal",
    "rows, or requiring that it has orthonormal columns.\nOne useful property of a unitary matrix is that the linear\ntransform it represents can be interpreted as a \u201crotation\u201d,\ni.e., it does not change the length of the vector that is being\ntransformed:\n\n\\[ ||Ux||_2^2 = x^T U^T Ux = x^T x = ||x||_2^2. \\]\n\nThe matrix S is a diagonal matrix of size \\(D \\times N\\) with non-negative entries along the diagonal. These diagonal entries are called the singular values. The columns of U and V are called the left and right singular vectors, respectively.\nBy convention, the singular values appear in a descending order in S, i.e., we have \\(s_1 \\geq s_2 \\geq s_3 ... \\geq s_D \\geq 0\\), where \\(s_j\\) is the j-th singular value.\nWe will see that this transform plays a key role in our discussion. We will take this representation for granted and not give a proof of the SVD. But we will show how to perform an optimal dimensionality reduction given this representation.\n\nSVD and Dimensionality Reduction\n\nWe want to \u201ccompress\u201d the data matrix \\(\\mathbf{X}\\) from dimension \\(D\\)\nto lets say dimension \\(K, 1 \\leq K \\leq D\\). More precisely, we\nare looking for a linear transform given by the \\(K \\times D\\) matrix\n\\(\\mathbf{C}\\) (the compression) and a second linear transform given by\nthe \\(D \\times K\\) matrix \\(\\mathbf{R}\\) (the reconstruction) so that\n\n\\[ ||\\mathbf{X} - \\mathbf{RCX}||_F^2 \\]\n\nis minimized over all choices of \\(\\mathbf{C}\\) and \\(\\mathbf{R}\\).",
    "In words, we want to compress the $D \\times N$ data matrix $\\mathbf{X}$ into the $K \\times N$ matrix $\\mathbf{CX}$ in such a way that the data is represented \u201cas faithful as possible\u201d.\n\nHow do we measure the quality of the representation? We ask that the reconstruction $\\mathbf{RCX}$ differs from the original matrix $\\mathbf{X}$ as little as possible in the sense that the Frobenius norm of their difference is small, where\n\n\\[ \\|\\mathbf{A}\\|_F^2 := \\sum_{i,j} |\\mathbf{A}_{ij}|^2. \\]\n\nNote that there are other natural ways of measuring the quality of a reconstruction but for simplicity we stick to this one measure.$^{2}$\n\n**Lemma.** For any $D \\times N$ matrix $\\mathbf{X}$ and any $D \\times N$ rank-$K$ matrix $\\mathbf{\\hat{X}}$\n\n\\[ \\| \\mathbf{X} - \\mathbf{\\hat{X}} \\|_F^2 \\geq \\| \\mathbf{X} - \\mathbf{U}_K \\mathbf{U}_K^\\top \\mathbf{X} \\|_F^2 = \\sum_{i=K+1}^N s_i^2, \\]\n\nwhere $\\mathbf{X} = \\mathbf{USV}^\\top$ is the SVD of $\\mathbf{X}$, the $s_i$ are the singular values of $\\mathbf{X}$, and $\\mathbf{U}_K$ is the $D \\times K$ matrix consisting of the first $K$ columns of $\\mathbf{U}$.\n\nWe state a proof of this fact at the end of these notes. Recall that the columns of $\\mathbf{U}$ are called the left singular vectors of $\\mathbf{X}$. What the lemma tells us is that we should compress the data by projecting it onto these left singular vectors. More precisely, the lemma tells us the important information...",
    "data is contained in the projection onto the first left singular vector, the second most important information is contained in the projection onto the second left singular vector etc. So the components are ordered in terms of importance, with the most important one being the first. In other words, our analysis/processing of the data uses the principal/most important components. This is why the above scheme is called the principal component analysis (PCA).\n\nThe expression $U_K U_K^T X$ has a very simple interpretation. Let $S(K)$ be the $D \\times N$ diagonal matrix that is equal to $S$ for the first $K$ diagonal entries but is 0 thereafter.\n\nWe claim that\n$$\nU_K U_K^T X = U_K U_K^T USV^T = US^{(K)} V^T. \\tag{2}\n$$\n\nWith this interpretation, the lemma states that the best rank-$K$ approximation to a matrix $X$ is obtained by computing the SVD and by setting all the singular values $s_j$, $j \\ge K+1$ to zero.\n\nThe claim (2) is easily seen by checking that\n$$\nU_K^T U = (I_{K \\times K}; 0) \\in \\mathbb{R}^{K \\times D}\n$$\nis a $D \\times D$ matrix whose first $K$ columns are the $K$ identity and whose remaining columns are 0.\n\n**Example Application.** Let us now discuss the implications of the SVD. One way to visualize the usefulness of the SVD is to see what it says about compression problems. For a set of images, let the vector of $D$ pixels that represent each image. We can then compress an image by running",
    "SVD and compress the picture with the scheme above, projecting the image onto the first $K$ columns of $U$. To see how well this works we can then reconstruct this image back to the original image space $\\mathbb{R}^D$ and visualize it next to its original. This is shown in Figure 2 above. \n\nNote that this is a slightly different application of what we had in mind when we started \u2013 as here we care about the compression, not so much about the lower-dimensional representations in $\\mathbb{R}^D$. But it gives a good intuition why this is a useful method.",
    "SVD and Matrix Factorization\n\nIn previous lectures we have seen already several applications of matrix factorizations. Let us now discuss how the SVD relates to this problem.\nAssume that we are given the data matrix $X$. Use the SVD to write it as $X = USV^T$.\n\n$$\nX = USV^T = U \\begin{Vmatrix}W \\\\ Z \\end{Vmatrix} S V^T = WZ^T.\n$$\n\nSo we have achieved a perfect factorization of our data matrix.\n\nThere are two differences compared to matrix factorization problems.\n\nFirst, in the matrix factorization problem we typically restrict $W$ and $Z$ to have few columns only, lets say $K$, where",
    "in SVD we can control the rank at any time later, and can let it range up to $\\min\\{D, N\\}$. Of course, in the low-rank case we cannot hope for a perfect factorization but we are looking for the best possible approximation.\nThis difference can be easily addressed as we have already seen. Let $1 \\leq K \\leq \\min(D, N)$. Let $S^{(K)}$ be the matrix that is equal to $S$ except that all singular values $s_j$ for $j \\geq K + 1$ are set to zero. We have seen this matrix already in our discussion of the SVD.\nThis gives us the rank-$K$ approximation\n\\[X_K := US^{(K)}V^\\top,\\]\nand indeed, as we have discussed, it is the best rank-$K$ approximation that we can find in the sense that the Frobenius norm of the difference is smallest possible and is equal to $\\sum_{i=K+1} s_i^2$, where the $s_i$ are again the singular values of $X$.\n\nWe can again write the above approximation in a factorized form. Again, let $U_K$ be the matrix consisting of the first $K$ columns of $U$. Similar to before we can now write\n\\[X_K = U_KS^{(K)} V^\\top = U_K \\begin{bmatrix} S^{(K)} \\\\ \\mathbf{0} \\end{bmatrix} V^\\top = WZ^\\top,\\]\nwhere $W$ is an $D \\times K$ matrix and $Z^\\top$ is a $K \\times N$ matrix.\n\nThe second difference is that in general matrix factorization problems we can have data matrix $X$ that can have many missing entries. Indeed, one can construct a low-rank factorization that was close in the known values in order to predict",
    "the missing values, as we will see in the next lecture. The method using the SVD on the other hand starts with a com- plete data matrix. There does not seem to be an easy \ufb01x to adapt the SVD to the case of missing values. And so we see that despite some similarities between these problems there are also some signi\ufb01cant differences.\n\nPCA and Decorrelation\n\nThere is another, probabilistic, view-point that gives insight why the PCA is a good idea. Assume that the $D$-dimensional data points are generated in an i.i.d. fashion according to some unknown distribution $D_X.$ These N data points form the columns of our $D \\times N$ matrix $\\mathbf{X}.$ Let us compute the empirical/sample mean and co-variance: We have\n\\[\n\\mathbf{x} = \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{x}_n, \\quad \\mathbf{K} := \\frac{1}{N} \\sum_{n=1}^{N} (\\mathbf{x}_n - \\mathbf{x}) (\\mathbf{x}_n - \\mathbf{x})^\\top\n\\]\nIf indeed the data comes from i.i.d. samples then the sample mean will converge to the true mean and the sample co- variance matrix will converge to the true covariance matrix as $N \\to \\infty.$ Assume that we have pre-processed the data matrix $\\mathbf{X}$ by subtracting the mean from each row. Using the SVD, the empirical covariance matrix can be written as\n\\[\n\\mathbf{K} = \\frac{1}{N} \\sum_{n=1}^{N} \\mathbf{x}_n \\mathbf{x}_n^\\top \n= \\mathbf{X X}^\\top = \\mathbf{U S V}^\\top \\mathbf{V S}^\\top \\mathbf{U}^\\top = \\mathbf{U S}^2 \\mathbf{U}^\\top \n\\]",
    "where $S_D$ is the $D \\times D$ diagonal matrix consisting of the $D$ first columns of $S$. \n\nNow consider instead the transformed data $\\hat{X} = U^TX$. It has a sample co-variance matrix of\n\n\\[\n\\hat{N}\\hat{K} = \\hat{X} \\hat{X}^T = U^TXX^TU = U^TUS^2U^TU = S_D^2.\n\\]\n\nThis means, we have linearly transformed the data in such a way that the empirical co-variance matrix is diagonal, i.e., the various components are uncorrelated. This gives us some intuition why it is perhaps useful to first linearly transform the data via the \"rotation\" $U^TX$.\n\nMore is true. Note that by definition of the SVD, the first singular value, $s_1$, is the largest of all singular values. And the empirical variance of the first feature component is equal to $s_1^2$ according to our calculation. This means that of the components in our feature vector $\\hat{X}$, the first component has the largest variance.\n\nAssume that we are doing classification. It is then intuitive that it is easier to classify features that have a large variance than those that have a small variance. To see this, assume the extreme case where the variance is 0 in a particular component, i.e., the data is constant in this component. This component is then not useful for classification. \nFrom this point of view, it is then intuitive why it is good to keep the first $K$ rows of $\\hat{X}$ when we perform a dimensionality reduction. These are the components that have the highest variance and they are uncorrelated.",
    "To make sure that we understand the probabilistic interpretation of PCA, let us consider the following example. Let $x_j$ be i.i.d. samples from a D-dimensional Gaussian of mean zero and with covariance matrix \n\n\\[\nK = Q \\Lambda Q^T,\n\\]\n\nwhere $Q$ is a $D \\times D$ unitary matrix and $\\Lambda$ is a diagonal matrix with strictly non-zero entries.\nLet $X$ be the resulting $D \\times N$ data matrix. Assume that we run a PCA on this matrix without any preprocessing. Under the assumption that all eigenvalues are distinct and that $N$ tends to infinity what do you expect $U$ to be? What could happen if some of the eigenvalues are equal?\n\nHow to Compute $U$ and $S$ Efficiently\nWe start again with the SVD\n\n\\[\nX = USV^T.\n\\]\n\nWe have seen in our discussion that for applications we need to compute $U$ and $S$. Let us see how we can do this efficiently.\nConsider the $D \\times D$ matrix $XX^T$. We have \n\n\\[\nXX^T = USSV^T (USV^T)^T,\n\\]\n\nLet $u_j, j = 1, \\ldots, D$, denote the columns of $U$. Then\n\n\\[\nXX^T u_j = US^2 V^T u_j = s_j^2 u_j.\n\\]",
    "So we see that the j-th column of $\\mathbf{U}$ is an eigenvector of $\\mathbf{X}\\mathbf{X}^\\top$ with eigenvalue $s_j^2$. Therefore, solving the eigenvector/value problem for the matrix $\\mathbf{X}\\mathbf{X}^\\top$ gives us a way to compute $\\mathbf{U}$ and $\\mathbf{S}$.\n\nThere is a subtle point here. If $\\mathbf{u}_j$ is an eigenvector of $\\mathbf{X}\\mathbf{X}^\\top$, then so is $-\\mathbf{u}_j$. So the signs of the columns of $\\mathbf{U}$ are not determined by this procedure. If we just want to compute $\\mathbf{X}_\\mathbf{K}$ in order to project $\\mathbf{X}$ onto its columns (PCA) then this sign does not matter since $\\mathbf{U}_\\mathbf{K}\\mathbf{U}_\\mathbf{K}^\\top$ is invariant to sign changes of columns of $\\mathbf{U}_\\mathbf{K}$.\n\nAnd what do we do if we want to determine the SVD? In this case the sign of the columns of $\\mathbf{U}$ is also not determined uniquely, it just has to be matched to the sign of the columns of $\\mathbf{V}$. Therefore, solve the eigenvector value eigenvector problem and fix some choice of signs to determine a $\\mathbf{D} \\times \\mathbf{D}$ matrix $\\mathbf{U}$ consisting of eigenvectors of $\\mathbf{X}\\mathbf{X}^\\top$. To find the matching $\\mathbf{V}$ just compute $\\mathbf{U}^\\top \\mathbf{X}$. This is equal to $\\mathbf{S}\\mathbf{V}^\\top$, but we know that the entries of $\\mathbf{S}$ are non-negative,$^{5}$ so we can easily compute the matching $\\mathbf{V}$.\n\nIn the exercise you will see that you can either solve the eigenvector problem for $\\mathbf{X}\\mathbf{X}^\\top$ or the one for $\\mathbf{X}^\\top\\mathbf{X}$. This comes in handy since we can then always work with the smaller of the two dimensions $\\mathbf{D}$ and $\\mathbf{N}$.\n\n$^{5}$Strictly speaking we do not compute the singular values $s_j$ but their squares $s_j^2$. But since we know that the singular values are non-negative we can just take the square root.",
    "Pitfalls of PCA\nAt this point it might seem that the PCA is a miracle cure. Just take the data, compute the SVD, and compress. But note that the SVD is not invariant under scalings of the features in the original matrix $\\mathbf{X}$. I.e., the final representation we get does depend on how we scale our individual features vectors and so there is a large degree of arbitrariness. It therefore remains very important that the data is normalized properly. Experience shows that it is a good idea to remove the mean of each feature and to normalize the variance to one.\n\nProof of the SVD Lemma\nLet us now prove our lemma. In fact, there are two parts that we need to show. First, let us show that if we pick the compressor and decompressor as prescribed in the statement we get\n$$ \\|\\mathbf{X} - \\mathbf{U}_K \\mathbf{U}_K^\\top \\mathbf{X}\\|_F^2 = \\sum_{i=K+1}^n s_i^2. $$\n\nWe have seen already in (2) that\n$$ \\mathbf{U}_K^\\top \\mathbf{X} = \\mathbf{U}\\mathbf{S}^{(K)} \\mathbf{V}^\\top ,$$\nwhere $\\mathbf{S}^{(K)}$ is a $D\\times N$ diagonal matrix that is equal to $\\mathbf{S}$ for the first $K$ diagonal entries but is 0 thereafter. Let $\\mathbf{S}^{(K)} = \\mathbf{S}-\\tilde{\\mathbf{S}}^{(K)}$, then\n$$ \\|\\mathbf{X} - \\mathbf{U}_K \\mathbf{U}_K^\\top \\mathbf{X}\\|_F^2 = \\| \\mathbf{U}\\tilde{\\mathbf{S}}^{(K)} \\mathbf{V}^\\top \\|_F^2 $$.",
    "The first claim is now proved by noting that\n\\[\n||U S' (K) V^\\top ||^2_F = ||S' (K) V^\\top ||^2_F = ||S'(K) ||^2_F = \\sum_{i=K+1} s_i^2.\n\\]\nIn the first step we multiplied the expression from the left by the unitary matrix $U^\\top$ and in the second step we multiplied the expression by the unitary matrix $V$ from the right. As we have discussed, such a \u201crotation\u201d does not change the Frobenius norm.\nTo prove that we cannot do any better we will follow the lead of Vanlaupet B, Willems JC, De Moor B (2006) Matrix factorization and stochastic state representations. In: Proc 45th IEEE conf on dec and control, San Diego, California, pp 4188\u20134193.\n\nIt remains to show that for any $D \\times N$ rank-$K$ matrix $\\hat{X}$,\n\\[\n||X - \\hat{X}||_F^2  \\geq \\sum_{i=K+1} s_i^2.\n\\]\nUsing the SVD of $X$ we get\n\\[\n||X - \\hat{X}||_F^2 = ||X - U \\hat{S} V^\\top ||_2^2 = ||U^\\top X V - \\hat{S}||_2^2.\n\\]\nAssume now that $\\hat{X}$ is in fact an optimal solution, i.e., it minimizes the Frobenius norm. Then it follows that $\\hat{S}$ is an optimal rank-$K$ approximation of $U^\\top X V$ and $\\hat{S}$ is a diagonal matrix with all 0 entries except potentially the first K diagonal entries. Write $\\hat{S}$ in the form\n\\[\n\\hat{S} = \\left( \\begin{array}{cc}\n\\Sigma & 0 \\\\\n0 & 0 \\\\\n\\end{array} \\right),\n\\]",
    "where $\\Sigma$ is a $K \\times K$ diagonal matrix.\n\nIt follows from the optimality assumption that $\\mathbf{U}^T \\mathbf{X} \\mathbf{V}$ must have a very special form. In particular, its top-left $K \\times K$ sub-matrix must be equal to $\\Sigma$. And it must be 0 everywhere else except perhaps for the bottom-right $(D-K) \\times (D-K)$ submatrix which can be non-zero.\n\nLet us discuss these claims in more detail. Write $\\mathbf{U}^T \\mathbf{X} \\mathbf{V}$ as\n\n\\[\n\\mathbf{U}^T \\mathbf{X} \\mathbf{V} = \\begin{pmatrix}\nA_{11} & A_{12} \\\\\nA_{21} & A_{22}\n\\end{pmatrix}\n\\]\n\nwhere $A_{11}$ is $K \\times K$. Our first claim is that $A_{11} = \\Sigma$. Assume that this is not the case. Then\n\n\\[\n\\begin{pmatrix}\nA_{11} & 0 \\\\\n0 & 0\n\\end{pmatrix}\n\\]\n\nis a matrix of rank at most $K$ that is a strictly \u201cbetter\u201d approximation to $\\mathbf{U}^T \\mathbf{X} \\mathbf{V}$ than $\\Sigma$, a contradiction.\n\nTo prove that $A_{12} = 0$ and $A_{21} = 0$ we proceed in a similar manner by considering the rank at most $K$ matrices\n\n\\[\n\\begin{pmatrix}\n0 & A_{12} \\\\\n0 & 0\n\\end{pmatrix}\n\\]\n\nand\n\n\\[\n\\begin{pmatrix}\n\\Sigma & 0 \\\\\nA_{21} & 0\n\\end{pmatrix}\n\\]\n\nrespectively. We skip the details.\n\nWe have so far shown that\n\n\\[\n\\mathbf{U}^T \\mathbf{X} \\mathbf{V} = \\begin{pmatrix}\n\\Sigma & 0 \\\\\n0 & A_{22}\n\\end{pmatrix}\n\\]\n\n(3)",
    "Using the SVD of $A_{22}$, $A_{22} = U_{22} \\Sigma_{22} V_{22}^T$, we can write\n\n\\[ \n\\mathbf{\\hat{U}}^T\n\\begin{pmatrix}\nI & 0 \\\\\n0 & U_{22}\n\\end{pmatrix}\n\\mathbf{X}\n\\begin{pmatrix}\nI & 0 \\\\\n0 & V_{22}\n\\end{pmatrix}\n\\mathbf{\\hat{V}} = \n\\begin{pmatrix}\n\\Sigma & 0 \\\\\n0 & \\Sigma_{22}\n\\end{pmatrix}.\n\\]\n\nWe see that this is a SVD of $\\mathbf{X}$ and so the diagonal elements have to be the singular values (recall that we have shown already that for any such representation the singular values are the squares of the eigenvalues of the symmetric matrix $\\mathbf{XX}^T$). Further, the largest singular values must be contained in the matrix $\\Sigma$ since otherwise again this would contradict the optimality of the rank at most $K$ approximation $\\mathbf{S}$. \n\nNow note that \n\\[ \n\\mathbf{\\hat{U}}^T\n\\begin{pmatrix}\nI & 0 \\\\\n0 & U_{22}\n\\end{pmatrix}\n\\mathbf{X}\n\\begin{pmatrix}\nI & 0 \\\\\n0 & V_{22}\n\\end{pmatrix}\n\\mathbf{\\hat{V}} - \n\\mathbf{\\hat{S}} = \n\\begin{pmatrix}\n0 & 0 \\\\\n0 & \\Sigma_{22}\n\\end{pmatrix}. \\quad (4)\n\\]\n\nTherefore, the Frobenius norm of (4) is equal to $||A_{22}||_F = \\sum_{j>k+1} s_j^2$, since we know that the diagonal matrix $\\Sigma_{22}$ contains the smallest singular values of $\\mathbf{X}$.",
    "Machine Learning Course - CS-433\n\nExpectation-Maximization Algorithm\n\nNov 30, 2022\n\nMartin Jaggi\nLast updated on: November 28, 2022\ncredits to Mohammad Emtiyaz Khan & R\u00e9mi Lebret\n\nEPFL",
    "Motivation\nComputing maximum likelihood for Gaussian mixture model is difficult due to the log outside the sum.\n\n$$\\max_{\\theta} L(\\theta) := \\sum_{n=1}^{N} \\log \\sum_{k=1}^{K} \\pi_k \\mathcal{N}(x_n | \\mu_k, \\Sigma_k)$$\n\nExpectation-Maximization (EM) algorithm provides an elegant and general method to optimize such optimization problems. It uses an iterative two-step procedure where individual steps usually involve problems that are easy to optimize.\n\nEM algorithm: Summary\nStart with $\\theta^{(1)}$ and iterate:\n\n1. Expectation step: Compute a lower bound to the cost such that it is tight at the previous $\\theta^{(i)}$.\n\n$$L(\\theta) \\geq L(\\theta, \\theta^{(i)})$$\n$$L(\\theta^{(i)}) = L(\\theta^{(i)}, \\theta^{(i)})$$\n\n2. Maximization step: Update $\\theta$:\n\n$$\\theta^{(i+1)} = \\arg \\max_{\\theta} L(\\theta, \\theta^{(i)})$$",
    "Concavity of log\n\nGiven non-negative weights $q$ s.t. $\\sum_k q_k = 1$, the following holds for any $r_k \\ge 0$:\n\n$$\n\\log \\left( \\sum_{k=1}^K q_k r_k \\right) \\ge \\sum_{k=1}^K q_k \\log r_k\n$$\n\nThe expectation step\n\n$$\n\\log \\sum_{k=1}^K \\pi_k \\mathcal{N}(x_n | \\mu_k, \\Sigma_k) \\ge \\sum_{k=1}^K q_{kn} \\log \\frac{\\pi_k \\mathcal{N}(x_n | \\mu_k, \\Sigma_k)}{q_{kn}}\n$$\n\nwith equality when,\n\n$$\nq_{kn} = \\frac{\\pi_k \\mathcal{N}(x_n | \\mu_k, \\Sigma_k)}{\\sum_{k=1}^K \\pi_k \\mathcal{N}(x_n | \\mu_k, \\Sigma_k)}\n$$\n\nThis is not a coincidence.",
    "The maximization step\nMaximize the lower bound w.r.t. $\\theta$.\n\n\\[\n\\max_{\\theta} \\sum_{n=1}^{N} \\sum_{k=1}^{K} q_k^{(t)} \\left[ \\log \\pi_k + \\log \\mathcal{N}(x_n | \\mu_k, \\Sigma_k) \\right]\n\\]\n\nDifferentiating w.r.t. $\\mu_k, \\Sigma_k$, we can get the updates for $\\mu_k$ and $\\Sigma_k$:\n\n\\[\n\\mu_k^{(t+1)} = \\frac{\\sum_{n} q_k^{(t)} x_n}{\\sum_{n} q_k^{(t)}}\n\\]\n\n\\[\n\\Sigma_k^{(t+1)} = \\frac{\\sum_{n} q_k^{(t)} (x_n - \\mu_k^{(t+1)})(x_n - \\mu_k^{(t+1)})^\\top }{\\sum_{n} q_k^{(t)}}\n\\]\n\nFor $\\pi_k$, we use the fact that they sum to 1. Therefore, we add a Lagrangian term, differentiate w.r.t. $\\pi_k$ and set to 0, to get the following update:\n\n\\[\n\\pi_k^{(t+1)} = \\frac{1}{N} \\sum_{n=1}^{N} q_k^{(t)}\n\\]",
    "Summary of EM for GMM\n\nInitialize $\\mu^{(1)}, \\Sigma^{(1)}, \\pi^{(1)}$ and iterate between the E and M step, until $\\mathcal{L}(\\theta)$ stabilizes.\n\n1. E-step: Compute assignments $q_{kn}^{(t)}$:\n\\[ q_{kn}^{(t)} = \\frac{\\pi_k^{(t)} N(X_n \\mid \\mu_k^{(t)}, \\Sigma_k^{(t)})}{\\sum_{k'=1}^K \\pi_{k'}^{(t)} N(X_n \\mid \\mu_{k'}^{(t)}, \\Sigma_{k'}^{(t)})} \\]\n\n2. Compute the marginal likelihood (cost):\n\\[ \\mathcal{L}(\\theta^{(t)}) = \\sum_{n=1}^N \\log \\sum_{k=1}^K \\pi_k^{(t)} N(X_n \\mid \\mu_k^{(t)}, \\Sigma_k^{(t)}) \\]\n\n3. M-step: Update $\\mu_k^{(t+1)}, \\Sigma_k^{(t+1)}, \\pi_k^{(t+1)}$:\n\\[ \\mu_k^{(t+1)} = \\frac{\\sum_n q_{kn}^{(t)} X_n}{\\sum_n q_{kn}^{(t)}} \\]\n\\[ \\Sigma_k^{(t+1)} = \\frac{\\sum_n q_{kn}^{(t)} (X_n - \\mu_k^{(t+1)})(X_n - \\mu_k^{(t+1)})^T}{\\sum_n q_{kn}^{(t)}} \\]\n\\[ \\pi_k^{(t+1)} = \\frac{1}{N} \\sum_n q_{kn}^{(t)} \\]\n\nIf we let the covariance be diagonal i.e.: $\\Sigma_k := \\sigma^2 I$, then EM algorithm is same as K-means as $\\sigma^2 \\rightarrow 0$.",
    "Posterior distribution\n\nWe now show that $q_{len}^{(t)}$ is the posterior distribution of the latent variable, i.e., $q_{len}^{(t)} = p(z_n = k | x_n, \\theta^{(t)})$\n\n\\[\np(x_n, z_n | \\theta) = p(x_n | z_n, \\theta)p(z_n | \\theta) = p(z_n | x_n, \\theta)p(x_n | \\theta)\n\\]",
    "EM in general\n\nGiven a general joint distribution $p(x_n, z_n|\\theta)$, the marginal likelihood can be lower bounded similarly:\n\nThe EM algorithm can be compactly written as follows:\n\n$$\n\\theta^{(t+1)} := \\arg \\max_{\\theta} \\sum_{i=1}^{N} \\mathbb{E}_{p(z_n | x_n, \\theta^{(t)})} [\\log p(x_n, z_n | \\theta)]\n$$\n\nAnother interpretation is that part of the data is missing, i.e. $\\langle x_n, z_n \\rangle$ is the \"complete\" data and $z_n$ is missing. The EM algorithm averages over the \"unobserved\" part of the data.",
    "NLP evaluation\n\nC. Grivaz, J.-C. Chappelier & M. Rajman\n\nLaboratoire d\u2019Intelligence Artificielle\nFacult\u00e9 I&C",
    "Outline\n\n\u25ba Evaluation protocol\n\u25ba Gold standard\n\u25ba Inter-annotator agreement\n\u25ba Evaluation metrics\n\u25ba Validity of the results",
    "NLP evaluation motivations\n\n- Evaluate the improvement of the technology on a specific task\n- Provide gold standards and objective comparison methods\n- Develop research and technology in NLP",
    "NLP evaluation protocol\n\n1. Define a control task\n2. Produce a reference (golden truth) from a large amount of typical data (for the task)\n3. Assess the quality of the reference\n4. Evaluate NLP system(s) on the reference\n5. Compare evaluations (statistical significance)\n6. Publish and discuss results",
    "Example: $n$-ary classification of linguistic entities\n\n1. **Define a control task**\n\nMany of the tasks performed by the existing NLP tools can be generically modeled as tagging tasks, i.e.:\nthe NLP tool automatically assigns, to each of the linguistic entities (documents, sentences, words, ...) to be processed, a single tag selected out of a finite number of possible tags.\n\nFor example:\n$\\blacktriangleright$  a part-of-speech tagger assigns, to each of the words present in a sentence, the grammatical category this word is associated with within this sentence;\n$\\blacktriangleright$  a parser assigns, to each of the sentences present in a corpus, a tag \"correct\" (resp. \"incorrect\") depending on whether this sentence can be considered as syntactically correct (resp. incorrect) w.r.t. the grammar used by the parser;\n$\\blacktriangleright$  a language identifier assigns, to each of the documents present in a corpus, a tag identifying the language this document is written in.",
    "Binary vs. $n$-ary classifications\n\nIf the number of distinct tags that can be assigned by a classifier is equal to $n$, the classification is generically referred to as an $n$-ary classification;\n\nMore specifically, we have:\n$\\blacktriangleright$ if $n = 2$ $\\longrightarrow$ binary classification\n$\\blacktriangleright$ if $n = 3$ $\\longrightarrow$ ternary classification\n\nNotice that any $n$-ary classification (using tags $t_1, t_2, \\ldots, t_n$) can be decomposed into a combination of $n$ binary classifications (respectively using the two tags $t_i$ and \"not $t_i$\u201d); however, these $n$ classifications may not be independent!",
    "Examples of binary and n-ary classifications\n\nExamples of binary classifications:\n\u25ba sentiment analysis: negative feeling vs. positive feeling\n\u25ba relevance analysis: relevant vs. \"not relevant\"\n\nExamples of n-ary classifications:\n\u25ba part-of-speech tagging: as many tags as grammatical categories (e.g. Noun, Verb, Adjective, Adverb, Determiner, Pronoun, ...)\n\u25ba language identification: as many tags as languages to be identified (English, French, Spanish, German, ...)",
    "An illustrative example: an English identifier\n\nConsider a language identifier, i.e. an NLP tools able to automatically associate to any text (or fraction of text) a tag identifying the language it is written in (e.g. EN for English, FR for French, GE for German, ES for Spanish, etc)\n\nIf N languages can be identified, the language identifier corresponds to an N-ary classifier, and ...\n\n...if we keep all EN tags unchanged and transform all the other produced tags into a new tag not(EN), we transform the N-ary classifier into a binary classifier (one of the N possible ones) corresponding to an English (text) identifier, i.e. an NLP tools that determines whether a text (or a fraction of text) is written in English or not",
    "1. Define a control task\n2. Produce a reference\n3. Assess the quality of the reference\n4. Evaluate NLP system(s) on the reference\n5. Compare evaluations (statistical significance)\n6. Publish and discuss results",
    "Need for a set of correct answers\n\nContrary to some other tasks, there is generally no simple way to know if a NLP system gives correct results\n\nespecially when the goal of an NLP task is to mimic something that a human can do\n\ngold standard: set of correct answers to a task,\nfor a sample of typical inputs for the control task\n\nEvaluation methodology:\nthe sample of input is then given to the automatic system and its output is compared to the gold standard",
    "Reference = data annotated with expected outputs\n\nIn NLP, the reference (golden truth) often takes the form of a corpus, in which each of the linguistic entities to be processed is associated with the expected (i.e. \"correct\") output, i.e. the output that would be produced by a human expert performing the control task.\n\nWe talk of an annotated corpus, the annotations being the outputs associated with the linguistic entities.\n\nWhen the annotations are produced by humans (and not by an automated NLP system), we talk of a manually annotated corpus.\n\nA reference is therefore a manually annotated corpus produced by humans, who can be considered as experts for performing the control task.",
    "Annotations can be very simple...\n\nFor example, in the case of the English text identifier, it could be a simple EN/notEN tag associated with each of the texts to be processed:\n\nThe cat ate the mouse        EN\nMy tailor is rich            EN\nSie ist jung                 notEN\nLuttons ensemble             notEN\nEl llega tarde               notEN\nCome on dude                 EN\nCome state                   notEN",
    "Example (the Penn Discourse Treebank)\n\nIntelogic holds 27.5% of Datapoint\u2019s common shares outstanding.\n\n(S\n(NP-SBJ (NNP Intelogic) )\n(VP (VBZ holds)\n(NP\n(NP (CD 27.5) (NN %) )\n(PP (IN of)\n(NP\n(NP (NNP Datapoint) (POS \u2019s) )\n(JJ common) (NNS shares) )\n(ADJP (JJ outstanding) )))))\n(. .) )",
    "What does it mean?\n\nThe former annotation example is a parse tree representing the syntactic structure corresponding to the sentence:\n\nIntelogic holds 27.5% of Datapoint's common shares outstanding.\n\nIntelogic holds 27.5% of Datapoint's common shares outstanding.",
    "Gold standard impact\n\n- Gold standard creation is extremely expensive\n\n- But globally amortized: if a gold standard exists, the whole field is likely to use it for comparison and evaluation\n\nNotice however that a systematic reuse of the same gold standard introduces a bias to the evaluated task.",
    "Gold standard creation process\n\n- Properly define the task in an annotator manual\n- Select the corpus to annotate\n- Train annotators:\n  - annotation instructions\n  - assess annotation quality: inter-annotator agreement (or other appropriate measures)\n- Annotate",
    "1. Define a control task  \n2. Produce a reference from a large amount of typical data (for the task)  \n3. Assess the quality of the reference  \n4. Evaluate NLP system(s) on the reference  \n5. Compare evaluations (statistical significance)  \n6. Publish and discuss results",
    "Humans do not always agree on NLP tasks\n\n- Despite the annotator manual, divergences always exist\n- These divergences highly depend on the subjectivity of the task\n- A resource is considered good only if the divergences are low\n\n$\\Rightarrow$ measure Inter-annotator agreement",
    "Disagreement example: word sense disambiguation\n\nTask: Word Sense Disambiguation (WSD):\nlabel each word of a text (within context) to its corresponding sense (typically from an ontology)\n\nExample (easy):\nI can hear bass sounds.\nThey like grilled bass. \\{fish, named \"baz\" in French\\}\n\nExample (not so easy):\ndisambiguate usage of \\textit{national} with an ontology where:\n1) limited to or in the interest of a particular nation\n2) concerned with or applicable to or belonging to an entire nation or country\n\n\\{from WordNet 3.1\\}",
    "Even relatively objective tasks lead to disagreement: syntax example\n\nPut the block in the box on the table.\nWhat is the attachment site of on the table?",
    "Measuring inter annotator agreement\n\n- \"Inter annotator agreement\" (IAA) is considered a measure of the quality of gold standards\n- It is also a measure of the subjectivity of a task\n- It must be objectively measured and reported",
    "Raw agreement\n\nSimplest measure of agreement:\n\nraw agreement = $\\frac{\\text{nb items agreed}}{\\text{total nb of items}}$",
    "Raw agreement drawback\n\nRaw agreement doesn\u2019t take by-chance agreement into account\n\nExample\nOn a binary classification corpus having 70% of non-ambiguous items, two annotators systematically disagree about all ambiguous items:\n\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\n & \\text{A yes} & \\text{A no} \\\\\n\\hline\n\\text{B yes} & 0 & 10 \\\\\n\\text{B no} & 70 & 20 \\\\\n\\hline\n\\end{array}\n\\]\n\nraw agreement = \\(\\frac{70}{100}\\)\n\nThey get a 70% raw agreement despite their complete disagreement!",
    "Dealing with chance agreement\n\nTaking chance agreement into account:\n\u25ba Idea: subtract chance agreement\n\n$$ \\frac{\\text{observed\\_agreement} - \\text{chance\\_agreement}}{1 - \\text{chance\\_agreement}} $$\n\n\u25ba Several measures exist\n\u25ba Measures differ in the way they represent chance agreement",
    "Cohen\u2019s kappa\nCohen\u2019s \u03ba (\u201ckappa\u201d) is the most famous inter annotator agreement coefficient for 2 graders only (generalization: Fleiss\u2019 kappa).\n\nIt takes each annotator into account (independently).\nExample\n\n\\[\n\\begin{array}{c|cc}\n& \\text{yes} & \\text{no} \\\\\n\\hline\n\\text{yes} & 0 & 10 \\\\\n\\text{no} & 20 & 70 \\\\\n\\end{array}\n\\]\n\n\u25ba Chance of saying yes: \\ $A: 0.2, \\  B: 0.1$\n\u25ba Chance of saying no: \\ $A: 0.8, \\ B: 0.9$\n\u25ba Chance of saying both yes if independent: \\ $0.2 \\times 0.1 = 0.02$\n\u25ba Chance of saying both no if independent: \\ $0.8  \\times 0.9 = 0.72$\n\u25ba Chance of independent agreement: $\\ 0.72 + 0.02 = 0.74$\n\n\\[\n\\kappa = \\frac{\\text{observed\\_agreement} - \\text{chance\\_agreement}}{1-\\text{chance\\_agreement}} = \\frac{0.7-0.74}{1-0.74} = \\frac{-0.04}{0.26} = -0.15\n\\]",
    "Interpretation of Cohen\u2019s kappa\n\n- Positive: better than chance\n- Negative: worse than chance (correlated disagreement)\n- 1: perfect agreement\n- 0 statistical independence\n- more than 0.6 is usually considered ok, and more than 0.8 considered good",
    "Practices\n\n- IAA measures are almost always reported, but often only the raw agreement is given\n- IAA is often only measured on a sample, sometimes on the whole corpus\n- Each rest of the corpus is often annotated by only one person\n- Only one annotation set is given at the end. When several annotations exist, they are merged",
    "NLP evaluation protocol (reminder)\n\n1. Define a control task\n2. Produce a reference from a large amount of typical data (for the task)\n3. Assess the quality of the reference\n4. Evaluate NLP system(s) on the reference\n5. Compare evaluations (statistical significance)\n6. Publish and discuss results",
    "Importance of separating the data\n\nComparing the program output to a gold standard\n\nMethodological issue: clearly separate the data:\n\u25ba Separate training (and validation) from testing\n  Do it fully honestly blindly randomly!! ;- )\n\u25ba Validation set: allows to estimate overfitting or meta-parameters.\n  Not to be confused with test set!!\n   clearly separated from test set (validation set is indeed a kind of training set):\n   \u25ba Train on the training set\n   \u25ba Test and adjust meta parameters on validation set\n   \u25ba Reduce overfitting using the validation set\n   \u25ba Final testing on the testing set (don\u2019t even look at it before!)\n\u25ba Repeat all this several times (to estimate variance)\n\n*The more so as so-called \u201ccross-validation\u201d is an evaluation method, done on the test set, which has \n  nothing to do with the validation set!!",
    "Training, validation and test sets\n\nData                              Test                               Test\n                                     \"Learning\"                     \n                             (if needed) Validation",
    "The confusion matrix\n\nThe confusion matrix is not an evaluation metric (i.e. a measure) itself, but it gives complete information about the success and errors from which several evaluation metrics can be derived.\n\nAll the evaluation metrics are summaries of the confusion matrix in one way or another.\n\nThe confusion matrix represents, for each reference class, how the system classifies its corresponding items.\n\nExample (ternary classification)\n\n\\[\n\\begin{array}{c|ccc}\n & \\text{reference} & & \\\\\n & A & B & C \\\\\n\\hline\n\\text{system} & & & \\\\\nA & 35 & 2 & 10 \\\\\nB & 3 & 46 & 1 \\\\\nC & 6 & 5 & 12 \\\\\n\\end{array}\n\\]",
    "Let's consider the English identification example again:\n\n\\[\n\\begin{array}{lll}\n\\text{Reference} & \\text{System} \\\\\n\\hline\n\\text{The cat ate the mouse} & \\text{EN} & \\text{EN} \\\\\n\\text{My tailor is rich} & \\text{EN} & \\text{EN} \\\\\n\\text{Sie ist jung} & \\text{notEN} & \\text{notEN} \\\\\n\\text{Luttons ensemble} & \\text{notEN} & \\text{notEN} \\\\\n\\text{El llega tarde} & \\text{notEN} & \\text{notEN} \\\\\n\\text{Come on dude} & \\text{EN} & \\text{notEN} \\\\\n\\text{Come state} & \\text{notEN} & \\text{EN}\n\\end{array}\n\\]\n\nwhere the fist column of tags corresponds to the reference tags (produced by human annotators) and the second to the tags produced by a given NLP English text identifier.",
    "Example: English identifier (2/2)\n\nIn this case, the corresponding confusion matrix is:\n\n\\[\n\\begin{array}{c|cc}\n  \\text{reference} & \\text{EN} & \\text{notEN} \\\\\n  \\hline\n  \\text{system} & & \\\\\n  \\text{EN} & 2 & 1 \\\\\n  \\text{notEN} & 1 & 3 \\\\\n\\end{array}\n\\]\n\nwhere\n- the values on the diagonal correspond to the correct classifications (the EN-EN cases are often called the \"true positives\" and the notEN-notEN cases the \"true negatives\")\n- the values outside the diagonal correspond to the incorrect classifications (the EN-notEN cases are often called the \"false positives\", and the notEN-EN cases, the \"false negatives\")",
    "Evaluation measures\n\nStandard/Usual (not specific to NLP):\n    Accuracy\n    Precision, Recall (and F-score)\n\nDedicated ones",
    "Accuracy\n\n\\[ \\text{accuracy} = \\frac{\\text{number of correctly classified items}}{\\text{total number of items}} \\]\n\n\\[ = \\text{(normalized) trace of the confusion matrix} \\]\n\nExample (former English identifier)\n\n\\[ \\text{accuracy} = \\frac{2+3}{2+1+1+3} = \\frac{5}{7} \\approx 71\\% \\]\n\n- Can be used with any number of classes\n- Used for classification tasks where all classes have the same importance\n- Accuracy does not take the difference between two classes into account:\n  - asymmetry can result from classes of different importance (e.g. diagnostic)\n  - or a class containing much more items than another",
    "A task with asymmetrical classes: information retrieval\n\nIR seen as a binary classification task\n\u25b8 a document is relevant or irrelevant to a query\n\nExample of asymmetry:\n\u25b8 Take a query to which 20 out of 100\u2019000 documents are relevant\n\u25b8 The perfect classifier has the following accuracy\n\n\\[\n\\frac{100\u2019000}{100\u2019000} = 100\\%\n\\]\n\n\u25b8 The uninteresting all documents are irrelevant classifier gets\n\n\\[\n\\frac{99\u2019980}{100\u2019000} = 99.98\\%\n\\]\n\nFor uneven classes, accuracy may not distinguish excellent from very poor systems",
    "Two types of error for information retrieval and similar tasks\n\n -  False positives:\ndocuments retrieved that should not have been\n\n -  False negatives:\ndocument not retrieved that should have been\n\nA specific confusion matrix:\n\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\n & \\text{relevant (R)} & \\text{irrelevant} \\\\\n\\hline\n\\text{retrieved (S)} & \\text{true positives} & \\text{false positives} \\\\\n\\hline\n\\text{not retrieved} & \\text{false negatives} & \\text{true negatives} \\\\\n\\hline\n\\end{array}\n\\]",
    "Precision, Recall and F-score\n\nDeal with unbalanced classes:\n- Use two measures instead of one:\n  Precision and Recall (to be defined in next slides)\n\nF-score is a summary of the two measures",
    "Precision\n\n\\[\n\\text{precision} = \\frac{\\text{correctly retrieved documents}}{\\text{total number of retrieved documents}}\n\\]\n\\[\n= \\frac{\\text{true positives}}{\\text{true positives + false positives}}\n\\]\n\n\u25ba Estimates the likelihood that a retrieved document is indeed relevant to the query\n\n\u25ba Ignores false negatives. Take only false positives into account\n\n\u25ba Ignores non-retrieved documents. Takes only retrieved documents into account\n\n\u25ba Could be biased by retrieving very few documents",
    "Recall (a.k.a. \"true positive rate\")\n\n\\[\n\\text{recall} = \\frac{\\text{correctly retrieved documents}}{\\text{total number of relevant documents}} = \\frac{\\text{true positives}}{\\text{true positives + false negatives}}\n\\]\n\n- Estimates (one minus) the probability to miss relevant documents\n- Ignores false positives. Take only false negatives into account\n- Ignores irrelevant documents. Takes only relevant documents into account\n- Can be biased by retrieving all documents: gives a perfect score to the system that retrieves all documents",
    "Precision & Recall: example\n\nSpam filtering example:\n\n\\[\n\\begin{array}{ccc}\n\\text{System} & \\text{Reference} \\\\\n\\hline\n\\text{email0} & \\text{OK} & \\text{OK} \\\\\n\\text{email1} & \\text{OK} & \\text{Spam} \\\\\n\\text{email2} & \\text{OK} & \\text{OK} \\\\\n\\text{email3} & \\text{Spam} & \\text{OK} \\\\\n\\text{email4} & \\text{OK} & \\text{OK} \\\\\n\\text{email5} & \\text{OK} & \\text{OK} \\\\\n\\text{email6} & \\text{Spam} & \\text{OK} \\\\\n\\text{email7} & \\text{Spam} & \\text{Spam} \\\\\n\\text{email8} & \\text{OK} & \\text{Spam} \\\\\n\\text{email9} & \\text{OK} & \\text{OK} \\\\\n\\text{emailA} & \\text{OK} & \\text{Spam} \\\\\n\\text{emailB} & \\text{Spam} & \\text{Spam} \\\\\n\\text{emailC} & \\text{OK} & \\text{OK} \\\\\n\\text{emailD} & \\text{OK} & \\text{OK} \\\\\n\\text{emailE} & \\text{OK} & \\text{OK} \\\\\n\\text{emailF} & \\text{Spam} & \\text{Spam} \\\\\n\\end{array}\n\\]\n\nConfusion matrix:\n\n\\[\nP = \n\\]\n\n\\[\nR = \n\\]\n\nNote:\n\n\\[\n\\text{accuracy} = \n\\]\n\n\\[\n\\text{always-ok system: accuracy} = \n\\]\n\n\\[\nR =\n\\]\n\n\\[\nP = \n\\]",
    "Precision vs Recall plots\n\nFor tasks where recall can be controlled (by controlling the amount of outputs), it could be informative to plot precision versus recall\n\nMore in the \"Information Retrieval\" lecture",
    "- Harmonic mean of precision and recall \n- The harmonic mean penalizes large divergence between numbers, contrary to other means\n\n\\[ F\\text{-score} = 2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}} \\]\n\nMore generally (for given different emphasis to precision and recall):\n\n\\[ F_{\\beta} = (1 + \\beta^2) \\times \\frac{\\text{precision} \\times \\text{recall}}{(\\beta^2 \\times \\text{precision}) + \\text{recall}} \\]",
    "Example of a non-classification task evaluated as binary classification: PARSEVAL\n\n- A parser output is a syntactic tree\n- But parsers are often evaluated as a binary classification task\n- Items: constituents\n- Classes: exists/does not exist\n- Precision: nb of correctly annotated constituent/constituents in parser's output\n- Recall: nb of correctly annotated constituent/constituents in gold standard\n- Can be computed taking account of labels or not",
    "Example of parser evaluation (1/4)\n\nConsider the sentence \"The cat ate the mouse\" associated to the following reference parse tree (i.e. syntactic structure):\n\n```\n         S\n        / \\\n      NP   VP\n     /     / \\\n   Det   V   NP\n  /     /     / \\\nThe   ate   Det  N \n            /     \\\n          the    mouse\n```\n\n\"the cat\" is a constituent (label = NP);\n\n\"cat ate the\" is not a constituent;\n\n\"the cat ate\" is not a constituent.\n\nA \"constituent\" is defined as any sequence of consecutive words in the sentence that corresponds to the footage (i.e. sequence of leaves) of a subtree in the parse tree associated to the sentence;\n\nin addition, a constituent can be associated to a syntactic label (the one corresponding to the root of the subtree associated with the constituent)",
    "Example of parser evaluation (2/4)\n\nA sentence of $N$ words thus corresponds to $\\frac{N(N+1)}{2}$ possible constituents (not necessarily distinct)\n\nand any parse tree will select a subset of these $\\frac{N(N+1)}{2}$ possible constituents.\n\nThe constituents selected by the reference tree associated to the sentence in the reference can then be interpreted as the \"relevant\" ones with the whole set of possible constituents,\n\nand the constituents selected by the tree associated to the sentence by the parser to evaluate as the \"retrieved\" ones\n\nThe Precision and Recall metrics can then be directly used to evaluate the parser",
    "Example of parser evaluation (3/4)\n\nFor our former example, assume we have a parser that outputs:\n\nNow we have (not taking into account syntactic labels: \n\nPossible constituents | Reference constituents | System constituents\n--------------------- | ----------------------- | -------------------\nThe                   | Rel                     | Rel\ncat                   | Rel                     | Rel\nate                   | Rel                     | Rel\nthe                   |                        | \nmouse                 |                        | \nThe cat               | Rel                     | Rel\ncat ate               |                        | notRel\nate the               |                        | notRel\nthe mouse             | Rel                     | Rel\nThe cat ate           | Rel                     | Rel\ncat ate the           |                        | notRel\nate the mouse         | Rel                     | Rel\nThe cat ate the       | Rel                     | Rel\ncat ate the mouse     |                        | notRel\nThe cat ate the mouse | Rel                     | Rel",
    "Example of parser evaluation (4/4)\n\nwhich corresponds to the following confusion matrix:\n\n\\[\n\\begin{array}{c|cc}\n\\text{reference} & \\text{Ret} & \\text{notRel} \\\\\n\\hline\n\\text{system} & & \\\\\n\\hline\n\\text{Rel} & 8 & 1 \\\\\n\\text{notRet} & 1 & 5\n\\end{array}\n\\]\n\nand the following Precision and Recall scores:\n\n\\[\nP = \\frac{8}{8+1} = \\frac{8}{9} \\approx 89\\%\n\\]\n\n\\[\nR = \\frac{8}{8+1} = \\frac{8}{9} \\approx 89\\%\n\\]",
    "Other NLP measures\n\nFor some specific NLP tasks, ad-hoc measures have been defined:\n\u25ba BLEU (bilingual evaluation understudy) measure: $n$-gram precision-like measure for machine translation\n\u25ba METEOR (Metric for Evaluation of Translation with Explicit ORdering) measure: unigram F-score-like measure for machine translation\n\u25ba ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measures: $n$-gram recall-like measures for automated summarization",
    "1. Define a control task\n2. Produce a reference from a large amount of typical data (for the task)\n3. Assess the quality of the reference\n4. Evaluate NLP system(s) on the reference\n5. Compare evaluations (statistical significance)\n6. Publish and discuss results",
    "Variability of the results\n\nWhatever evaluation metric you use, measuring it only once on one single test set is not appropriate.\n\nYou shall estimate its variability (e.g. variance) as well!\n\nThis means having several different test sets\u2026\n\nHow to?\n\nOne common way is to use so-called \u201ccross-validation\u201d.",
    "Cross-validation\n----------------\n\nIdea: using several test/learning sets splittings to get a more accurate estimation of the results\n\n(Notice: not necessarily any validation set here, despite the name!)\n\n- Repeat k times:\n  - split the original data set into n subsets:\n    - Repeat n times with a different test (sub)set each time:\n      - use n - 1 subsets for learning and 1 for testing\n      - compute evaluation using the (different) test set\n\n- estimate variability of the results\n\n$\\Rightarrow k \\times n$ cross-validation (e.g. 2 \u00d7 5, 1 \u00d7 10): run k times a (different) n-fold cross-validation\n\nNote: why $k \\times n$ rather than $1 \\times (k \\cdot n)$?\n$\\Rightarrow$ increases variability: e.g. chance to have two given samples in the same subset is $\\approx \\frac{k/n}{k \\cdot n} \\text{ versus } \\frac{1}{(k \\cdot n)}$\n\n$\\left(\\frac{k/n}{k \\cdot n} \\text{ is in fact } \\frac{ (n - 1)^k}{n} = \\frac{k/n - \\sum_{i < k}(\\frac{1}{i})}{k/n}\\right)$",
    "Statistically significant evaluation\n- Having evaluations allow to compute standard deviations of results\n- Which allows to compute confidence intervals or even confidence boxes",
    "Comparing two systems in a statistically significant way\n\nSimple example: (paired) Student's t-test: compare two classifiers on the same data of $T$ test subsets\n(assuming normal distribution and equal variance;\ngeneralizations: Welch's t-test, ANOVA)\n\n$\\Delta_i$: performance difference between the two classifiers on test subset $i$\n\nempirical arithmetic mean: $\\mu = \\frac{1}{T} \\sum_{i=1}^T \\Delta_i$\n\nempirical unbiased standard deviation: $s = \\sqrt{\\frac{1}{T-1} \\sum_{i=1}^T (\\Delta_i - \\mu)^2}$\n\nThen $t = \\frac{\\mu \\sqrt{T}}{s}$ is compared to some threshold value for the desired confidence level. \nFor instance, at 95%, $|t|$ must be bigger than 1.645 (for $T > 1$)\nTo have a result statistically significant at more than 99%, $|t|$ must be bigger than 2.326",
    "The impact of inter annotator agreement on maximal accuracy\n\n\u25ba The best possible result is that of a human\n\u25ba But diversity exist as long as the IAA is not perfect\n\u25ba This diversity is not only made of mistakes but of subjectivity as well\n\u25ba So it would not be realistic for a computer system to go closer to the gold standard than humans do",
    "Evaluation campains\n\n- Allow for objective comparison of systems\n\n- Have given rise to a number of hand annotated corpora for specific tasks (e.g. Penn Treebank, many are distributed by the Linguistic Data Consortium (LDC, http://www.ldc.upenn.edu/) and the European Language Resources Association (ELRA, http://www.elra.info/))\n\n- Evaluation campaigns : specific task, specific evaluation framework, specific time (e.g. conference workshops)\n\n- Example: TREC (information retrieval), ParsEval, SensEval (word sense disambiguation)",
    "Conclusions\n\n- NLP systems need to be evaluated in order to be objectively compared\n- Most NLP task can only be evaluated by being compared to solutions done by humans\n- Humans do not always agree and some tasks are subjective\n- Several measure exist that need to be computed and which significance need to be statistically measured\n- To get clean results, test data should never be used in anyway for development",
    "References\n\n[1] Consequences of Variability in Classifier Performance Estimates, by T. Raeder, T. R. Hoens and N. V. Chawla, in 10th IEEE International Conference on Data Mining (ICDM), pp. 421\u2013430, 2010.\n\n[2] On Comparing Classifiers: Pitfalls to Avoid and a Recommended Approach, by S. L. Salzberg, in Data Mining and Knowledge Discovery, 1, pp. 317\u2013327, 1997.",
    "Introduction to Natural Language Processing\n\nMORPHOLOGY \u2013 TRANSDUCERS\n\nMartin Rajman\nMartin.Rajman@epfl.ch\n\nand\n\nJean-C\u00e9dric Chappelier\nJean-Cedric.Chappelier@epfl.ch\n\nArtificial Intelligence Laboratory",
    "Objectives of this lecture\n\n- Present morphology, important part of NLP\n- Introduce transducers, tools for computational morphology",
    "Contents\n\n- Morphology\n- Transducers\n- Operations and Regular Expressions on Transducers",
    "Morphology\n\nStudy of the internal structure and the variability of the words in a language:\n\n   \u2022 verbs conjugation\n   \u2022 plurals\n   \u2022 nominalization (enjoy \u2192 enjoyment)\n\n\ud83d\udd01 inflectional morphology: preserves the grammatical category\n      give       given       gave      gives       ...\n\n\ud83d\udd01 derivational morphology: change in category\n      process       processing       processable       processor       processability",
    "Interest: use _a priori_ knowledge about word structure to decompose it into morphemes and produce additional syntactic and semantic information (on the current word)\n\n$\\text{processable} \\rightarrow \\text{process- } \\quad - \\text{able} \\quad \\text{\u2245 2 morphemes}$\n\nmeaning:\nrole:\nsemantic information:\n\n$\\text{process-}$\nprocess\nroot\nmain\n\n$-\\text{able}$\npossible\nsuffix\nless\n\nThe importance and complexity of morphology vary from language to language\n\nSome information represented at the morphological level in English may be represented differently in other languages (and vice-versa). The paradigmatic/syntagmatic repartition changes from one language to another\n\nExample in Chinese: ate \u2192 expressed as \"eat yesterday\"",
    "Stems \u2013 Affixes\n\nWords are decomposed into morphemes: roots (or stems) and affixes.\n\nThere are several kinds of affixes:\n1. prefixes:\nin- credible\n2. suffixes:\nincred -ible\n3. infixes:\nExample in Tagalog (Philippines):\nhingi (to borrow) \u2192 humingi (agent of the action)\nIn slang English! \u2192 \"fucking\" in the middle of a word\nMan-fucking-hattan\n4. circumfixes:\nExample in German:\nsagen (to say) \u2192 gesagt (said)",
    "Stems \u2013 Affixes (2)\n\nseveral affixes may be combined:\nexamples in Turkish where you can have up to 10 (!) affixes.\n\nuygarla\u015ft\u0131ramad\u0131klar\u0131m\u0131zdand\u0131rm\u0131\u015fs\u0131n\u0131zcas\u0131na\nuygar+la\u015f+t\u0131r+ama+d\u0131k+lar\u0131m\u0131z+dan+m\u0131\u015f+s\u0131n\u0131z+cas\u0131na\ncivilize+BEC+AUS+NEG+ABLE+PPART+PL+P1+ABL+PAST+2PL+ASIF\nas if you are among those whom we could not cause to become civilized\n\nWhen only prefixes and suffixes are involved: concatenative morphology\n\nSome languages are not concatenative:\n- infixes\n- pattern-based morphology",
    "Example of semitic languages\n\nPattern-based morphology\n\nIn Hebrew, the verb morphology is based on the association of\n\u2022 a root, often made of 3 consonants, which indicates the main meaning,\n\u2022 and a vocalic structure (insertion or vowels) that refines the meaning.\n\nExample: LMD (learn or teach)\nLAMAD \u2192 he was learning\nLUMAD \u2192 he was taught",
    "Computational Morphology\n\nLet us consider flexional morphology, for instance for verbs and nouns\n\nNoun flexions: plural\n\nGeneral rule: +s\nbut several exceptions (e.g. foxes, mice)\n\nVerb flexions: conjugations\n\n- tense, mode\n- regular/irregular\n\nHow to handle flexions (computationally)?",
    "Computational Morphology\n\nExample: surface form: is\ncanonical representation at the lexicon level (formalization): $be+3+s+Ind+Pres$\n\nThe objective of computational morphology tools is precisely to go from one to the other:\n* **Analysis:** Find the canonical representation corresponding to the surface form\n* **Generation:** Produce the surface form described by the canonical representation\n\nChallenge: have a \"good\" implementation of these two transformations\n\nTools: associations of strings $\\rightarrow$ transducers",
    "String associations\n\n$$\n(X_1, X'_1) \\\\\n\\vdots \\\\\n(X_n, X'_n) \n$$\n\n(eaten, eat)\n\n(processed, process)\n\n(thought, think)\n\nEasy situation: $\\forall i, \\ |X_i| = |X'_i|$ Example: $(abc, ABC)$\n\u21d2 represented as a sequence of character transductions\n\n$$(abc, ABC) = (a,A)(b,B)(c,C)$$\n\n\u03b5* strings on a new alphabet: strings of character couples\n\nNot so easy: If $\\exists i, \\ |X_i| \\ne |X'_i|$ requires the introduction of empty string \u03b5\n\nExample: $(ab, ABC) \\not\\simeq  (\u03b5a\u03b5, A B C) =(\u03b5,a)(a,B)(b,c)$$",
    "Dealing with $\\epsilon$\n\nWhere to put the $\\epsilon$?\n\nExample: $(ab,ABC) \\simeq (\\epsilon ab, ABC)$\n\nbut also $(ab,ABC) \\simeq (a \\epsilon b, ABC)$\n\nor $(ab,ABC) \\simeq (ab \\epsilon, ABC)$\n\nGeneral case:\n\n$$ \\binom{n}{m} \\quad \\text{(with $m < n$)} $$\n\nHard problem in general $\\rightarrow$ need for a convention",
    "Transducer (definition)\n\nLet $\\Sigma_1$ and $\\Sigma_2$ be two enumerable sets (alphabets), and\n$$\\Sigma = (\\Sigma_1 \\cup \\{\\varepsilon\\}) \\times (\\Sigma_2 \\cup \\{\\varepsilon\\}) \\setminus \\{(\\varepsilon, \\varepsilon)\\}$$\nA transducer is a DFSA on $\\Sigma$\n\n$\\Sigma_1$: \"left\" language\n: upper language\n: input language\n\n$\\Sigma_2$: \"right\" language\n: lower language\n: output language",
    "Some transductions: $(bb, bb) \\ [0,0,2]$\n\n$(ababb, baab) \\ [0,1,2,0,0,2]$",
    "Different usages of a transducer\n\n\u2460 association checking \n \\( (abba, baaa) \\in \\Sigma^* \\) ?\n\n\u2461 Generation: string\u2081 \u2192 string\u2082 \n \\( bbab \\rightarrow ? \\)\n\n\u2462 Analysis: string\u2082 \u2192 string\u2081 \n \\( ? \\rightarrow ba \\)\n\n\u2460: easy: (\u2261 FSA: nothing special)\n\nWhat about \u2461 and \u2462?",
    "Transduction\n\nWalk through the FSA following one or the other element of the couple (projections)\n\n\\textcolor{red}{\\textbf{not deterministic in general!}}\n\nThe fact that a transducer is a deterministic (couple-)FSA does not at all imply that the automaton resulting from one projection or the other is also deterministic!\n\nnon-deterministic evaluation \\\\\nbacktracking on \"wrong\" solutions $\\implies$ The projection is \\textcolor{red}{not constant time} (in general)\n\nWhen a transducer is deterministic with respect to one projection or the other, it is called a \\textbf{sequential transducer}\n\nA transducer is not sequential in general. In particular if one language or the other (upper or lower) is not finite, it is not sure that a sequential transducer can be produced.",
    "Example: $bbab \\rightarrow$ ?\n\n$bbab \\rightarrow bbba \\rightarrow ba$",
    "Example:?\u2192 $b a$",
    "Operations and Regular Expressions on Transducers\n\nAll FSA regular expressions: concatenation, or, Kleene closure $(*)$, ...\n\nExample: (concatenation) $a:b \\ c:a^* recognizes ac$ and produces $ba$\n\ncross-product of regular languages: $E_1 \\otimes E_2$ recognizes $L_1 \\times L_2$\nexample: $a^+ \\otimes b^+ \\rightarrow (a^n, b^m) \\ \\forall n, m \\ge 1$\n!! this is $\\ne (a \\otimes b)^+$\n\nComposition of transducers: $T = T_1 \\circ T_2$\n$(X_1, X_2) \\in T \\iff \\exists Y : (X_1, Y) \\in T_1$ and $(Y, X_2) \\in T_2$\n\nReduction: extraction of the upper or the lower FSA",
    "(Other) examples of applications\n\n(morphology)\n\n\u2605 text-to-speech (grapheme to phoneme transduction)\n\n\u2605 specific lexicon representation (composition of some access and inverse functions)\n\n\u2605 filters (remove/add/modify marks; e.g. HTML)\n\n\u2605 text segmentation",
    "Use of composition:\n\n- Identification of a paradigm ($T_1$) \n- Implementation of this paradigm ($T_2$) \n- Exception handling ($T_3$)\n\nExample: input: chat+NP,\u00a0fox+NP, ... (+NP means \"noun plural\")\n\n$$\nT_1: ([a-z] +)(+NP \\circ +\\mathbf{x}) \\quad \\text{paradigm identification: plural nouns (trivial here: only one paradigm (+1))}\n$$\n\n$$\nT_2: ([a-z] +)(+1 \\circ \\mathbf{+Xs}) \\quad \\text{plural inflection of nouns (regular part)}\n$$\n\n$$\nT_3: ([a-z] +)(+Xs) \\circ hes \\mid x \\rightarrow x \\text{en} \\mid ... \\mid [hx ...]([+X] \\mathbf{e}s) \\quad \\text{correction of exceptions}\n$$\n\n$$\nT_1 \\circ T_2 \\circ T_3: \\quad \\text{plural for nouns}\n$$",
    "Detailed example on the plural of nouns:\n\ngeneral case: add a terminal 's'\ncat+NP $\\rightarrow$ cats, dog+NP $\\rightarrow$ dogs, ...\n\nExceptions (several kind):\n\n- fly flies\n- fox foxes, but ox oxen!\n- ..\n\nMethod: find all the paradigms (linguists' role) and implement a transducer for each of them\n\n$\\longrightarrow$ add the paradigm identification in the lexical description",
    "Keypoints\n\n- Flexional and derivational morphologies, their roles\n- Main functions of transducers: association checking, generation and analysis\n- Deterministic and not deterministic nature of transduction",
    "References\n\nE. Roche, Y. Schabes, Finite-state Language Processing, pp. 14-63, 67-96, A Bradford Book, 1997.",
    "A quick reminder about noun plurals in English\n\nComputational Linguistics\nMartin Rajman\nArtificial Intelligence Laboratory",
    "Fully regular plurals\n\n- default rule:\n  Add \u201cs\u201d to the end of the singular form\n  \n- Examples:\n  (dog, dogs)\n  (arrow, arrows)\n  ...",
    "Semi-regular plurals\n\nSome \u201cregular\u201d plurals need to be modified to be easy to pronounce (\u201ceuphonic rules\u201d)\n* Euphonic rule 1: if the singular noun ends in \u201cs\u201d, \u201cx\u201d, \u201cz\u201d, \u201cch\u201d, or \u201csh\u201d, add \u201ces\u201d instead of \u201cs\u201d\n(guess, guesses)\n(box, boxes)\n(buzz, buzzes)\n(catch, catches)\n(dish, dishes)\n... but (systematic exception) if the final \u201cch\u201d is pronounced \u201ck\u201d, add \u201cs\u201d instead of \u201ces\u201d\n(stomach, stomachs)\nas well as some fully irregular exceptions\n(ox, oxen)",
    "Semi-regular plurals (2)\n\n\u2022 Euphonic rule 2: if the singular noun ends in a consonant followed by \u201cy\u201d, change the \u201cy\u201d to \u201cies\u201d\n  (baby, babies)\n  (fly, flies)\n\nNote: there must be a consonant before the \u201cy\u201d...\n  (boy, boys)\n  (buy, buys)",
    "Irregular plurals\n\n- Collective nouns (aka uncountable nouns) have no plural form\n  (hair, ---)\n  (mud, ---)\n\n... but the regular plurals may also be acceptable in specific contexts:\n\n  \"Her hair is black\" ... but ... \"I saw at least one grey hair, and there are probably more grey hairs there\" \n  $\\rightarrow$ (hair, hairs)\n  \n  \"They throw mud at each other\" ... but ... \"These subterranean muds are being removed\"\n  $\\rightarrow$ (mud, muds)",
    "Irregular plurals (2)\n\nInvariant nouns (aka invariable nouns) do not change when inflected to the plural\n\n\u201cDeer have antlers\u201d\n\nNote that there is a (subtle) difference for a noun not to have a plural (i.e. to be uncountable), or to have a plural form that is the same as the singular one\n   - uncountable: \u201cHer hair is black\u201d is correct, while \u201cHer hair are black\u201d is not\n   - invariable: \u201cThis deer is fast\u201d and \u201cDeer are fast\u201d are both correct (but do not mean the same)",
    "Other irregular plurals\n\n\u2022 **Case 1:** For most nouns ending in \"f\" or \"fe\", change the ending \"f\" or \"fe\" to \"ves\"\n  (half, halves)\n  (knife, knives)\n\n... but\n  (belief, beliefs)\n  (if, ifs) \u2192 \"There are so many ifs and buts in this policy\"",
    "Other irregular plurals (2)\n\n\u2022 Case 2: For most nouns ending in \"is\", change the ending \"is\" to \"es\"\n    (crisis, crises)\n    (hypothesis, hypotheses)\n\n... but\n\n    (vis, vires)\n\nwhere \"vis\" is a Latin word meaning \"power\" that has been imported in English, while preserving its Latin plural (\"vires\")\n    \u2192 \"An example of vis is the influence of the leader\"",
    "Other irregular plurals (3)\n\nCase 3: For many nouns ending in \u201co,\u201d change the ending \u201co\u201d to \u201coes\u201d\n(tomato, tomatoes)\n(mosquito, mosquitoes)\n(volcano, volcanoes)\n\n... but\n\n(photo, photos)\n(video, videos)\n(piano, pianos)",
    "Fully irregular plurals\n\nFor some (often very frequent) words, the plural corresponds to a much more complicated modification\n\n(man, men)\n(mouse, mice)\n(foot, feet)\n(tooth, teeth)\n...",
    "Computational morphology for English nouns\n\nComputational Linguistics\nMartin Rajman\nArtificial Intelligence Laboratory",
    "Fundamentals\n\nGoal: use transducers to represent associations between strings representing:\n\u2022 surface forms, i.e. words as they appear in texts;\nand\n\u2022 canonical representations, i.e. formal representations of the morphological analysis of these words\n\nExamples of surface forms:\ncats, book, flies, ...\n\nExample of canonical representations:\ncat+N+P, book+N+S, fly+N+P, ...",
    "Canonical representations\n\nThe typical format of a canonical representations is:\n\nLemma+GrammaticalCategory+MorphoSyntacticFeature_{1}+MorphoSyntacticFeature_{2}+...\n\nwhere:\n- Lemma (or Root) is the canonical form of an inflected word; i.e. the form usually found in dictionaries, e.g. the singular form for nouns, or the infinitive for verbs;\n- GrammaticalCategory (or Part-of-Speech) is the tag used to represent the grammatical category of the word, e.g. N for a noun, Adj for an adjective, or V for a verb;\n- MorphoSyntacticFeature_{k} (k=1, 2, 3, ...) are the tags used to represent the morphosyntactic features (e.g. the number, the gender, the tense, the person, etc.) that are relevant to identify a specific inflection of a word;\n\nand\n- \"+\" is a (conventional) separating character.",
    "Examples of canonical representations\n\n- (cat+N+p, cats): associating the canonical representation \"cat+N+p\" to the surface form \"cats\" expresses in a formal way that \"cats\" is the flection of the noun \"cat\" corresponding to its plural form (\"p\" being the tag for the value \"plural\" of the morphosyntactic feature \"number\");\n\n- (turn+V+Ind+Pres+3+s, turns): associating the canonical representation \"turn+V+Ind+Pres+3+s\" to the surface form \"turns\" expresses in a formal way that the surface form corresponding to the flection of the verb (\"V\") \"to turn\" at the 3rd person (\"3\") singular (\"s\") of the present (\"Pres\") indicative (\"Ind\") is \"turns\".",
    "In other words...\n\nImplementing some Computational Morphology for English nouns is finding an efficient way of representing a, potentially very large, set of (canonical representation, surface form) associations, such as:\n\n\\[\n\\begin{align*}\n&(\\text{cat+N+S, cat})\\\\\n&(\\text{cat+N+P, cats})\\\\\n&(\\text{book+N+S, book})\\\\\n&(\\text{book+N+P, books})\\\\\n&(\\text{fly+N+S, fly})\\\\\n&(\\text{fly+N+P, flies})\\\\\n&(\\text{fox+N+S, fox})\\\\\n&(\\text{fox+N+P, foxes})\\\\\n&(\\text{deer+N+S, deer})\\\\\n&(\\text{deer+N+P, deer})\\\\\n&(\\text{mouse+N+S, mouse})\\\\\n&(\\text{mouse+N+P, mice})\\\\\n&(\\text{ox+N+S, ox})\\\\\n&(\\text{ox+N+P, oxen})\\\\\n&\\ldots\n\\end{align*}\n\\]\n\nBy \"efficient way\", we mean a method that:\n- allows to describe all the targeted associations without having to write them explicitly one-by-one;\n- provides a computational mechanism with a low algorithmic complexity able to produce the surface form(s) associated with a given canonical representation (\"generation\"), or the canonical representation(s) associated with a given surface form (\"analysis\")",
    "How to do this with transducers?\n\nThe idea is to use the composition $T_1 \\circ T_2 \\circ T_3$ of 3 transducers:\n\n1. a transducer $T_1$ that identifies the morphological paradigm, i.e. the systematic transformation rule(s) to be implemented for regular forms\n2. a transducer $T_2$ that implements the identified systematic rule(s)\n3. a transducer $T_3$ that handles all the exceptions to the implemented rules",
    "T\u2081: Identifying the morphological paradigm\n\n\u2022 In English, the morphology of regular noun plurals is very simple, as it corresponds to a single systematic rule\n\u2022 The morphological paradigm thus consists of only one rule, arbitrarily numbered here as rule 1\n\u2022 T\u2081 is therefore the transducer that associates a canonical representation of the form \u201croot+N+p\u201d, where root is any possible nominal root, to the intermediate string \u201croot+1\u201d:\n\n$T_1 = ([a-z]+|\\+)((\\+N|\\+p)x(\\+1))$\n\nwhere \u201cx\u201d represents the \u201ccross-product\u201d operator, \u201c\\\u201d is a special character that prevents the character \u201c+\u201d to be interpreted as the Kleene plus operator, and \u201c[a-z]\u201d represents any alphabetic character",
    "$T_1$: Example\n\nWhen applied to the list\n\n(cat+N+p,\nbook+N+p,\nfly+N+p,\nfox+N+p,\ndeer+N+p,\nmouse+N+p,\nox+N+p)\n\n$T_1$ represents the following list of associations\n\n(cat+N+p, cat+1)\n(book+N+p, book+1)\n(fly+N+p, fly+1)\n(fox+N+p, fox+1)\n(deer+N+p, deer+1)\n(mouse+N+p, mouse+1)\n(ox+N+p, ox+1)",
    "$T_2$: Implementing the morphological paradigm\n\n\u2022 The identified (single) systematic rule for English regular noun plurals is:\n\nAdd \u201cs\u201d to the end of the root\n(as, for nouns, the root corresponds to the singular form)\n\n\u2022 $T_2$ is therefore the transducer that associates an intermediate string of the form \u201croot+1\u201d to a new intermediate string of the form \u201crootXs\u201d, where the character X (called the \u201ctrace\u201d) identifies the \u201cborder\u201d between the root and the suffix \u201cs\u201d:\n\n$$T_2 = ([a-z]+)((\\{1\\})x(Xs))$$\n\nNote: placing a trace X in the new intermediate string will make it easier to handle the various exceptions to be implemented in $T_3$",
    "$T_2$: Example\n\nWhen applied to the list (resulting from $T_1$)\n\n(cat+1, book+1, fly+1, fox+1, deer+1, mouse+1, ox+1)\n\n$T_2$ represents the following list of associations\n\n(cat+1, catXs)\n(book+1, bookXs)\n(fly+1, flyXs)\n(fox+1, foxXs)\n(deer+1, deerXs)\n(mouse+1, mouseXs)\n(ox+1, oxXs)",
    "\\$T_3\\$: Handling the exceptions\n\n- In this illustrative example, we will only consider 2 types of exceptions:\n  1. Euphonic rule 1 (simplified):\n     If the root ends in \u201cx\u201d, change the ending \u201cx\u201d to \u201cxes\u201d\n  2. Euphonic rule 2 (simplified):\n     If the root ends in \u201cy\u201d, change the ending \u201cy\u201d to \u201cies\u201d\n\n- \\$T_3\\$ is therefore the transducer that associates an intermediate string of the form \u201crootxXs\u201d (resp. \u201crootyXs\u201d) to a new intermediate string of the form \u201crootxes\u201d (resp. \u201crooties\u201d), where \u201crootx\u201d (resp. \u201crooty\u201d) is any root ending in \u201cx\u201d (resp. \u201cy\u201d):\n\n\\$\nT_3 = ([a-z]+[((xXs)(x(xes))|((yXs)(y(ies))](/[^\\text{x}^\\text{y}]/((Xs)(Xs))))) \n\\$\n\nwhere \u201c[^\\text{x}^\\text{y}]\u201d represents any character but \u201cx\u201d or \u201cy\u201d",
    "$T_3$: Example\n\nWhen applied to the list (resulting from $T_2$)\n\\[ \n\\begin{array}{lll}\n(\\text{catXs,} & \\text{bookXs,} & \\text{flyXs,} & \\text{foxXs,} & \\text{deerXs,} & \\text{mouseXs,} & \\text{oxXs}) & \\quad & T_3 \\text{ represents the following list of associations} \\\\\n& & (\\text{catXs, cats}) \\\\\n& & (\\text{bookXs, books}) \\\\\n& & (\\text{flyXs, flies}) \\\\\n& & (\\text{foxXs, foxes}) \\\\\n& & (\\text{deerXs, deers}) \\\\\n& & (\\text{mouseXs, mouses}) \\\\\n& & (\\text{oxXs, oxes}) \\\\\n\\end{array}\n\\]",
    "$T_1 \\circ T_2 \\circ T_3 : $ Example\n\nWhen applied to the original list\n\n(cat+N+p, book+N+p, fly+N+p, fox+N+p, deer+N+p, mouse+N+p, ox+N+p )\n\n$T_1 \\circ T_2 \\circ T_3$ represents the following list of associations\n\n(cat+N+p, cats)  \n(book+N+p, books)  \n(fly+N+p, flies)  \n(fox+N+p, foxes)  \n(deer+N+p, deers)  \n(mouse+N+p, mouses)  \n(ox+N+p, oxes)\n\nwhere the first 4 associations are correct, but the last 3 (in red) are erroneous and would require a more sophisticated definition of the transducer T3 responsible for handling the exceptions.",
    "Part of Speech Tagging\n\nM. Rajman & J.-C. Chappelier\n\nArtificial Intelligence Laboratory\nSchool of Computer and Communication Sciences",
    "Contents\n\n\u2712 What is Part-of-Speech Tagging\n\n\u2712 A simple probabilistic model: HMM tagging",
    "Morpho-lexical level\n\nAims:\n\u25ba resolution of some ambiguities (e.g. $can:V$ vs. $can:N$)\n\u25ba suppression of some lexical variability which is not necessarily meaningful for certain applications\n    (e.g. difference between \u201ccat\u201d and \u201ccats\u201d in Information Retrieval).\n\nTools:\n\u25ba Part-of-Speech tagging\n\u25ba Stemming / Lemmatization",
    "Lemmatization\n\nAutomatically reduce word form to their canonical form, within context\n\ncanonical form: infinitive for verbs, singular for nouns, (masculin) singular for adjectives, ...\n\nExample:\n\nexecutes \u27f6 execute  \nbought \u27f6 buy\n\nLemmatization is easy if PoS tagging has been performed (and lemma information is available in the lexicon)\n\nOtherwise: \"stemming\" (mostly known for English: Porter\u2019s stemmer): basically, encoding most significative morphological rules",
    "Automatically assign Part-of-Speech (PoS) Tags to words in context\n\nExample:\nA computational process executes programs accurately\nDet Adj N V N Adv\n\nNon trivial task because of lexical ambiguities:\nprocess $\\rightarrow$ V or N?\nprograms $\\rightarrow$ N or V?\n\nand of OoV forms (neologisms, proper nouns mainly).\n\n\\(\\Rightarrow\\) Two main components:\n- guesser: assign PoS tag list to OoV\n- chooser/disambiguator",
    "PoS tagging (formalisation)\n\nGiven a text and a set of possible (word, tag) couples (a.k.a. the vocabulary/lexicon), choose among the possible tags for each word (known or unknown) the right one according to the context. \n\nImplies that the assertion \"the right one according to the context\" is properly defined (\u21d4 goldstandard), e.g. means \"as given by a human expert\" (! inter-annotator agreement).\n\nSeveral approaches:\n\n\ud83d\udd39 (old) Rule-based: Brill's tagger\n\n\ud83d\udd39 Probabilistic:\n   Hidden Markov Models (HMM), Conditional Random Fields \n   (CRF), Maximum entropy cyclic dependency network \n   (MaxEnt)\n\n\ud83d\udd39 \"Neural\" (also probabilistic, but less clearly): averaged perceptrons, Support-Vector Machines (SVM), Long Short-Term Memory (LSTM)",
    "PoS tagging (example)\n\nExample from the Brown Corpus (https://en.wikipedia.org/wiki/Brown_Corpus, available in NLTK):\n\nThe/AT company/NN sells/VBZ a/AT complete/JJ line/NN of/IN gin/NN machinery/NN all/QL over/IN the/AT cotton-growing/JJ world/NN ./.\n\nTags explained (from original Brown Corpus documentation):\n\n| Tag  | Description                    | Examples                                               |\n|------|------------------------------- |------------------------------------------------------  |\n| AT   | article                        | the, an, no, a, every [...]                             |\n| NN   | noun, singular, common         | failure, burden, court, fire [...]                      |\n| VBZ  | verb, present tense, 3rd person singular | deserves, believes, receives, takes, [...] |\n| JJ   | adjective                      | recent, over-all, possible, hard-fought [...]          |\n| IN   | preposition                   | of, in, for, by, considering [...]                      |\n| QL   | qualifier, pre                 | well, less, very, most [...]                            |\n| .    | sentence terminator            | . ? ! ;\n\n\u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL)\nPatrick Ruch, M. C. Duplessis\nPart of Speech Tagging                               Part of Speech Tagging - 7 / 28",
    "Complexity/Grain of tag set can vary a lot (even for the same language).\n\nOriginal Brown Corpus tagset contains 87 PoS tags (!)\n\nFor instance, it contains 4 kind of adjectives:\n```\nJJ   adjective                                  recent, over-all, possible, hard-fought [...]\nJJR  comparative adjective                      greater, older, further, earlier [...]\nJJS  semantically  superlative adjective       top, chief, principal, northernmost [...]\nJJT  morphologically  superlative adjective    best, largest, coolest, calmest [...]\n```",
    "Tag sets (2/2)\n\nNLTK \u201cuniversal\u201d tagset is much shorter: 12 tags (from NLTK documentation):\n\n| Tag  | Meaning             | Examples |\n|------|---------------------|----------|\n| ADJ  | adjective           | new, good, high, special, big, local |\n| ADP  | adposition          | on, of, at, with, by, into, under |\n| ADV  | adverb              | really, already, still, early, now |\n| CONJ | conjunction         | and, or, but, if, while, although |\n| DET  | determiner, article | the, a, some, most, every, no, which |\n| NOUN | noun                | year, home, costs, time, Africa |\n| NUM  | numeral             | twenty-four, fourth, 1991, 14:24 |\n| PRT  | particle            | at, on, out, over, per, that, up, with |\n| PRON | pronoun             | he, their, her, its, my, I, us |\n| VERB | verb                | is, say, told, given, playing |\n| .    | punctuation marks   | . ; ! |\n| X    | other               | ersatz, esprit, dunno, gr8, university |",
    "Contents\n\n- Part-of-Speech Tagging\n  - Probabilistic: HMM tagging",
    "Probabilistic PoS tagging\n\nLet $w^n_1 = w_1 ... w_n$ be a sequence of n words.\n\nTagging $w^n_1$ consists in looking a corresponding sequence of Part-of-Speech (PoS) tags $T^n_1 = T_1 ... T_n$ such that the conditional probability $P(T_1, ..., T_n|w_1,..., w_n)$ is maximal\n\nExample:\nSentence to tag: *Time flies like an arrow*\nSet of possible PoS tags: $\\mathcal{T} = \\{Adj, Adv, Det, N, V, ..., WRB\\}$\n\nProbabilities to be compared (find the maximum):\n$P(Adj\\ Adj\\ Adj\\ Adj\\ Adj|time flies like an arrow)$\n$P(Adj\\ Adj\\ Adv\\ Adv\\ Adv|time flies like an arrow)$\n$...$\n$P(Adj\\ N\\ V\\ Det\\ N|time flies like an arrow)$\n$...$\n$P(N\\ V\\ Adv\\ Det\\ N|time flies like an arrow)$\n$...$\n$P(WRB\\ WRB\\ WRB\\ WRB\\ WRB|time flies like an arrow)$\n(of course, many of these are null and won't even be considered)",
    "Probabilistic PoS tagging\n\nLet $w_1^n = w_1 ... w_n$ be a sequence of $n$ words.\n\nTagging $w_1^n$ consists in looking a corresponding sequence of Part-of-Speech (PoS) tags $T_1^n = T_1...T_n$ such that the conditional probability $P(T_1,...,T_n|w_1,...,w_n)$ is maximal\n\nHow to find $T_1^n = \\arg \\max_{T_1^n} P(T_1^n | w_1^n)$?\n\nBayes Rule:\n\n\\[ P(T_1^n | w_1^n) = \\frac{P(w_1^n | T_1^n) \\cdot P(T_1^n)}{P(w_1^n)} \\]",
    "Probabilistic PoS tagging (2)\n\nAs maximization is performed for a given $w_1^n$,\n\n\\[\n\\underset{T_1^n}{\\text{argmax}} \\, P(T_1^n | w_1^n) = \\underset{T_1^n}{\\text{argmax}} \\left( P(w_1^n | T_1^n) \\cdot P(T_1^n) \\right)\n\\]\n\nFurthermore (chain-rule):\n\n\\[\nP(w_1^n | T_1^n) = P(w_1 | T_1^n) \\cdot P(w_2 | w_1, T_1^n) \\cdots P(w_n | w_1^{n-1}, T_1^n)\n\\]\n\n\\[\nP(T_1^n) = P(T_1) \\cdot P(T_2 | T_1) \\cdots P(T_n | T_1^{n-1})\n\\]",
    "Hypotheses:\n\n$\\circ$ limited lexical conditioning\n\\[ P(w_i|w_1, ..., w_{i-1}, T_1, ..., T_{i-1}, T_i, ..., T_n) = P(w_i|T_i) \\]\n\n$\\circ$ limited scope for syntactic dependencies: $k$ neighbors\n\\[ P(T_i|T_1, ..., T_{i-1}) = P(T_i|T_{i-k}, ..., T_{i-1}) \\]\n\n(Note: it's a Markov assumption)",
    "Therefore:  \n$$P(w_1^n|T_1^n) = P(w_1|T_1) \\cdot \\ldots \\cdot P(w_n|T_n)$$  \n\n$$P(T_1^n) = P(T_k^1) \\cdot P(T_{k+1}|T_1, \\ldots, T_k) \\cdot \\ldots \\cdot P(T_n|T_{n-k}, \\ldots, T_{n-1})$$  \n\nand eventually:  \n$$P(w_1^n|T_1^n) \\cdot P(T_1^n) = P(w_1|T_1) \\cdot P(T_k^1) \\cdot \\prod_{i=k+1}^n \\left( P(w_i|T_i) \\cdot P(T_i|T_{i-k}^{i-1}) \\right)$$  \n\nThis model corresponds to a k-order Hidden Markov Model (HMM)",
    "(order 1) Hidden Markov Models (HMM)\n\nA order-1 HMM is:\n\n- a set of states $\\mathcal{C} = \\{C_1, ..., C_n\\}$\n\n- a transition probabilities matrix $A: a_{ij} = P(Y_{t+1} = C_j \\mid Y_t = C_i)$, shorten $P(C_j \\mid C_i)$\n\n- an initial probabilities vector $I: i_i = P(Y_1 = C_i)$ or $P(Y_t = C_i \\text{; start})$, shorten $P(C_i)$\n\n- a set of \"observables\" $\\Sigma$ (not necessarily discrete, in general)\n\n- $m$ probability densities on $\\Sigma$, one for each state (emission probabilities): $B_i(o) = P(X_t = o \\mid Y_t = C_i)$ (for $o \\in \\Sigma$, shorten $P(o \\mid C_i)$\n\nHMM will be presented in details in the next lecture",
    "Example: PoS tagging with HMM\n\nSentence to tag:\nTime flies like an arrow\n\nExample of HMM model:\n\nPoS tags: $\\mathcal{T} = \\{\\text{adj}, \\text{adv}, \\text{det}, N, V, \\ldots\\}$\nTransition probabilities:\n$P(\\text{N}|\\text{adj}) = 0.1, P(\\text{V}|\\text{N}) = 0.3, P(\\text{adv}|\\text{N}) = 0.01, P(\\text{adv}|\\text{V}) = 0.005, P(\\text{det}|\\text{adv}) = 0.1, P(\\text{adj}|\\text{V}) = 0.3, P(\\text{N}|\\text{det}) = 0.5$\n(plus all the others, such that stochastic constraints are fulfilled)\n\nInitial probabilities:\n$P(t=\\text{adj}) = 0.01, P(t=\\text{adv}) = 0.001, P(t=\\text{det}) = 0.1, P(t=\\text{N}) = 0.2, P(t=\\text{V}) = 0.003$\n\nWords: $\\mathcal{E} = \\{\\text{an, arrow, flies, like, time,}\\ldots\\}$\nEmission probabilities:\n$P(\\text{time}|\\text{N}) = 0.1, P(\\text{time}|\\text{adj}) = 0.001, P(\\text{time}|\\text{V}) = 0.05, P(\\text{flies}|\\text{N}) = 0.1, P(\\text{flies}|\\text{V}) = 0.01, P(\\text{like}|\\text{adv}) = 0.005, P(\\text{like}|\\text{V}) = 0.1, P(\\text{an}|\\text{det}) = 0.3, P(\\text{arrow}|\\text{N}) = 0.5",
    "Example: PoS tagging with HMM (cont.)\n\nIn this example, 12 = 3 \u00b7 2 \u00b7 2 \u00b7 1 \u00b7 1 analyzes are possible, for example:\n\n$P(\\text{time/N files/V like/ADV an/DET arrow/N}) = 1.13 \\cdot 10^{-11}$\n$P(\\text{time/ADJ flies/N like/V an/DET arrow/N}) = 6.75 \\cdot 10^{-10}$\n\nDetails of one of such computation:\n\n\\[\nP(\\text{time/N files/V like/ADV an/DET arrow/N}) = P_n(N) \\cdot P(\\text{time}/N) \\cdot P_v(N) \\cdot P(\\text{files}/V) \\cdot P(\\text{ADV}/v) \\cdot P(\\text{like}/ADV) \\cdot P(\\text{DET}/adv) \\cdot P(\\text{an/DET}) \\cdot P(\\text{N/det}) \\cdot P(\\text{arrow/N})\n\\]\n\\[\n= 2e-1 \\cdot 1e-1 \\cdot 3e-1 \\cdot 1e-2 \\cdot 5e-3 \\cdot 5e-3 \\cdot 1e-1 \\cdot 3e-1 \\cdot 5e-1 \\cdot 5e-1 \n\\]\n\\[\n= 1.13 \\cdot 10^{-11}\n\\]\n\nThe aim is to choose the most probable tagging among the possible ones (e.g. as provided by the lexicon)",
    "HMMs\n\nHMM advantage: well formalized framework, efficient algorithms\n\n\\textcolor{blue}{}Viterbi: linear algorithm $(O(n))$ that computes the sequence $T_1^n$ maximizing $P(T_1^n|w_1^n)$ (provided the former hypotheses)\n\n\\textcolor{magenta}{}Baum-Welch: iterative algorithm for estimating parameters from unsupervised data (words only, not the corresponding tag sequences)\n(parameters = $P(w|T_i)$, $P(T_j|T_{j-k}^{j-1})$, $P(T_1, \\ldots, T_k)$)",
    "Parameter estimation\n\nsupervised (i.e. manually tagged text corpus)\nDirect computation\nProblem of missing data\n\nunsupervised (i.e. raw text only, no tag)\nBaum-Welch Algorithm\nHigh initial conditions sensitivity\n\nGood compromise: hybrid methods: unsupervised learning initialized with parameters from a (small) supervised learning",
    "CRF versus HMM\n\n(linear) Conditional Random Fields (CRF) are a discriminative generalization of the HMMs where \"features\" no longer need to be state-conditional probabilities (less constraint features).\nFor instance (order 1):\n\nHMM\n$$P(T^1_1,w^n_1) = P(T_1)P(w_1|T_1) \\prod_{i=2}^n P(T_i|T_{i-1})P(w_i|T_i)$$\n\nCRF\n$$P(T^1_1|w^n_1) = \\frac{1}{Z(w_1^n)} \\prod_{i=2}^n \\exp \\left( \\sum_j \\lambda_j f_j(T_{i-1}, T_i, w_1^n, i) \\right)$$\n\n(with\n$$P(T_{i-1}, T_i|w_i) \\propto \\exp \\left( \\sum_j \\lambda_j f_j(T_{i-1}, T_i, w_1^n, i) \\right)$$)",
    "Other Models and Performances\n\n[from https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art); see also: https://nlpoverview.com/#a-pos-tagging http://nlpprogress.com/english/part-of-speech_tagging.html]\n\nOn the \u201cWallStreet Journal\u201d corpus:\n\n\\begin{tabular}{llll}\n\\textbf{name} & \\textbf{technique} & \\textbf{publication} & \\textbf{accuracy (\\%)} \\\\\n\\hline\nTnT & HMM & Brants (2000) & 96.5 \\\\\nGENiA Tagger & MaxEnt & Tsuruoka, et al. (2005) & 97.0 \\\\\nAveraged Perceptron & & Collins (2002) & 97.2 \\\\\nSVMTool & SVM & Gim\u00e9nez and M\u00e0rquez (2004) & 97.2 \\\\\nStanford Tagger 2.0 & MaxEnt & Manning (2011) & 97.3 \\\\\nstructReg & CRF & Sun (2014) & 97.4 \\\\\nFlair & LSTM-CRF & Akbik et al. (2018) & 97.8 \\\\\n\\end{tabular}",
    "- The aim of PoS tagging is to choose among the possible tags for each word of the text the right tag according to the context\n\n- Different efficient techniques exist allowing for both supervised and unsupervised learning\n\n- Performances: $95 - 98 \\%$        (random $\\rightarrow \\approx 75 - 90 \\%$)\n\n- Be familiar with the principles of HMM tagging\n\n- Word normalization (a.k.a. \"lematization\") is easy once PoS tagging has been done",
    "References\n\n[1] C. D. Manning, *Part-of-Speech Tagging from 97% to 100%: Is It Time for Some Linguistics?* In Alexander Gelbukh (ed.), Computational Linguistics and Intelligent Text Processing, Lecture Notes in Computer Science 6608, pp. 171\u2013189, Springer, 2011.\n\n[2] *Ing\u00e9nierie des langues*, sous la direction de Jean-Marie Pierrel, chap. 5, Hermes, 2000.\n\n[3] R. Dale, H. Moisl & H. Sommers, *Handbook of Natural Language Processing*, chap. 17, Dekker, 2000.\n\n[4] C. D. Manning, H. Sch\u00fctze, *Foundations of Statistical Natural Language Processing*, chap. 10, MIT, 1999.",
    "PROBABILISTIC PARSING\n\nMartin Rajman\nMartin.Rajman@epfl.ch\n\nand\n\nJean-C\u00e9dric Chappelier\nJean-Cedric.Chappelier@epfl.ch\n\nLaboratory of Artificial Intelligence",
    "Objectives of this lecture\n\nPresent SCFGs, the extension of formal grammars to deal with more difficult problems",
    "Contents\n\n1. Introduction: probabilities\n   * Why?\n   * How?\n   * What?\n   \n2. $n$-grams\n   * SCFG\n     - Introduction / Notations\n     - Definition\n     - Learning",
    "Parsing: probabilistic approach\n\nWHY probabilities?\n\nLinguistic resources needed for semantic/pragmatic models, even for more sophisticated syntactic models, are hard to obtain/create\n\n* Extension of (simple) standard syntactic models\n* to be able to make choices among sentences/structures (in case of ambiguity)\n* Automatic Learning of models from corpora",
    "What does it mean to \"probabilize\"?\n\nImplicitly represent the linguistic constraints that we do not want to or do not know how to integrate into the models:\n\nSet of linguistic phenomena that cannot or are hard to express in operational terms but that still are possible to evaluate (on corpora)\n\nThe probability is then a measure of the quality of the adequation between the sentence/structure and the underlying model.",
    "WHAT is \"probabilized\"?\n\nThe point of view is different depending on whether the syntactic model is used as a recognizer or as an analyzer\n\n- A recognizer is only able to tell whether the input sentence is correct or not\n- An analyzer is more complex and produces additional information for the correct sentences: a structure representing the syntactic organization of the words.",
    "Parsing: probabilistic approach (4)\n\n\\begin{array}{|c|c|c|}\n\\hline\n & \\text{recognizer} & \\text{analyzer} \\\\\n\\hline\n\\text{what is probabilized?} & \\text{sentences} & \\text{parse trees associated to a given sentence} \\\\\n\\hline\n\\text{meaning of the probabilities} & \\text{adequation of a sentence to the model} & \\text{adequation of a structure (tree) to the model} \\\\\n & P(w_{1}^{n}) & P(T|w_{1}^{n}) \\\\\n\\hline\n\\text{example} & N\\text{-grams} & SCFG \\\\\n\\hline\n\\end{array}\n\nNotice: Although in principle probabilities have no reason to depend on the formal description of the language they are associated with, their operational definition in practice can hardly be build independently of the generative model defining the language (i.e. the grammar)",
    "Parsing: probabilistic approach (5) \n\nGeneral scheme of realization of probabilistic model:\n\\begin{itemize}\n\\item Identify the probability to estimate: $P(W_1...W_n)$ or $P(A|W_1...W_n)$\n\\item on the basis of linguistic hypotheses, express this probability by restricted number of parameters: $P = f(p_1...p_k)$\n\\item On the basis of a well defined corpora, estimate retained parameters in order to be able to compute probabilities\n\\end{itemize}",
    "$N$-grams\n\nOne possible probabilization of a language: estimate probabilities of sequences of words by their occurrence frequencies in a reference corpus\n\n\ud83d\udccd For an accurate estimation, huge amounts of data are required\n\n\ud83d\udcd1 reducing the number of parameters: estimate probabilities of fixed-size sequences ($N$-grams) and then approximate the probabilities of a longer sequence on the basis of these parameters:\n\n$$\nP(w_1, ..., w_n) = P(w_1, ..., w_{N-1}) \\cdot \\prod_{i=N}^{n} P(w_i | w_{i-N+1}, ..., w_{i-1})\n$$\n\nExample: ($N = 2$)\n\n$$\n\\begin{array}{ccc}\n\\text{the cat ate a mouse} & \\quad & \\text{ate mouse a cat the} \\\\\n(\\text{the cat}) & (\\text{cat ate}) & (\\text{ate a}) & (\\text{a mouse}) & \\quad & (\\text{ate mouse}) & (\\text{mouse a}) & (\\text{a cat}) & (\\text{cat the})\n\\end{array}\n$$",
    "Contents\n\n   - Introduction\n   - $n$-grams\n   - SCFG\n      - Introduction / Notations\n      - Definition\n      - Learning",
    "SCFG: Summary\n\na Stochastic Context-Free Grammar is\n* a CFG for which\n    \u2022 each rule $R$ is associated with a stochastic coefficient $p(R)$ such that\n        - $0 \\leq p(R) \\leq 1$\n        - $\\sum_{R':left(R')=left(R)} p(R') = 1$\n    \u2022 $P(T = R_0 \\circ \\ldots \\circ R_n) = \\prod_{i=0}^n p(R_i)$\n\nMaximization or consistent grammars",
    "Notations\n\nFor a context-free grammar $\\mathcal{G}$ we will use the following notations:\n$\\mathcal{L}(\\mathcal{G})$ the language recognized by $\\mathcal{G}$    $\\mathcal{R}(\\mathcal{G})$ the set of rules of $\\mathcal{G}$\n$\\mathcal{A}(\\mathcal{G})$ the set of partial trees of $\\mathcal{G}$ (with root S)\n$\\mathcal{T}(\\mathcal{G})$ the set of complete trees of $\\mathcal{G}$    $\\mathcal{T(G)} \\subseteq \\mathcal{A(G)}$\n\nFor a tree $T\u2019$ of $\\mathcal{A(G)}$, $r(T\u2019)$ will denote its root, $F(T\u2019)$ the ordered sequences of its leaves and $lmnt(T\u2019)$ the left-most non-terminal leave of $T\u2019$. If $T$ does not have any non-terminal leave, $lmnt(T) = \\varepsilon$\n\nExample\n\n$F(T\u2019) = \\{the, cat, V, PNP\\}$\nand $lmnt(T) = V$",
    "Notations (2)\n\nFurthermore, the same notation $R$ will be used for both the rule and the corresponding elementary tree:\n\n$ NP \\rightarrow \\text{Det N} $\n\nThe symbol $\\circ$ denotes the internal composition rule on $ \\mathcal{A}(G) $ that returns the tree resulting from the substitution of the left-most non-terminal leave of the left tree by the right tree when it is possible, and $\\epsilon$ if not.\n\nFor a rule $R$ of $R(G)$, left$(R)$ denotes the left-hand side of $R$.",
    "SCFG\n\nDesambiguation: Let $\\mathcal{G}$ be a Stochastic CFG and $W = w_1^n$ a sentence with several interpretations $T_1, ..., T_k$ according to $\\mathcal{G}$. The goal is to choose among the $T_i$s\n\nIn a standard approach, such a choice is made on semantic/pragmatic criteria\n\nIn the probabilistic approach, the choice is made according to the probabilities of the $T_i$ trees. In other terms, we are looking for:\n\n\\[ T = \\mathrm{Argmax}_{T_i} P(T_i|W) \\]\n\nBut \n\n\\[ P(T_i|W) = \\frac{P(T_i, W)}{P(W)} = P(T_i) \\]\n\nsince $T_i$ precisely is a tree that analyses $W$\n\nWe are therefore looking for $T = \\mathrm{Argmax}_{T_i} P(T_i)$",
    "$T_i$ is interpreted as the result of a given (unknown) stochastic process $\\xi$\n\n$\\Rightarrow$ because of the one-to-one mapping that exists in CFG between trees and derivations (sequences of rules), $\\xi$ is supposed to be a stochastic process on **rules**, i.e. a random sequence in $\\mathcal{R}(\\mathcal{G})$\n\n$\\Rightarrow$ We will therefore characterize $P(T)$ using $P(\\xi = R_0, ..., R_n)$\n\n\\[P(\\xi = R_0, ..., R_n) = P(R_0) \\cdot \\prod_{i=1}^{n} P(R_i | R_1, ..., R_{i-1})\\]",
    "Definition of \u03be\n\nTo fully define \u03be we need the definition of $P(R_0)$ and $P(R_i|R_1,...,R_{i-1})$:\n\u2022 $R_0$ is the constant \"random\" variable S (null-depth tree with root S, the start-symbol)\nTherefore $P(R_0 = S) = 1$\n\u2022 $P(R_i|R_0,...,R_{i-1})$ is null if left$(R_i) \\neq \\text{lmnt}(R_0 ... 0 ... R_{i-1})$\n\nWhat value for the probability when it is not zero?",
    "Value for $P(R_i|R_0,...,R_{i-1})$\n\nAs up to now, this probability is conditioned by left$(R_i) = lmnt(R_0 \\circ ... \\circ R_{i-1})$\nIf we make the assumption that it is conditioned ONLY by this, then\n\n$P(R_i|R_0,...,R_{i-1}) = P(R_i|lmnt(R_0 \\circ ... \\circ R_{i-1})) = P(R_i|left(R_i))$\n\nwhich therefore only depends on $R_i$ and will be denoted by $p(R_i)$. It is called the\n\"stochastic coefficient\" of the rule $R_i$\n\n$p(R_i)$ is a parameter of the processus $\\xi$ and, by construction, we have:\n$\\forall R \\in \\mathcal{R}(G)$ \n$$\\sum_{\\begin{array}{c}R' \\in \\mathcal{R}(G):\\\\ left(R')=left(R)\\end{array}} p(R') = 1$$\n\nNotice that limiting $P(R_i|R_0,...,R_{i-1})$ to the conditioning by\n$P(R_i|lmnt(R_0 \\circ ... \\circ R_{i-1}))$ only is a strongly restrictive hypothesis on the processus $\\xi$\n",
    "Probability of a tree?\n\nFinally, the probability of a (valid) sequence of rules is:\n\\[ P(R_0, ..., R_n) = \\prod_{i=1}^n p(R_i) \\]\n\nEach \\( T \\) in \\( \\mathcal{T(G)} \\) corresponds to a unique (valid) sequence of rules, therefore\n\n\\[ P(T) = P(R_0, R_1, ..., R_k) = \\prod_{i=1}^k p(R_i) \\]\n\nIn short: For SCFGs, the probability of a tree is the product of the stochastic coefficient associated to its rules",
    "Probability of a tree? (2)\n\nBUT... is it really a probability on $T(G)$?...\n\nWhat is $\\sum_{T \\in T(G)} P(T)$?\n- It converges\n- towards a limit lower or equal to 1\n- But that can be < 1\n\nExample: $S \\rightarrow S S (p)$ \\quad $S \\rightarrow a\\ (1-p)$\n\nTherefore the correct probabilization is:\n$$\\hat{P}(T) = \\frac{P(T)}{\\sum_{T \\in T(G)} P(T)}$$\n\nIn the case where the grammar is consistent (i.e. $\\sum P(A) = 1)$ (or in the case where only the maximum probability is considered), the two approaches are equivalent. The only problematic case here is when one deals simultaneously with several not consistent grammars.",
    "Probability of a sentence $P(W)$\n\nThe probability of a sentence is defined by:\n\n$$P(W) = \\sum_{\\substack{T \\in G(W) \\\\ F(T) = W}} \\hat{P}(T)$$\n\nNotice that $P(T, W) = \\hat{P}(T) \\cdot \\delta(W - F(T))$ (Kronecker notation) which justifies the formulas used at the beginning of the course",
    "SCFG: Implementation\n\nIt is possible to compute $\\text{Argmax } P(T_i)$ and/or $P(W) = \\sum P(T_i)$ during the bottom-up phase of the CYK analysis, using dynamic programming\n\nFor a given element in a cell, a value $v_i$ representing the maximum (or the sum) of the probabilities of its interpretations is stored\n\nNotice:\n\n$P(X) = \\prod P(R_i)$\n\n$= p(R) \\cdot P_1 \\cdots P_n$",
    "When a new interpretation of element $i$ is build (by composition of elements $j$ and $k$), the value $v_i$ is updated according to:\n\n$$ v_i = \\max(v_i, v_j v_k \\rho_i ) $$\n(or)\n$$ v_i = v_i + v_j v_k \\rho_i $$\n\nwith $\\rho_i = 1$ if element $i$ is a item $[\\alpha \\cdots]$\n\nand $\\rho_i = p(R_k)$ if element $i$ is a non-terminal obtained by applying rule $R_k$\n\nThe initial value for the $v_i$ s is 0",
    "Let us consider that a treebank made of the following parse trees is available:\n\\[ T_1: \\]\n\n\\[\n\\begin{array}{ccccccccccc}\n& & & & S_{7,2} & & & & & & \\\\\n& & & / & & \\backslash & & & & & \\\\\n& & NP_{5,5} & & & & VP_{7,4} & & & & PNP_{7,3} \\\\\n& / & \\backslash & & NPO_{7,7} & & / & & \\backslash & & \\backslash \\\\\nDet_{5,5} & the & NP_{10} & boy & V_{1,4} & delivers & Det_{7,3} & a & NPO_{7,7} & \\\\\n& & & & & & Prep_{1,5} & with & NP_{10} & \\\\\n& a & barrel & & & & \\backslash & N_{7,12} \\\\\n& & & & & truck & \\\\\n\\end{array}\n\\]",
    "$T_2:$\n\n\\begin{aligned}\n&S_{11} \\\\\n&\\quad \\NP_{15} \\\\\n&\\quad \\quad \\NP_0^{17} \\\\\n&\\quad \\quad \\quad \\Det_{18} \\\\\n&\\quad \\quad \\quad \\quad \\text{the} \\\\\n&\\quad \\quad \\quad \\N_{10} \\\\\n&\\quad \\quad \\quad \\quad \\text{boy} \\\\\n&\\quad \\VP_{14} \\\\\n&\\quad \\quad \\V_{14} \\\\\n&\\quad \\quad \\quad \\text{delivers} \\\\\n&\\quad \\quad \\NP_0^{17} \\\\\n&\\quad \\quad \\quad \\Det_9 \\\\\n&\\quad \\quad \\quad \\quad \\text{a} \\\\\n&\\quad \\quad \\quad \\N_{11} \\\\\n&\\quad \\quad \\quad \\quad \\text{barrel} \\\\\n&\\quad \\PNP_{13} \\\\\n&\\quad \\quad \\Prep_{13} \\\\\n&\\quad \\quad \\quad \\text{with} \\\\\n&\\quad \\quad \\NP_{15} \\\\\n&\\quad \\quad \\quad \\NP_0^{17} \\\\\n&\\quad \\quad \\quad \\quad \\Det_9 \\\\\n&\\quad \\quad \\quad \\quad \\quad \\text{a} \\\\\n&\\quad \\quad \\quad \\quad \\N_{13} \\\\\n&\\quad \\quad \\quad \\quad \\quad \\text{cap} \\\\\n\\end{aligned}",
    "Grammar extraction (2)\n\nFrom the trees present in the corpus, we can extract the context-free grammar $G$, made of the following 15 rules:\n\n\\[\n\\begin{array}{ll}\n\\text{rule} & p_i \\\\\nr_1: S \\rightarrow NP \\, VP & p_1 \\\\\nr_2: S \\rightarrow NP \\, NP \\, NP \\, NP & p_2 \\\\\nr_3: PNP \\rightarrow Prep \\, NP & p_3 \\\\\nr_4: VP \\rightarrow V \\, PNP & p_4 \\\\\nr_5: NP \\rightarrow N & p_5 \\\\\nr_6: NP \\rightarrow Det \\, N PNP & p_6 \\\\\nr_7: NFO \\rightarrow Det \\, N & p_7 \\\\\n\\end{array}\n\\]\n\n\\[\n\\begin{array}{ll}\n\\text{rule} & p_i \\\\\nr_8: Det \\rightarrow the & p_8 \\\\\nr_9: Det \\rightarrow a & p_9 \\\\\nr_{10}: N \\rightarrow boy & p_{10} \\\\\nr_{11}: N \\rightarrow barrel & p_{11} \\\\\nr_{12}: N \\rightarrow truck & p_{12} \\\\\nr_{13}: N \\rightarrow cap & p_{13} \\\\\nr_{14}: V \\rightarrow delivers & p_{14} \\\\\nr_{15}: Prep \\rightarrow with & p_{15} \\\\\n\\end{array}\n\\]\n\nwhere the $p_i$ denote the probabilities associated with each of the rules\n\nHow can we estimate them?",
    "Estimating the probabilities\n\nsupervised learning: When a tree-bank (annotated corpus) is available, stochastic coefficients are estimated by the relative frequencies (maximum likelihood estimation):\n\n$p(R) = \\frac{\\text{nb. occurrences of } R}{R' \\text{ such that left}(R') = \\text{left}(R)}$\n\nunsupervised learning: When only text is available (and also a grammar): EM estimation of the coefficients: inside-outside algorithm\n* iterative algorithm\n* converges towards a local minimum\n* highly sensitive to initial values\n\nhybrid approaches: using a (small) tree-bank and a (large) corpus of text",
    "Estimating the probabilities (2)\n\nIn our case (supervised learning), we get:\n\n\\[\n\\begin{array}{l c}\n\\text{rule} & p_i \\\\\nr_1: S \\rightarrow \\text{NP VP} & 1/2 \\\\\nr_2: S \\rightarrow \\text{NP PNP} & 1/2 \\\\\nr_3: \\text{PNP} \\rightarrow \\text{Prep NP} & 1 \\\\\nr_4: \\text{VP} \\rightarrow \\text{V NP} & 1 \\\\\nr_5: \\text{NP} \\rightarrow \\text{N0} & 5/6 \\\\\nr_6: \\text{NP} \\rightarrow \\text{NP Prep} & 1/6 \\\\\nr_7: \\text{N P0} \\rightarrow \\text{Det N} & 1 \\\\\n\\end{array}\n\\]\n\\[\n\\begin{array}{l c}\n\\text{rule} & p_i \\\\\nr_8: \\text{Det} \\rightarrow \\text{the} & 1/3 \\\\\nr_9: \\text{Det} \\rightarrow \\text{a} & 2/3 \\\\\nr_{10}: N \\rightarrow \\text{boy} & 1/3 \\\\\nr_{11}: N \\rightarrow \\text{barrel} & 1/3 \\\\\nr_{12}: N \\rightarrow \\text{truck} & 1/6 \\\\\nr_{13}: N \\rightarrow \\text{cap} & 1/6 \\\\\nr_{14}: V \\rightarrow \\text{delivers} & 1 \\\\\nr_{15}: \\text{Prep} \\rightarrow \\text{with} & 1 \\\\\n\\end{array}\n\\]",
    "Keypoints\n\n- Probabilities of SCFGs are implicit linguistic constraints serving as measures of the adequation between the sentence and the model\n- The role of probabilities is to identify the correctness of the sentence and eventually to choose one interpretation among several\n- Calculation of probabilities of syntactic interpretations of sentences\n- Estimation of probabilities of SCFGs from training corpora",
    "References\n\n[1] C. D. Manning, H. Sch\u00fctze, *Foundations of Statistical Natural Language Processing*, ch. 11, 12, MIT, 1999.\n\n[3] D. Jurafsky & J. H. Martin, *Speech and Language Processing*, ch. 12, Prentice Hall, 2000.\n\n[4] R. Dale, H. Moisl & H. Sommers, *Handbook of Natural Language Processing*, ch. 22, Dekker, 2000.",
    "Lexical Semantics\n\nMartin Rajman\n&\nJean-C\u00e9dric Chappelier",
    "Overview\n\n- Basic concepts\n- Semantic relations\n- Resources for Lexical Semantics: Wordnet\n- Applications of Lexical Semantics\n- Word Sense Disambiguation",
    "Basic concepts",
    "Lexical Semantics vs. Compositional Semantics\n\n* Lexical semantics: The study of the meaning of words\n  - Word meaning is:\n    * structured, i.e. words have lexical relationships\n    * context-sensitive, i.e. can vary with different contexts\n\n* Compositional Semantics: the study of the meaning of linguistic sentences\n  - Words contribute to the meaning of sentences but don\u2019t have a meaning by themselves\n  - Example: \u201cJohn likes Mary\u201d -> likes(John,Mary)",
    "Compositional Semantics\n\n- *Compositional Semantics* is the study of the meaning of complex linguistic units such as sentences, paragraphs, or documents\n- A standard approach for exploring compositional semantics with human subjects are reading tests",
    "Reading tests\n\n- Consider the following text:\n\u201cUnder Peter\u2019s supervision, John is participating to an experiments consisting in placing on a table blocks with various shapes and colors initially lying on the floor.\nThe first day, he puts two triangle blocks on the table, one red and one green.\nThe second day, he replaces the red triangle block by a square block of the same color, and added a green triangle block.\u201d\n\n- Answer the following questions:\n    1. Who is manipulating the blocks during the experiment?\n    2. How many blocks are on the table at the end of the experiment?\n    3. What is the shape of the red block(s) on the table at the end of day 1?\n    4. How many triangles have been manipulated during the whole experiment?",
    "Reading tests (2)\n\n- The test may seem trivial to (almost any, at least English speaking) human subject\u2026 however, it requires a lot of knowledge to be successfully passed!\n   - Knowledge about involved objects: What is a block? What is a shape? What is a color? What is a table? What is a floor?\n   - Knowledge about involved actions: What is participate? Consist? Lie? ...\n   - Knowledge about people who are referred to: Who is John? Who is Peter?\n   - Knowledge about the language: syntactic analysis (e.g. in \u201cblocks (...) initially lying on the floor\u201d, what is the subject of lying?); anaphora resolution (who is the pronoun \u201che\u201d in the second sentence referring to?)\n   - Knowledge about the real world: e.g. when a block is put on a table, it stays there (while a drop of water may evaporate or a feather may be blown away) or if somebody is participating to an experiment, s/he is performing the actions during this experiment, not the person who is supervising it! ...",
    "How could this be automated?\n\n- We need to be able to convert the information expressed in linguistic units into some exploitable (formal) representation\n- For a formal representation, to be exploitable means, among others, that:\n  \u25cb it can be modified through various transformations, also expressed in linguistic terms;\n  \u25cb it can be the subject of various analysis (e.g. counting some of its constituents), also expressed in linguistic terms.",
    "Usual representations\n\n\u2022 Symbolic representations:\n   \u27a2 various formal logics: the meaning is expressed as a logical formula that can then be manipulated through various inferential mechanisms;\n   \u27a2 various graph based representations: the meaning is expressed as a graph that can then be manipulated through various graph transformations;\n\n\u2022 Vectorial representations:\n   \u27a2 typically approaches based on \u201cdistributional semantics\u201d (e.g. Word embeddings): the meaning is represented as a vector in a (usually high dimension) vector space and can then be manipulated through vector based operations (e.g. weighted sums, projections, etc.)",
    "Usual representations (2)\n\n- Currently, only vectorial representations can be deployed at a large scale because:\n    - it is extremely difficult (if not impossible) to guarantee the consistency of large sets of logical propositions derived from textual input, which often makes the inferential mechanisms very hard to use;\n    - there isn\u2019t yet a consensus neither on which are the most suitable graph-based representations (semantic nets? Conceptual graphs? ...) for expressing the meaning of linguistic entities, nor on which are the proper operations to be applied to these representations;\n\n- ... but the associated vector based operations seems to be too simplistic for suitably mimicking the transformations that are required to manipulate linguistic meaning.",
    "Intermediate conclusion\n\n- Large scale Compositional Semantics is still out of reach, and\n- This lecture will therefore restrict on a simpler form of semantics, the semantics of individual words, e.g. Lexical Semantics",
    "The triangle of signification [Frege]\n\n- Minds grasp senses,\n- Words express them,\n- Objects are referred to by them",
    "Lexical Semantics\n\n- *Lexical Semantics* is the study of the meaning of words (i.e. of the simplest linguistic units)\n- A standard approach for exploring lexical semantics for human subjects are dictionaries (not to be confused with encyclopedias which are not concerned with word meanings but with comprehensive information about subjects/topics/fields from the real world) \n- Note: In this course, a dictionary (especially when tailored for some automated processing) will also often be called a lexicon",
    "Lexeme\n\n- An individual entry in the lexicon\n- A pairing of a particular orthographic and phonological form with some symbolic meaning representation\n  \n| Orthographic form | Phonological form | Meaning                                             |\n|-------------------|-------------------|-----------------------------------------------------|\n| 1. bass           | [beys]            | adj. low in pitch; a bass instrument                |\n| 2. bass           | [bas]             | n. (...) freshwater or marine fishes (...)         |\n| 3. wood           | [woo d]           | n. (...) substance of a tree (...)                  |\n| 4. would          | [woo d]           | v. A pt.and pp.of WILL                             |\n\nTuesday 22 April, 2008       Computational Linguistics course            6",
    "Lexicon\n- Finite list of lexemes\n- Can include\n  - Compound nouns\n  - Other non-compositional phrases, e.g. proper names",
    "Word sense\n\n- A lexeme\u2019s meaning component\n- Different dictionaries have different notions of word senses, how to represent them and how to split them\n- A word sense can be represented for example as:\n  - A text description\n  - A definition based on its relationship to other lexemes (\u201cis a\u201d, \u201chas a\u201d)",
    "Dictionary definitions\n\u2022 Propose a definition for the word \"bee\"...",
    "Dictionary definitions (2)\n\nDefinition of \u201cbee\u201d (according to the English Wiktionary):\n\n\u201cA flying insect, of the superfamily Apoidea, known for its organised societies and for collecting pollen and (in some species) producing wax and honey.\u201d\n\nThe definition requires the meaning of the words it contains...\n- Apoidea: A taxonomic superfamily within the order Hymenoptera \u2013 the bees and some wasps.\n- To fly: To travel through the air, another gas or a vacuum, without being in contact with a grounded surface.\n- Insect: An arthropod in the class Insecta, characterized by six legs, up to four wings, and a chitinous exoskeleton.",
    "Lexical semantics vs. Compositional semantics (again)\n\n- If the different meanings (aka senses) of a words are defined by well chosen definitions in natural language (as it is the case in dictionaries), we are faced with a vicious circle:\n  understanding the meaning (i.e., making it exploitable) of the different senses of a word (lexical semantics) requires to understand the meaning of the associated definitions and thus the availability of some form of compositional semantics...\n\n- To break this vicious circle, natural language cannot be used to define the various meanings of a word and some more formal representations must be used instead; in this course, we will consider two types of formalisms:\n  - semantic relations, and\n  - synsets (see the slides on Wordnet)",
    "Semantic Relations",
    "Overview\n\n- Homonymy\n- Polysemy\n- Synonymy\n- Hyponymy/Hyperonymy\n- Overlap\n- Meronymy/Holonymy",
    "Homonymy\n\n- A relation that holds between words that have the same surface form but different meanings\n  - Bat\u00b9: The wooden club used in certain games\n  - Bat\u00b2: Flying mammal of the order Chiroptera\n- Homophones: distinct lexemes with the same pronunciation (wood, would)\n- Homographs: distinct lexemes with the same orthographic form (bass [bas], bass [beys])",
    "Homonymy, homophony, homography\n\n\u2022 Homophony: two distinct words are homophones is they have the same pronunciation (i.e. the same \u201cphonological form\u201d)\nExample: \u201cdie\u201d and \u201cdye\u201d\n\n\u2022 Homography: two words are homographs if they are spelled the same (i.e. have the same \u201corthographic form\u201d) but not pronounced the same\nExample: \u201cbass\u201d (the fish) and \u201cbass\u201d (the guitar)\n\n\u2022 Homonymy: two words are homonyms if they are spelled and pronounced the same, but do not have the same meaning\nExample: \u201cbat\u201d (the wooden club) and \u201cbat\u201d (the flying mammal)",
    "Polysemy\n\n- A relation that holds between multiple *related* meanings within a single lexeme\n\n| Orthographical form | Meaning |\n|---------------------|---------|\n| Crown               | 1. Headgear worn by a monarch \\newline 2. The highest part of anything, e.g. a tree \\newline 3. The part of a tooth that is covered by enamel \\newline ... |",
    "Homonymy vs. Polysemy\n\n- Both homonyms and polysems are spelled and pronounced the same but ...\n- homonyms have a different etymology and usually correspond to two distinct entries in a lexicon, while polysems share the same etymology but correspond to two different meaning of the same lexicon entry\n\nExample:\n- \"bat\" (the flying mammal) comes from a dialectal variant of the Middle English \u201cbakke\u201d, while \"bat\" (the wooden club) comes from the Old English \u201cbatt\u201d, while\n- \"crown\" (the headgear) and \"crown\" (the highest part) both come from the Anglo-Norman \u201ccoroune\u201d",
    "Types of polysemy\n\nMetaphor\n - \"Germany will pull Slovenia out of its economic slump\"\n - \"I spent 2 hours on that homework\"\n\nMetonymy\n - \"The White House announced yesterday\"\n - \"This chapter talks about part-of-speech tagging\"\n - Bank (building) and bank (financial institution)",
    "Synonymy\n\n- Two words are synonymous if they have the same sense\n- Criteria for synonymy:\n  - They have the same value for all their semantic features\n  - They map to the same concept\n  - They satisfy the Leibniz substitution theory\n    - The substitution of one for the other never changes the truth value of a sentence in which the substitution is made\n- Example of non-synonyms:\n  - Tony is the big brother\n  - Tony is the large brother",
    "Hyponymy/Hypernymy\n\nA hyponym is a word whose meaning contains the entire meaning of another, known as the superordinate or hypernym.\n\nanimal                device\n\ndog     cat     mouse     printer\n\nis_a_kind_of",
    "Overlap\n\nTwo words overlap in meaning if they have the same value for some (but not all) of the \u201csemantic features\u201d.\n\n\u2013 Hyponymy is a special case of overlap where all the features of the hypernym is contained by the hyponym.\n\nsister                niece\n[+human]           [+human]\n[-male]             [-male]\n[+kin]               [+kin]",
    "Meronymy/Holonymy\n\n- A word w1 is a meronym of another word w2 (the holonym) if the relation is-part-of holds between the meaning of w1 and w2.\n  - Meronymy is transitive and asymmetric\n  - A meronym can have many holonyms\n  - Meronyms are distinguishing features that hyponyms can inherit.\n    - Ex. If \u201cbeak\u201d and \u201cwing\u201d are meronyms of \u201cbird\u201d, and if \u201ccanary\u201d is a hyponym of \u201cbird\u201d, then (by inheritance), \u201cbeak\u201d and \u201cwing\u201d must be meronyms of \u201ccanary\u201d.\n\n- Limited transitivity:\n    - Ex. \u201cA house has a door\u201d and \u201ca door has a handle\u201d, then \u201ca house has a handle\u201d (?)",
    "Different type of meronymic (part-whole) relationships\n\n- Component-object (branch/tree)\n- Member-collection (tree/forest)\n- Portion-mass (slice/cake)\n- Stuff-object (aluminium/airplane)\n- Feature-activity (paying/shopping)\n- Place-area (Lausanne/Vaud)\n- Phase-process (adolescence/growing up).",
    "Lexical Semantics with semantic relations\n\nConsider the following meanings of the word \u201cmouse\u201d:\n1. Any small rodent of the genus Mus.\n2. An input device that is moved over a pad or other flat surface to produce a corresponding movement of a pointer on a graphical display.\n\nHow could you use semantic relations to distinguish between these two meanings?",
    "Lexical semantics with semantic relations (2)\n\nMouse:\n1. hyponym of \u201crodent\u201d\n2. hyponym of \u201cdevice\u201d",
    "Lexical Semantics with semantic relations (3)\n\nConsider the following meanings of the word \u201cwood\u201d:\n1. The substance making up the central part of the trunk and branches of a tree.\nexample: this table is made of wood\n2. A forested or wooded area.\nexample: he got lost in the wood\n3. A type of golf club, the head of which was traditionally made of wood.\nexample: he played golf with a wood\n\nHow could you use semantic relations to distinguish between these two meanings?",
    "Lexical semantics with semantic relations (4)\n\nWood:\n1. hyponym of \u201csubstance\u201d\n2. hyponym of \u201carea\u201d\n3. hyponym of \u201cclub\u201d",
    "Let us go further!...\n\nThe definitions based on semantic relations given so far are good enough for distinguishing the meanings of various polysemic words but they do not allow to distinguish between the hyponyms of a given hypernym!...\n\nBut how to distinguish between mouse_1 and rat_1?",
    "Let us go further!... (2)\n\n- Let us recall the definitions of mouse_1 and rat_1:\n\n\u27a2 mouse_1: Any small rodent of the genus Mus.\n\n\u27a2 rat_1: Any medium-sized rodent belonging to the genus Rattus.\n\n- To distinguish between mouse_1 and rat_1, additional semantic relations may be used...",
    "Let us go further!... (3)\n\nFor example:\n\u27a2 mouse_1: hyponym of \u201crodent\u201d and meronym of \u201cMus\u201d\n\u27a2 rat_1: hyponym of \u201crodent\u201d and meronym of \u201cRattus\u201d\n\nwhich, if we add the fact that \u201cMus\u201d and \u201cRattus\u201d are both hyponyms of \u201cgenus\u201d would lead to the following graph based representation:",
    "Let us go further!... (4)\n\n- This way of proceeding follows the Aristotelian principle of \u201cGenus-Differentia\u201d:\n    - Genus: each word meaning is first associated to a hypernym through a \u201chyponymy/hypernymy\u201d relation (this is equivalent to defining the superclass associated with a given class in an object oriented model)\n    - Differentia: each word meaning is then uniquely differentiated from the other hyponyms of its hypernym by additional relations associating it with other words meanings\n- Of course, to make this type of approach realistic on a large scale, more than two semantic relations are required!",
    "Let us go further!... (5)\n\n- Exercise: Apply the Genus-Differentia approach to differentiate:\n  \u27a2 wood_1: The substance making up the central part of the trunk and branches of a tree.\n\nfrom\n\n  \u27a2 stone_1: A hard earthen substance that can form large rocks.",
    "Intermediate conclusion (2)\n\nIn a relation based approach to Lexical Semantics, the word meanings are defined as the nodes of a directed graph the arcs of which correspond to various semantic relations\n\nThe targeted semantic graph is built with the main purpose of correctly differentiating the various meanings of the words (which is one of the primary objectives of Lexical Semantics), and, as such, it will most often lead to a semantic model that will not be sophisticated enough to more advanced exploitations such as the automated generation of the answers to the questions asked in the simple reading test given at the beginning of the lecture; for this the semantic model will have to be embedded in a more complex one providing the possibility to produce semantic representation for more complex linguistic units than words (Compositional Semantics)",
    "WordNet\n\nhttp://wordnet.princeton.edu/perl/webwn",
    "WordNet Search - 3.1\n\nWord to search for: mouse\n\nNoun\n\nS: (n) mouse (any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails)\nS: (n) shiner, black eye1, mouse2 (a swollen bruise caused by a blow to the eye)\nS: (n) mouse3 (person who is quiet or timid)\nS: (n) mouse4, computer mouse (a hand-operated electronic device that controls the coordinates of a cursor on your computer screen as you move it around on a pad; \"a mouse takes much more room than a trackball\")\n\nVerb\n\nS: (v) sneak1, mouse1, creep2, pussyfoot1 (to go stealthily or furtively; \"..stead of sneaking around spying on the neighbor's house\")\nS: (v) mouse2 (manipulate the mouse of a computer)",
    "Word to search for: mouse\n\nNoun\n$ \\{\\} $ n mouse1\n$ \\{\\} $ n shiner1, black eye1, mouse2\n$ \\{\\} $ n mouse5\n$ \\{\\} $ n mouse4, computer mouse1\n\nVerb\n$ \\{\\} $ v sneak1, mouse1, creep2, pussyfoot1\n$ \\{\\} $ v mouse2",
    "Synsets\n\n- Synset is the set of word forms that share the same sense\n  - Synsets do not explain what the concepts are, they signify that concepts exists\n- Hypothesis: \n  - A synonym is often sufficient to identify the concept.\n    - Example\n      - \"board\" means 1) piece of lumber 2) group of people assembled for some reason\n        - Sense 1: {board, plank} Sense 2: {board, committee}\n  - True for English which is rich in synonyms\n    - May not be true for all languages!",
    "How is meaning represented?\n\nDifferential approach (Wordnet)\n\u2013 Meanings (concepts) are represented as a list of word forms that distinguish their meaning from other meanings: the synset.\n    \u2022 No two synsets should have exactly the same set of word forms \n\nConstructive approach (conventional dictionaries)\n\u2013 the meaning representation (e.g. dictionary gloss) has to contain sufficient information to accurately define a concept\n    \u2022 Not so easy, definitions are often cyclic\n        \u2013 Tree: \u201ca plant having a permanently woody main stem or trunk...\u201d\n        \u2013 Wood: \u201cthe hard, fibrous substance composing most of the stem and branches of a tree\u201d \n    \u2022 Conventional dictionaries rarely meet this requirement",
    "Word categories and semantic relations in Wordnet\n\n\u2022 Nouns\n  - Organised as topical hierarchies with lexical inheritance (hyponymy/hypernymy and meronymy/holonymy).\n\n\u2022 Verbs\n  - Organised by a variety of entailment relations\n\n\u2022 Adjectives\n  - Organised on the basis of bipolar opposition (antonymy relations)\n\n\u2022 Adverbs\n  - Like adjectives",
    "Building the noun hierarchy\n\n* Hyponymy relation:\n  - Transitive\n  - Asymmetric\n  - Generates a taxonomic hierarchy (there is normally a single hypernym).\n\n* Semantic primes:\n  - Select a (relatively small) number of generic concepts and treat each one as the unique beginner of a separate hierarchy.",
    "Natural groupings of unique beginners\n\n\u2022 Small 'Tops'\n\n{thing, entity}\n\n{living thing, organism} {nonliving thing, object}\n\n{plant, flora} {animal, fauna} {artifact} {natural object}\n\n{person, human being} {substance} {food}",
    "Application of lexical semantics in language engineering",
    "Applications of lexical semantics\n\nApplications\n- Speech processing\n- Linguistic analysis\n- Information Retrieval\n- Information Extraction\n- Machine translation\n- Cohesive extractive summarization\n- Spelling error correction\n\nTasks\n- Word sense disambiguation\n- Lexical cohesion\n  - A group of words is lexically cohesive when all of the words are semantically related; for example, when they all concern the same topic.\n  - Lexical cohesion can be computed using lexical semantic resources (thesaurus)\n- Semantic indexing\n- Semantic role labeling",
    "Lexical semantics in Speech Processing\n\nText to speech\n- WSD\n  - Choose the right pronunciation of a word depending on the word sense\n\nSpeech recognition\n- WSD\n  - Choose the right word among possible words with the same pronunciation (homophones)\n- Lexical cohesion\n  - A measure of lexical cohesion can be used to recognize when speech recognition software has made errors. The incorrect words usually do not cohere with the rest of the text.\n\n\u201cbass\u201d [beys] [bas]\n[seeling] \"ceiling\" \"sealing\"\n\nThe dog's leash/folder",
    "Lexical semantics in Information Retrieval\n\n- Semantic indexing\n  - Indexing word senses instead of words\n  - Improves\n    - Recall by handling synonymy\n    - Precision by handling homonymy and polysemy\n\nExample 1: Different indexing of the term \"Java\"\n  - Programming language\n  - Type of coffee\n  - Location\n\nExample 2: a query for \"cars\" will also return a document that mentions only \"automobiles\"",
    "Lexical semantics in Information Retrieval\n\nIndexing schemes\na) Standard indexing with words (stems or lemmas)\n\n$W_{ij,k}$\n\n$C_1 \\quad C_2 \\quad C_3$\n\n$C_1 \\quad C_2$\n$C_3$",
    "Lexical semantics in Information Retrieval\n\n- Indexing schemes\n  b) Indexing with a semantic ontology, each indexing term is extended with all the hypernym senses\n\n$w_{i,j,k}$\n\n$C_1 \\quad C_2 \\quad C_3 \\quad \\ldots \\quad C_n \\quad root$\n\n$w_i \\quad w_j \\quad w_k$\n\n$C_1 \\quad C_2$\n\n$C_3$",
    "Lexical semantics in Information Retrieval\n\n* Indexing schemes\nc) Synset (or hypernyms synsets) indexing, each indexing term is replaced with its hypernym synset\n\nTuesday 22 April, 2008   Computational Linguistics course   16",
    "Lexical semantics in Information Retrieval\n\nIndexing schemes\nd) Minimum Redundancy Cut (MRC) indexing, each indexing term is replaced with it's dominating semantic concept defined by MRC",
    "Lexical semantics in Information Retrieval\n\nTuesday 22 April, 2008 Computational Linguistics course 18",
    "Lexical semantics in Spelling Error Correction\n\n- In some cases a spelling error can result in a real word in the lexicon and therefore cannot be detected by a conventional spell checker\n\nExample: It is my sincere hole [hope] that you will recover soon\n\n- Such errors can only be detected by computing lexical cohesion and identifying tokens that are semantically unrelated to their context",
    "References\n\n- Cruse, D. A. (1986). Lexical Semantics. Cambridge, New York.\n- Dan Jurafsky and Jim Martin, Speech and Language Processing, Chapter16, Prentice Hall, 2000.\n- Mark Stevenson, Word Sense Disambiguation, CSLI Press, 2003.\n- Sanda Harabagiu and Dan Moldovan, Enriching the WordNet Taxonomy with Contextual Knowledge Acquired from Text, in Natural Language Processing and Knowledge Representation: Language for Knowledge and Knowledge for Language, (Eds) S. Shapiro and L. Iwanska, AAAI/MIT Press, 2000, pages 301-334.\n- Sanda Harabagiu and Dan Moldovan, A Parallel System for Text Inference Using Marker Propagations, IEEE Transactions in Parallel and Distributed Systems August, 1998, pages 729-747.\n- FrameNet web site: http://framenet.icsi.berkeley.edu/",
    "NLP r\u00e9sum\u00e9 Lucie\n\nWeek 1\n\nLanguage is implicit and ambiguous. Syntax is used to avoid mistakes and reduce ambiguity.\n\nLinguistic processing levels:\n- Morphological: Recognize words, use lexicon. Resource: Morphological rules + lexicon (orthograph).\n- Syntactic: Structural level of sentence. Check the rules (positional or selectional) of grammar in sentence. Resource: grammar.\n- Semantic: Understand sentence. Resource: logical propositions, semantic networks, definition of word.\n- Pragmatic: Contextualize. Resources: Hum!\n\nWeek 2\n\nLexicon structure\nCan be done using lots of data structures but best is FSA. \nRead the FSA from top to bottom and number all the possible paths.\n\nBegin alphabetically. At each bifurcation, look RIGHT, take smallest path strictly greater than the number (adding from top to bottom) then subtract to number. Then go to next bifurcation. When get to a final state do 1 - unit reach 0.\n\nMorphology\nAnalyze the structure and variability of the words (conjugaison, plurals, substantives), inflection morphology but not derivatives and compounds. \nRoot: house, write, establish. Affixes (cardinal morpheme --> smallest unit). With inflection, we can add plural, cases, gender, tense, mood, person. Ex: book(s), work(s).\n\nAffixes: pre, suffix, infix, circumfix. In English we use only concatenative morphology.\n\nDerivational morphology: expand vocabulary based on affixes. Transform one lexeme into another lexeme, changing category and/or meaning. Ex: nominalization (propose-proposition, authorize-authorization). Can use rules or lexicon. Resource: Lexicon (morphological rules). Apply if not in lexicon (define). 2 ways of conversion.\n\nExample transformation: Verbal suffixation (empirical set of rules).\n\nSyntax: Morphological sequence + structural inbox.\nStructure: From canonical grammar.\n\nCanon Form S -> t1tr...tk (defined by the canonical grammar).\n\n$S \\rightarrow A \\mid B_1 B_2$\n\n$A \\rightarrow aS \\mid B_1 \\mid ...$\n\n$B \\rightarrow a \\mid b$\n\nEx **: tree can further guide the use of the word by a syntactical validator, and if recognized by syntactical validator, good tree (generic class). Sentence property determined by sentence with great properties be it generic root of the tree $P_1, P_2, ... P_k$.\n\nAFS (regular expressions)\nGenerate simple structures (e.g., count), composition, reduction (extract).\n\nUse of transducers:",
    "Check if radical = modified word (association check), radical to modified (generation), modified to radical (analysis).\nThe 2 lasts are not deterministic.\n\nRegular language\nRene (n \u0303 100 plus fois\nn = 1) union\nCrois: cross product (avec une virgule)\n\u25ca: concatenation (met finite states sur init state\n\nWeek 3\n\nOut of vocabulary (OoV). (A lexicon should handle this possible transformations).\n- Spelling error. Distortions are modelled by transformations (how to rewrite). For example, transposition (exchange letters), one letter is modified.\n- Neologisms. Derivations are modelled by transformations (how to rewrite). For example, name derivation $\\rightarrow$ substantivise.\n- Borrowings are now words from another language. Decompose in n-grams, and insert in a lexicon, complete again test average.\n- Loanwords: Work 87%.\n\nEdit distance (Eresswelitch): Minimal diff between 2 forms. for ex., insertion of a letter, deletion, substitution, transposition... Use dynamic prgramming.\n\n$$\\begin{aligned}\n  D(x_i, y_i) & \\\\\n & \n\\\\ \n\\end{aligned}$$\n\nTake the minimum of the length. If equal, 0, if not, 1. Compares the different diff of k letter else (k1).\nApprach. Insertion of i, from i to j, and j is a test. both 2 letters reversed, then take value 2 times else k1 but instead of $D_X (X_1, X_i)= k1+...$.\n\n$$D(X_1Y_1, X_i Y_k)$$\n\nConsider diff and look if the suffix or ends and do it one by one. Input words into lexicon:\n$X Y Z$\n\nSpelling error correction with FSA:\n\n$$\\begin{aligned}\nD(X, (x_i, y_i)) \\\\\nD(x_i, x_2)X_k : (X_k) - \\text{insertion 1 letter, etc}\n\\end{aligned}$$\n\nWeighted edit distance:\n$$C_{l(l)} = C(i \u2212 l) = 1\\\\\nC(x_k) = C(x_j + 1) = (l-l) \\\\\nC(l_x= x^{2-1} l_y= y^{c_{kl}} 1 / 2)\n$$\n\nMust be non-overlapping",
    "Week 5\n\nPart-of-speech (PoS) tagging\n\nWe want to resolve some ambiguities (don\u2019t mistake a verb for a noun) and reduce the voc size. We assign tags to words (like word type), which is then not trivial to be done by a computer. We use the given notation for the content or tools (such as 1) rule based: Brill\u2019s tagger, or 2) Probabilistic: Hidden Markov chains, conditional random fields,...).\n\nPoS tagging: We care about PoS tags of those words for some type, and the order of two following words matters.\n\nLemmatization\nMass to study-reduce any word to its simpler word version (/v canonical form) using the context (singular, infinitive, . . . ). Find the root. <\u2013 This is a PoS tagging (per word level).\n\n1) Rule based: brill, superfnltiun (tagger)\nApply rules (for manually encoded steps). Learning and updating rules. Template shapes (how the application runs, . . . ), lexical phase, . . . \nPhases of Brill (simple PoS tagger):\n1) templ(s,t) Assign PoS tag based on the shaded lexicon.\n2) Application: Apply all rules to reduce the current lexicon PoS tag, and update the current.\nLearning from annotated/reference. \nAsk for errors, incorrect ones, and create other templates/rules to repeat the tod.\n\nThe new rule reduces those. Iteration on new rules. Can be expressed in output of the lexer. Output their PoS tags, then train those learning PoS tags.\n\nRoof not a finished procedure. Can only return tags and then from tags to inf:\n\n\n2) Probabilistic Hidden Markov Model\n$$\\text{Argmax}_{T}P(T|O) = \\text{Argmax}_{T}P(O|T)P(T)$$\n$$P(T|O) =  \\frac{P(T)P(O|T)}{P(O)}$$\n$$P(O) = \\sum_{t}P(T)P(O|T)$$\nEstimation of parameters can be done supervised (direct computation) but problem of missing data, or unsupervised (Baum-Welch) with high hidden consistency fields. Best are hybrid models. Using tags: 95% good!!\n\nWeek 6\n\nHMM: we want to estimate the l fs (probabilities)\n- need a lexicon, voc size, and prob that they begin a sentence\n- Transition A(i, j) other word probabilities of word being PoS with each other word type (k previous word)\n- emission P(wn In) probabilistic PoS with observation\n- Train. the HMM with order 1 or 2 (bigrams).\n\nThe 3 typical problems of HMM of parameters \u03b8, observation sequence O1.. Ot.\n1. Likelihood: P(O1,...,Op|\u03b8 )\nEstimate the probability of observation given model by Forward Backward see the estimation of\n$$P(O|\u03b8 )$$\n2. Decoding: find the most likely sequence of hidden states\n$$\\text{Argmax}\u00b7P(\u03b8|O)$$\n3. Learning: find \u03b8 that maximizes P(O|\u03b8 )\n$$\\text{Argmax}_{(\u03b8)}\u00b7P(\u03b8|O)$$\n\nForward-backward algorithms for the 1st problem",
    "$$\\alpha_1(i) = P(O_1 = o_1,...,O_t = o_t, S_t = i|C) = P(O_1 = o_1,...,O_{t-1} = o_{t-1}, S_{t-1} = j, O_t = o_t, S_t = i|C)\n=P(O_t = o_t | S_t = i)P(S_t = i| S_{t-1} = j )\n= b_i(o_t)\\sum_{j=i}^n \\alpha_{t-1}(i) a_{ij}(C)$$\n\nViterti algorithm for the second problem (POS taging)\n\n$$\\delta_1(i) = b_i(o_1) \\pi_i |_S = C)$$\n\nFor $t = 2$ to L \nFor all $j=1$ to C\n$$ (\\delta t(j) = b_j (o_t) \\max_{1 \\le i \\leq c} 1_{t-1 = i} a_{ij}(C)$$\n\nFor $t = 2$ to L do\nFor all $(i = 1 to C$)\n$$ \\psi_t (i) = \\arg\\max_{1 \\leq \\leq C} (\\delta_{(t-1)}(i) a_{ij})(c)   $$\n\nreconstruct backwords (from $S_L to S_1$ the best path following the marked transitions $ \\psi$ \n\nBaum-Welch algorithm for the third problem \n1. Let HMM be an initial parameter set\n2. Compute $\\alpha_t (i) and \\beta_t(i)$ by , and x\n3. Compute expected values via the transition formulas\n4. if p(O|) - p(O) $ \\gt  c(\\epsilon  0) (to 2)\n\nWeek 7\nWe want to find relation between following sentences. Sometimes a marker (conjunction...) helps us understand the relation. Sometimes there is a long space of sentences relation.\n\n- P then Q -> P causes then (there is a logical causal relation between both sentences.)\n\nInter annotator agreement (IAA) is considered as a measure of the quality of gold standards.\n\nInter annotator agreement : H and A development -> There Agreement ( H + A annotation same/ total)\n Disagreement ( H+A different annotation )/ total\n\nKappa measure -> Random \n- P(E) agreement expected given there is a number of topics / total (X subset column and line in IAA)\n\n$$ K = \\frac{Pr(a) -Pre(e)}{1-Pre(e)}$$\n=> if 1 then perfect agreement\n\nConfusion matrix : H\n\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\n& Actual : & \\\\\n\\hline\nSystem output: & P & N \\\\\n\\hline\nP & true P & false P \\\\\n\\hline\nN & false N & true N \\\\\n\\hline\n\\end{array}\n\\]\n\nPrecision: Measure of accuracy provided that a class label has been predicted. Precision =\n(syst positives) / total syst positives)\nrecall = System detection / (total of G.S. positives) recall )\nTrue Positive Rate [ hit rate] = Proportion of true pos/ true pos + [miss])\nFalse negative rate = false neg/ [true pos+ miss])\nF measure (harmonic mean of precision and recall) ) \n ROC-AUC = Area under the curve <- P  if 0.5 -> =1  false pos / true neg + false pos\nEvaluation measure three classes: Precision for class 1 . recall for class 1 \n\nWe also need to measure the variance of the evaluation. For that we use k times n-hold cross-validation.\n\nWeek 8\n\nSyntactic level: Analysis of the structure. Parsing is the concept of recognizing a set of words, and analyzing the syntactic relation between them.\n\n- Phrase structure: modelling trees. Considers ordering of words in a local way.\n  - Dependency structure: Subject verb object, coreferences, functional role of words\n  - Parse each sentences => scoring or preference\n     + procedure to write the grammar.\n\n- ",
    "CYK (generic syntactic parsing algorithm)\nCompute all the possible syntactic interpretation (trees).\nBuilds a big triangle shaped table. beginning on bottom with input hyper. Then, way computer backwards to the very top level. Always, amongst each possible cut: level S corresponds to size of N words, so do V => w1 w2 w3 and V2 w4 w5.\nChomsky normal form: X -> X X maximum 2 terms !!!\n\nNP: Noun phrase (Groupe nominal)\nVP: Verbal phrase (Verbe + complement)\nPP: Prepositional phrase (preposition+ complement)\n\nWeek 9\n\n2 others syntactic parsing algorithms:\n\n1) Early parsing\nForm: the state: a pointer, initially points on the left of words, this is the set 0, and the number on the right indicates position within the rule. Handling the sets and finding out what rule is to be expanded next when the pointer is at the beginning, in the middle, etc. When the rules fits, move on with the rule, put word number 1 and let the pointer at the beginning and the input on the left end.\n\nWeek 10\n\nA recognizer is only able to decide whether the input sentence is correct or not\nParse steps: starting from the top nodes, find all the valid interpretations of several sentences: a structure representing all the possible parsings; AG;\nN-grams (recognizer parsing algorithm): following N others and check without grammar;\nThe algorithm is logical and we build a window of length N\n\nMarkov: once a word is known, this depends only on the word before\n1-st = ordinary regular categories. HMMs (animated corpus) = a language; EM\nHMM (Hidden Markov Model): tagging = ambiguous interpretation (the tree is correct or not) \nNewspapers: use of language is not very accurate, which makes text harder to parse.\n\nWeek 11\n\nThe vector space model is applied to documents: 2 steps: first make (select special terms) then vectors for each document;\nVector space: match documents together, check if each document has an element of the vectors intersections; how many times 1 occur, 2 steps: \nStep0: \u201cSuppose the documents are indexed by an inverted file.\u201d\nIndexing = list does:\nStep1: first build a file containing all the documents name and;\nStep2: a list, for each term, indicates in he, in which documents it occur;\nRecursive recall and precision for information retrieval is defined as follows:\n$Rec(l) = \\frac{A}{A+C}$ \n$Pr(L) = \\frac{A}{A+B}$ \nwith L layer numbers, each Ai correct positioning in the layer. Ci wrong variation, Bi value in other layer instead of the same.\nPrecision with less than 20% recall is considered to be low: \nAdvantages: \n-relevant for large entities;\nDisadvantages: \n-less accurate\n-does not take consideration grammar;\n-uses very few distance measures;\nWorks better when space with lower space, where we use keywords repetition. Always normalize expression.",
    "Cosine similarity: \\( \\cos \\theta = \\frac{a \\cdot b}{|a||b|} \\) (We want the smallest angle)\n\nTf-idf (Importance of each word in 1 document): tf-idf = term frequency (tf occurrences in this document) * inverse document frequency (log # Documents / # Documents with this word)\n\nPrecision is the proportion of the documents retrieved by the system that are relevant (according to the referential)\nRecall is the proportion of the relevant documents which were retrieved by the system\n\nWeek 12\n\nTextual data analysis: Path between ML and NLP\n1) Classification (reordering in the original space)\n    Frameworks supervised (class can be known a priori) or unsupervised.\n    NB. What subjects (classes) have to share. Hierarchy; statistical, distance of each feature.\n    Classifiers: Statistical (Bayesian/Naive), linear, hierarchical / Non-statistical, Overlapping / (no overlapping)\n    \\[\n    \\text{Supervised/Naive Bayes}\n    \\]\n    \\[\n    P(C|x_1 \\ldots x_n) = \\frac{P(C) \\cdot \\prod_{i=1}^{n}P(x_i|C)}{P(x_1 \\ldots x_n)}\n    \\]\n    \\( P(C) \\) = apriori., \\( P(C|x_1 \\ldots x_n) \\) = posteriori\n    \\( x_i \\) = data value not classed (C class). We assume:\n    \\textbf{No sharing of data} (as in the product above: We have this \n    independency hypothesis)\n     \n    \\text{Unsupervised}\n    1) Create n data cluster (up to their existence). Number: # in K-means method. Compute the distances between points and clusters.. et redo until end. \n    \\text{K-means}\n    \\[\n    \\omega_k = \\arg \\min_{\\omega} \\sum_{i=1}^{k} | x_i - \\mu_k |^2\n    \\]\n    reinstall distances comparisons\n    \n    \\[\n    f = w_1 f_1 + w_2 f_2 \\quad : f = \\sum_{j}^{} x_{ij} w_ij\n    \\]\n    \\text{Ex: library }\n\n2) Visualization (projection in a low-dimension space)\n    PCA... non-negative...corresp. PCA, Correspondence analysis\n\nWeek 13 (Seminar)\n\nNeural networks (NN) are used to make likelihood, optimized using SGD.\n    Most famous relations:\n    Same writing-pronunciation, diff. meaning, same signification\n    Motivation: Only part of the words comes from the same distribution.\n    - Similarity-based word by analogy \n    \n    We can infer the relation between 2 words from across a certain distribution.\n\nWeek 14 (not in exam)\n\nHomonymy: Same writing-pronunciation, diff. meaning\nHomography: Same writing-different pronunciation, meaning\nHomophony: Diff. writing-same pronunciation, same meaning\nMeronymy: Hand is meronym of body\nHyponymy: Blue is hyponym of color",
    "Syntactic Parsing: Introduction, CYK Algorithm\n\nM. Rajman & J.-C. Chappelier\n\nLaboratoire d'Intelligence Artificielle\nFacult\u00e9 I&C",
    "Objectives of this lecture\n\n\u2691 Introduce syntactic level of NLP\n\u2691 Present its two components: formal grammars and parsing algorithms\n\nContents:\n\u2691 Introduction\n\u2691 Formal Grammars\n\u2691 Context-Free Grammars\n\u2691 CYK Algorithm",
    "Syntactic level\n\nAnalysis of the sentence structure\n\ni.e. \"grammatical\" analysis (in the linguistic sense)\n\nIn automatic natural language processing\n\n formal grammars and parsing theory\n\ntwo separated/complementary aspects:\n\nprocedural | declarative  \ngeneric algorithms | data  \nparsing algorithm | formal grammar",
    "Parsing\n\nParsing can be seen as:\n\n\u25b6 RECOGNIZING a sequence of words\n    \u25ba Is a given sentence correct or not?\n\nor as\n\n\u25b6 ANALYZING a sequence of words\n    \u25ba For a syntactically correct sentence, give the set of all its possible interpretations.\n      (Returns the empty set for incorrect sentences)",
    "Syntactic constraints\n\nLet's first play a game...\n\nConsider the following multi-set of 14 words:\n{cat, couch, he, lovely, nice, neighbor, of, on, sat, talked, the, the, the, with}\n\nFrom such a multi-set, one can derive $14! = 87'178'291'200$ (!) possible sequences...\n\n...most of which do not correspond to any reasonably acceptable sentence :\n\n\u25ba cat couch he lovely nice neighbor of on sat talked the the the with\n\u25ba he cat the nice lovely the neighbor sat of talked on with the couch\n\u25ba ...\n\nBut some do!\nFind some of these...",
    "Some possible sentences\n\nHere are some:\n\n\u25ba the lovely cat of the neighbor he talked with sat on the nice couch\n\u25ba the nice neighbor he sat with talked of the cat on the lovely couch\n\u25ba the neighbor he sat with talked lovely of the cat on the nice couch\n\u25ba the neighbor he sat on talked with the nice couch of the lovely cat",
    "What is acceptable and what is not?\n\nA sequence of words can be rejected for several different reasons:\n\n\u25ba the words are not in the \u201cright\u201d order:\n    * cat the on sat the couch nice\n    * the rules defining what are the acceptable word orders in a given language are called \u201cpositional constraints\u201d\n\n\u25ba related word pairs are not matching \u201cright\u201d:\n    * cats eats mice\n    * the rules defining what are the acceptable word pairs in a given language are called \u201cselectional constraints\u201d (e.g., \u201cagreement rules\u201d)",
    "What is acceptable and what is not? (2)\n\nIt is not enough for a sequence of words to satisfy all positional and selectional constraints to be acceptable, see Chomsky\u2019s famous example:\n*Colorless green ideas sleep furiously.*\nbut the reason is different: the sequence is rejected because it is meaningless; indeed, how can something colorless be green ? or a sleep to be furious ?\n\nAs this type of problem is related to meaning, it will not be considered here; we will consider any sequence satisfying all positional and selectional constraints as acceptable;\nto avoid potential confusion, we will refer to such sequences as *\u201csyntactically acceptable\u201d*.",
    "Where is the border?\n\n\u25ba Syntactic acceptability is not as clear cut as one may think!\n\u25ba The underlying hypothesis is that any syntactically acceptable sequence may possibly be given a meaning, even if this may require some context to guarantee that a large enough fraction of speakers indeed understand it as intended (which is crucial for any linguistic entity to be truly useful, but, maybe, in pure poetry)\n\u25ba For example: What do you understand if one talks about a \u201csmall giant\u201d?...",
    "Now, what do you understand, if \u201csmall giant\u201d is included in the following context:\n\"The sheer size of a company does not guarantee its survival; it must also remain agile to adapt to rapidly changing economic conditions. As soon as a large company begins to be hampered by heavy internal procedures, it gradually turns into a small giant, and represents an easy prey for its competitors.\"\n\nHowever, the situation may become fuzzier, if the required context gets harder to create:\n\"giving something to someone\" is clear,\n\"giving something for someone\" as well,\nbut how should we interpret \"giving something beyond someone\"?",
    "Positional constraints\n\nAs already mentioned, positional constraints govern the word order in a language:\n\nthe more such constraints, the more the language tends to be fixed order (e.g. French, German),\n\nthe less, the more it tends to be free order (e.g. Latin, Italian)\n\nFor example: in English \"girls like roses\" is acceptable,\n\nwhile \"girls roses like\" or \"like girls roses\" are not\n\n(and \"roses like girls\" is acceptable, but means something else);\n\nin Latin, virtually any combination of \"puellae rosas amant\" is acceptable and means the same (up to, possibly, a different emphasis)",
    "How to deal with selectional constraints?\n\nAs already mentioned, selectional constraints are taking into account constraints such as agreement rules that are further restricting the word sequences to be considered as (syntactically) acceptable.\n\nFor example, in English \"cats eat mice\" is acceptable, while \"cats eats mice\" is not, because the number agreement between \"cats\" (plural) and \"eats\" (singular) is violated.\n\nAgreement rules can be taken into account by preserving the required morpho-syntactic features in the PoS tags assigned to words (e.g. a number agreement will require to use PoS tags such as NOUN$_{s}$ (noun singular), NOUN$_{p}$ (noun plural), VERB$_{s}$ (verb singular), and VERB$_{p}$ (verb plural)).",
    "What formalism?\n\n\u25cf symbolic grammars / statistical grammars\n\n\u25cf symbolic grammars:\n    \u25a0 phrase-structure grammars (a.k.a constituency grammars, syntagmatic grammars) recursively decompose sentences into constituents, the atomic parts of which are words (\"terminals\").\n        Well suited for ordered languages, not adapted to free-order languages.\n        Better expresses structural dependencies.\n\n    \u25a0 dependency grammars focus on words and their relations (not necessarily in sequence): functional role of words (rather than categories, e.g. \"agent\"/\"actor\" rather than \"noun\").\n        More lexically oriented.\n        Dependency grammars provide simpler structures (with less nodes, 1 for each word, and less deep), but are less rich than phrase-structure grammars\n\n\ud83d\udd17 Modern approach: combine both",
    "Formal phrase-structure grammars\n\nA formal phrase-structure grammar $\\mathcal{G}$ is defined by:\n- A finite set $\\mathcal{C}$ of \"non-terminal\" symbols\n- A finite set $\\mathcal{L}$ of \"terminal\" symbols\n- The upper level symbol $S \\in \\mathcal{C}$\n- A finite set $\\mathcal{R}$ of rewriting rules\n\n$\\mathcal{R} \\subseteq \\mathcal{C}^{+} \\times (\\mathcal{C} \\cup \\mathcal{L})^{*}$\n\nIn the NLP field, the following concepts are also introduced:\n- lexical rules\n- pre-terminal symbols or Part of Speech tags",
    "What kind of grammar for NLP?\n\nReminder: Chomsky\u2019s Hierarchy: complexity is related to the shape of the rules\n\n\\[\n\\begin{array}{| l | l | l | l |}\n    \\hline\n    \\text{language class} & \\text{grammar type} & \\text{recognizer} & \\text{complexity} \\\\\n    \\hline\n    \\text{regular} & X \\rightarrow w \\, \\text{or} \\, X \\rightarrow w Y \\, (\\text{type 3}) & \\text{FSA} & O(n) \\\\\n    \\hline\n    \\text{context-free} & X \\rightarrow Y_1 \\ldots Y_n \\, (\\text{type 2}) & \\text{PDA} & O(n^3) \\\\\n    \\hline\n    \\text{context-dependent} & \\alpha \\rightarrow \\beta \\, (|\\alpha | \\leq |\\beta | \\, (\\text{type 1})) & \\text{Turing machine} & \\text{exp.} \\\\\n    \\hline\n    \\text{recursively enumerable} & \\alpha \\rightarrow \\beta \\, (\\text{type 0}) & & \\text{undecidable} \\\\\n    \\hline\n\\end{array}\n\\]\n\nembedding: \u201cthe bear the dog belonging to the hunter my wife was a friend of bites howls\u201d\n\ncrossing: \u201cDiamonds, emeralds, amethysts are respectively white, green and purple\u201d",
    "What kind of grammar for NLP? (2)\n\nreal-life NLP constraints => important limitations on complexity \n=> algorithms at most polynomial time complex\n\nWorst-case complexity of parsing grammar types:\n\n\\[\n\\begin{array}{lll}\n& \\text{expressive power} & \\text{real time} \\\\\n\\text{regular and LR(k)} & O(n) & 22 \\text{ ms} \\\\\n\\text{context-free} & O(n^3) & 11 \\text{ s} \\\\\n\\text{tree-adjoining grammars} & O(n^6) & 32 \\text{ h} \\\\\n\\text{more complex models} & \\exp. & 42 \\text{ days}\n\\end{array}\n\\]\n\n\u21d2 models actually used: context-free grammars (or midly context-sensitive grammars)\n\nNotice that in practice, higher level description formalisms might be used for developing the grammars,\nwhich are afterwards translated into CFG for practical use (\"CF backbone\").",
    "Context Free Grammars\n\nA Context Free Grammar (CFG) $\\mathcal{G}$ is (in the NLP framework) defined by:\n\n- a set $\\mathcal{C}$ of syntactic categories (called \"non-terminals\")\n- a set $\\mathcal{L}$ of words (called \"terminals\")\n- an element $S$ of $\\mathcal{C}$, called the top level category, corresponding to the category identifying complete sentences\n- a proper subset $\\mathcal{T}$ of $\\mathcal{C}$, which defines the morpho-syntactic categories or \"Part-of-Speech tags\"\n- a set $\\mathcal{R}$ of rewriting rules, called the syntactic rules, of the form:\n  \\[\n  X \\rightarrow X_1 X_2 ... X_n\n  \\]\n  where $X \\in \\mathcal{C} \\backslash \\mathcal{T}$ and $X_1 ... X_n \\in \\mathcal{C}$\n- a set $\\mathcal{L}$ of rewriting rules, called the lexical rules, of the form:\n  \\[\n  X \\rightarrow w\n  \\]\n  where $X \\in \\mathcal{T}$ and $w$ is a word of the language described by $\\mathcal{G}$.\n\n$\\mathcal{L}$ is indeed the lexicon",
    "A simplified example of a Context Free Grammar\n\nterminals: a, cat, ate, mouse, the\n\nPoS tags: N, V, Det\n\nnon-terminals: S, NP, VP, N, V, Det\n\nrules:\n\n$R_1$: S \u2192 NP VP\n\n$R_2$: VP \u2192 V\n\n$R_3$: VP \u2192 V NP\n\n$R_4$: NP \u2192 Det N\n\nlexicon: N \u2192 cat  Det \u2192 the",
    "Syntactically Correct\nA word sequence is syntactically correct (according to $\\mathcal{S}$) $\\iff$ it can be derived from the upper symbol S of $\\mathcal{S}$ in a finite number of rewriting steps corresponding to the application of rules in $\\mathcal{S}$.\nNotation: $S \\Rightarrow^* w_1 ... w_n$\nAny sequence of rules corresponding to a possible way of deriving a given sentence $W = w_1 ... w_n$ is called a derivation of $W$.\nThe set (not necessary finite) of syntactically correct sequences (according to $\\mathcal{S}$) is by definition the language recognized by $\\mathcal{S}$.\nA elementary rewriting step is noted: $\\alpha \\rightarrow \\beta$; several consecutive rewriting steps: $\\alpha \\Rightarrow^* \\beta$ with $\\alpha$ and $\\beta \\in (E \\cup \\mathcal{L})^*$\nExample: if as rules we have $X \\rightarrow a X, Y \\rightarrow b$ and $Z \\rightarrow c$, then for instance:\n$X Y Z \\Rightarrow a Y Z \\Rightarrow ab Z \\Rightarrow abc$",
    "Example\n\nThe sequence \"the cat ate a mouse\" is syntactically correct (according to the former example grammar)\n\n\\[\n\\begin{array}{l}\nR_1 \\quad S \\rightarrow NP\\ VP \\\\\nR_4 \\quad NP \\rightarrow Det\\ N\\ VP \\\\\nL_2 \\quad \\text{the N VP} \\\\\nL_1 \\quad \\text{the cat VP} \\\\\nR_3 \\quad VP \\rightarrow V\\ NP \\\\\nL_5 \\quad \\text{the cat V NP} \\\\\nR_4 \\quad NP \\rightarrow Det\\ N \\\\\nL_3 \\quad \\text{the cat ate N} \\\\\nL_4 \\quad \\text{the cat ate a mouse}\n\\end{array}\n\\]\n\nIts derivation is $\\{R_1, R_4, L_2, L_1, R_3, L_5, R_4, L_3, L_4\\}$",
    "Example (2)\n\nThe sequence \"ate a mouse the cat\" is syntactically wrong (according to the former example grammar)\n\n$R_1: S$\n$R_2: NP \\,VP$\n$R_4: Det \\,N \\,VP$\n$ \\cancel{ate / Det \\,N \\,VP}$\n\nExercise: Some colorless green ideas sleep furiously\n\nSyntactically correct \u2260 Semantically correct",
    "Each derivation of a sentence \\( W \\) can be represented graphically in the form of a tree in which each rewriting rule is represented as a sub-tree of depth 1: the root (resp. the leaves) corresponds (resp. correspond) to the left-hand side (resp. the right-hand side) of the rule.\n\n\\[\n  \\begin{array}{c}\n    \\vdots \\\\\n    X \\\\\n    / \\mid \\backslash \\\\\n    Y_1 \\quad \\dots \\quad Y_k \\\\\n    \\vdots\n  \\end{array}\n\\]\n\n\\((..., R_i, ...)\\) with \\( R_i : X \\rightarrow Y_1 \\dots Y_k \\)\n\nSuch a tree will be called a syntactic tree (or parse tree, or syntactic structure) associated to \\( W \\) by \\(\\mathcal{S}\\).",
    "Syntactic tree(s) associated with a sentence\n\nExample:\n\n         S\n       /   \\\n     NP   VP\n    / \\     / \\\nDet  N  V  NP\n  |    |    |    /  \\\n  the cat  ate Det N\n                      |    |\n                      a  mouse",
    "Mapping between trees and derivations\n\nA priori, several derivations can correspond to the same tree\n\nExample (\u201cthe cat ate a mouse\u201d): $R_1, R_4, L_2, L_1, R_3, L_5, R_4, L_3, L_4$ (where the NP is derived before the VP) and $R_1, R_3, L_5, R_4, L_3, L_4, R_4, L_2, L_1$ (where the VP is derived before the NP) correspond to the same tree\n\nHowever, if, by convention, derivations are restricted to left-most derivations (i.e. derivations where rewriting rules are exclusively applied to the left-most non-terminal), there is a one-to-one mapping between derivations and parse trees.\n\nWarning! This is not true in general for grammars more complex than context-free grammars.\n\nThis property is one of the important properties of the CF grammars and will be used for their probabilization.",
    "Syntactic ambiguity\n\nOne of the major characteristics of natural languages (in opposition to formal languages) is that they are inherently ambiguous at every level of analysis.\n\nFor example, at the syntactic level:\n\n- words are often associated with several parts-of-speech (for example \"time\" can be a verb or a noun).\nThis can lead to multiple syntactic interpretations corresponding to global structural ambiguities\nExample: time flies like an arrow\n\n- word attachments are often not completely constrained at syntactic level. This can lead to multiple syntactic interpretations corresponding to local structural ambiguities\nExample: She ate a fish with a fork",
    "Examples of syntactic ambiguities\n\nShe ate a fish with a fork/bone",
    "Syntactic ambiguity (2)\n\nAs the syntactic ambiguity of a given sentence $W$ will be expressed through the association to $W$ of several syntactic structures,\n\ngrammars used to describe natural languages need to be ambiguous.\n\nThis corresponds to a major difference with the grammars that are usually used for formal languages (e.g. programming languages) and have fundamental consequences on the algorithmic complexity of the parsers (i.e. syntactic analyzers) that are designed for Natural Language Processing.",
    "Syntactic parsing\n\nOne of the main advantages of the CFG formalism is that there exist several generic parsing algorithms that can recognize/analyze sentences in a computationally very efficient way (low polynomial worst case complexity).\n\nefficient == $O(n^3)$ worst case complexity\n\nThe two most famous of such algorithms are:\n\n- the CYK (Cocke-Younger-Kasami) algorithm (first proposed in the early 60\u2019s)\n- and the Earley parser (late 60\u2019s)\n\n\\[\n\\begin{array}{ccc}\n\\text{Input} & \\text{Output} & \\text{Resource} \\\\\n\\text{sentence} & \\{ \\text{trees (analyzer)} & \\text{CFG} \\\\\n& \\text{yes/no (recognizer)} \\} & \n\\end{array}\n\\]",
    "The CYK algorithm\n\nCYK is a bottom-up chart parsing algorithm characterized by 3 interesting features:\n\n- its worst case parsing complexity is $O(n^3)$ (where n is the number of words of the sentence to be analyzed);\n- a very simple algorithm that is easy to implement;\n- it can provide partial analysis of syntactically correct subsequences of syntactically incorrect sequences.\n\nHowever, its standard implementation suffers from two important drawbacks:\n\n- the CF grammar used by the parser has to be in a predefined format (the Chomsky normal form) and therefore the grammar usually needs to be first converted into this predefined format;\n- the complexity is always $O(n^3)$ even when the grammar is in fact regular.",
    "CYK algorithm: basic principles\n\nAs it is usual for chart parsing algorithms, the CYK algorithm will compute in an efficient way all the possible syntactic interpretations of all the sub-sequences of the sequence to be analyzed.\n\nSubsequences of the sentences are combined in a bottom-up fashion, using the rules present in the grammar.\n\n$$ X \\rightarrow Y Z $$\n\nHow to prevent the space of possible combinations of subsequences from exploding?\nRestrict the types of CFG\u2019s allowed.",
    "Chomsky Normal Form\n\nAny context-free grammar can be converted into an equivalent Chomsky Normal Form (CNF) grammar\n\nA CFG is in CNF if all its syntactic rules are of the form:\n\n\\[ X \\rightarrow X_1 X_2 \\]\n\nwhere \\( X \\in \\Sigma \\cup T \\) and \\( X_1 , X_2 \\in \\Sigma \\).\n\nA context free grammar is in extended Chomsky Normal Form (eCNF) if all its syntactic rules are of the form:\n\n\\[ X \\rightarrow X_1 \\quad \\text{or} \\quad X \\rightarrow X_1 X_2 \\]\n\nwhere \\( X \\in \\Sigma \\cup T \\) and \\( X_1 , X_2 \\in \\Sigma \\cup \\epsilon \\)",
    "R1: $S \\rightarrow NP \\ VP$\n\nR2: $NP \\rightarrow Det \\ N$\n\nR3: $NP \\rightarrow Det \\ N \\ PNP$\n\nR4: $PNP \\rightarrow Prep \\ NP$\n\nR5: $VP \\rightarrow V \\ NP$\n\nR6: $VP \\rightarrow V \\ NP \\ PNP$\n\nL5: $V \\rightarrow ate$\n\nincreases the number of non-terminals and the number of rules\n\nR1: $S \\rightarrow NP \\ VP$\n\nR2: $NP \\rightarrow Det \\ N$\n\nR3.1: $NP \\rightarrow X_1 \\ PNP$\n\nR3.2: $X_1 \\rightarrow Det \\ N$\n\nR4: $PNP \\rightarrow Prep \\ NP$\n\nR6: $VP \\rightarrow V \\ NP$\n\nR7.1: $VP \\rightarrow X_2 \\ PNP$\n\nR7.2: $X_2 \\rightarrow V \\ NP$\n\nL5.1: $V \\rightarrow ate$\n\nL5.2: $VP \\rightarrow ate$",
    "CYK algorithm: basic principles (2)\n\nThe algorithmically efficient organization of the computation is based on the following property:\n\nif the grammar is in CNF (or in eCNF) the computation of the syntactic interpretations of a sequence $W$ of length l only requires the exploration of all the decompositions of $W$ into exactly two sub-sequences, each of them corresponding to a cell in a chart. The number of pairs of sub-sequences to explore to compute the interpretations of $W$ is therefore $n - 1$. \n\nIdea: put all the analyses of sub-sequences in a chart",
    "CYK algorithm: basic principles (3)\n\nThe syntactic analysis of an n-word sequence $W = w_1 ... w_n$ is organized into a half-pyramidal table (or chart) of cells $C_{ij}$ ($1 \\leq i \\leq n$, $1 \\leq j \\leq n$), where the cell $C_{ij}$ contains all the possible syntactic interpretations of the sub-sequence $w_j ... w_{j+i-1}$ of i words starting with the j-th word in $W$.\n\n$ X \\in C_{ij} $\n\nThe computation of the syntactic interpretations proceeds row-wise upwards (i.e. with increasing values of i).",
    "S\n\nS\n\nS $\\quad VP_{X_2}$\n\nS\n\n$VP_{X_2}$ $\\quad PNP$\n\n$NP_{X_1}$ $NP$\n\n$NP_{X_1}$\n\nDet $\\quad N$ $\\quad V$ $_{\\quad Det \\quad N}$  $_{\\quad Prep \\quad Det \\quad N}$\n\ni/j 1 2 3 4 5 6 7 8\n\nthe cat ate a mouse in the garden",
    "Formal algorithm\n\n1) Initialisation: fill first row with corresponding Part-of-Speech\n\n2) Fill chart:\n\nfor all $2 \\leq i \\leq n$ (row) do  \nfor all $1 \\leq j \\leq n - i + 1$ (column) do  \nfor all $1 \\leq k \\leq i - 1$ (decomposition) do  \nfor all $X \\in \\text{chart}[1][j]$ do  \nfor all $Y \\in \\text{chart}[i - k][j + k]$ do  \nfor all $Z \\rightarrow X \\ Y \\in e$ do \nAdd $Z$ to $\\text{chart}[i][j]$",
    "Analyzer or recognizer?\n\n\u25ba The preceeding algorithm does not store the parse trees.\n   \ud83d\udd75 Recognizer (check wheter S is in top cell or not) or, for an analyser, need to reconstruct the parse trees.\n\n\u25ba For an analyzer, it's definitely better to store the parse trees in the chart while parsing:\n   Extend\n   Add Z to chart[i][j]\n   with\n   Add pointers to X and Y to the interpretations of Z in chart[i][j]",
    "As the computation of the syntactic interpretations of a cell $C_{ij}$ requires $(i-1)$ explorations of pairs of cells $(1 \\leq k \\leq i-1)$, the total number of explorations is therefore\n\\[\n\\sum_{i=2}^n \\sum_{j=n-i+1}^{n-1} (n-i+1) = \\sum_{i=2}^n (n-i+1) (i-1) \\in \\mathcal{O}(n^3)\n\\]\nA cell contains at most as many interpretations as the number $|\\mathcal{C}|$ of syntactic categories contained in the grammar, the worst case cost of an exploration of a pair of cells corresponds therefore to $|\\mathcal{C}|^2$ accesses to the grammar.",
    "Complexity (2)\n\nAs cost of the access to the rules in the grammar can be made constant if efficient access techniques (based on hash-tables for example) are used, the worst case computational complexity of the analysis of a sequence of length $n$ is:\n$O(n^3)$ and $O(|\\mathcal{G}|c^2)$\n\nWe can here see one drawback of the CNF: $c$ is increased.\n\nThere are modified versions of the CYK algorithm where CNF is no longer required (i.e $c$ is then smaller): bottom-up chart parsing\n\nNotice: Once the chart has been filled ($O(n^3)$ complex), one parse tree of the input sentence can be extracted in $O(n)$.",
    "Complexity (3)\n\nPITFALL!! It is easy to implement this algorithm in such a way that the complexity becomes $O(\\exp n)!$\n\nIf indeed the non-terminals produced in a cell are duplicated (instead of factorizing their interpretations), their number can become exponential!\n\nExample:\n\\[\n\\begin{aligned}\nS &\\rightarrow S\\:S\\quad & S&\\rightarrow a\n\\end{aligned}\n\\]\n\nEXPONENTIAL                                                                                       CUBIC",
    "Beyond CNF: bottom-up chart parsing\n\nIdea: get rid of (e)CNF constraint\n\nHow to?\n\non-line binarization, when needed, during bottom-up analysis\n\nMainly:\n\nfactorize (with respect to $\\alpha$) all the partial derivations $X \\rightarrow \\alpha \\cdot \\beta$ $\\alpha \\cdot$ \u2026 \nThis is possible because processing bottom-up.\n\n$\\alpha$ and $\\beta$ are (non-empty) sequences of non-terminals.",
    "Bottom-up Chart Parsing\n\nMore formally, a CYK algorithm in which:\n\n- cells contain two kind of objects:\n  $[\\alpha \\cdots, i, j]$ and $[X, i, j]$ respectively\n\n- initialization consists in adding $[X, i, i]$ for all $X \\rightarrow w_j \\in \\mathscr{R}$\n  ($w_j$ is a sequence of tokens of the input sentence; see \"Dealing with compounds\" later slide)\n\n- and the completion phase becomes:\n  (association of two cells)\n\n  \\[\n  [\\alpha \\cdots, i,j] \\oplus [X, j+1,k+1] = \n  \\begin{cases} \n  [\\alpha X \\cdots, i, k+1] & \\text{if} \\ Y \\rightarrow \\alpha X \\beta \\in \\mathscr{R} \\\\\n  [Y, i, k+1] & \\text{if} \\ Y \\rightarrow \\alpha X \\in \\mathscr{R}\n  \\end{cases}\n  \\]\n\n  \\[\n  (\"self-filling\")\n  \\]\n\n  \\[\n  [X, i, j] \\rightarrow \n  \\begin{cases} \n  [X \\cdots, i,j] & \\text{if} \\ X \\rightarrow X \\beta \\in \\mathscr{R} \\\\\n  [Y, i, j] & \\text{if} \\ Y \\rightarrow X \\in \\mathscr{R}\n  \\end{cases}\n  \\]",
    "Bottom-up Chart Parsing: illustration\n\nDet        N        V        Det       N\nThe      dog    hate      the      cat\n\nInitialization:\n\nDet        \u2022\u2022         v        \u2022\u2022       Det       N\nThe      dog     hate    the      cat\n\nCompletion:",
    "Bottom-up Chart Parsing: Example\n\nS\n\nS\n\nNP \u2022\u2022\n\nNP\n\nDet \u2022\u2022\n\nDet\n\nVP\n\nNP\nDet\n\nV \u2022\u2022\n\nV\n\nNP\n\nDet\n\nN\n\nThe crocodile ate the cat\n",
    "Dealing with compounds\n\nExample on how to deal with compounds during initialization phase:\n\ncredit       card\n\nN               \n\nN       V      N",
    "Keypoints\n\n\u279f Role of syntactic analysis is to recognize a sentence and to produce its structure\n\n\u279f Different types of formal grammars, relation between description power and time constraints\n\n\u279f CYK algorithm, its principles and complexity",
    "References\n\n[1] D. Jurafsky & J. H. Martin, *Speech and Language Processing*, chap. 12, 13, and 16, Prentice Hall, 2008 (2nd ed.).\n\n[2] C. D. Manning and H. Sch\u00fctze, *Foundations of Statistical Natural Language Processing*, chap. 3, MIT Press, 2000.\n\n[3] N. Indurkhya and F. J. Damerau editors, *Handbook of Natural Language Processing*, chap. 4, CRC Press, 2010 (2nd edition).",
    "Introduction to \u201cIntroduction to Natural Language Processing\u201d + Corpus-based NLP + Linguistic Processing Levels\n\nJ.-C. Chappelier\n\nLaboratoire d\u2019Intelligence Artificielle\nFacult\u00e9 I&C",
    "About the course (1/2)\n\nThis course is an introduction to the basics of NLP so as to provide a strong background everyone doing NLP should have in order to:\n\n\u25ba know and understand the core NLP concepts\n\u25ba have a reference baseline to compare to\n\u25ba have the minimal linguistic background so as to understand the problems/challenges\n\nThis course is NOT about Deep Learning (nor Transfert Learning)",
    "About the course (2/2)\n\nWebSite: coling.epfl.ch/\n\nGRADING:\n\u27a1 4 quiz during semester 25% (i.e. 6.25% each):\n45 minutes each.\nsee the website for the dates\n\n\u27a1 final exam: 75%\n3 hours.",
    "Objectives of this lecture\n\n- Introduce natural language and its functions\n- Show possible applications/realizations and associated constraints\n- Give general overview of natural language processing\n- Present the processing levels of an NLP system and their relations",
    "Contents\n\n- NLP Applications\n- Functions of Natural Language\n- Corpus-Based Approach to NLP\n- Linguistic Processing Levels\n- Example of an NLP architecture\n- Interdependencies between processing levels",
    "Natural Language Processing/Understanding\n\nNatural Language Processing is (and has long been) a great challenge in AI:\n \n\u25ba How can we construct a computationally exploitable representation (and which one?) from a observed text?\n\u25ba How can we generate (natural) text from computer representations?\n\nWe don\u2019t know yet how to properly model human language (nor thoughts).\n\nWe instead rely on learning from data and performance evaluation on specific tasks.\n\nModeling the task(s) can still lead to new insights how to model human language.",
    "Main Application Domains\n\n Automated Translation\n   Second World War, European Community, Canada, Switzerland, ... (Systran, Reverso, Google, ...)\n\n Writing Assistance\n   Spelling error correction (Cordial, Ispell, MS-Word, ...)\n   Text generation (Canadian weather forecast, Financial reports, ...)\n   Summarization tools\n\n Information Retrieval / Web Search / Information Extraction (Google, ...)\n   \n Information filtering and classification\n   emails, news, patents, ...\n\n Natural Language Interaction / Interfaces\n   Vocal Command\n   Vocal Access/Servers (phone-book inquiry, ...)",
    "Natural Language\n\nNatural vs. Formal:\n\u25ba formal languages are by construction explicit and non-ambiguous\n\u25ba natural languages are in essence implicit and ambiguous\n\nimplicit:\n\nRemove the stones from the cherries and put them in the pie.\nThe hunter shot the tiger; his wife too.\n\nambiguous:\n\nTime flies like an arrow.\nShe was eating a fish with\n      bones.\n      anger.\n      some friends.\n      a fork.",
    "Natural language functions\n\nCOMMUNICATION:\n\u2b9a Conciseness\n\nThe student gave his homework to the professor who told him that it could have been better.\n\nThe student gave the homework of the student to the professor. The professor told the student that the homework of the student could have been better.\n\n$Student.give(Student.homework, Professor);$\n\n$Professor.tell(Student, be\\_better(Student.homework));$\t\n\n\u2b9a Shared knowledge\n\n- I gave him a nice pen.\n- A \"Mont Blanc\"?\n- Yes, this brand is really great!\n- How large is it?\n- Well, big enough for 20 head of cattle.",
    "REPRESENTATION:\n\n\u2203 unlimited expressive power\n\nlogical expressions of any order:\nEarth is curved.\nAll politicians lie.\nEverything quickly done is not well done.\n\n\\( \\begin{align*}\n\\text{curved\\_earth} &= \\text{TRUE} \\\\\n\\forall x, \\, \\text{politician}(x) \\rightarrow \\text{lier}(x) \\\\\n\\text{quickly(do)} = \\infty \\\\\n\\forall x, \\, \\text{do}(x) \\rightarrow \\neg \\text{not good}(x) \\\\\n\\end{align*} \\)\n\nand even non sense!\n\nFollowing the antagonist bi-polar logic, it could be assumed that we enter a kind of \u201cT-state\u201d in which imaginary/rational-real updating and potentiation tend towards a dynamic stability...",
    "Natural language functions (3)\n\nWhy is natural language implicit and ambiguous?\nimplicit enables conciseness (ellipsis, anaphoric references, ...)\n... but entails potential ambiguities\n\nunlimited expressive power requires flexible interpretation rules\n... and therefore forbids the meaning to be exclusively expressed by the surface form.\n\nHow is it possible that we still understand each other?\n\ud83d\udc49 very large amount of shared knowledge\n\n(previous) Examples:\n\u25ba we usually eat cherries and not their stones\n\u25ba we assume that hunters are not all criminals\n\u25ba we know that a writing pen is never big enough for 20 head of cattle\n\n\u00a9 EPFL\n\nIntroduction to NLP -- 11/45",
    "NLP and Industrial Applications\n\nFor real-world NLP applications:\n\nTask specification is essential: even a small modification of the targeted task may turn a NLP application from feasible to impossible to achieve\n\nExample: computer assisted translation vs. automatic translation of free text (e.g. Web)\n\neffective usefulness: NLP is not always the best solution and sometimes other means/medias should be preferred\n\nThink about how to evaluate the \"usefulness / drawbacks\" ratio as well as the implementation difficulties when planning to introduce NLP into some application.",
    "Constraints due to the applicative context\n\nThe two main application contexts correspond to the two main functions of language:\n\n1. language = communication tool\n   - e.g. applications for interfaces\n   Constraint: Real Time\n   $$\\approx 180 \\text{ word/mn} \\rightarrow 1 \\text{ word every 300 ms}$$\n\n2. language = knowledge representation formalism\n   - e.g. applications for Information Retrieval \n   Constraint: huge amounts of data (to compensate the still relatively poor performance)\n   $$10'000 \\text{ documents within 1 day} \\approx 300 \\text{ word/s} \\rightarrow 1 \\text{ word every 3 ms}$$",
    "Constraints due to the applicative context (2)\n\nThe constraints imposed by real-world NLP applications entail the need for:\n1. fast processing $\\Rightarrow$ polynomial algorithms\n2. a good coverage of the (sub-)language corresponding to the considered application\n$\\Rightarrow$ sufficient linguistic resources",
    "Choice of Language Models\n\nThe use of polynomial-time algorithms impose severe limitations on the complexity of the linguistic models to be considered.\n\nExamples of how algorithmic complexity is related to the expressive power of grammatical models:\n\n\\[\n\\begin{aligned}\n&\\text{regular and LR(k) grammars : } O(n) &\\text{22 ms} \\\\\n&\\text{context-free grammars : } O(n^3) &\\text{11 s} \\\\\n&\\text{tree adjoining grammars : } O(n^6) &\\text{32 h} \\\\\n&\\text{more complex models : exp.} &\\text{42 days} \\\\\n\\end{aligned}\n\\]\n\nWhen neural networks are used, the complexity lies in the architecture used. The relation between the expressive power and the computational complexity of the architecture is (nowadays) out of scope/interest.",
    "Why is NLP difficult?\n\n\u279e lack of linguistic competence\n\n\u279e power laws (at all levels)\n\n\u279e curse of dimensionality (high dimension + sparseness)\n\n\u279e subjectivity (Inter-Annotator (dis)Agreement)\n\n\u279e multi-scale",
    "Need for representative ressources\n\nLinguistics skills are quite difficult to find in the industry\nand\nlinguistic resources are often difficult (= costly) to produce\n\u21d2 Resources may be at least as costly as the design of the core system itself\nand this is even more the case for resources at the semantic level\n\nNote that the most advanced neural architectures could be considered as a way to computationally exploit very complex probability distributions.",
    "Corpus-based linguistics\n\nThe goal is thus not so much to reproduce the human linguistic competence with approaches that try to model our understanding of language, but...\n\n...to reproduce, for a given task (applicative framework), the corresponding linguistic behaviour with models that can be (semi-)automatically trained from large amounts of textual data representative for the considered task.",
    "The evaluation of the considered models does not aim at measuring their explanatory power (about human language) but the improvement of their performance for the considered application\nCorpus-based, Performance-oriented computational linguistics",
    "Corpus-based linguistics: the evolution\n\n\u25b6 before (< 1980): hand written rules\n\n\u25b6 first wave (\u2243 1980-2015): probabilistic models (HMM, SCFG, CRF, ...)\n\n\u25b6 neural-nets and word-embeddings (2011\u2013):\nword2vec (2013), GloVe (2014)\n(shallow, then later deep) neural nets to represent word by learning to predict their context\n\n\u25b6 transfer learning (2018\u2013):\nULMFIT (2018), ELMo (2018), BERT (2018), OpenAI GPT2 (2019)\nuse pre-trained word embeddings to initialize the first layers of a neural network, followed by a task-specific architecture that is trained in a supervised way",
    "So, is this course a Machine Learning Course?\n\nMachine Learning: is sometimes described as:\n\nmessy raw data --> best ML of the world --> magnificent output",
    "So, is this course a Machine Learning Course?\n\nMachine Learning: good preprocessing is (still) (very) important\n\nmessy raw data\n\n(preprocessing)\n\npreprocessed data                           some available ML                           decent output",
    "So, is this course a Machine Learning Course?\nMachine Learning: need for (good) supervision\n\nmessy (preprocessing) annotated raw data (and preprocessed) \n              \u2193                   data\npreprocessed  \u2192   some available ML  \u2192   decent data \n(preprocessing)                   (learning)           output\n\nIntroduction to NLP \u2014 21 / 45",
    "So, is this course a Machine Learning Course?\nMachine Learning: need to understand (origins of) outputs, analyze errors, ...\n\nmessy raw data $\\rightarrow$ preprocessing $\\rightarrow$ preprocessed data $\\rightarrow$ some available ML $\\rightarrow$ decent output \npreprocessed data $\\rightarrow$ some other ML $\\rightarrow$ decent output\n\nannotated (and preprocessed) data $\\rightarrow$ (learning) $\\rightarrow$ some available ML $\\rightarrow$ decent output $\\rightarrow$ results/ analysis/ decision",
    "So, is this course a Machine Learning Course?\n\n- NLP makes use of Machine Learning (as would Image Processing for instance)\n- but good results require:\n  - good preprocessing\n  - good data (to learn from), relevant annotations\n  - good understanding of the pros/cons, features, outputs, results, ...\n\nThe goal of this course is to provide you with the core concepts and baseline techniques to achieve the above mentioned requirements.",
    "Why is NLP difficult?\n\n- lack of linguistic competence\n- power laws (at all levels)\n- curse of dimensionality (high dimension + sparseness)\n- subjectivity (Inter-Annotator (dis)Agreement)\n- multi-scale",
    "The impact of power laws (e.g. Zipf Law, \"Zeta distribution\")\n\nExample (Brown Corpus):\nmost frequent word (\"the\"): $\\approx 7\\%$ of all word occurrences (69971 over 1 million)\n\nsecond most frequent (\"of\"): 3.5%\n\nOnly 135 different words make 50% of the corpus (occurrences)\n\nConversely 50% of the vocabulary (not the same \\%) are hapaxes (1 occurrence only) (that cover 2.5% of the corpus)",
    "The impact of power laws (e.g. Zipf Law, \"Zeta distribution\")\n\nproperly treat most of the corpus is thus easy for computers\n\n=> everybody can rapidly and easily get a \"not too bad\" system\n\n=> The illusion of NLP success",
    "The impact of power laws\n(e.g. Zipf Law, \u201cZeta distribution\u201d)\nbut getting a 0.1% improvement\nw.r.t. actual state of the art is re-\nally not that easy! \n\n$\\epsilon$: need to model the \u201cspecial cases\u201d (rare occurrences)\n\n$\\epsilon$: a good system needs BOTH! (efficient engineering/machine learning, and good NL coverage)",
    "Need good and representative (NL) data\n\n\u201cThere is no data like more data\" [Mercer 85]\n\n\u201cMore data is more important than better algorithms\u201d [E. Brill]\n\n\u201cWe see that even out to a billion words the learners continue to benefit from additional training data.\u201d [Banko & Brill 01]\n\nMajor issue: produce large good and representative NL resources\n\ud83d\udc49 put relevant linguistic knowledge into the learning data\n\ud83d\udc49 In a NLP system, resources production/acquisition may be at least as costly as the design of the core system itself",
    "Why is NLP difficult?\n\n  - lack of linguistic competence\n\n  - power laws (at all levels)\n\n  - curse of dimensionality (high dimension + sparseness)\n\n  - subjectivity (Inter-Annotator (dis)Agreement)\n\n  - multi-scale: many levels, ambiguity",
    "Linguistic Processing Levels\n\nFor any complete linguistic analysis, an NLP system must be able to:\n\n- recognize \"words\" (morpho-lexical level)\n  M. O'Connel payed $ \\textdollar 12,000, \\text{(V.T.A. not included)} \\text{with his credit card.}\n  \n- structure the word sequences (syntactic level)\n  Time flies like an arrow.\n\n- understand the meaning of word sequences (semantic level)\n  She ate fish with her friends / its bones.\n\n- contextualize the literal meaning (pragmatic level)\n  He asked the custom officers about the taxes and payed them.",
    "Lexical Level\n\nWhy such a level?\nTo recognize: What is a word/token?\n\nNon-alphabetical Languages (Chinese), Languages without separators (Thai)\nAmbiguous separators\ncredit card, due to\nU.N.O., 34,2 degrees\n\nout-of-vocabulary forms: dorr, thatcherism, .bat files, Sun\n\nDomain of morphology (study of the structure of the words) and of lexicography (inventory and classification of accepted forms in a language)\nparadigmatic dimension of the language (vs. syntagmatic)\n\nassociated linguistic resources: electronic lexica",
    "Syntax: study of the constraints to be verified for a word sequence to be considered as (syntactically) \"correct\" in a given language (sentence).\n\nThese constraints can be either selectional (agreements) or positional.\n\nAssociated linguistic resources: (formal) grammars.",
    "What is Syntax useful for?\n\n1. to solve (or reduce) some ambiguities in the lower levels:\n   phonetic level: $[i][l][u][k] \\to$ I look \n            $\\to$ eye look \n            $\\to$ Hi! Luke \n            $\\to$ ...\n   \n   lexical level: he  went away\n            he went \n            wind\n            end\n\n2. to help the extraction/description/use of semantic/pragmatic facts\n   Example: selectional constraints associated with the verb \u201cto eat\u201d\n    * animated subject\n    * edible object",
    "Semantic and pragmatic levels\n\nSemantic: meaning out of any context (i.e. literal meaning)\n\nnotions of meaning space and of knowledge representation\n    - numerical repr.\n    - distance\n    - formal repr.\n    - symbolic operators\n\nPragmatic: meaning within the elocution context\n\nUse of knowledge representation formalisms for formal knowledge/common sense models",
    "Example of a simplified NLP architecture\n\nLEXICON\n\nSYNTACTIC PARSER\n\nTEXT\n\nGRAMMAR\n\nSEMANTIC ANALYZER\n\nSEMANTIC DICTIONARY\n\nTreatment\n\nResource/data",
    "Treatment .vs. Resources\n\nEach NLP processing step requires Treatments (algorithms) and Resources (data)\n\nTreatments are mostly language independant\n\nResources are highly language (and even application) dependant\n\nGood Quality Linguistic Resources are difficult/costly to obtain/handle \u21e8 at least as costly as the treatments themselves\n\nExample of resources:\nat the morpho-lexical level: morphological rules (grammar of the word) and electronic lexica\nat the syntactic level: formal grammars of the language (or syntactically annotated corpora)\nat the semantic and pragmatic levels : formal models of knowledge (logical propositions, semantic networks, conceptual graphs, ...)",
    "Example of a (French) lexicon excerpt\n\navocat           Ncms    avocat           a v o k a\navocate          Ncf     avocat           a v o k a t\navocats          Ncmp    avocat           a v o k a\navoir            Vinf    avoir            a v w a R\navoir            Ncns    avoir            a v w a R\navoirs           Ncmp    avoir            a v w a R\navoisina         Vcip3s  avoisiner        a v w a z i n a\navoisinai        V1s     avoisiner        a v w a z i n E\navoisinait       Vii3s   avoisiner        a v w a z i n E\navoisinant       Vpr     avoisiner        a v w a z i n a\navoisine         V1s     avoisiner        a v w a z i n\navoisine         Vi3s    avoisiner        a v w a z i n\navoisiner        Vinf    avoisiner        a v w a z i n e\navoisinera       Vif3s   avoisiner        a v w a z i n R\navoisinerai      Vifg1s  avoisiner        a v w a z i n R E\navoisinerait     Vci3s   avoisiner        a v w a z i n R E\navoisineras      Vif2s   avoisiner        a v w a z i n R a\navoisinez        V2p     avoisiner        a v w a z i n e\navoisiniez       Vci2p   avoisiner        a v w a z i n j e\navoisinons       V1p     avoisiner        a v w a z i n O\navoisin\u00e2mes      Vas1p   avoisiner        a v w a z i n a m\navoisin\u00e2t        Vas3s   avoisiner        a v w a z i n a\navoisin\u00e9e        Vpp     avoisiner        a v w a z i n e\navoisin\u00e9es       Vpp     avoisiner        a v w a z i n e\navoisinant       Vppa    avoisiner        a v w a z i n a\navoisin\u00e2mes      Vlias1  avoisiner        a v w a z i n a m\navoisin\u00e2t        Vlias3  avoisiner        a v w a z i n a\navoisine         Vli2s   avoisiner        a v w a z i n\navaisina\u00eemes     Vai3s   avoisiner        a v w a z i n a m\navaisina\u00eet       Va3s    avoisiner        a v w a z i n a\n\nTranslation to English:\nLawyer \nFemale lawyer \nLawyers\nTo have \nTo have \nAssets \nTo approximate\nI approximate\nWas approximating\nApproximate\nI approximate\nApproximate\nTo approximate\nWill approximate \nWill approximate \nWould approximate\nYou will approximate \nYou approximate\nYou will approximate \nWe approximate\nWe have approximated\nHe/She/It was approximated\nWas approximated \nWas approximated \nApproximating\nWe have approximated\nWas approximated \nApproximates\nApproximate\nWe have approximated\nShe/He/It approximates",
    "Example of a grammar excerpt\n\nP -> GN GV {\n    < GN.nombre, GV.nombre,\n      *nombre,\n      < P.mode, GV.mode, >\n}\n\nGN -> Det N {\n    < Det.genre, N+.genre,\n      Det.nombre, N+.nombre,\n      < GN.genre, N+.genre,\n      GN.nombre, N+.nombre, >\n}\n\nN+ -> ADJ N+ { * }\nN+ -> N ADJ { * } \n\nGV -> GV GN {\n    < GV.nombre, GV.nombre,\n      GV.temps, GV.temps,\n      GV.mode, GV.mode,\n      GV.temps, GV.temps,\n      GV.mode, GV.mode, >\n}\n\nGV -> V {\n    < V.nombre, V.nombre,\n      V.temps, V.temps,\n      V.mode, V.mode, >\n}\n\nGV -> NEGpr\u00e9 V NEGpost {\n    < V.nombre, V.nombre,\n      V.temps, V.temps,\n      V.mode, V.mode,\n      GV.nombre, neg ! >\n}",
    "Examples of syntactic representations\n\nS\n\nNP            VP\n\nDet  Nom  VP          PP\n\n     Adj  Nom  TV  NP   Prep NP\n                 NN      Det Nom\n                             Adj  Nom\n                                 NN\nthe   merry  girl drew a   smiling bear with a   red   ball",
    "Example of semantic information (dictionary)\n\nboard (noun)\n\n1 : the side of a ship\n\n2 a : a piece of sawed lumber of little thickness and a length greatly exceeding its width \n   b plural : STAGE\n\n3 archaic : TABLE \n   a : a table spread with a meal \n   c : daily meals especially when furnished for pay \n   d : a table at which a council or magistrates sit \n   e (1) : a group of persons having managerial, supervisory, investigatory, or advisory powers \n     <board of directors> <board of examiners>\n\n...\n\n5 a : a flat usually rectangular piece of material (as wood) designed for a special purpose: as SPRINGBOARD, SURFBOARD\n\n...",
    "Example of semantic representation\n\nHe nailed down the board.",
    "Interdependencies between processing levels\n\nInterdependencies between the lexical level and the other levels:\n\nExample of spelling error correction:\n\nthe tost of the coin\n\ntost \u2192 lost  : syntax\n  toast : semantics\n  cost : pragmatics\n  toss : pragmatics",
    "syntactic-semantics\n\nShe ate a fish with a fork\nShe ate a fish with a fork\n\nsemantic knowledge...",
    "syntactic-pragmatics dependency\n\n...but with: *Time flies like an arrow.*\n\npragmatic knowledge",
    "Keypoints\n\n- NLP very demanded in numerous applications\n- Caracteristics (conciseness and ambiguity) and functions (communication and representation) of natural language\n- Trade-off between expressive power and processing time\n- Linguistic resources are very important\n- Corpus-based linguistics doesn\u2019t try to explain the natural language, but to improve the performances of the applications\n- Main stages of linguistic analysis and architecture of an NLP system\n- Components of an NLP system (word recognition and structuring, phrase understanding and contextualization) and their implementation\n- Interdependence between NLP components (recognition conditioned by structuring, structuring guided by the meaning and the context)",
    "References\n\n[1] D. Jurafsky & J. H. Martin, *Speech and Language Processing*, Prentice Hall, 2008 (2nd edition).\n\n[2] C. D. Manning & H. Sch\u00fctze, *Foundations of Statistical Natural Language Processing*, MIT Press, 1999 (6th printing 2003).\n\n[3] N. Indurkhya & F. J. Damerau *Handbook of Natural Language Processing*, CRC Press, 2010 (2nd edition).\n\n[4] M. Rajman editor, *\"Speech and Language Engineering\"*, EPFL Press, 2006.",
    "Introduction to Natural Language Processing\n(Home) Exercises with solutions\n\nContents\n1 NLP levels 2\n2 Tokenization/Lexicons/n-grams 3\n3 Morphology 6\n4 Out-of-Vocabulary forms 9\n5 Part-of-Speech tagging 10\n6 Parsing I 17\n7 Parsing 2 21\n8 Lexical Semantics 24\n9 Text Classification 26\n10 Information Retrieval 33\n11 Evaluation 42",
    "1 NLP levels\n\nExercise I\n\nA company active in automatic recognition of hand-written documents needs to improve the quality of their recognizer. This recognizer produces text sequences of correct English words, but some of the produced sequences do not make any sense. For instance the processing of a given hand-written input can produce a set of transcriptions like: \"A mor sauton abut ther ofles\", \"It was a nice story afterwards\", and \"I Thomas at nice not the space\".\n\nWhat is wrong with such sentences? NLP techniques of which level might allow the system to select the correct ones? What would be the required resources?\n\nSolution\n\nThose sentences are not \"grammatically\" (syntactically) correct. It should be filtered out at the syntactic level using a (phrase-structure) grammar.",
    "2 Tokenization/Lexicons/n-grams\n\nExercise II\n\nAccording to your knowledge of English, split the following sentence into words and punctuation:\n\nM. O'Connel paid $12,000 (V.A.T. not included) with his credit card.\n\nWhich of these words won't usually be in a standard lexicon? Justify your answer.\n\nAssuming separators are: whitespace, quote (\u2018), full-stop/period (.), parentheses,\nand that separators split tokens, tokenize the former sentence.\n\nHow would you propose to go from tokens to words? (propose coherent implementations)\n\n\nSolution\n\nwords and punctuation: M|O\u2019Connel|paid|$|12,000|(V.A.T.|not|included)|with|his|credit|card|.\n\nUsually not a problem: \u2018words\u2019 that lead to lexicalize (too many hard-to-predict occurrences): O\u2019Connel,\n$12000.\n\n\u2018O\u2019Connel\u2019 could be in some lexicon of proper names (but not so usual), or recognised by some\nNER (Named-Entity Recognition).\n\n\u2018$12,000\u2019 would need some specific schema (e.g. for regular expressions: e.g. a FSA), but this is also\noften done as a post-process in some other NER.\n\n\ntokens: M | O\u2019Connel | paid | $ | 12, 000 | ( | V.A.T. | not | included | ) | with | his | credit | card | .\n\nNormed words: \n\n\u2022 aggregation: several (consecutive) tokens where the resulting word is in an unknown \naggregated token (several tokenization)\n\n\u2022 use of a learning algorithm: learn also possible solutions, for instance in the compact form of\na lexicon, to keep only \u2018real\u2019 words.",
    "Exercise III\n\nConsider the following toy corpus:\n\nthe cat cut the hat\n\n\u2022 How many different bigrams of characters (including whitespace) do you have in that corpus?\n\u2022 How many occurrences do you have in total? (i.e. including repetitions)\n\u2022 Considering only lowercase alphabetical and white space bigrams: how many bigrams are possible?\n\u2022 What are the parameters of a bigram model using the same set of characters (lowercase alphabetical and whitespace)?\nNote: using both overlapping sequences, if the parameters are estimated using MLE (maximum likelihood estimation) on the above corpus (make use of a calculator or even a computer if necessary).\n\n*the -> cat*\n\nFully justify your answer.\n\n\u2022 What is the probability of the same sequences, if the parameters are estimated using Dirichlet prior for having all its components equal to 0.1?\nFully justify your answer.\n\nSolution\n\nThere are 12 different bigrams (denoting here the whitespace with `X\u00b4 to better see it): Xc, Xh, Xt, at, ca, cu, ha, he, he, th.\n\nThere are 18 occurrences in total (i.e. the 12 bigrams in total 18). Here the counts with Xs:  Xc : 1, Xh : 2, Xt : 1, at : 2, ca : 1, cu : 1, ha : 1, he : 2, tX : 2, th : 2, tX : 2, tX: 2.\n\nThere are (27)^2 possible bigrams.\n\n*P_Xc = 1/18, P_Xh = 2/18, P_Xt = 1/18, P_at = 2/18, ...*\n\nParameters are the 729 probabilites of the 729 bigrams (X to X) = 27 * 27. Th: 49 zero, 9 appearance of X.",
    "* Using M.L.E., the probability of the observed bigrams are proportional to their number of occurrences: $\\text{1/1B: 2/1B, } \\text{1/1R: 1/1R, } \\text{1/1B: 1/1B {}, 1R: 2/1R, } \\text{1/1B: 1/1R, } \\text{1/1R: 0/B: 1/1B, } \\text{1/1B: 1/1R, } \\text{1/1B: 0/B: 1/1B}$ and all the other are $0$.\n\n* The objectivity of any sequence containing an unseen bigram is $0$ (as a product of terms, at least one of which is $0$, which is the case for both sequences (bigram$^{/ 0/new iseem$)\n\n* With a Dirichlet prior with parameter \u03b1 = 0.5, how each observed bigram gets :\n\n0.05 so: to count add the denominator so: $1+(0\u00d75) = 2.0 \\text{0.5 \u00d7 6.5} = 2.5$, leading to the normalised probapi $= 0.55$. Assumes and $1.05 = 1.0$( $\\text{1/1B : 2/2},{}^{0}_{3.5}{}^{(1.0 -{}^{1R})}$ observed bigrams and $0.05/1\\$2.5$ ...\n\n* All the unseen bigrams have a probability of $0.05/{50.5/2i}$ and 6/10.05).\n\nIf $\\text{}$ Below, we compare the sequences that have highest and thus the bigrams seen in the learning:\n\n\\[ P(\\text{winheat}) = \\frac{P(\\text{hi} / \\text{he})}{P(\\text{})} \\times \\frac{P(\\text{w} / \\text{hi})}{P(\\text{})} \\times \\frac{P(\\text{i} / \\text{we})}{P(\\text{})} \\]\n\n\\[ \\frac{P(\\text{e} / \\text{v})}{P(\\text{})} \\times\n\\frac{P(\\text{i} / \\text{hi})}{P(\\text{})} \\]\n\n* and\n\n\\[ =\\sum_{\\text{Pl}(\\tilde{P}(X)} \\times ...\nP(\\text{w}){ \\tilde{X})}} =|-f)| = | \\leq P{|}(\\text{hi}){\\tilde{}i}){\\tilde{P}(v)}, \\frac{\\frac{\\frac{P(\\tilde{}}) X) N^{-2}){|\\{\\frac{\\frac{P(X)(1)<P (X WITH H CURRENTTOOLS)}}{\\frac{P(\\mathbf{a)}{02)b)}{l}(0,166)c k/\\frac{}[\\frac{P(\\mathbf{} X) / P Y{}0/ X FOUR)/1/ P (\\mathbf() X0)0)}{\\wideck{})\n\nsimilarly for \n\n\\[ P(\\text{{}}{d}}}\n\nP\\mathbf{}' /\\mathbf{} /(0))\\mathbf{P(xi'}$ 1:1.35(}}))\n\n\\[ =\\frac{3\\times(0 \u00d7 leed{} \\frac{1.0({{'P(\\tilde{}} X)=3})) / \u2208{|})|\\mathbf{}}7 -{/l)\n\nRegarding the other sequen :\n\n\\[ P(\\text{k \\text{c(khar}} \\sum_{0))} 1.\\frac{}{}^()=3{}} / \\mathbf{} + / =\\frac{}2$ 3\u00d7\u00d7\\mathbf{}{\\mathbf{}\uff10.}\\mathbf{1}{}}/P\\tilde{i])\n\nNotice above that the $/$ two sequences do not have the same length, i.e. their probabilities shall belong as well to the sum as normalising of the long length, as can observe) hspswe$\\log{\\frac{1.5}{{}}$ normalising the inequality). The probability of \nthe same remain solution (for the probability of length 1.06) on the shorter/member of the (the molecule will be mole pte than the shorter0).",
    "3 Morphology\n\nExercise IV\n\ni) Briefly describe the specific objectives of the morphological module in the general perspective of automated Natural Language Processing.\nSolution: The purpose of morphology is to study of the internal structure and the formation of the words in a language; like verbal conjugations, plurals, nominalization.\n\nii) What three different types of morphologies that can be considered? Briefly describe the main objectives of each.\nSolution: inflectional morphology: to change in the grammatical category (e.g. give, given, gave, etc).\nderivational morphology: change in category (e.g. process, procession, processor, etc)\nagglutinative morphology\n\niii) For what types of languages is concatenative morphology well suited? Are there other types of mor- phologies? How? For what languages?\nSolution: those where either prefixes and suffixes are used.\nMore complex languages use inflectional ones (e.g. Tagalog, Hebrew) or circumfixes (e.g. Ger- man). Pattern-based morphology should thus be used then.\n\nExercise V\n\ni) Explain the difference between inflectional and derivational morphology.\nIllustrate your explanation with examples of sentences in English or French.\nSolution: \ninflectional morphology: change in grammatical category (e.g. give, given, gave),\nderivational morphology: changes in meaning and grammatical category (e.g. process, \nprocession, processor, etc).\n\nii) Provide a precise definition of concatenative morphology and illustrate your answer with one or two examples in English or French.\nSolution: Concatenative morpohology uses prefixes and suffixes directly on words to convey changes (e.g. prefix: insignificant; suffixes: watches, singing).\n\niii) For what types of languages is it well suited?\nAre there other types of morphologies? For what languages?\nSolution: concatenative morphology can be used in easier ones, more complex languages use inflectional ones like Tagalog, Hebrew and circumfixes e.g. German. Pattern-based morphology should thus be used.",
    "the complexity of the morphology can vary a lot between languages: as easy as in Spanish, as hard as in Turkish, or Hebrew, Tagalog,...\n\nGive some concrete examples of NLP applications that can benefit from some form of morphological processing. Justify your answer.\n\nIn the specific case of Information Retrieval (IR), explain what can be done if a full fledged morphological processor is not available. What consequences do you expect this to have on information retrieval?\n\nSome areas where the morphology helps most: sense of the word in the sentence (to ease disambiguation), simplify it (e.g. Information Retrieval, Text Classification,...).\n\nFor IR, a pseudo-morphological lemmatiser help there is available. Overall performance improvement is very significant (efficiency). Time required to process the words depends on the relative quality of the method chosen: light intuitive processing might be chosen first.\n\nSuppose a formal definition of a transducer. Give some good reasons to use such a tool for linguistic processing. (e.g. FST)\n\nSolution: \n\nIt provides a (Deterministic) Finite-State Automaton on character pairs (cross-product of alphabet).\n\nIt also provides a finite-state implementation for mapping two languages (cross-product of words), which is the purpose of Morphos.\n\n```\nhe          he+V+Pres3S             produces produce+V+Pres3S\nclaims      claim+V+Pres3S           has      have+V+Pres3S\nblames      blame+V+Pres3S           tries    try+V+Pres3S\nproduces    produce+V+Pres3S         achieves achieve+V+Pres3S\nhas         have+V+Pres3S            fails    fail+V+Pres3S\ntries       try+V+Pres3S             does     do+V+Pres3S\nachieves    achieve+V+Pres3S         succeeds succeed+V+Pres3S\nfails       fail+V+Pres3S            controls control+V+Pres3S\ndoes        do+V+Pres3S              achieves achieve+V+Pres3S\nsucceeds    succeed+V+Pres3S         fails    fail+V+Pres3S\ncontrols    control+V+Pres3S         tries    try+V+Pres3S\nachieves    achieve+V+Pres3S         tries    try+V+Pres3S\ncontrol     control+V+Pres           achieves achieve+V+Pres3S\nclaimed     claim+V+Past             achieved achieve+V+Past\nblame       blame+V+Pres             fails    fail+V+Pres3S\nproduces    produce+V+Pres3S         controls control+V+Pres3S\nachieves    achieve+V+Pres3S         attained attain+V+PastPart\n```\n(a) In the pairs (blames+, blame+V+Pres3S), what does the ``3S\" mean? (resp. ``succeed+V+Pres3S\" correspond to? What is each of the two forms useful for?\nSolution: \"3S\" means third person present singular. This is the form used when the subject of the verb is he/she/it and the verb is in the present form.\n\nRepresent the purpose of such a morphological transducer as:\n\na simple automaton implementing the concatenation of three transducers:\n\n1. a transducer for lexical look-up.\n",
    "2. a transducer for the regular inflections;\n3. a transducer for exception handling.\n\nProvide the regular expressions defining each of the transducers and indicate how the transducers should be combined.\n\nSolution: make a picture of them or use regular expressions, for instance:\n\n$T = T_{inf} \\circ T_3$\nwhere:\n* $T_{lex}$ : \n  - simply the FSA coding the lexicon (a FSA is a FST) as the list of canonical forms:\n* $T_{inf}$ :\n  - $\\Sigma_{inf} = \\{ \\epsilon | s | \\epsilon \\}\\ 0 \\ |\\{ edv \\} s \\ |\\{ en \\} 0 \\ |\\{ en \\} 1 \\ |\\{ ieds \\} \\frac{{X1}}{{X}}s \\ |\\{ ieds \\} \\ _ s | \\{ ieds \\} \\frac{{X1}}{{X}} 0 s \\ |\\{ ied \\} s \\ |\\{ ed \\} 0 |$\n* $T_3 = T_{lex}$ :\n  - the lexicon of the exceptions: irregular verbs, difficult to write with regexps (unless tricky look-behind regular operators; but easy to draw, like: \"break-X3ed homgrblubreaken; know-Knew-X0wn | knows | knowperldoc\").\n* Finally:\n  - $T_{complete} = T_{inf} \\ - \\{ jEds | kIed \\} \\ |\\{ X1en \\}_<_ 0_s) |\\ { general exception handling}\"\n* $T_{inf}$ (classic inflections): \n  - $\\Sigma_{inf} = (\\epsilon|s|\\epsilon)\\ 0 |(i|edv).s |\\gamma(i|edn)| \\frac{{* ieds - 2}}{{X1K}}2...@)$ - @ \\{ (cleaning of remaining markers in regular cases)$ ",
    "4 Out-of-Vocabulary forms\n\nExercise VI\n\nConsider an NLP application that needs to measure the edit distance between words using the chart-based algorithm.\n\nProvide the filled data structure resulting from the application of the algorithm to the pair \u201ceazy\u201d and \u201cfranz\u201d. Briefly justify your answer.\n\nSolution:\n\n\\[\n\\begin{array}{ccccc}\n&   & f & r & a & n & z \\\\\n& 0 & 1 & 2 & 3 & 4 & 5 \\\\\ne & 1 & 1 & 2 & 3 & 4 & 5 \\\\\na & 2 & 2 & 2 & 2 & 3 & 4 \\\\\nz & 3 & 3 & 3 & 3 & 3 & 3 \\\\\ny & 4 & 4 & 4 & 4 & 4 & 4 \\\\\n\\end{array}\n\\]\n\nEach cell contains the distance between the corresponding initial prefix strings.",
    "5 Part-of-Speech tagging\n\nExercise VII\n\nWhat is the tagging of the following sentence\n\ncomputers process programs accurately\n\nwith the following HMM tagger:\n\n(input) lexicon:\n\\[\n\\begin{aligned}\n&computers &N &0.123 \\\\\n&process &N &0.01 \\\\\n&process &V &0.21 \\\\\n&programs &N &0.23 \\\\\n&programs &V &0.15 \\\\\n&accurately &Adv &0.789 \\\\\n\\end{aligned}\n\\]\n\n(input) transitions:\n\\[\n\\begin{aligned}\n&P\\ (N| Adv) &=& 0.12 \\\\\n&P\\ (V| V) &=& 0.007 \\\\\n&P\\ (N|N) &=& 0.6 \\\\\n&P\\ (V|N) &=& 0.4 \\\\\n&P\\ (Adv|V) &=& 0.75 \\\\\n&P\\ (N|V) &=& 0.2 \\\\\n&P\\ (V| Adv) &=& 0.05 \\\\\n&P\\ (Adj|N) &=& 0.246 \\\\\n\\end{aligned}\n\\]\n\nSolutions\n\n4 choices (it\u2019s a lattice):\n\ncomputers  process  programs  accurately\nN          V         N         Adv\n\nDifferences are (skip the common factors):\n\n\\[\n\\begin{aligned}\n&P\\ (V|N)\\  \\times P\\ (N|V)\\  \\times P\\ (Adv|N) &= P(N|N)\\ \\times P\\ (V|N)\\ \\times P\\ (Adv|V)\\\\ \n0.4 \\times 0.2 \\times0.12 &=& 0.6 \\times 0.4 \\times 0.75\\\\\n0.0096 &<& 0.18\\\\\n\\end{aligned}\n\\]",
    "Tagging obtained (not corresponding to the one expected by an average English reader : ) : K\n\ncomputers process programs accurately.\nN V N Adv\n\nExercise VIII\n\nWe aim at tagging English texts with \u201cPart-of-Speech\u201d (PoS) tags. For this, we consider using the following model (partial picture: \u2026some picture...\n\nExplanation of (some) tags:\n\n\\[\n\\begin{tabular}{|c|c|c|l|}\n\\hline\nTag & English expl. & Expl. fran\u00e7aise & Example(s) \\\\\n\\hline\nJJ & Adjective & adjectif & new \\\\\nNN & Noun, Singular & nom commun singulier & car \\\\\nNNS & Noun, Plural & nom commun pluriel & cars \\\\\nNNP & Proper Noun & nom propre & John \\\\\nRB & Adverb & adverbe & quite, very, now, easily \\\\\nVB & Verb base form & verbe & take \\\\\nVBD & Verb simple past & verbe (pr\u00e9t\u00e9rit) & took \\\\\nVBZ & Verb 3rd person singular present & verbe 3 person.sing & takes \\\\\nVBP & Verb non-3rd person singular present & verbe pl. present & take \\\\\nWDT & Wh-determiner & d\u00e9terminant relatif & which \\\\\nWP & Wh-pronoun & pronom relatif & who \\\\\nWPS & Possessive wh-pronoun & pronom relatif (poss.) & whose \\\\\n\\hline\n\\end{tabular}\n\\]\n\nQ. What kind of model (of PoS tagger) is it? What assumption(s) does it rely on?\n\nQ. What are its parameters? Give examples and the appropriate name for each.\n\nWe use the following (part of) lexicon:\n\n\\[\n\\begin{tabular}{|c|c|}\n\\hline\nflight & NN \\\\\ngood & JJ \\\\\nthe & DT \\\\\nbook & NN \\\\\ninclude & VBP \\\\\ninclude & VB \\\\\nhas & VBZ \\\\\nproperties & NNS \\\\\nbooked & VBN \\\\\n\\hline\n\\end{tabular}\n\\]\n\nand consider the following sentence:\n\nmy daughter whose first adult tooth has just developed programs\n\n",
    "0) With this lexicon, how many different PoS taggings does this sentence have? Justify your answer.\n0) What (formal) parameters make the difference in the choice of these different PoS taggings (for the above model)?\n0) Give the explicit mathematical formulas of these parts that are different.\n\nAssume that the following tagging is proposed:\nmy/PRP$/possesive/NNS/world/NNS/filled/JJ/with/DT/tooth/NN/x/a/VBZ/sea/JJB/developed/VBN/programs/NNS\nHow is it possible? Give an explanation using the former formulas.\n\nSolutions\n\n0) This is an HMM of order 1 (Well, the picture is actually a part of a Markov chain. The \"hidden\" part will be provided by the emission probabilities, i.e. the lexicon).\n\nHMM emission lexicon:\n$$P(w_i | t_i)$$\nincludes lexical conditioning (P (NN | a) = ...) conditional (P (NN_i | C_i)) and trigrams for structure dependencies:\n$$P(C|w_i - 1, w_i) = P (C | C_w, C_w-1)$$\n\nIts parameter sets are:\n1. Initial probabilities: $P(tag)$\n2. Emission probabilities: $P(lex_1, ..., tag_N)$\n3. Transition probabilities: $P(tag_i | tag_{i-1}, tag_{1-i-2})$\n\\\\\nExamples: initial: $P(t0)$, transition: $P(J|INN)$, emission: $P(debit|JJ)$.\n\n\\begin{align*}\nmy & PRP$ \\\\\nphoto & NN \\\\\nof & IN \\\\\nplate & NN \\\\\nstatue & VBZ \\\\\ndebit & JJ \\\\\nJ & NN \\\\\nx & NN \\\\\nanother & VBZ \\\\\na & NN \\\\\npeter & NN \n\\end{align*}\n\n\\(\\to 2 \\times 2 \\times 16\\) possible taggings",
    "my/PRP$ daughter/NN whose/WP$ first/JJ adult/JJ tooth/NN has/VBZ just/RB developed/VBN programs/VBZ\nmy/PRP$ daughter/NN whose/WP$ first/JJ adult/JJ tooth/NN has/VBZ just/RB developed/VBN programs/VBP/VBZ\n\n---\n\n\u2022 Differences are due to two sub-products:\n\nOn one hand:\n\n$P(J/VBN) * P(VBN|J) * P(J/NNS) * P(adult|J) * P(daughter|N)$\n\nfor X either \u201cJ\u201d or \u201cRB\u201d and Y either \u201cJ\u201d or \u201cNN\u201d, and on the other hand:\n\n$P(WP$|NN) * P(daughter|NN) * P(developed|V) * P(programs/V)$\n\nsay X either \u201cVBP\u201d or \u201cVBN\u201d and Y either \u201cNNS\u201d or \u201cVBZ\u201d.\n\n---\n\nNOTICE:\n\n1. do not forget emission probabilities:\n$x$ belong to the x-tag but the first example has tag-to tag e.g. \u201cadult\u201d, not only $P(\\langle R|R)$ (here in- $R=$ (VBP/VBN)) for the transition to \u201ctooth\u201d.\n\n$R$ is possible simply by the fact that the product:\n\n$P(WP$) * F(nnd) * P(J/J) * P(adult/J) * P(J/N) * P(brother/J) * P(developed|VBN) * P(NN$|VB) * P(NNS|VBN)$\n\nis bigger than any other of the products for the same noun part, which is possible (e.g. each term bigger than any corresponding other, or even one much bigger than all the other products, etc.)\n\n---\n\nExercise IX\n\n1. What is the problem addressed by a Part-of-Speech (PoS) tagger?\nWhy is it hard? What are the two main difficulties?\n2. What is the main assumption used in the example of the given (word, part-of-speech) pairs in order to model the dependencies between the words with their part-of-speech?\nWhat data do you need to use if memory is an issue?\n3. Use the last example where you need to deduce:\n   a. the four different tags that are needed for PoS tagging?\n   b. what are their main differences?\n\n1/34",
    "Assume that the texts to be tagged contain unknown words, which are either capitalized words, or spelled wrong, or simply general common words not seen during the training. When all capitalized words correspond to proper names, and most of the spelling-errors correspond to words already in the lexicon (only a few of the spelling errors correspond to words not seen during training),\n\nHow would you handle such a situation in a concrete NLP application (that uses a PoS tagger)? Explain your decisions.\n\nAssume that the texts to be tagged contain 1.5\\% of unknown words and that the performance of the tagger to be used is 95\\% on known words.\n\nWhat will be the overall performance in the following two situations:\n\n(a) all unknown words are systematically wrongly tagged?\n(b) by using the solution you proposed in (1) in a situation where 80\\% of the unknown words are capitalized words (they are proper nouns), among which 95\\% are unknown, and 20\\% are spelling words, among which 95\\% are known, among which 1\\% correspond to spelling errors, and 5\\% are just unknown words?\n\nProvide a calculation (a complete formula but not necessarily the final numerical result) and an explanation.\n\nSolutions\n\na) The problem addressed by a PoS tagger is to assign part-of-speech tags (i.e. grammatical roles) to words in a sentence or text.\n\nb) When tagging a word (based on the lexical HMM) systems can have multiple grammatical roles, which can (in)valid word of vocabulary (error i.e. unknown words).\n\nc) This task can be considered also as a labeling problem where the algorithm choose the best label (tag) for unknown words.\n\nd) As stated in the present question we have to decide how to cope with them, which often depends on training data and the specific application.\n\ne) Finite-State Transducers seems really appropriate to this task under the memory consumption constraint (Linear). The number of arcs and nodes of FSTs is therefore linear in the input size (which is somewhat guaranteed to stay linear in FSA if we also suppose to not take into account lexical neighborhood estimation of the tagged word).\n\nf) Also words represented by FST arc-segments, cannot be aligned with each other except for the length of the word segments.\n\ng) Empirically, we can say that when the FST implementation will compare (or also to compare not even to computation) the method implicitly.\n\nh) Text categorization being actually one possible implementation for the corresponding FST.",
    "- The two main methods presented in the course for PoS tagging are Brill\u2019s tagger and Hidden Markov Models.\n\n- Brill\u2019s is rule based whereas HMM are a probabilistic model;\n- HMM can handle unsupervised learning whereas Brill\u2019s tagger requires supervision.\n- Brill\u2019s tagger has an integrated guesser (through \"lexical rules\") whereas HMM require an additional lexicon and a set of OOV probabilities. \n- The tagger\u2019s performance isn\u2019t significantly oriented in the sense that the applied rules belong more to the syntax than to principles or rules, understandable by a human, might be inferred in a less optimal (although not so easy and not recommended)\n\nThe idea is to use capitalized words wherever possible (at the Brill\u2019s tagger does in lexical rules)\n\n2) The whale idea is to use spelling errors as much as possible. This is hard in a completely crosslingual setting (except with a general corpus) when the Brill\u2019s tagger takes advantage of those patterns that are learned. \nThe better idea is therefore to use these error patterns: a meta search engine for example Lexing the parsing. The idea indeed lies in the threshold of the spelling error occurring in a large lexicons whose words were loaded with errors before and can be adapted to a multicultural corpus.\n\nHere is the guesser corresponding to the tagger used should be as follows:\n\nFor example, for those forms that were wrongly tagged (e.g. for 93.56% -15%), e.g.:\n\n$0.85 \\cdot 0.92 = 0.78$ (where $15\\%$ where wrongly guessed) correcting them by contexts errors)\n\nOn the other hand, $0.15 \\cdot 0.3 = 0.045$ where tags were correct. This way we cannot be expected to improve.\n\n\nSimilarly, using similar rules, we can expect the performance within the spelling errors only in terms of recall, and this will solve more problems of the parsing:\n$P = 0.3$, if the analysis and adaptation is performed/semantically: assumes this $0.15 \\, ok \\, within \\, the \\, guessing$\nThis could be summarized as:\n\\[\n\\begin{array}{|l|l|l|}\n\\hline\n & \\text{If correct \\%} & \\text{If wrong \\%} \\\\ \\hline\n15\\% \\, WR & 92.5 \\, ok & 7.5 \\, WRONG \\\\ \\hline\n15\\% \\, unknown & 70\\% \\, ok \\, within \\, 92.5 \\, ok \\, context & 27 \\, wrong \\\\ \\hline\n93.56\\% \\, known & 97\\% \\, ok & 2\\% \\, WRONG \\\\ \\hline\n\\end{array}\n\\]\n\nExercise X\n\n20) Consider an HMM Part-of-Speech tagger, the tagset of which contains, among others: DET, V, N, ADV and ADJ, and some of the parameters of which are:",
    "$P_1(\\text{a|DET}) = 0.1, \\quad P_1(\\text{accurately|ADV}) = 0.1, \\quad P_1(\\text{computer|X}) = 0.1,$$\n\n$P_1(\\text{process|V}) = 0.95, \\quad P_1(\\text{process|N}) = 0.025,$$\n\n$P_1(\\text{program|N}) = 0.1, \\quad P_1(\\text{program|V}) = 0.020,$$\n\n$P_1(Y|X): (\\text{for instance } P_1(\\text{N|DET}) = 0.55)$\n\n\\begin{tabular}{ c|c c c c c }\n  X & DET & V & N & PRO & ADJ & ADV \\\\\n  \\hline\n  DET & 0.03 & 0.03 & 0.41 & 0.02 & 0.11 & 0.07 \\\\\n  V & 0.08 & 0.08 & 0.02 & 0.09 & 0.05 & 0.02 \\\\\n  N & 0.03 & 0.03 & 0.03 & 0.18 & 0.08 & 0.03 \\\\\n  PRO & 0.12 & 0.12 & 0.06 & 0 & 0 & 0.08 \\\\\n  ADJ & 0.14 & 0.14 & 0.01 & 0.14 & 0.01 & 0.04 \\\\\n  ADV & 0.08 & 0.08 & 0.03 & 0.05 & 0.09 & 0.01 \\\\\n\\end{tabular}\n\n$\\text{and}:$\n\n$P_1(\\text{DET}) = 0.20, \\quad P_1(\\text{N}) = 0.06, \\quad P_1(\\text{V}) = 0.14, \\quad P_1(\\text{PRO}) = 0.15, \\quad P_1(\\text{ADJ}) = 0.01,$\n\n$P_1(\\text{ADV}) = 0.02.$\n\n(a) How are the probabilities $P_1$, $P_2$, and $P_3$ usually called?\n\n(b) Write the most probable tagging of the sentence\n$$a \\quad computer \\quad process \\quad programs \\quad accurately$$\n\nusing initialization\n$$P_2(\\text{a $\\to$ computer}) \\cdot P_3(\\text{computer $\\to$ process}) \\cdot P_3(\\text{process $\\to$ programs}) \\cdot P_3(\\text{programs $\\to$ accurately})$$\n\nwhich leads to a solution:\n\n(c) What would be the output of the HMM POS tagger on the above sentence?\n\nFully justify your answer.\n\n\\begin{tabular}{ c|c c c c c }\n  X|N  & a  & computer  & process  & programs  & ADV \\\\\n  \\hline\n  a & DET(DET) & 18 & 460 & 2,000 & 2 \\\\\n  computer & s & 90 & 15 & 8 & 3 \\\\\n  process & 100 & 14 & 31 & 100 & 3 \\\\\n  programs & N & 150 & 10 & 7 & 3 \\\\\n  accurately & 100 & 20 & 10 & 10 & 8 \\\\\n\\end{tabular}\n\nNoticing that $s_1 =$s, $s_2 = $x. Only the first three enter the game, amongst which the first is higher by the tail. \n\n$$DET \\quad N \\quad DET$$\n\n$$a \\quad computer \\quad process \\quad programs \\quad accurately$$\n\n$$DET \\quad N \\quad V \\quad N \\quad \\text{ADV}$$",
    "6 Parsing 1\n\nExercise XI\n\nConsider using a parser with the following (partial) grammar:\n\nS -> NP VP\nNP -> det N\nNP -> NP PP\nVP -> V \nVP -> V NP\nVP -> V BG PP\nPP -> P NP\n\nand (also partial) lexicon:\n\n2012 -> N\nSwitzerland -> N\nUSA -> N\nexports -> N\nincrease -> VBG\nincreasing -> VBG\nthe -> Det\nto -> P\nfrom -> P\nare -> V\n\nUsing the CYK algorithm, parse the following sentence with the above lexicon/grammar:\n\nthe exports from the USA to Switzerland are increasing in 2012\n\nProvide both the complete, fully filled, data structure used by the algorithm, as well as the result of the parsing in the form of a/the parse tree(s).\n\nSolution\n\nTransform to CNF:\n\nX -> VBG VBG\nVP -> VBG\n\n(incomplete) \n\nChart:\n\n(next page)",
    "Notice: the blue NP has two interpretations. This leads to two full parse-trees:\n\nExercise XII\n\n(a) Give the result of the CYK algorithm applied to the following sentence: \nthe cat is looking at the mouse\nusing the following grammar:\n\nS $\\to$ VP\nNP $\\to$ Det N\nVP $\\to$ VBG\nVP $\\to$ V\nPP $\\to$ Prep NP\nNP $\\to$ Adj N\nAdj $\\to$ V-ing",
    "and the following lexicon:\n\nat:Prep\nblack:Adj\ncat:N\nformer:Adjs\nin:Prep\nis:V/be\nlooking:Ving\nmouse:N\nthe:Det\nunder:Prep\nold:Adj\nthe:Det\nunder:Prep\n\n2 Draw all the parse trees that could be obtained from the previous question.\n\n3 What is an \"Earley item\"? Provide one typical example using the above sentence and grammar.\n\n4 The above grammar over-generates. One reason is that some adjectives, e.g. former, can only occur before a noun. For instance,\n\nThe cat is a former is correct in English (but accepted by the above grammar).\n\nAnother reason for over-generation is that some grammar rules deal with adjectives occurring before a noun. For instance:\n\nthe looking at the mouse cat is black\n\nis incorrect in English (but accepted by the above grammar).\n\nExplain how the above grammar might be modified to prevent these two types of over-generation.\n\n5 It is incorrect in English that sentences with either strictly syntactically or semantically incorrect PP-attachment:\nthe cat is in or\nis under the mouse.\n\nIllustrate how such incorrect PP-attachment is generated in English because some items like \"IN\" may have a PP. The second example is incorrect because \"sake\" can be substituted by any item like In this case, the preposition \"in\" and the second adjective \"former\" which are syntactically or semantically incorrect may be generated by the above PP. Propose modifications to the grammar in order to prevent these types of over-generation.\n\nSolutions\n\nNotice: the blue VP has two interpretations.\n\n   S\n   |\n    VP\n  / | \\\n VP  Adj   PP\n / | \\\nV VP  PP\n|   |   |\nV Adj  Pp Det N\n|\nVing\n\n",
    "\u25cf See lecture slides for definitions. Example here: (Adj  $\\to$ Adj + PP; 3)\n\nThe solution is to differentiate the two kind of adjectives. For instance:\n\nAdj  $\\to$  Adj  PP   \nAdj  $\\to$  Adj  $\\stackrel{A}{PP}$   \nAdj  $\\to$  $\\stackrel{B}{Adj}$  $\\stackrel{B}{PP}$   \nAdj  $\\to$  $\\stackrel{C}{Adj}$  $\\stackrel{A}{PP}$   \nAdj  $\\to$  Adj  $\\stackrel{X}{PP}$   \n(and, of course, add the right PPs tag into the lexicon, e.g. $\\text{Former:Adj}^X$)\nHere we keep the PPs tag as: $Adj^B$  $\\to$  $Adj^B$  $PPA$\n\n\u25cf Specialize adjective even further, for instance:\n\nAdj  $\\to$  Adj  PP   \n$\\stackrel{Look}{Adj}$  $\\to$  $\\stackrel{Look}{Adj}$  lookPP   \n\nwhere $Adj^X$ is the kind of adjective than could be complemented with a $PP$.\nFurthermore, we should be avoided if it is the accumulation of $PP$s on the same terminal.\nI.e. we should NOT have $X  \\to  X  +  PP$ when the same X\nThe main idea here is to go for a feature grammar and lexicalize some of the dependencies.",
    "7 Parsing 2\n\nExercise XIII\n\nBelow is a part of the lexicon and grammar for parsing English queries. Note that there is no error with the probabilities, the list of rules shown here is simply incomplete.\n\n\\[\n\\begin{array}{ccc}\n\\text{word} & \\text{POS} & \\text{Prob} \\\\\n\\text{show} & \\text{V} & 0.36 \\\\\n\\text{me} & \\text{Pro} & 0.24 \\\\\n\\text{the} & \\text{Det} & 0.12 \\\\\n\\text{bird} & \\text{N} & 0.10 \\\\\n\\text{blue} & \\text{Adj} & 0.09 \\\\\n\\text{and} & \\text{Conj} & 0.08 \\\\\n\\text{garden} & \\text{N} & 0.07 \\\\\n\\end{array}\n\\]\n\n\\[\n\\begin{array}{ccc}\n\\text{rule} & & \\text{Prob} \\\\\nS \\to NP\\ VP & & 0.76 \\\\\nS \\to Aux\\ NP\\ VP & & 0.12 \\\\\nS \\to VP & & 0.12 \\\\\nVP \\to V\\ NP & & 0.67 \\\\\nVP \\to V & & 0.33 \\\\\nNP \\to Det\\ N & & 0.41 \\\\\nNP \\to Pro & & 0.34 \\\\\nNP \\to NP\\ Conj\\ NP & & 0.25 \\\\\n\\end{array}\n\\]\n\n0. What are the two principal goals of syntactic parsing?\n\n1. Using the CKY algorithm, and the above grammar and lexicon, analyze the sentence:  \n   \\textit{Show me the bird and the garden.} with these steps:\n   * Show both the CKY chart at sentence length $n$ (with the values filled in, and all the possible parse trees).\n   * Which analysis gets the best probability?\n\nSolutions\n\n0. Recognition and analysis: see lecture slides.\n\n1. CKY transformation (for instance):  \n   X1 = NP Pro (0.10); X2 = NP V NP (0.23)  \n\n\\[\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n & \\text{1} & \\text{2} & \\text{3} & \\text{4} & \\text{5}\\\\\n\\hline\nS & & & & & \\\\\n\\hline\nNP & & & & & \\\\\n\\hline\nVP & & & & & \\\\\n\\hline\nN & & & & & \\\\\n\\hline\n\\end{array}\n\\]\n\n\\[\n\\begin{array}{|c|c|}\n\\text{S} & \\text{VP} \\\\\n\\text{Pro} & \\text{N} \\\\\n\\text{V} & \\text{VP} \\\\\n\\text{V} & \\text{N} \\\\\n\\end{array}\n\\]\n\nNote: the blue VP has two interpretations.",
    "parse trees (expressed w.r.t. the original grammar):\n\n\\[\n\\begin{array}{l}\n\\text{NP} \\\\\n|\\text{NP} \\quad \\text{VP} \\\\\n|\\text{Pron} \\quad \\text{V} \\quad \\text{NP} \\quad \\text{PP} \\\\\n|\\text{Pron} \\quad \\text{V} \\quad \\text{Det} \\quad \\text{N} \\quad \\text{PP} \\\\\n|\\text{Pron} \\quad \\text{V} \\quad \\text{Det} \\quad \\text{N} \\quad \\text{P} \\quad \\text{Det} \\quad \\text{N} \\\\\nwho \\quad started \\quad an \\quad argument \\quad with \\quad the \\quad partners\n\\end{array}\n\\]\n\n\\[\n\\begin{array}{l}\n\\text{NP} \\\\\n|\\text{NP} \\quad \\text{VP} \\\\\n|\\text{Pron} \\quad \\text{VP} \\\\\n|\\text{Pron} \\quad \\text{V} \\quad \\text{PP} \\\\\n|\\text{Pron} \\quad \\text{V} \\quad \\text{NP} \\\\\n|\\text{Pron} \\quad \\text{V} \\quad \\text{Det} \\quad \\text{N} \\\\\n|\\text{Pron} \\quad \\text{V} \\quad \\text{Det} \\quad \\text{N} \\quad \\text{P} \\quad \\text{NP} \\\\\nwho \\quad started \\quad an \\quad argument \\quad with \\quad the \\quad partners\n\\end{array}\n\\]\n\nsecond is best. Compute only the part that differs, not the whole product:\n\n\\[\nP(b) = N_1 \\cdot 0.13 \\cdot N_3 \\\\\nP(b) = N_1 = \\epsilon; 0.25 - N_2\n\\]\n\n\\[\n0.13 = 0.25 \\quad and \\quad 0.13 \\neq 0.18; \\quad not \\quad any \\quad computation \\quad to \\quad do \\quad whatsoever!\n\\]\n\nExercise XIV\n\nYou are given the following partial linguistic resources:\n\n\\[\n\\begin{array}{cccc}\nS \\quad \\rightarrow \\quad NP \\quad VP & (4.3) \\\\\nNP \\quad \\rightarrow \\quad Det \\quad N & (4.1) \\\\\nNP \\quad \\rightarrow \\quad N & (3.5) \\\\\nVP \\quad \\rightarrow \\quad VP \\quad PP & (0.4) \\\\\nVP \\quad \\rightarrow \\quad V \\quad NP & (3.1) \\\\\nVP \\quad \\rightarrow \\quad V & (2.7) \\\\\nPP \\quad \\rightarrow \\quad P \\quad NP & (1.3) \\\\\n\\end{array}\n\\]\n\n\\[\n\\text{and}\n\\]\n\n\\[\n\\begin{array}{ccc}\nthe &\\,\\,\\,\\, \\text{Det} &\\,\\,\\,\\, 0.3 \\\\\na &\\,\\, \\text{Det} & 0.4 \\\\\nman &\\,\\, \\text{N} & 0.2 \\\\\ncoat &\\,\\, \\text{N} & 0.1 \\\\\non &\\,\\, \\text{P} & 0.5 \\\\\nwith &\\,\\, \\text{P} & 0.25 \\\\\ngarden &\\,\\, \\text{N} & 0.2 \\\\\n\\end{array}\n\\]\n\nWhat do these resources represent? How are they called?\n\nParse the string ``the/a coat on a/the garden'' by using the CYK algorithm. Provide the value and the $n$-dim structures generated by this algorithm as well as the resulting parse trees.\n\nWhat is the most probable parse for the former sentence? Justify your answer.",
    "Solutions\n\n1. PCFG rules. Grammar and lexicon. \n\n2. First do CNF transformation:\n\n$VP_x -> V NP (p: 0.1)$\n$VP_x -> V PP (p: 0.9)$\n\n\\[\n\\begin{array}{ccc}\n & S & \\\\\n & / \\backslash & \\\\\n & NP \\quad VP_x & \\\\\n & /   \\quad  / \\backslash & \\\\\n & Det\\ N & V \\quad NP & \\\\\n & c.n \\quad / \\ \\backslash & \\\\\n & & \\ Det\\ \\quad N\\  NP & \\\\\n & & the \\quad garden \\quad / \\backslash & \\\\\n & & & home \\quad PP & \\\\\n & & & \\ PP & \\\\\n\\end{array}\n\\]\n\nNotice: the blue VP has two interpretations.\n\nParse trees (compared with the original grammar):\n\n\\[\n\\begin{array}{ccc}\n & S & \\\\\n & / \\backslash & \\\\\n & NP \\quad VP & \\\\\n & / \\ \\quad \\backslash & \\\\\n & Det \\ N \\quad VP & \\\\\n & / \\ \\ \\ \\ \\quad \\backslash & \\\\\n & c.n \\quad \\quad \\ V \\quad PP & \\\\\n & & cut \\quad \\quad / \\  \\quad \\backslash & \\\\\n & \\quad  & \\ & \\quad home   \\ t\u1eeb   the & \\\\\n & \\quad \\quad \\ \\backslash & & garden &\\\\\n\\end{array}\n\\]\n\n\\[\n\\begin{array}{ccc}\n & S & \\\\\n & / \\backslash & \\\\\n & NP \\quad VP & \\\\\n & / \\ \\quad \\backslash & \\\\\n & Det \\ N \\quad VP & \\\\\n & / \\ \\ \\ \\ \\quad \\backslash & \\\\\n & c.n \\quad \\quad \\ V \\quad NP & \\\\\n & & cut \\quad \\ \\   & \\quad / \\ \\quad \\backslash & \\\\\n & & \\ & \\quad Det \\quad N & \\\\\n & & \\ & \\quad the \\quad garden &\\\\\n\\end{array}\n\\]\n\n* second is best. Compute only the part after $(in black), not the whole product.\n\n$P(b_1) = K_1 \\cdot 0.1 \\cdot K_5$\n\n$P(b_2) = K_1 \\cdot 0.45 \\cdot K_2$\n\n$0.1 < 0.45; \u2234 b_2$ not too much computation to do...",
    "8 Lexical Semantics\n\nExercise XV\n\nThe objective of this question is to illustrate the use of a lexical semantics resource to compute lexical cohesion.\n\nConsider the following toy ontology providing a semantic structuring for a (small) set of nouns:\n\n\\[\n\\begin{array}{c}\n\\text{animate entities} \\\\\n\\human\\text{beings} \\quad \\text{animals} \\quad \\text{abstract entities} \\quad \\text{concrete entities} \\\\\n\\woman \\quad \\text{child} \\quad \\text{human} \\quad \\text{freedom} \\quad \\text{happiness} \\quad \\text{chair} \\quad \\text{pen} \\quad \\text{dog} \\\\\n\\end{array}\n\\]\n\n\\begin{enumerate}\n    \\item[a)] Give some examples of NLP tasks for which lexical cohesion might be useful. Explain why:\n    \\begin{itemize}\n        \\item IR: need to measure lexical cohesion at query word.\n        \\item Summarization: check coherence of extracted sentences.\n        \\item Spelling: disambiguation of possible choices in spelling error correction (e.g. bug or bag for WSD).\n        \\item Machine translation (semantic filter).\n    \\end{itemize}\n\n    \\item[b)] What is the semantic relation that has been used to build the ontology? \n    \\emph{Answer}: Is-a semantic relation. Tasks that do not use built-in lexical semantics resources can benefit.\n\n    \\item[c)] Select relevant relation, give a short definition and a concrete example.\n    \\emph{Answer}: Is-a.\n\n    \\item[d)] What specific point? \n    \\emph{Answer}: Example, pen and dog.\n\n    \\item[e)] Select simple example. \n    \\emph{Answer}: The word \u201cmouse\u201d appears at two different places in the toy ontology. What stress does this create? \n    \\begin{itemize}\n        \\item Address: whether it is a node (in the ontology) or itself.\n        \\item Address type: one is animal, other is object (subject of explanation).\n        \\item Example cat at $2$ different levels.\n    \\end{itemize}\n\n    \\item[f)] What is lexical cohesion? Explain.\n\n    \\item[g)] Compute WordNet distance between following sentences:\n    \\begin{itemize}\n        \\item[a)] \u201cA dog sits on the table.\u201d\n        \\item[b)] \u201cTwo pens are near the dog. There are plenty of pens on the table.\u201d\n    \\end{itemize}\n    \\emph{Answer}: Measures should be performed on this text to make it readable, use score of the sentence.\n\n    \\emph{Answer}: Methods: tokenization, maybe stopwords filtering, PoS tagging for nouns, lemma extraction (or stemming).\n\\end{enumerate}",
    "We want to use lexical cohesion to decide whether the provided text consists of one single topical segment corresponding to both sentences, or of two distinct topical segments, each corresponding to one of the sentences.  \nThe lexical cohesion of any set of words (in canonical form) is defined as the average lexical distance between all pairs of words present in the set. The lexical distance between any two words is L1 defined as the length of a shortest path between the two words in the available ontology. \n\nFor example, \"freedom\" and \"happiness\" are at distance 2. (length 1, number of links, of the path: happiness - abstract entities - freedom), while \"freedom\" and \"dog\" are at distance 4 (length of the path: freedom - abstract entities - animal - mammals - dog).\nTo compute this measure, we need an ontology. Example:\n\nExtract of the distance (lexical distance) between all pairs of words present in the above text and in the posited ontology (there are 6 such pairs).\n\n\\[\n\\begin{align*}\nD(cat, dog) &= 2 \\\\\nD(cat, table) &= 6 \\\\\nD(dog, freedom) &= 4 \\\\\nD(dog, pen) &= 6 \\\\\nD(table, freedom) &= 6 \\\\\nD(table, pen) &= 4 \\\\\n\\end{align*}\n\\]\n\nCompute the lexical cohesion of each of the two sentences, and then the lexical cohesion of the whole text.\nBased on the obtained values, what decision should be taken as far as the segmentation of the text into topical segments is concerned?\n\n\\[\nD(s1) = \\cfrac{2}{1} = 2\n\\]\n\n\\[\nD(s2) = \\cfrac{6 + 4 + 6 + 6 + 4}{2 * 6} = \\cfrac{4(6 + 6)}{2*6} = \\cfrac{3}{4/3}\n\\]",
    "9 Text Classification  \n\nExercise XVI  \nIn an automated email router of a company, we want to make the distinction between three kind of emails: technical (about computers), financial, and the rest (\"irrelevant\"). For this we plan to use a Naive Bayes approach.  \n\na. What is the main assumption made by Naive Bayes classifiers? Why is it \"Naive\"?  \n\nWe will consider the following three messages:  \n\n1. The Dow Industrials tumbled 120.54 to 10924.74, hurt by GM's sales forecast and two economic reports. Oil rose to $71.92.\n\n2. BitTorrent Inc. is boosting its network capacity as it prepares to become a legal distributor of films in May. BitTorrent will announce alliances with movie studios at the T1 and movie content via the BT platform. Bd has now filed papers for returning video of a short-form product.\n\n3. Intel will sell its XScale PXAxxx applications processor and 3G baseband processor assets to Marvell for $600 million, plus unspecified assets. The deal could make Marvell the top supplier of 3G and late corporate basebands. In Intel's case, exit enables a sharper focus on mainstream Intel businesses, including dreams on low energy PCs.\n\nb. What pre-processing steps (before actually using the Naive Bayes classifier) do you consider adapted to the input text?\n\nc. For the first text, give an example of the corresponding output of the pre-processor.",
    "Suppose we have collected the following statistics about the word frequencies within the corresponding classes, where \"0.00...\" stands for some very small value:\n\n|$c\\backslash w$|technical|financial|irrelevant|\n|--|--|--|--|\n|Dow|0.01|0.07|0.00...|\n|GM|0.02|0.03|0.00...|\n|GE|0.03|0.01|0.01|\n|Intel|0.04|0.03|0.00...|\n|IBM|0.01|0.02|0.00...|\n|losses|0.01|0.10|0.00...|\n|capacity|0.04|0.01|0.00...|\n|chipset|0.03|0.01|0.00...|\n|court|0.00...|0.03|0.00...|\n|impact|0.02|0.02|0.00...|\n|market|0.01|0.05|0.01|\n|overall|0.01|0.04|0.01| \n|french|0.04|0.01|0.00...|\n|sentence|0.06|0.00...|0.01|\n|weights|0.01|0.00...|0.00...|\n|the|0.06|0.02|0.06|\n\n**a)** In a typical NLP architecture, where/how would you store this information? Explicit your answer, e.g. precise data structures, table organization.\n\n**b)** For each of the three models, in what category will it be classified, knowing that on average 50% of the documents are financial, 40% are technical, and 10% are irrelevant.\nYou can assume that all the singletons of the sentences are relevant (i.e. do not repeat the results).\n\n**c)** Provide a full explanation of all the steps and computations that lead to your answer.\n\nWe now want to specifically focus on the processing of compounds such as \"network capacity\" in the second round.\n\n**d)** How are the compounds handled by a Naive Bayes classifier if no specific pre-processing is applied?\n\n**e)** What things if the compounds are handled by the NL pre-processor?\n\n**f)** Among this situation, will NL pre-processing handling compounds result to have the Naive Bayes classifier learn them?\n\n**g)** Outline how you build a pre-processor for compound words. \n\nNote: that this is only partial information, statistics about other words not presented here have also been collected.",
    "Solutions\n\nQ2.1 The main assumption is that features/attributes contributing to the likelihood are independent, conditionally to classes:\n\\[ P(f_1, \\ldots , f_n | C) = \\prod P(f_k | C) \\]\nThis is in practice definitely a strong assumption. This is the reason why is called \"Naive\".\n\nQ2.2 In text classification, preprocessing is really crucial in order to allow a \"good\" representation mainly through proper lexical variability reduction.\n\nUsual NLP steps for reducing lexical variability include: tokenization (removal of punctuation), PoS tagging, lemmatization, and application of grammatical \"contagiones\" words (connectors), some PoS tagging is beneficial for disambiguation.\n\nIf lemmatization is not possible, stemming could be considered either.\n\nWe could also have a more evolved tokenizer including Entity Recognition (e.g. based on regular patterns) or even Name Entity Recognition for Proper Nouns.\n\nQ3.3 Lemmatized with name entity recognition, this could lead to:\n\\[ forecast = \\$num barrel oil <time> \\]\n\nforecast\u00a0.nomprice expect oil time <number>\nForecast <Time>\n\n\u00a0 \u00a0 < ...>\n\nforecast barrel oil + numprice expect announce\n\nThe economic activity contribute rise oil price <time> (this was not expected as an embedded proposition...).\n\n<forecast numprice>\n\nForecast v. (\\#synthetic_clusters) 27. (brown) nl (bn) (mconomic=l), {forecast,1}\nQ4.1 This is a more difficult question... when the flexibility is basically useless\nbecause there are already enough labeled data, the empirical success depends on the representation learned from the additional association to low-high key space very difficult to link the association space.\n\nOtherwise some external a (regional domain) layer would be build, the role of the lexicon for the object works in a very weak sense of the whole index in: social node containing relative importance of difference highly depends on the size of the vocabulary to be stored and generalized and is also computationally entrenched in NLP.\n\nThis can be represented as a relatively marogic [....]\n\nThe affine space with associative layer level memory\n\\$\\theta\\$ 3.4 Let's consider an array with arbitrary memory (whatever its implementation is available):\n\nexample --> 123454 be the location then an array such that ARRAY[1]=1234541-number. so:\n\u00a0 \u00a0 Location = ascii\n\nSuch a task would lead the probability arrays very likely to be very large. Thus more that space requirements the model would be worth using here.",
    "Q2.5 What make the discrimination between the class are the $P(\\text{word}|\\text{class})$ and the priors: $P(C_i)$. Indeed, the Naive Bayes classifier uses two features:\n\n$$\\underset{C_i}{\\mathrm{argmax}} \\{P(C_i|x_1,...,x_n)\\} = \\underset{C_i}{\\mathrm{argmax}} \\{P(C_i) \\prod_j P(x_j|C_i)\\}$$\n\nAs stated in the question, assuming that all the rest is irrelevant, the first text will have\n\n|       | technical | financial | irrelevant |\n|-------|-----------|-----------|------------|\n| Dow   | 0.010     | 0.050     | 0.015      |\n| GM    | 0.005     | 0.013     | 0.031      |\n| forecast  | 0.007     | 0.017     | 0.010      |\n| \u03a3     | 0.022     | 0.080     | 0.056      |\n\nthe maximal product of which is clearly for the second class: \"financial\".\n\nFor the second text we have:\n\n|       | technical | financial | irrelevant |\n|-------|-----------|-----------|------------|\n| network | 0.093     | 0.040     | 0.031      |\n| tcp/ip  | 0.041     | 0.031     | 0.009      |\n| 0.0085  | 0.024     | 0.011     | 0.010      |\n| ping    | 0.005     | 0.007     | 0.004      |\n| \u03a3       | 0.252     | 0.089     | 0.054      |\n\nthe maximal product of which is clearly for the first class: \"technical\".\n\nFor the third text:\n\n|                 | technical | financial | irrelevant |\n|-----------------|-----------|-----------|------------|\n| Intel           | 0.008     | 0.001     | 0.009      |\n| processor       | 0.007     | 0.003     | 0.006      |\n| register        | 0.002     | 0.007     | 0.003      |\n| computer        | 0.007     | 0.011     | 0.005      |\n| instructions    | 0.004     | 0.006     | 0.012      |\n| 3D graphics     | 0.034     | 0.002     | 0.008      |\n| motherboard     | 0.007     | 0.002     | 0.039      |\n| to              | 0.003     | 0.001     | 0.004      |\n| chips           | 0.009     | 0.001     | 0.005      |\n| completely      |           |           |            |\n| \u03a3               | 0.139     | 0.034     | 0.091      |",
    "which could be organized:\n\n\\[\n\\begin{array}{|c|c|c|c|}\n\\hline\n& \\text{technical} & \\text{financial} & \\text{irrelevant} \\\\\n\\hline\nIntel & 0.01 & 0.03 & 0.08 \\\\\nsmartphone & 0.02 & 0.01 & 0.07 \\\\\nprocessor & 0.01 & 0.02 & 0.08 \\\\\nbusiness & 0.02 & 0.09 & 0.05 \\\\\ncomputers & 0.07 & 0.02 & 0.10 \\\\\nPC & 0.07 & 0.01 & 0.10 \\\\\nsoftware & 0.01 & 0.05 & 0.08 \\\\\nbuinesses [business] & 0.01 & 0.07 & 0.06 \\\\\npeople & 0.01 & 0.01 & 0.001 \\\\\nemployees & 0.01 & 0.01 & 0.001 \\\\\n\\hline\n\\end{array}\n\\]\n\nshowing that the $P(\\cdot|C_i)$ part is the same for the first two classes (and much smaller for \"irrelevant\")\n\nThus the prior $P(C_i)$ will make the decisions and this last text is classified as \"technical\".\n\nQ1.6 compounds are simply treated as such by the Naive Bayes and are thus, due to the \"Naive\" independence assumption, handled as separable tokens.\n\nQ1.7 If the processors are to be recognised compounds as such they will thus be included as features and manipulated with those handled as words. This is actually a way (preprocessing/tokenization) of rebalancing between \"features\" of the Naive Bayes, these features no longer belonging to single tokens:\n\n\\[\nP(\\text{newspapers}) = P(\\text{news}) P(\\text{papers}) = 0 \\text{ (unless we have seen the two tokens \"news\" and \"papers\")}\n\\]\n(Maybe not capitalized)\n\nThe compound as a whole is seen as a feature if indeed after preprocessing has no gap, but more often simply appearing in the parameters, which is no longer be assumed to be $P(\\text{news}|C_i)P(\\text{papers}|C_i)$.\n\nQ1.8 compound tokenization is a wide topic of lexical acquisition. It is now an NLP topic of research and increasingly more seen as statistical result not opposed but in complement of the older approach that looked at the linguistical/human knowledge world.\n\nFor instance, the entropy tells us when and how to consider the tokenizing.\n\nIn some domains (finance) the general world or bigger topics end-words used, using, e.g., mutual information or other criteria are recognised more as (in the bag) separate frequent tokens, which is true also of the newer package algorithms that learnt the statistical A&B for e.g. by NN, NN of NN. Those mutual recognitions offer arguably more mathematical basis and less combinatorics.",
    "Exercise XVII\n\nYou are responsible for a project aiming at providing on-line recommendations to the customers of a on-line book selling company.\n\nThe general idea behind this recommendation system is to cluster books according to both customers and content similarities, so as to propose books similar to the books already bought by a given customer. The choice of a key representative is a clustering algorithm is not easy: it should be both like by the majority of the users group. Thus clustering should be not only be achieved according to the average user satisfaction, but should also be refined by the content of the books themselves. Put in place what we need to address this case systematically.\n\n0. Briefly explain how books could de clustered according to similar content. Give the main steps and intermediate results.\n    main steps:\n    - pre-processing: keep univocally meaningful elements, remove less semantically important elements.\n    - main NLP steps for reducing textual information include: tokenization (removal of punctuation and stop words), lemmatization and stemming\n    - representing text in a possible compressed but representative form (TF-IDF?, bag of words, word sequence, keeping parts of phrases? semantic role considered entities?).\n    - possibly generating some statistics including Named Entity Recognition (e.g. authors? publishers? languages? topics?...)\n\n1. How could we measure the representativity of an element chosen in a way that should represent a cluster?\n    e.g. TF-IDF based or bag of words representation from word sequences to vectors \n    cosine distance of elements inside a cluster\n    use of the naive bayesian classification method.\n\n2. The chosen clustering algorithm is not effective enough. What other algorithms could you propose and what are their pros and cons? What adaptations could you think to improve the insufficient clustering performances? Which other results you recommend for the targeted task?\n    e.g. hierarchical approach to allow a progressive clustering rather than an isolated final algorithm (K-means...)\n\n    - simple k means clustering for low density co-occurrence (good math implementation with possible libraries)\n    - affordle representations in tree diagrams (would they complemented them with mixed techniques)\n    - possibly, individual K-means adaptations modification based on results of item results, including inner cluster relative contribution\n\n3. The books could be noted by hand (and were noted) and evaluated them. If possible, with relations derived from the grouping.\n\n4. Consider the following six \"documents\" (toy example):\n        4. \"Beacons are out sorted at this very time for the fields to their home port, now faces are opened\"  ",
    "d6. \"What pen for what cone? A red pen for a red cone, a black pen for a black cone, a brown pen for a brown cone... Understand?\"\n\nand suppose (toy example) that they are indexed only by the two words: pen and cone.\n\n(a) Draw their vector representations.\n\n(b) Give the definition of the cosine similarity. What vector\u2019s feature(s) is it sensitive to? Not sensitive to? Only absolute vector angle/direction, not length, i.e. not related volume and mass.\n\n(c) Write the shape of the dendrogram clustering algorithm on those six documents, using (where it makes sense and) single linkage?\n\nHints: $1 - \\text{SIM}(d_i,d_j) = \\sqrt{2 - 2/\\sqrt{\\pi}}$\n\nand sketch first at what you should be absolutely do: no need to compute every pair of similarity!!!\nSo can choose as well d_i defining face and even the drawing alone might be sufficient \n(no computation at all!!!)\n\n$d_{i1}$ (d6)\n\n(d) Is this an example where a similarity function can be invalid?\n\nNo! Always true, but more similar means bigger cosine!\nTo explain: cluster $\\{d_{11},d_{12}\\}$ belong together because there are some values: $D(1,2)=1-\\sqrt{1/\\pi},D(\\mathbf{z_1,\\mathbf{z_2}})=\\sqrt{2-2/\\sqrt{\\pi}}$.",
    "### Information Retrieval\n\nExercise XVIII\n\n1) Describe the main principles of the standard vector space model for semantics.\n\n2) Consider the following document:\n\n\\[ D = \\text{\"The exports from Switzerland to the USA are increasing in 2006\"} \\]\n\n  Propose a possible indexing set for this document. Justify your answer.\n\n3) What is the similarity between the above document D and\n\n\\[ D' = \\text{\"Swiss exports have increased this year\"} \\]\n\n  Justify your answer.\n\n4) Briefly explain the important limitation(s) of the standard vector space approach.\n\n5) Explain how the multidimensional techniques such as the Distributed Semantics can be used to overcome these limitations.\n\n6) Give some concrete examples of NLP applications that might benefit from the semantic vector representation techniques.\n\n7) Considering the above indexed sets, does the indexing set you considered in question Q2 capture the semantic between D and this other document\n\n\\[ D' = \\text{\"The exports from Switzerland are increasing in 2006\"} \\]\n\n  If yes: how? If not, why?\n\n8) Would a parser be available, how could it be used to provide a (partial) solution to the problem?\n\n### Solutions\n\n1) The standard approach to vector semantics can be decomposed into two main steps:\n- the indexing or desegregation phase: during this phase, the documents for which the representation vectoriale are needs to be produced are parsed, into sentences and typically into words. More abstractly, this phase establishes a limited inventory of indices or terms.\n- In the vectorial space phase, we associate with each of the documents a set of its indexing features vectors. Note further that, for the rest of the processing, one sets the indexing features list and dimensions lists.",
    "be considered. The rest of the documents will be ignored. Notice also that the sets of indexing features are sets..., and that therefore any notion of word order is lost after the indexing phase.\n\nFor example, if we consider the toy document collection consisting of the two following documents...\n\nD1 ---> \"the results of the experiments on transgenic plants will be issued soon\"\n\nD2 ---> \"as soon as the experiments will be over, the laboratory will issue a report\"\n\nA possible output of the indexing phase for these documents might be...\n\nD1 ---> {result, experiment, transgenic, plant, issue}\n\nD2 ---> {experiment, issue, laboratory, soon}\n\nbut it is important to notice that the order of the word lemmas in the indexing sets is in fact meaningless, and D1 and D2 might indifferently be represented as...\n\nD1 ---> {experiment, issue, plant, result, transgenic}\n\nD2 ---> {experiment, issue, laboratory, soon}\n\nWe now define longer but necessary notations:\n\n- The words of the source texts\n\n- The vector representing the k weights of the k selected features for document i after the indexing phase, and before the set transformations occurring in the representation phase.\n\nWithin these notations, the indexing phase returns a set of N vector of the following form ...After the indexing, we proceed to transform the indexing phase returned documents into ... representation of documents ...\n\nWe now define the representation vector $vec{x}$ in which the i-th document is simply the (indexed/lemmas/words after the indexing phase) feature set ... that will be of use subsequently, represented as ... $vec{x}$ is an indexed representation of the document.\n\nThe influence of selected representation models in NLP scenarios is clear if we focus on a select ... . Formally, this is accompanied by the framework of feature vector space models, ... meaning the importance of a vector space. A vector is feature selected (indexed document) that is of very high relevance, for the frequency of its occurrence and its distinct aid in classifying, for example to distance from feature space resulting in the necessary distinction of experiment and theory.\n\nThe semantics of the indexing phase have an acclaimed role in better processing the documents through appropriate selections. \n\nIndeed, in models based on selecting key words for the indexing feature vector space, the precise role remains clear for commonly aiding the NLP tasks .. . We stipulate that ...\n\nWe will focus on co-selection, defined as the process of selecting features that appear vital in more than one document, can be viewed as similarity-aiding.\n\nThe angle $\\theta$ representing documents D1 and D2 in the vector representing document frequency and \u2026\n\nThe semantic proximity between D1 and D2 is simply defined as...",
    "where $X \\cdot Y$ denotes the dot-product between vector $X$ and vector $Y$, and $|X| = \\sqrt{X \\cdot X}$ represents the norm (i.e. the length) of vector $X$.\n\nNotice that this simple similarity might be further sophisticated in order to take into account a possible importance for the various dimensions of the vector space:\n\nA possible approach is to use weights and dot-products of the form:\n\n\\[ V_1 = [a \\cdot f_1, b \\cdot f_2] \\]\n\nand\n\n\\[ V_2 = [a \\cdot f_3, b \\cdot f_4] \\]\n\nwhere $f_i$ are the feature values, and $a, b, ...$ are some (usually positive) coefficients.\n\nWe then need to figure out how the weights for the dimensions would be set. One way is to use the \"term document frequency.\" i.e., set larger weights for feature dimensions in the document corresponding to more salient features. The idea of putting more emphasis to document specific salient features is very useful in a corpus with many documents.\n\nFor example, if we take $X_i = a \\cdot idf(e_i)$ and $Y_i = b \\cdot idf(e_i)$, where $idf(e_i)$ is the document specific importance of the $i$-th word, given by:\n\n\\[ idf(e_i) = \\log \\frac{N}{df(e_i)} \\]\n\nwhere ($tf_e$ is a constant), $N$ is the number of documents, and $df(e_i)$ is the number of documents inclusive of entity $e_i$. We then, can get a similar values of idf based on multiple documents.\n\n\u2022 The simplest approach to produce the indexing text associated with a document is to use a tokenizer, take stemmed words ignoring stop words and sort the significant tokens in an increasing order. e.g., indexing text of $D_1$ might be:\n\n\\[ \\text{increas, Switzer, Switzerland, Swiss, USA} \\]\n\nA more sophisticated approach would consist in using a lemmatizer in which case, the indexing text might look like:\n\n\\[ \\text{economy, export, House, increase, Verb, Switzerland, frozen, House, USA, frozen, noun} \\]\n\nOne could also consider the word classes given by:\n\n\\[ \\text{Noun: Switzerland, increase} \\]\n\nOne solution could be:\n\n\\[ \\text{economy, export, increase, Switzerland, USA} \\]\n\nWe might also consider,\n\n\\[ \\text{Swiss, increas, Swiss, Switzer, USA} \\]\n\nMany similarity measures could be considered, e.g, Dice, Jaccard, cosine.\n\nFor cosine: the dot product is:\n\n\\[ 2 ( \\text{export and increase}) \\]\n\nand the norms are $\\sqrt{5}$ and $\\sqrt{5}$",
    "One of the important limitations of the standard vector space approach is that the use of the cosine similarity imposes that the dimensions of the vector space are orthogonal and that therefore the indexing features associated with the dimensions have, by convention, a null similarity.\n\nIn fact this is a problem as it is extremely difficult to guarantee that the indexing features associated with the dimensions are indeed semantically fully uncorrelated. For example, it is highly probable, that words such as \u2018car\u2019 and \u2018vehicle\u2019 or \u2018book\u2019 and \u2018magazine\u2019 evoke a certain level of \u2018shared\u2019 ideas (which should be interpreted so that the vector \u2018coming\u2019 with the words cannot be null).\n\nA possible partial solution for this problem is to use more sophisticated representation techniques such as the Distributional Semantics (DS).\n\nIn fact the general idea of the indexing features does not refer any more to the words contained in the document collection, but also to the co-occurrences of the indexing feature-words in the documents. Moreover, a new association score is not attached to a word or to its occurrences in a document, but, instead it is attached to its combined appearance with other index terms in specific contexts. The co-occurrence vectors characterizing the indexing features are organized in the same way as the standard term vectors, but now with the help of co-occurrence matrices instead of simple Document-Term-Matrices (DTM), the elements of those vectors evolving with the same cosine similarity calculations:\n\n$$\\text{ID} = Cov(\\vec{ID}_a, \\vec{ID}_b) = \\sum_{i=1}^{n} Cov(w_iID)$$\n\nAs the notions \u2018vehicle\u2019 and \u2018car\u2019 share similar co-occurrences (i.e. appears in documents together with many similar words), their similarity will be \u2018not zero anymore\u2019.\n\nAny NLP application thus, benefits the most from the semantic similarity notion between textual entities and thus, indexing features may be represented in the same dimensionality by associating them according to the order of combined appearance (co-occurrence weights) with other words, instead of simple word occurrence.\n\nExample: In the course of a co-occurrence analysis, the indexing features of the words car and vehicle are modified according to changes in the weights given to morphological analyzers.\n- High similarity: Most frequent groups in which the \u2018car\u2019 appears are the \u2018same\u2019 and \u2018in the same order\u2019 as for the word vehicle.\n- High dissimilarity: If the meanings associated to \u2018vehicle\u2019 are substituted by those coming from the groups in which words such as \u2018journey\u2019 and \u2018engine\u2019 appear frequently with different orders, the semantic vector associated to them are transformed in different directions.\n- Therefore, after indexing an incoming new document following the previous model: meaning(car)too and meaning(vehicle) == meaning(from Paris to Marseille).\n- The same weights of the incoming text are ordered for the following comparisons of the document representation of the reference corpus and the incoming documents in the same presentation space.\n- Indexing models are much more insensitive to noise: each text is represented by the vector representing the most similar meaning to the next document, and conversely:\n$$text(incoming A) \\leftrightarrow text(B)$$ in this meaning.\n\nNo, The indexing sets associated with D and D\u2019 would be exactly the same; and would therefore not be able to discriminate between these two documents (which nevertheless do not mean the same)...",
    "If a parser would be available, grammatical roles might be automatically associated with the reduced indexing features. For example, specific organization roles could be associated with prepositional nominal phrases such as \u201cto the USA\u201d or \u201cfrom Switzerland\u201d which could then be represented as \u201cto_USA\u201d and \u201cfrom_Switzerland\u201d.\nIn this case, the indexing sets associated with D and D\u2019 would be:\nIndex(D) = {200%, export, from_Switzerland, increase, to_USA} \nand \nIndex(D\u2019) = {200%, export, from_USA, increase, to_Switzerland} \n\nand would allow D and D\u2019 to be discriminated.\n\nExercise XIX\n\nQ. What is the cosine similarity?\n\n2. Consider the following two documents:\nD1: Dog cat dog. Eat cat too!\nD2: Eat homework. It's raining cats and dogs.\n\nWhat would be their cosine similarity in a typical information retrieval setup? Explain all the steps.\n\n3. In a typical statistical information retrieval setup, given a new, unseen query retrieve a document from the collection of the corpus and justify your answer.\nAssume a collection size of eight documents. The following is the query and the three documents for retrieval:\nQuery: retrieve similar document similarity information retrieval\nA: Information retrieval models predict document similarity using cosine distance.\nB: Information retrieval techniques include the use of probabilistic and vector space models.\nC: Information retrieval systems use keyword matching techniques.\n\n(a) Using the Cosine Similarity definition discussed, find an example of three distinct document vectors ensuring that the given document vectors provide the corresponding cosine similarity listed. Specify what each index means in your example.\n(b) Using the concept of logical indexing below when two similarity measures exist, provide an example with justification.\n\n3. An information retrieval system based on the concept of logical indexing can be useful for:\n(a) Retrieve the notions of two associated pairs,\n(b) Define and classify special metadata to make sure we have a proper group,\n(c) Recover phrases that describe a specific element to a logical group of pairs,\n(d) Reconstruct a sentence in a new tag-level (maybe several). Justify your answer and define the notions of precision and recall.",
    "**Solutions**\n\n1) It's a possible measure used for document semantic content similarity. It operated on a vector representation of the document \"meaning\" and is computed as\n\n\\[\n\\frac{\\vec{d_1} \\cdot \\vec{d_2}}{\\sqrt{\\vec{d_1} \\cdot \\vec{d_1}} \\sqrt{\\vec{d_2} \\cdot \\vec{d_2}}}\n\\]\n\n2) First a part-of-speech tagger might be applied in order to both filter out some stop words (and make the distinction between can_N, the common, and can_V, the verb, be kept, and prepare for lemmatization, i.e. normalization of the surface forms to the \"full words\".\nIn this example, typically (tags \"training\"):\n\n\\[\nD1: dog \\quad cat \\quad dog \\quad cat \\quad can \\quad be \\quad true\n\\]\n\\[\nD2: dog \\quad cat \\quad dog \\quad cat \n\\]\n\nThen a vectorial representation is built, typically a words frequency (tf) vector. In this example (corresponding to dog, cat, can, be, true):\n\n\\[\n\\vec{d_1} = (2, 2, 1, 1, 1)\n\\]\n\\[\n\\vec{d_2} = (2, 2, 0, 0, 0)\n\\]\n\nThen the above cosine formula is used, leading to\n\n\\[\n1 - \\frac{2*2 + 2*2 + 1*0 + 1*0 + 1*0}{\\sqrt{2^2 + 2^2 + 1 + 1 + 1} \\sqrt{2^2 + 2^2 + 0 + 0}} = <result>\n\\]\n\nWell... in principle NO... unless the system is updated to answer something anyway:\nThe numerator of the cosine is just the sum of common terms (then weights are orthogonal to all similar... thus not summed in the denominator...) Only if they count is enough. The summation of the cosine undefined divisions by 0 might be 0... then the whole machine ever shall be containing... (cf. below the hidden part of common characteristic.)\n\n3) The intersection computes the unique intersection and union from the tf vector, for instance:\ntf \ndf \nVisa computation nf_intersection then\nSum_tfidfs(l1, l2, cos...)\nFirst notice: with a Boolean representation, the dot product is the same as the (cardinal of the) intersection of the sets of documents etc...\nThat in this instance, then we could work directly with the boolean case then (binary case (W), ACL'97) \nExample: The following tf docs/vectors where Jaccard is a set-intersection\n\n\\[\n\\vec{d_1} = (2, 2, 1, 1, 1)\n\\]\n\\[\n\\vec{d_2} = (2, 2, 0, 0, 0)\n\\]\n\nAnd recall sometimes a union:\n(Then both the intersection over union and the cosine are different impacts, thus using Jaccard should be used is differentiation.)\n\n\\[\n(\\vec{d_1} \\cdot \\vec{d_2}) = \\frac{1}{1^2}\n(As \\quad n1 \\quad and \\quad n2)\nnormal \\quad length \\quad for \\quad n1 \n(\\sum max ((a_i = 2, 2i,j)) \nZ, n, more...; = and will get: resulting = plugged mode 4 already here! \nf.im.first...;n1;nj; and intersecting a_class_and_b.txt_4 \nfrom recall: modulating up e.g. with terms (d, 0) for which several examples can be instantiated\n",
    "b1: 1 1 0 0 0 0 0 0\nb2: 0 0 1 1 0 0 0 0\nb3: 1 1 0 0 1 1 0 0\nb4: 0 0 0 0 0 0 0 0\nD1: 1 0 0 1 0 0 1 1 \nD2: 1 0 1 0 1 0 0 1 \nD3: 1 0 0 1 0 1 0 0\n\nIn this case the two Jaccard are both equal to 1/5 and the two cosines are 1/\u221a5 and 2/\u221a15.\n\n(b): see lectures.\n\nExercise XX\n\nOfficial NLP evaluations (especially for task such as Information Retrieval or Information Extraction) are often carried out in the form of \"evaluation campaigns\".\n\nPrecisely describe the various steps of such an evaluation campaign.\n\nFor each of the steps, clearly indicate the main goals.\n\nSolution a): There may always be a tension between specificity and exhaustivity: take a significant sample of the data. First you define the context: then you define the \"golden truth\" i.e. what output must be given to a few examples. Next you have to build the system which will then produce its own outputs and pass to evaluation - phase where the output is compared with the reference output. Specific measures, which you can publish, make conventions and discuss.\n\nAs an example of evaluation campaign, the following \"referential (\"golden truth\") has been produced:\nb1        b2        b3        b4\n(a)       1         2          1         3\n(b)       2         1          1         0\n(c)       0         3          2         0\n(d)       1         0          2         2\n\nGiving rise to:    \nmean:    2          3          3         0\nmean:    1\u20444      3\u20444      1\u20442       1\u20443\n\nIt is easy to note that the reference defines c) associated with a query reference q; defines the set of documents deemed to be relevant for the query by the human judges.\n\nIs there a unique assessment and, if not, since when one tries to produce it?\n\nSolution b):\n(a): ambiguity (meaning of the text, not the question, is the solution unique?)\n(b): bias (inter-judge annotator agreement\n                  prenominal positions)\n(c): answer distinct (agreement \u2013 too biased)\n\nExercise: end.\n\n(1) and (2) and (3) and (4) are related: the later being a consequence of the former.\n\nConsider now Information Retrieval systems $S_1$ and $S_2$ that produced the following outputs for the 4 reference queries $q_1, q_2, q_3, q_4$:\n\n$S_1$:    (d,b,c,d,a)\n$S_2$:    (b,c,d,c,d)",
    "s1: \n    q1: d4 d2 d3 d6 d1 d7 d8 d5 d9 d10\n    q2: d2 d7 d1 d4 d6 d3 d10 d8 d5 d9 \n    q3: d2 d4 d9 d3 d8 d5 d10 d6 d1 d7\n    q4: d6 d2 d8 d4 d10 d1 d3 d7 d5 d9\n\ns2:\n    q1: d3 d5 d1 d10 d4 d7 d2 d9 d8 d6\n    q2: d1 d5 d9 d8 d4 d7 d3 d6 d10 d2\n    q3: d3 d5 d9 d7 d4 d8 d10 d6 d2 d1\n    q4: d4 d2 d5 d3 d8 d9 d6 d1 d10 d7\n\n:referential\n    q1: d1 d2 d3 d4 d5\n    q2: d1 d2 d3 d4 d5\n    q3: d1 d2 d3 d4 d5\n    q4: d1 d2 d3 d4 d5\n\nwhere qx denotes the document references that do not appear in the referential. To make the answer easier, we copied the referential on the right.\n\nFor each of the two systems, compute the mean Precision and Recall measures (provide the results as fractions). Explain all the steps of your computation.\n\nq1: P=$\\frac{4}{5}$   R=$\\frac{4}{10}$   mean: P=$\\frac{4}{30}$  R=$\\frac{4}{30}$\nq2: P=$\\frac{2}{3}$ R=$\\frac{2}{10}$ mean: P=$\\frac{2}{30}$ R=$\\frac{2}{30}$ \nq3: P=$\\frac{4}{10}$ R=$\\frac{4}{10}$ mean: P=$\\frac{4}{30}$ R=$\\frac{4}{30}$ \nq4: P=$\\frac{4}{10}$ R=$\\frac{4}{10}$ mean: P=$\\frac{4}{30}$ R=$\\frac{4}{30}$  \nmean: P=$\\frac{1}{8}$ R=$\\frac{1}{8}$ \n\nq1: P=$\\frac{2}{4}$ R=$\\frac{2}{5}$ mean: P=$\\frac{1}{2}$ R=$\\frac{1}{5}$ \nq2: P=$\\frac{2}{4}$ R=$\\frac{2}{5}$ mean: P=$\\frac{1}{2}$ R=$\\frac{1}{5}$  \nq3: P=$\\frac{2}{4}$ R=$\\frac{2}{5}$ mean: P=$\\frac{1}{2}$ R=$\\frac{1}{5}$  \nq4: P=$\\frac{2}{4}$ R=$\\frac{2}{5}$ mean: P=$\\frac{1}{2}$ R=$\\frac{1}{5}$  \nmean: P=$\\frac{1}{2}$ R=$\\frac{1}{5}$  \n\n6. Explain how it is possible to compute Precision at different Recalls.\n\nOne way is to compute a given number of documents increasing so as to increase recall infinitely to recall 1, measure what is the system to decide: all the available documents until here the point we arrive.\n\n7. How is it possible to compute the average Precision/Recall curves? Explain in detail these variations and their impact.\n\nAs it would be too tedious to compute the average Precision/Recall curves by hand, plot, on a graph, the possible Precision and Recall values obtained in question (1). In the given four queries, consider for each, graphs.\n\nIn question 1, 2 which is a better relative evaluation of the two systems?\n\n(a) We do not have enough data, as we have not considered enough variations for each of the systems. This is based on what is the reformulation in the documents. There are 3.\n\n(b) There are different scores of precision for different plots and so different order.\n\nThe last two in this system: \n(1) $s1$ has better recall. $s2$ better precision. In general $s2$ performs slightly better.",
    "The Precision/Recall based evaluation of the IR systems S1 and S2 above does not explicitly take into account the order in which the documents have been returned by the systems. For this purpose, another metric can be used: the Precision at k ($P@k$), which corresponds to the ratio of relevant documents among the top $k$ documents retrieved by a system.\n\nCompute the average $P@k$ values for k between 1 and 5 for the systems S1 and S2 above. What additional insight do these values provide in addition to the Precision/Recall curves? Based on these insights, what is your relative evaluation of the two systems? How does it compare to the $F_1$ values?\n\n\\[\n\\begin{array}{c|ccccc|c}\nk & 1 & 2 & 3 & 4 & 5 & \\text{Avg} \\\\\n\\hline\nS1 & 1 & 1/2 & 1/3 & 1/4 & 1/5 & 45/15 \\\\\n& 1 & 1 & 2 & 0 & 1 & 9/5 \\\\\n& 1 & 1/2 & 1/3 & 2/4 & 1 & 48/15 \\\\\n& 0 & 1/2 & 1/3 & 1 & 0 & 30/15 \\\\\n\\hline\nS2 & 1 & 1/2 & 1/3 & 1/4 & 1/5 & 1 \\\\\n& 1 & 1/2 & 1/3 & 1/4 & 1 & 2 \\\\\n& 1 & 1/2 & 1 & 1/4 & 0 & 1 \\\\\n& 1 & 0 & 1/3 & 1/4 & 1 & 4/3 \\\\\n\\end{array}\n\\]\n\nOne way to evaluate IR systems is to set some threshold: a returned element is relevant if it appears among the top $k$ results.\n\nAnother way to evaluate IR systems is:\n\nWhile the P/R framework does not take into account the order in which the documents are returned, $P@k$ does. Thus, it provides more relevance; we can see if a system puts more relevant documents among its top results.\n\nIn the example above, S2 is not better in terms of relevance than S1. We see systems can provide the same values for some evaluation metrics.\n\n$P@k$ can be used for other types of text-based tasks. S1 is better for web search. $k=2$ maybe for another type of search.\n\nAnother framework that has been used for performance of an NLP system is in the form of a function. This is also the case with the Precision/Recall framework:\n\n\\[\nF = \\frac{1}{\\frac{\\alpha}{P} + \\frac{1-\\alpha}{R}}\n\\]\n\nWe can combine Precision and Recall when Precision/Recall measure into a single number. If we use $F_1$, we give the corresponding equation:\n\n\\[\nF_1 = 2 \\cdot \\frac{P \\cdot R}{P + R} = \\frac{2 \\cdot P \\cdot R}{P + R}\n\\]\n\nWhen $\\alpha = 1$ emphasizes $P$; otherwise emphasizes $R$.\n\nAccuracy is the ratio of correct results provided by the system (out total number of results from the system):\n\n\\[\n\\text{Accuracy} = \\frac{\\text{correct results}}{\\text{total results}}\n\\]\n\nGiven $F \\neq \\text{Accuracy}$\n\nHere are some examples of applications that illustrate:\n\n1. Document relevance in Web Search: Precision is more important because it is annoying to refer to irrelevant documents.\n\nMore important to document precision in Web searches because a few relevant documents is better than lots of possibly pertinent documents in early stages.\n\nRecall that evaluation in legal or medical-like search where exhaustivity (of correct documents) is important.",
    "11 Evaluation\n\nExercise XXI\n\n1. Evaluation is a crucial notion for Natural Language Processing and is extensively used throughout the field.  \nGive some arguments justifying why evaluation is especially important for NLP. In particular, explain the role of evaluation when a corpus-based approach is used.\n\n2. Many evaluation metrics can be considered for various NLP tasks. The simplest one is usually the ratio between the number of times an NLP system has performed a task correctly against the total number of tasks performed.  \nGive several examples of NLP tasks for which accuracy can be used as an evaluation metric.\n\n3. In general, what property(ies) must an NLP task satisfy in order to be evaluated through an accuracy metric?\n\n4. Consider a Part-of-Speech tagger producing the following output:  \n**The/Det program/nn can/mdn with/Prep three/Num types/nn of/Prep inputs/N.*\n\na) Compute the accuracy of the tagger.  \n(What is the ratio of the performance of this system with respect to the State of the Art? Is this ratio justified?)\n\nb) What is the relation between accuracy and the error rate? In which case would you choose to use an error rate rather than accuracy?\n\n5. A commercial service announces the following information about its performance:  \n\"Our system identifies several key information in customer messages: emotions (happiness, sadness, etc.), \nproduct references, geographic information (location, region, etc.) and the urgency level of the message (high, low, neutral).  \nEach customer message is analyzed in less than 10 ms, and we are proud to announce that our system does not produce any 'breaking news' message every 1000 messages processed.\"  \nBased on your knowledge in evaluation, interpret the following:\n\na) The error rate:  \n\"The objective of 1/1000 is considered to be 'breaking news' by the system.\"  \nIn other words, producing 'breaking news' means a message is erroneously processed.\n\nb) The accuracy:  \n\"... proud to announce only two 'breaking news' messages every 1000 messages processed.\"\n\nUse the provided figures to compute the accuracy of the system.  \nWhen accuracy is used in this context, justify its use and, possibly, propose some performance improvement and compare the outcome.",
    "Another very general evaluation framework concerns those NLP tasks (e.g. Information Retrieval), where the goal of the system is to propose a set of outputs among which some will turn to be correct, while other might not. In this type of situations, the standard evaluation metrics are the Precision and the Recall.\n\nGive the formal definition of Precision and Recall and indicate some examples of NLP tasks (other than IR) that can be evaluated with the Precision/Recall metrics.\n\nConsider the following Precision/Recall curves\n\nWhat conclusions can one derive from such curves? Provide a detailed interpretation of the results.\n\nIt is often desirable to be able to express the performance of a NLP system in the form of one single number, which is not the case with Precision/Recall curves.\n\nPropose and explain a way to convert a Precision/Recall performance into a single metric defined between 0 and 1. What does such a measure express? What is it able to indicate and what is it not?\n\nFind some examples of applications that can be evaluated with the single metric derived from a Precision/Recall curve and interpret the results.\n\na. a situation where more weight should be given to Precision;\n\nb. a situation where more weight should be given to Recall;\n\nSolutions\n\na few hints:\n\n- there is no theoretical proof nor optimal in NLP\n- not a fan of non-objective evaluation: subjective opionions lead to qualitative measure\n- always thinking: when exploiting, the objective is to cheat\n  go for metric / objective\n- Precision variability over time: train shift, fix whatever reasons, e.g. change in law\n- feedback loop (propose clues where it can help the best)",
    "(a) POS tagging, but also IR, TC, IE (depends on what we actually call \"task\"). For the latter, accuracy sounds like precision (but depends once again on what we actually mean by \"task\").\n(b) a reference must be available, \"correct\" and \"incorrect\" must be clearly defined.\n\n7/10: below. Soft reliable (once usable)\n6/10: at +-0 . . . c) . . . rob (does not make any sense: they are the same (opposite, actually))\nover 10/10: ??? not the \"good\" sign:\n\n$$\n\\begin{array}{|l|l|l|}\n\\hline\n               & OK\\ Sys & KO\\ sys \\\\\n\\hline\nKO\\ Sys        & 9/10 & 993/1000 \\\\\n\\hline\n               & \\approx -0.9  & \\approx -.99 \\\\\n\\hline\n\\end{array}\n$$\n\nNo; different priori and risks; need to minimize:\n\n- an election:\none cheats the axis: the axis: the higher the axes the better; ideally (theoretical) top right corner.\nActually, by tagging or tagging well, the recall for certain: is certainly much bigger than the figure presented (we're targeting long recall).\n- search engines: we favor weighted averages ( $F_{\\beta}$ )\n- Person search (like in class)\n- Recognition of a person who calls: above and below axes: small (only a few well-chosen axes): possibility of cheating (the other way). See W3 schools on this.\n\nIf one progresses \"well,\" then these correct documents are important (implying that, if we want to handle them, they are not that many. Typically in legal situations.\n\n\n\nExercise XXII\n\nYou have been hired (by NSA?) to evaluate an email monitoring system aimed at detecting potential security issues. The targeted goal of the application is to decide whether a given email should be further reviewed or not.\n\n- Give four standard measures usually considered for the evaluation of such a system? Explain their meaning.\n- Which one may be more important in this task?\n- More / \u201cmore fair\u201d / overall performance measure of correct/incorrect only one advantage (by causing false negatives?)\n1\u2212Pr (errors)/major errors and major error / false positives / false negatives\n- to identify of frequent error: could be of covertly classified emails that should not out by another: identify false negatives that contents (person ?) false negatives =  can be handled by classifying very long: for highly trusted emails.",
    "- Recall / r true positive rate: number of correctly classified emails over number of emails classified in class by experts (in the reference) 1gnore false positives \u2022 Can be biased by classifying all documents in the most important class \n- Area under ROC Curve : Plot true positive rate vs false posi |: easy one to compare two systems\n- F Score - Harmonic mean of precision and recall; balances P and R r non single number: for more complete situation\n\n2) For three of the measures you mentioned in the previous question, what are the corresponding scores for a system providing the following results :\n\nThe main point here is to discuss WHAT to compute: keep the 4 as true class N as false or ? can also consider overall (one total score by class) and specific (one by class)\n\nnumber of correctly classified emails and overall performance : \n\nfrom there we have the following :\n\nwhat is normal and not important yet)\n\nnumber of mis-classified emails:144 thus overall error=5/14\n\nPR for C1: P=5/7:R=5/8\n\nPR for CI: P=4/1 1: R=4/7*\n\nP:Second class: R/N and swap for CI\n\nCt: PPR=I/13... and just swap for cO)\n\n\ntotal number of documents issued are: 157)\n\nnumber of total documents found\n\nThus the scores and classification errrs for C2\n\n small systems in terms of overall not looking for N and errors but\n\n PR classifying 144 missing 144 over other!!\n\n oust say: Non class Klaas is the number of cases\n\n overall e/miss-downs to):system I\n\nsystem 1  system 2  system 3\n0.3075     0.2058    0.1944\nstd dev\nmissed 0.10yy wd/loo    0.007 as 0.005 errors against old er\n\nWhich system would you fewer remarkable? with significant differences in error(ease for system 1 and ease difference)\nI compared the classification you using typical skew of wrong classification (11 to t1 such v, x seems to better other amare below class errors, not: easy to look). (for te nan errors by)\nthus I think system 1, is overall easy to spot not significant only noticing skewness).\nOtherwise opinions ?:\ngive the reader hints about reasonable starting point to work with:\nthus in my opinion difference is what 4opposite it very few :\ndifference in miss/fts between two cases is what negligible?\nthus preferred system is between 4.5 et 5.45\n\nIt should be keep in question to answer what is the std dev ofthe3op error rates assigning systems with}\n\n4/5/4/5 \n\nThus output is\n 4/1rokes\n 5ere\n5#diff;4",
    "Out of Vocabulary Forms\nSpelling Error correction\n\nJean-C\u00e9dric Chappelier\nJean-Cedric.Chappelier@epfl.ch\n\nand\n\nMartin Rajman\nMartin.Rajman@epfl.ch\n\nArtificial Intelligence Laboratory",
    "Contents\n\nOut of Vocabulary Forms\nSpelling Error Correction\n    Edit distance\n    Spelling error correction with FSA\n    Weighted edit distance",
    "Out of Vocabulary forms\n\n\u25cf Out of Vocabulary (OoV) forms matter: they occur quite frequently (e.g. $\\simeq 10\\%$ in \n    newspapers)\n\nWhat do they consist of?\n    \u2013 spelling errors: foget, summmary, usage, ...\n    \u2013 neologisms: Internetization, Tacherism, ...\n    \u2013 borrowings: gestalt, rendez-vous, ...\n    \u2013 forms difficult to exhaustively lexicalize: (numbers,) proper names, abbreviations, ...\n    \u25cf identification based on patterns is not well-adapted for all OoV forms\n\n\u261e We will focus here on spelling errors, neologisms and borrowings.",
    "for spelling errors (resp. neologisms), distortions (resp. derivations) are modelled by transformations, i.e. rewriting rules (sometimes weighted)\n\nExample:\n  - Transposition (distortion): $XY \\rightarrow YX$ [1.0]\n    where X and Y stands for variables\n  - tripling (distortion): $XX \\rightarrow XXX$ [1.0]\n  - name derivation: $ize:INF \\rightarrow ization:N$ [1.0]\n\na given lexicon (regular language) and a set of transformations define the edit space to be explored\n\nThe aim is to find the position of the OoV forms in the edit space with respect to known (lexicalized) forms (neighbourhoods, similarity, distance)",
    "Spelling errors and neologisms (2)\n\nif the transformation set is simple enough: automatic (or semi-automatic) learning of the transformation set is possible\nExamples:\n- morphological rules for Spanish\n- transformations for spelling error correction after OCR",
    "For borrowings \n\u21d2 identification of the source language\n\nwhen no large coverage lexica are available for the other languages, but only representative texts\n\nDecomposition into n-grams of characters: Example: for trigrams\n\ndribble \u2192 (dri, rib, ibb, bbl, ble)\n\nIn practice: n varies from 2 to 4\n\nFrom reference corpora, computation of a frequency matrix (n-gram \u00d7 language)\n\n\u21d2 approximation of likelihood of a word to belong to a given language\n\nExample for trigrams:\n\n\\[ P(\\text{dribble} | L) = P(\\text{dri}|L) \\cdot P(\\text{rib}|L) \\cdot P(\\text{ibb}|L) \\cdot \\ldots \\cdot P(\\text{ble}|L) \\]\n\nTrigrams for French, English, German and Spanish: 87% discrimination accuracy",
    "Likelihood versus posterior probability\n\nWhy the likelihood $P(w|L)$ rather than the posterior probability $P(L|w)$?\n\n- They are both hard to accurately model without further assumptions ($w$ belongs to a huge set!)\n- but no further simplification can be made on $P(L|w)$: $w$ is fixed (and there is nothing to gain \"simplifying\" L!)\n- $P(w|L)$ can be further simplified making assumptions on $w$\n- Using the Bayes' rule:\n  \\[\n  \\operatorname{Argmax}_L P(L|w) = \\operatorname{Argmax}_L P(w|L) \\cdot P(L)\n  \\]\n  $P(L)$ introduces the likelihood anyway! (which could then be simplified further)\n- If you can accurately estimate $P(L)$, sure, make use of it!\n- Otherwise, the least biased hypothesis (maximum entropy) is to a priori assume that all languages are all equally possible: maximizing posterior probability is then the same as maximizing likelihood",
    "Contents\n\nOut of Vocabulary Forms\n\nSpelling Error Correction\n   + Edit distance\n   + Spelling error correction with FSA\n   + Weighted edit distance",
    "Spelling error correction\n\nall strings\n\nTwo approaches:\n                     Exact                 Probabilistic\nlexicon-based\n\ncorrect forms:   lexicon   any string\nmetric:  edit distance   probability\n\nIn this lecture:\n- only a few words about the probabilistic approach (next slide)\n- mainly: exact, lexicon-based, approach\n\nIntroduction to Natural Language Processing (CS-431)                   M. Rajman\n                                                                                   J.-C. Chappelier",
    "Probabilistic approach summarized (1/2)\n\nMake (one more time!) use of $n$-grams\n\n$w$: OoV token to be corrected\n\n$c$: candidate correction, out of $C(w)$, set of possible candidates for $w$\n\n$$\\text{Argmax}_{c \\in C(w)} P(c|w) = \\text{Argmax}_{c \\in C(w)} P(c) \\cdot P(w|c)$$\n\n$P(c)$: language model ($n$-grams of words/tokens; $n = 1$ here, but could easily be extended to neighboring tokens ($n > 1$ then))\n\n$P(w|c)$: error model: edit distance and/or $m$-grams of characters",
    "Probabilistic approach summarized (2/2)\n\nA usual (unexplicit?) assumption is that $P(w|c)$ is many orders of magnitude higher for smaller edit distance (than for higher): thus closer candidate are considered first, leading to this simple algorithm:\n\n- if $C_1(w)$ is not empty, return $\\text{Argmax}_{c \\in C_1(w)} P(c)$;\n- (else) if $C_2(w)$ is not empty, return $\\text{Argmax}_{c \\in C_2(w)} P(c)$;\n- etc...\n\nwhere $C_d(w)$ is the set of candidates at distance $d$ from $w$\n\nFor more details: see http://norvig.com/spell-correct.html",
    "Edit distance\n\nalso called Levenshtein distance\n\ndistance between 2 forms\n= minimal number of transformations to change one into the other\n\nExample of transformations:\n* insertion: examp _ le \u2192 examp l e\n* deletion: examp _ le \u2192 examp _ e\n* substitution: exemp _ le \u2192 examp _ le\n* transposition: exapm _ le \u2192 examp _ le",
    "Computation of edit distance (1)\n\nNotations:\n$X_i$: ith char of string $X$\n$X_i^j$: if $i \\le j$: substring $X_i, \\ldots, X_j$; empty string otherwise\n\nExample: $X = \\text{castle}$\n$X_3 = s$\n$X_4^6 = \\text{tle}$\n$X_4^4 = \\text{t}$\n$X_1^0 = \\epsilon$\n\nComputation of the distance $D(X, Y)$ by dynamic programming:\n- step by step in a chart $m$ where each cell $m_{ij}$ contains the distance between the two substrings $X_1^i$ and $Y_1^j$:\n$$\nm_{ij} = D(X_1^i, Y_1^j)\n$$",
    "Computation of edit distance (2)\n\n$D(X^0, Y^j) = j$ \\hspace{10mm} initialization\n\n$D(X^i, Y^0) = i$\n\n$D(X_i^1, Y_j^1) = D(X_i^1, Y_{j-1}^1)$\n\n$D(X_i^1, Y_i^1) = 1 + \\min \\begin{cases}\nD(X_{i-2}^1, Y_{j-2}^1), \\\\\nD(X_{i-1}^1, Y_j^1), D(X_i^1, Y_{j-1}^1) \n\\end{cases} $\n\n$= 1 + \\min \\begin{cases}\nD(X_{i-1}^1, Y_{j-1}^1), \\\\\nD(X_{i-1}^1, Y_j^1), D(X_i^1, Y_{j-1}^1)\n\\end{cases}$\n\n\\hspace{10mm} if $X_i = Y_j$ (equality)\n\n\\hspace{10mm} else if $i \\geq 2$ and $j \\geq 2$\n\n\\hspace{10mm} and $X_{i-1} = Y_j$ and $X_i = Y_{j-1}$ (transposition, deletion, insertion)\n\n\\hspace{10mm} else (substitution, deletion, insertion)",
    "several possible ways of computing: rowwise, columnwise or diagonal",
    "Computation of edit distance (3)\n\nExample, columnwise:\n\nfor all $i$ from 0 to $|X|$ (size of $X$) do\n    $m_{i0} = i$\nfor all $j$ from 1 to $|Y|$ do\n    $m_{0j} = j$\nfor all $i$ from 1 to $|X|$ do\n    for all $j$ from 1 to $|Y|$ do\n        if $X_i = Y_j$ then\n            $m_{ij} = m_{i-1,j-1}$\n        else if $i \\ge 2$ and $j \\ge 2$ and $X_{i-1} = Y_j$ and $X_i = Y_{j-1}$ then\n            $m_{ij} = 1 + \\min \\{m_{i-2, j-2}; m_{i-1, j}; m_{i, j-1} \\}$\n        else\n            $m_{ij} = 1 + \\min \\{m_{i-1, j-1}; m_{i, j-1}; m_{i-1, j} \\}$\n\nReturn $m_{|X|, |Y|}$",
    "Edit Distance (example)\n\n$D(\\text{example}; \\text{exampel})$\n\n$D(\\text{exemple}; \\text{exampel})$\n\nIntroduction to Natural Language Processing (CS-431)",
    "Spelling error correction using a FSA\n\nProblem: approximative search of lexicalized (surface) forms \n= within a max. distance range\n\ni.e. Fault-tolerant recognition (within a regular language): \nFind all ending paths such that the corresponding string is within a distance range less than $\\theta$ of the given input string.\n\nRemark: a trie is a special case of FSA",
    "Finite-State Automata (FSA)\n\nFormally:\n\\begin{itemize}\n\\item $Q$: (finite) set of states\n\\item $\\Sigma$: (finite) alphabet\n\\item $\\delta$: arcs (mapping from $Q \\times \\Sigma$ to $Q$)\n\\item $q_0 \\in Q$: initial state\n\\item $F \\subset Q$: final states\n\\end{itemize}\n\nInterface:\n\\begin{itemize}\n\\item initialState(): provides $q_0$\n\\item $(q, a) \\rightarrow $nextAfter$(p,c)$: returns next state and character after character 'c' starting from state 'p'\n\\item Formally: returns $\\mathrm{Argmin}_a \\{(q,a) \\in Q \\times \\Sigma \\text{ such that } a > c \\text{ and } \\delta(p, a) = q\\}$\n\\item isFinal(p): are we done with $p$? Checks whether $p \\in F$ or not.\n\\end{itemize}\n",
    "Pruning criteria: cut-off edit distance\n\nTo make it useful in practice \u21d2 Fast \u21d2 good pruning\n\n$\\theta$ cut-off edit distance\n\n$D_{\\theta}(X^{n}_{1}, Y^{m}_{1}) = \\min_{I(m)} \\min_{1 \\leq i \\leq m} D(X^{i}_{1}, Y^{i}_{1})$\n\n$I(m) = \\min(n, \\max(1, m - \\theta))$\n\n$J(m) = \\min(n, \\max(1, m + \\theta))$\n\nImportant property:\n\n$D_{\\theta}(X, Y) > \\theta \\Rightarrow \\forall Z \\, D(X, Y + Z) > \\theta$",
    "Cut-off Edit Distance: example\n\n$D_{c}(X,Y) = \\min \\{2, 1, 2, 3, 4\\} = 1$",
    "Walk through a FSA within a $\\theta$ distance range\nPrefix-compatible Depth-first version\n\nInput: a string to be corrected ($X$), a lexicon in the form of a FSA and a maximal error threshold ($\\theta$)\n\nPush($\\epsilon, \\epsilon, q_0$)\nwhile Stack is not empty do\n  Pop($Z, c, p$)\n  $(q, a) =$ nextAfter($p, c$)\n  if $(q, a) \\neq \\emptyset$ then\n    Push($Z, a, p$)\n    $Y \\leftarrow Z + a$\n    if $D_{c}(X, Y) \\leq \\theta$ then\n      Push($Y, \\epsilon, q$)\n      if isFinal($q$) and $D(X, Y) \\leq \\theta$ then\n        Add $Y$ to solutions",
    "Implementation issues\n\n\u2460 Efficient computation of $D_e$ with the previously described chart :\n\u00a0\u21d4 recomputation of the last column ($m$) only\n\u00a0\u21d4 Computation of $D$ and $D_e$ in the same loop\n\n\u2461 $\\mathbf{Y} \\leftarrow \\mathbf{Z} + \\alpha$: beware (local copies, pointers etc...).\n\nSimilarly, do not naively implement \"Push($\\mathbf{Y}$, $q$)\".\n\n\u2462 In some (programming) languages: it could be worth transposing the algorithm:\n$\\mathbf{Y}$ (which is changing) for rows and $\\mathbf{X}$ for columns",
    "$X = ababa\\ _{\\text{VS.}}\\ (aba|bab)^*\\ \\text{for}\\ \\theta = 1$\n\nSolutions $\\exists^{R}$ $ababa$, $ababab$, $bababa$",
    "Contents\n\n- Out of Vocabulary Forms\n- Spelling Error Correction\n  \u2794 Edit distance\n  \u2794 Spelling error correction with FSA\n  \u2794 Weighted edit distance",
    "Limitations?\n\nweighting  \nExample: diacritics, uppercase  \n\u00e9l\u00e8ves \u2192 \u00e9l\u00e8ves  \naloves \u2192 \u00e9l\u00e8ves  \n\nspecific transformations  \nExample: typing errors  \ntupe \u2192 type  \nusqge \u2192 usage  \nmore generally: deuit \u2192 fruit  \n\nwhitespaces  \ntheothers \u2192 the others  \nothe rs \u2192 others  \n\n3 aspects of the same problem  \nSolution: generalization of the edit distance: weighted edit distance",
    "Weighted Edit Distance\n\nweighted transformations such that :\n- $C(\\text{Id}) = 0$\n- $C(f) > 0 \\quad f \\neq \\text{Id}$\n- $C(f^{-1}) = C(f)$\n- $C(f \\circ g) = C(f) + C(g)$\n\n\\[ D(X; Y) = \\min_{f:Y=f(X)} C(f) \\]\n\nIt is actually a distance on $\\Sigma^*$\n\nDifference with the preceding distance: $C(\\epsilon)$ is not necessarily the same (= 1).",
    "Remarks\n\n1. Distance on $\\sum^* \\Rightarrow \\forall X, Y, \\exists f : Y = f(X)$\n\nTrue if Ins and Del are in the transformation set\n\n2. non overlapping transformations\n\ni.e. cannot apply a transformation to the result of the previous transformation\n\nCounter-Example: $ba \\xrightarrow{\\text{Transp}} ab \\xrightarrow{\\text{Sub}} ac$",
    "Coherence Constraints\n\n\"Semantic Integrity\":\n- $C(Del) + C(Ins(x)) > C(Sub(x))$\n- $C(Split) < C(Ins(x)) \\Rightarrow C(Merge) < C(Del)$\n- $C(Transp) < C(Ins(x)) + C(Del)$\n\nIntroduction a new $f$ such that $f = o_i f_i$ is useful if and only if\n$$\nC(f) < \\sum_{i} C(f_i)\n$$",
    "Weighted Edit Distance: computation\n\n\\[ \\text{supp}(f) \\]\n\n\\[ X : \\text{x...x} \\quad \\text{xxx} \\quad \\text{x...x} \\]\n\n\\[ Y : \\text{yyy} \\quad \\text{yyyy} \\]\n\n\\[ \\text{min1}  \\]\n\n\\[ \\text{min2}  \\]\n\n\\[ \\text{min2} = \\min_f \\left[ \\min1(f) + C(f) \\right] \\]\n\n(min1 and min2 are the values stored in the chart)",
    "Weighted Edit Distance: computation (2)\n\n\\[ D(X^0_i, Y^0_j) = j \\quad \\text{initialization} \\]\n\\[ D(X^i_1, Y^0) = i \\]\n\\[ D(X_i^i, Y_j^j) = D(X_{i-1}^i, Y_{j-1}^j) \\quad \\text{if } X_i = Y_j \\text{ (equality)} \\]\n\\[ = C(f) + \\min \\{ \\min_i (f) \\} \\quad \\text{for all applicable transformations } f \\text{ of the same weight} \\]\n\\[ = \\cdots \\quad \\text{for all possible weights.} \\]\n\nIncreasing \\(C(f)\\)\n\nThe optimization lies in the grouping of similar cases: same weight and compatible transformations (Example: previously Transp and Sub were incompatible because \\(C(\\text{Transp}) < 2 C(\\text{Sub})\\). But each of them is compatible with Del and Ins.\n\nNote: \\(\\min_i (f) \\) is the set of all the minimal values for all possible \\(f\\) at this point; they shall, of course, already be computed at this point (loop condition)",
    "Example\n\nD(example;exemple)\n\n\\[\n\\begin{array}{c|c|c|c|c|c|c|c}\n& e & x & a & m & p & l & e \\\\\n\\hline\ne & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\\\\nx & 1 & 0 & 1 & 2 & 3 & 4 & 5 \\\\\na & 2 & 1 & 1 & 2 & 3 & 4 & 5 \\\\\nm & 3 & 2 & 2 & 1 & 2 & 3 & 4 \\\\\np & 4 & 3 & 3 & 2 & 1 & 2 & 3 \\\\\nl & 5 & 4 & 4 & 3 & 2 & 1 & 2 \\\\\ne & 6 & 5 & 5 & 4 & 3 & 2 & 1 \\\\\n\\end{array}\n\\]\n\nD(ex\u00e9mple;exemple)\n\n\\[\n\\begin{array}{c|c|c|c|c|c|c|c}\n& e & x & e & m & p & l & e \\\\\n\\hline\ne & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\\\\nx & 1 & 0 & 1 & 2 & 3 & 4 & 5 \\\\\n\u00e9 & 2 & 1.1 & 2.1 & 3.1 & 4.1 & 5.1 & 6.1 \\\\\nm & 3 & 2 & 2.1 & 2.1 & 3.1 & 4.1 & 5.1 \\\\\np & 4 & 3 & 3.1 & 3.1 & 3.1 & 4.1 & 5.1 \\\\\nl & 5 & 4 & 4.1 & 4.1 & 4.1 & 4.1 & 5.1 \\\\\ne & 6 & 5 & 5.1 & 5.1 & 5.1 & 5.1 & 5.1 \\\\\n\\end{array}\n\\]\n\n$C(\\text{\u00e9}\\rightarrow e)=0.1$",
    "Keypoints\n\nOne has to handle out of vocabulary forms\n\nEdit (Levenshtein) distance, weighted edit distance\n\nSpelling error correction with FSA",
    "References\n\nK. Oflazer, *Error-tolerant Finite State Recognition with Applications to Morphological Analysis and Spelling Correction*, *Computational Linguistics*, Volume 22, Number 1, 1996.\n\nSection 8.2 in M. Rajman editor, *Speech and Language Engineering*, EPFL Press, 2006.\n\nSections 3.10 and 3.11 in D. Jurafsky and J. H. Martin, *Speech and Language Processing*, Prentice Hall, 2008 (2nd edition).\n\nSection 3.3 in C. D. Manning, P. Raghavan and H. Sch\u00fctze, *Introduction to Information Retrieval*, Cambridge University Press, 2008.",
    "Textual Data Analysis\n\nJ.-C. Chappelier\n\nLaboratoire d'Intelligence Artificielle\nFacult\u00e9 I&C",
    "Objectives of this lecture\n\nBasics of textual data analysis:\n- classification\n- visualization: dimension reduction / projection\n\n(useful for a good understanding/presentation of classification/clustering results)",
    "Is this course a Machine Learning Course?\n\nNLP makes use of Machine Learning (as would Image Processing for instance)\nbut good results require:\n   \u25ba good preprocessing\n   \u25ba good data (to learn from), relevant annotations\n   \u25ba good understanding of the pros/cons, features, outputs, results, ...\n\nThe goal of this course is to provide you with specific knowledge about NLP.\n\nNew:\n\nThe goal of this lecture is to make some link between general ML and NLP. This lecture is worth deepening with some real ML course.",
    "Introduction: Data Analysis\n\nWHAT does Data Analysis consist in?\n\n\"to represent in a live and intelligible manner the (statistical) informations, simplifying and summarizing them in diagrams\"\n\n        [L. Lebart]\n\nclassification (regrouping in the original space)\n\nvisualization: projection in a low-dimension space\n\nClassification/clustering consists in regrouping several objects in categories/clusters (i.e. subsets of objects)\n\nVisualization: display in an intelligible way the internal structures of data (documents here)",
    "Contents\n\n1. Classification\n   1. Framework\n   2. Methods (in general)\n   3. Presentation of a few methods\n   4. Evaluation\n\n2. Visualization\n   1. Introduction\n   2. Principal Component Analysis (PCA)\n   3. Multidimentional Scaling",
    "Supervized/unsupervized\n\nThe classification can be\n\n\u25ba **supervized** (strict meaning of classification):  \n&nbsp;&nbsp;&nbsp;&nbsp;Classes are known *a priori*  \n&nbsp;&nbsp;&nbsp;&nbsp;They are usually **meaningful** for the user\n\n\u25ba **unsupervized** (called: *clustering*):  \n&nbsp;&nbsp;&nbsp;&nbsp;Clusters are based on the inner structures of the data (e.g. neighborhoods)  \n&nbsp;&nbsp;&nbsp;&nbsp;Their meaning is really more dubious\n\n**Textual** Data Analysis: relate documents (or words) so as to...  \n&nbsp;&nbsp;&nbsp;&nbsp;**structure (supervized)** / **discover structure (unsupervized)**",
    "Classify what?\n\nWHAT is to be classified?\n\nStating point: a chart (numbers) representing in a way or another a set of objects\n- continuous values\n- contingency tables: cooccurrence counts\n- presence/absence of attributes\n- distance/(dis)similarity (square symetric chart)\n\n$N$ \"row\" objects (or \"observations\") $x^{(i)}$ characterized by $m$ \"features\" (columns) $x_j^{(i)}$\n\nTwo complementary points of view:\n1. $N$ points in $\\mathbb{R}^m$\n2. $m$ points in $\\mathbb{R}^N$\n\nNot necessarily the same metrics:\n```\nobjects similarities              vs.             feature similarity\n```",
    "Classify what?\n\n$x_{j}^{(i)}$ \u2014 \"importance\" of feature j for object i",
    "Textual Data Classification\n\n\u25ba What is classified?\n    \u25ba authors (1 object = several documents)\n    \u25ba documents\n    \u25ba paragraphs\n    \u25ba \"words\"/tokens (vocabulary study, lexicometry)\n\n\u25ba How to represent the objects?\n    \u25ba document indexing\n    \u25ba choose the textual units that are meaningful\n    \u25ba choice of the metric/similarity\n\npreprocessing: \"unsequentialize\" text, suppress (meaningless) lexical variability\n\nFrequently: lines = documents, columns = \"words\" (tokens, words, n-grams)\n\nthe former two \"visions\" are complementary",
    "Textual Data Classification: Examples of applications\n\n- Information Retrieval\n- Open-Questions Survey (polls)\n- emails classification/routing\n- client survey (complaints analysis)\n- Automated processing of adds\n- ...",
    "Most of classification techniques use distance measures or (dis)similarities: matrix of the distances between each data points: $\\frac{N(N-1)}{2}$ values (symetric with null diagonal)\n\ndistance:\n1. $d(x, y) \\ge 0$ and $d(x, y) = 0 \\Longleftrightarrow x = y$\n2. $d(x, y) = d(y, x)$\n3. $d(x, y) \\le d(x, z) + d(z, y)$\n\ndissimilarity: 1 and 2 only",
    "Some of the usual metrics/similarities\n\nEuclidian:\n\n$d(x, y) = \\sqrt{\\sum_{j=1}^{m} (x_j - y_j)^2}$\n\ngeneralized ($p \\in [1, ...\\infty]$):\n\n$d_p(x, y) = \\left(\\sum_{j=1}^{m} (x_j - y_j)^p\\right)^{1/p}$\n\n$\\chi^2$:\n\n$d(x, y) = \\sum_{j=1}^{m} \\lambda_j \\left(\\frac{x_j}{\\sum_j y_j} - \\frac{y_j}{\\sum_j y_j}\\right)^2$\n\nwhere $\\lambda_j = \\frac{\\sum_j x_j y_j}{\\sum_j y_j}$ depends on some reference data $(u_i, i = 1...N)$",
    "Some of the usual metrics/similarities\n\n- cosine (similarity) :\n\n\\[ \n\\mathcal{J}(x, y) = \\frac{\\sum_{j=1}^m x_j y_j}{\\sqrt{\\sum_{j=1}^m x_j^2} \\sqrt{\\sum_{j=1}^m y_j^2}} \\quad \\frac{x}{\\lVert x \\rVert} \\cdot \\frac{y}{\\lVert y \\rVert}\n\\]\n\n- for probability distributions :\n\n  - KL-divergence:\n  \\[\n  D_{\\text{KL}}(x, y) = \\sum_{j=1}^m x_j \\log \\left(\\frac{x_j}{y_j} \\right)\n  \\]\n\n  - Jensen-Shannon divergence:\n  \\[\n  J_S(x, y) = \\frac{1}{2} \\left( D_{\\text{KL}} \\left( x, \\frac{x + y}{2} \\right) + D_{\\text{KL}} \\left( y, \\frac{x+y}{2} \\right) \\right)\n  \\]\n\n  - Hellinger distance:\n  \\[\n  d(x, y) = d_{\\text{euclid}} (\\sqrt{x}, \\sqrt{y}) = \\sqrt{\\sum_{j=1}^m (\\sqrt{x_j} - \\sqrt{y_j})^2}\n  \\]",
    "Computational Complexity\n\nVarious complexities (depends on the method), but typically:\n$$ \\frac{N(N-1)}{2} $$ distances\n\n$$ m $$ computations for one single distance\n\u27f9 complexity in $ mN^2 $\n\nCostly: $ m \\simeq 10^3, N \\simeq 10^4 \\Rightarrow 10^{11} $ !!",
    "Classification as a mathematical problem\n\nsupervised:\nfunction approximation\n$f(x_1, \\ldots, x_m) = C_k$\ndistribution estimation:\n$P(C_k | x_1, \\ldots, x_m)$ or $P(x_1, \\ldots, x_m | C_k)$\nparametric: multi-Gaussian, maximum likelihood, Bayesian inference, discriminative analysis\nnon-parametric: kernels, K nearest neighbors, LVQ, neural nets (Deep Learning, SVM)\ninference:\nif $x_i = \\ldots$ and $x_j = \\ldots$ (etc.) then $C = C_k$\n$\\Leftrightarrow$ decision trees\n\nunsupervised (clustering):\n(local) minimization of a global criterion over the data set",
    "Many different classification methods\n\nHow to choose? \u2192 Several criteria\n\nTask specification:\n\u25ba supervised\n\u25ba unsupervised\n\n\u25ba hierarchical\n\u25ba non hierarchical\n\n\u25ba overlapping\n\u25ba non overlapping (partition)\n\nModel choices:\n\u25ba generative models ($P(X, Y)$)\n\u25ba discriminative models ($P(Y|X)$)\n\u25ba parametric\n\u25ba non parametric (= many parameters)\n\u25ba linear methods (Statistics)\n\u25ba trees (GOFAI)\n\u25ba neural networks",
    "Classification methods: examples\n\n\u25ba supervised\n  \u25ba Naive Bayes\n  \u25ba K-nearest neighbors\n  \u25ba ID3 \u2013 C4.5 (decision tree)\n  \u25ba Kernels, Support Vector Machines (SVM)\n  \u25ba Gaussian Mixtures\n  \u25ba Neural nets: Deep Learning, SVM, MLP, Learning Vector Quantization\n  \u25ba ...\n\n\u25ba unsupervised\n  \u25ba K-means\n  \u25ba dendrograms\n  \u25ba minimum spanning tree\n  \u25ba Neural net: Kohonen\u2019s Self Organizing Maps (SOM)\n  \u25ba ...\n\nThe question you should ask yourself:\nWhat is the optimized criterion?",
    "Bayesian approach\n\nProbabilitic modeling: the classification is made according to $P(C_k|x)$: an object $x^{(i)}$ is classified in category\n\n\\[\n\\operatorname*{argmax}_c P(C|x = x^{(i)})\n\\]\n\nDiscriminative: model $P(C_k|x)$ directly;\n\nGenerative: assume we know $P(C_k)$ and $P(x|C_k)$,\nthen using Bayes formula:\n\n\\[\nP(C_k = x^{(i)}) = \\frac{P(x = x^{(i)}| C_k) \\cdot P(C_k)}{P(x = x^{(i)})} = \\frac{P(x^{(i)}| C) \\cdot P(C)}{\\sum_c P(x^{(i)}|C) \\cdot P(C)}\n\\]\n\n$P(C)$: \"prior\"\n\n$P(C_k|x)$: \"posterior\"\n\n$P(x|C)$: \"likelihood\"\n\nIn practice, those distributions are hardly known.\nAll the difficulty consists in \"learning\" (estimating) them from samples making several hypotheses.",
    "Naive Bayes\n\nSupervised generative probabilistic (non overlapping) model:\n\nClassification is made using the Bayes formula\n\n\\[P(C)\\]\n\nis estimated directly on a typical example\n\nWhat is \"naive\" in this approach is the computation of \\[P(x|C)\\]\n\nHypothesis: feature independance:\n\n\\[P(x|C) = \\prod_{j=1}^{m} p(x_j | C)\\]\n\nThe \\[p(x_j | C)\\] (a priori much fewer than the \\[P(x|C)\\]) are estimated on typical examples (learning corpus).\n\nIn the case of Textual Data: features = indexing terms (e.g. lemmas)\n\n* This hypothesis is most certainly wrong but good enough in practice",
    "(multinomial) Logistic regression\n\nSupervised discriminative probabilistic (non overlapping) model:\nDirectly model $P(C|x)$ as:\n\n\\[ \nP(C|x) = \\prod_{j=1}^{m} f(x_j, C) = \\frac{\\exp \\left( \\sum_{j=1}^{m} w_C,j x_j \\right)}{\\sum_{C'} \\exp \\left( \\sum_{j=1}^{m} w_{C', j} x_j \\right)}\n\\]\n\nwhere $w_{C, j}$ is a parameter, the \"weight\" of $x_j$ for class C\n($x_j$ being here some numerical representation of j-th indexing term: 0\u20131, frequency, log-normalized, ...).\n\nThe parameters $w_{C, j}$ can be learned using various approximation algorithms (e.g. iterative or batch; IGS, IRLS, L-BGFS, \u2026), for instance:\n\n\\[ \nw_{C, j}^{(t+1)} = w_{C,j}^{(t)} + \\alpha \\left( \\delta_{C, \\hat{C_n}} - P(C|x_n) \\right) x_{nj}\n\\]\n\nwith $\\alpha$ a learning parameter (step strength/speed) and $\\delta_{C, \\hat{C}_n}$ the Kronecker delta function between class $C$ and expected class $\\hat{C}_n$ for sample input $x_n$.",
    "K nearest neighbors \u2013 Parzen window\n\nnon hierachical non overlapping classification\n\nK nearest neighbors:\nvery simple:\nclassify a new object according to the majority class in its K nearest neighbors (vote).\n(no learning phase)\n\nParzen window:\nsame idea, but the votes are weighted according to the distance to the new object",
    "Dendrograms\n\nIt's a bottom-up hierarchical clustering\nStarts form a distance chart between the $N$ objects\n\n\u2460 Regroup in one cluster the two closest \"elements\" and consider the new cluster as a new element\n\n\u2461 compute the distances between this new element and the others\n\n\u2462 loop in \u2460 while there are more than one element\n\n\ud83e\udc46 representation in the form of a binary tree\n\nComplexity: $\\mathcal{O}(N^2 \\log N)$\n",
    "Dendrograms: \"linkage\" scheme (1/2)\n\"regroup the two closest elements\"\nex: closest?\n\nTwo questions:\n1. How to define the distance between two clusters (two sets of elements)?\n(based on the distances between the elements)\n\\[ d(A,B) = ? \\]\n\n2. How to (efficiently) compute distance between a former cluster and a (new) merge of two clusters?\n(based on the former distances between clusters)\n\\[ d(C,(A+B)) = ? \\]",
    "Dendrograms: \"linkage\" scheme (2/2)\n\n\"regroup the two closest elements\" >>> closest? \n\nLet \\( A \\) and \\( B \\) be two subclusters: what is their distance?\n(Lance-Williams algorithm)\n\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\nmethod & definition \\; D(A, B) = & merging \\; D(A \\cup B, C) = \\\\\n\\hline\nsingle linkage: & \\min_{x \\in A; y \\in B} d(x, y) & \\min (D(A, C), D(B, C)) \\\\\n\\hline\ncomplete linkage: & \\max_{x \\in A; y \\in B} d(x, y) & \\max (D(A, C), D(B, C)) \\\\\n\\hline\naverage linkage: & \\frac{1}{|A| \\cdot |B|} \\sum_{x \\in A; y \\in B} d(x, y) & \\frac{|A| \\cdot D(A, C) + |B| \\cdot D(B, C)}{|A| + |B|} \\\\\n\\hline\n\\end{array}\n\\]",
    "K-means\n\nnon hierarchical non overlapping clustering\n\n1. choose a priori the number of clusters: $K$\n2. randomly draw $K$ objects as clusters' representatives (\"clusters' centers\")\n3. partition the objects with respect to the $K$ centers (closest)\n4. recompute the $K$ centers as the mean of each cluster\n5. loop in 3 until convergence (or any other stopping criterion).",
    "K-means (2): example with \\( K = 2 \\)\n\nRandom choice of initial \u201cmeans\u201d\n\nAssignment of classes\n\nRe-computation of means\n\nRe-assignment of classes\n\nRe-computation of means then re-affectation of classes\n\nETC...",
    "K-means (3)\n\ncluster representatives:\nmean (centre of gravity): $R_k = \\frac{1}{N_k} \\sum_{x \\in C_k} x$\n\nThe algorithm is convergent because the intra-class variance can only decrease:\n\n$$V = \\sum_{k=1}^{K} \\sum_{x \\in C_k} p(x)(x,R_j)^2$$\n\n$$(p(x): \\text{ probability of the objects})$$\n\nBUT it converges to a local minimum; improvements:\n- stable clusters\n- Deterministic Annealing\n\nOther methods similar to K-means:\n- having several representatives\n- compute representatives at each binding of an individual\n- choose representatives among the objects",
    "about Word Embeddings & Deep Learning\n\n\"Word embedding\":\n\u25b8 numerical representation of words (see \"Information Retrieval\" lecture)\n\u25b8 a.k.a. \"Semantic Vectors\", \"Distributional Semantics\"\n\u25b8 objective: relative similarities of representations correlate with syntactic/semantic similarity of words/phrases.\n\ntwo key ideas:\n1. representation(composition of words) = vectorial-composition(representations(word))\n   for instance: representation(document) = $\\sum_{word \\in document}$ representation(word)\n\n2. remove sparseness, compactify representation: dimension reduction\n\n\u25b8 have been around for a long time (renewal these days with the \"deep learning buzz\")\n   Harris, Z. (1954), \"Distributional structure\", Word 10(2):146-162.\n   Firth, J.R. (1957), \"A synopsis of linguistic theory 1930-1955\", Studies in Linguistic Analysis. pp 1-32.",
    "Word Embedings: different techniques\n\n\"Many recent publications (and talks) on word embeddings are surprisingly oblivious of the large body of previous work [...]\"\n(from https://www.gavagai.se/blog/2015/09/30/a-brief-history-of-word-embeddings/)\n\nMain techniques:\n\u25ba co-occurrence matrix; often reduced (LSI, Hellinger-PCA)\n\u25ba probabilistic/distribution (DSIR, LDA)\n\u25ba shallow (Mikolov) or deep-learning Neural Networks\n\nThere are theoretical and empirical correspondences between these different models (see e.g. Levy, Goldberg and Dagan (2015), Pennington et al. (2014), \u00d6stlerlund et al. (2015)).",
    "about Deep Learning\n\n\u25b6 there is NO need of deep learning for good word-embedding\n\u25b6 not all Neural Network models (NN) are deep learners\n\u25b6 models: convolutional NN (CNN) or recurrent NN (RNN, incl. LSTM)\n\u25b6 still suffer the same old problems: overfitting and computational power\n\na final word, from Michel Jordan (IEEE Spectrum, 2014):\n\n\"deep learning is largely a rebranding of neural networks, which go back to the 1980s.\nThey actually go back to the 1960s; it seems like every 20 years there is a new wave\nthat involves them. In the current wave, the main success story is the convolutional\nneural network, but that idea was already present in the previous wave.\"\n\nWhy such a reborn now?\n\u27a1 more data (user-data pillage), more computational power (GPUs)",
    "about Embeddings: some references\n\nSome softwares:\nword2vec, glove, tensorflow, gensim, mallet, http://www.wordvectors.org/\n\nSome papers:\nO. Levy, Y. Goldberg and I. Dagan (2015), \u201cImproving distributional similarity with lessons learned from word embeddings\u201d, Journ. Trans. ACL, vol. 3, pp. 211-225.\n\u00d6stendorf et al. (2015) \u201cFactorization of Latent Variables in Distributional Semantic Models\u201d, proc. EMNLP.\nJ. Pennington, R. Socher, and C. D. Manning (2014) \u201cGloVe: Global Vectors for Word Representation\u201d, proc. EMNLP.\nT. Mikolov et al. (2013), \u201cDistributed Representations of Words and Phrases and their Compositionality\u201d, proc. NIPS.\nR. Lebret and R. Collobert (2013), \u201cWord Embeddings through Hellinger PCA\u201d, proc. EACL.\n\nmore about this topic in two weeks",
    "Classification: evaluation\n\n\u25ba classification (supervised): evaluation is \"easy\" \u2192 test corpus (some known samples kept for testing only)\n\u25ba clustering (unsupervised): objective evaluation is more difficult: what are the criteria?\n\n(supervised) Classification: REMINDER (see \"Evaluation\" lecture)\n\u25ba Check IAA (if possible)\n\u25ba Measure the misclassification error on the test corpus\n    Ex: really separated from the learning set (and also from the validation set, if any)\n    Ex: criteria: confusion matrix, error rate, ..\n\u25ba Is the difference in the results statistically significant?",
    "Clustering (unsupervised learning) evaluation\nThere is no absolute scheme with which to evaluate clustering, but a variety of ad-hoc measures from diverse areas/point-of-view.\n\nFor $K$ non overlapping clusters (with objects having a probability $p$), standard measures include:\n\nIntra-cluster variance (to be minimized):\n$$ V = \\sum_{k=1}^K \\sum_{x_j \\in C_k} p(x_j) d(x, x_j)^2 $$\n\nInter-cluster variance (to be maximized):\n$$ V = \\sum_{k=1}^K \\left( \\sum_{x_j \\in C_k} p(x_j) \\right) d(x_{kk}, x)^2 = \\sum_{k=1}^K p(C_k) d(x_{kk}, x)^2 $$\n\nThe best way is to think to how you want to assess the quality of a clustering w.r.t. your needs:\nusually: high intra-cluster similarity and low inter-cluster similarity\n(But what does \"similar\" mean?...)\nOne way also is to have manual evaluation of the clustering.\nNote: and if you already have a gold-standard with classes: why not use (supervised) classification in the first place??\n(rather than using a supervised corpus to assess unsupervised methods...)",
    "\"Visualization\"\n\nVisualize: project/map data in 2D or 3D\n\nMore generaly: techniques presented in this section are to lower the dimension of data\n\n$\\Rightarrow$ go form N-D to n-D with $n < N$ or even $n \\ll N$\n\n$\\Rightarrow$ usualy means: go from sparse to dense representation\n\n________________________ --- complementary\n\nvisualization: projection in a low-dimension space\n\nclassification: regrouping in the original space\n\nWhich one to start with, depends on your data/application (can even loop between the two)",
    "Several approaches\n\n  - Simple methods (but poorly informative): ordered list, \"thermometer-like\", histograms\n\n  - some of the classification methods can be used:\n      - use/display the classes\n      - e.g. dendrograms with minimal spanning tree\n\n  - Linear and non-linear projections/mappings\n    (projection: in the same space as original data\n    mapping: in some other space)",
    "Several Representation Criteria\n\nA good visualization technique combines several representation criteria:\n\u25b6 positions (relative, absolute) \n  (from far the most used criterion, but do not forget the others!)\n\u25b6 colors\n\u25b6 shapes\n\u25b6 others... (cf Chernoff's faces)",
    "Linear projections\n\nProjections on selected sub-spaces of the original space\n\n\u25ba Principal Components Analysis (PCA ) [Pearson 1901]:\n    object\u2013feature chart (continuous values)\n    feature similarity: correlations\n    object similarity: distance on the feature space\n\n\u25ba Correspondance Analysis:\n    contingency tables\n    row/column symetry (features)\n    $\\chi^2$ metric\n\nEx: Singular value decomposition",
    "Principal Components Analysis (PCA)\n\nInput: a matrix $M$ objects (rows) \u2013 features (columns) (of size $N \\times m$ with $N > m$)\n\ncentered: $M_e = x(i) - \\bar{x}$\n\nSingular value decomposition (SVD) of $M$:\n\neigenvalue decomposition of $MM^T$ (i.e. the covariance matrix (multiplied by $(N-1)$))\n\n$M = U\u039bV^T$\n\n$\u039b$ diagonal, ordered: $\\lambda_1 \\ge \\lambda_2 \\ge ... \\ge \\lambda_m \\ge 0$\n\n$U$ of size $N \\times m$ with orthogonal columns and $V$ orthogonal, of size $m \\times m$",
    "PCA (2)\n\nThe \"principal components\" are the columns of $M V$ (or of $V$)",
    "PCA (3)\n\nProjection in a low dimension space:\n\n\\[\n\\tilde{M} = U_q \\Lambda_q V_q^t\n\\]\n\nwith $q < m$ and $X_q$ matrices reduced to only the q first singular values\n\n\\[\n\\tilde{M}\n\\]\n\nis the better approximation of rank $q$ of $M$.\n\n\"better approximation\" w.r.t. several criteria:\n\n$L_2$ norm, biggest variance (trace and determinant of the covariance matrix), Frobenius norm, ...\n\nThis means that the subspace of the first $q$ principal components is the best linear approximation of dimension $q$ of the data, \"best\" in the sense of the distance between the original data points and their projection.",
    "PCA (4): how to choose dimension $q$?\n\n\u25ba sometimes imposed by the application (e.g. for visualization $q = 2$ or 3)\n\n\u25ba otherwise: make use of the spectrum :\n  \u25b8 simple: choose $q$ where there is a \u201cbig step\u201d in $\\lambda_i / \\sum_j \\lambda_j$ plot (a.k.a. \u201cCattell\u2019s scree plot\u201d or \u201cexplained variance\u201d):\n\n  \u25b8 advanced: see:\n    Tom Minka, Automatic choice of dimensionality for PCA, NIPS, 2000.\n    \\href{https://tminka.github.io/papers/pca/}{https://tminka.github.io/papers/pca/}",
    "PCA (4)\n\nSimple and efficient approximation method using sub-spaces (i.e. linear manifolds)\n\nWeaknesses:\n1) linear method (precisely what makes it easy to use!)\n2) since the methods maximizes the (co)variance, it is strongly dependant on the measure units used for the features\n\nIn practice, except when the variance is really what has to be maximized, the data are renormalized before: it is then the correlation matrix which is decomposed rather than the (co)variance.",
    "\"Projection Pursuit\"\n\nLinear projection methods on a low dimension space (1, 2 ou 3) but maximizing another criterion than (co)variance.\n\n\u21d2 No analytic solution: numerical optimization (iteration and local convergence)\n\u21d2 The criterion has to be easily computable\n\nSeveral possible criteria:\nentropy, dispersion, higher momenta (>2), divergence to normal distribution, ...",
    "linear vs. non-linear\n\nPCA:\n\nnon-linear method:",
    "Non-linear Methods\n\n- \"principal curve\" [Hastie & Stuetzle 89]\n- ACC (neural net) [Demartines 94]\n- Non-linear PCA (NLPCA) [Karhunen 94]\n- Kernel PCA [Sch\u00f6lkopf, Smola, M\u00fcller 97]\n- Gaussian process latent variable models (GPLVM) [Lawrence 03]",
    "Multidimensional Scaling (MDS)\nuses the chart of distances/dissimilarities between objects\n\nSammon Mapping: criterion:\n\\[ \nC(d, \\tilde{d}) = \\sum_{x\\neq y} \\frac{\\left( d(x,y) - \\tilde{d}(x,y) \\right)^2}{d(x,y)} = \\sum_{x\\neq y} \\text{weight}(x,y) \\cdot \\text{error}(x,y) \n\\]\n\nwhere $d$ is the dissimilarity in the original object space, and $\\tilde{d}$ the dissimilarity in the projection space (e.g. Euclidian)\n\u261e more accurate representation of objects that are close\n\nMore recent alternatives:\n\n\ud83d\udd39 t-SNE (t-Distributed Stochastic Neighbor Embedding)\n[L.J.P. van der Maaten and G.E Hinton; Visualizing High-Dimensional Data Using t-SNE; Journal of Machine Learning Research 9(Nov):2579-2605, 2008]\n\n\ud83d\udd39 UMAP (Uniform Manifold Approximation and Projection for Dimension Reduction)\n[L. McInnes, Healy J., N. Saul and L. Grossberger; UMAP: Uniform Manifold Approximation and Projection; Journal of Open Source Software 3(29):861 (2018).]",
    "Keypoints\n\n\u25ba Many classification/clustering techniques (coming from different fields)\nKnow the main characteristics, criteria\nKnow at least two methods (e.g. Naive Bayes and K-means), that could be useful as baseline in any case.\n\u25ba A priori choice of \"the best method\" is not easy:\nwell define what you are looking for, means (time, samples, ...) you have access to\n\u25ba It\u2019s even more difficult for Textual Data \u27f9 preprocessing is really essential (lemmatization, parsing, ...)\n\u25ba Pay attention to use a proper methodology: good evaluation protocol, statistical test, \u2026\n\u25ba Classification/Clustering and Projection methods are complementary in (Textual) Data Analysis\n\u25ba Use several representation/classification criteria\n\u25ba Visualization: Focus on usefulness first:\nWhat does it bring/shows to the user? How is it useful?\nPay attention not overwhelming the user...",
    "References\n\nF. Sebastiani, *Machine learning in automated text categorization*, ACM Comput. Surv, 34(1): 1-47, 2002.\n\nC. Bishop, *Pattern Recognition and Machine Learning*, Springer, 2006.\n\nB.D. Ripley, *Pattern recognition and Neural Networks*, Cambridge University Press, 1996.\n\nV. Vapnik, *The Nature of Statistical Learning Theory*, Springer, 2000.\n\nB. Sch\u00f6lkopf & A. Smola, *Learning with Kernels*, MIT Press, 2002.",
    "Words? Tokens!\n\nJ.-C. Chappelier\n\nLaboratoire d'Intelligence Artificielle\nFacult\u00e9 I&C",
    "Objectives of this lecture\n\n- Where to start NLP processing chain from? Words?\n- How to handle lexica (list of words) electronically\n- $n$-gram models",
    "Lexical level\n\nWhat is the input of a NLP system? Where to start from?\n\u261e  it's a sequence of characters\n\nCharacters however seems a bit too low-level to play the role of the atomic constituents of the language\n\u261e  lack of generalization\n\nWhat should then be the atomic entities of NLP?\nWhat should basic core information be related to?\n\u261e  This is a difficult question! (Still open?)\n(phonological words? syntactic words? concepts?)\n\nHowever, a general agreement is to focus on words.\n\nIt\u2019s precisely the role of the lexical level:\nfirst to identify, and then associate required information with the words.",
    "What is a word??\n\nThe notion of \u201ccorrect word\u201d is difficult to define, especially out of context/application:\n\n\u201ccredit card\u201d, \u201cSan Francisco\u201d, \u201cco-teaching\u201d: 1 or 2 words?\n\nIs \u201cJohn\u2019s\u201d from \u201cJohn\u2019s car\u201d one single word?\nOr are they two words? Is \u201c \u2019s\u201d a word?\nSimilarly, what about \u201cI\u2019m\u201d, \u201cisn\u2019t\u201d, ...?\n\nAnd it\u2019s even worse for languages having agglutinative morphology (e.g. German), or languages without explicit delimiter (e.g. Thai):\nsee the \u201cMorphology\u201d lecture.\n\nAnd what about: \u201cI called SC to ask for an app,\u201d or \u201cC U\u201d\ndefinition of words depends on the application/context\nShould carefully think about it!!\n\nIf your goal is to build a lexicon as portable/universal as possible:\nchoose minimal tokens and let a properly designed tokenizer (or even further modules) glue these tokens in a way that fits each specific application.",
    "Word vs. tokens\n\nTentative definitions (may change here and there):\n\n\u25ba Word (also sometimes called \"type\"): an element of the vocabulary; \ni.e. we _a priori_ define what words have to be.\nReminder: depends on the application!\n\n\u25ba Token: ambiguously defined as (definition may vary):\n  1. either\n    - a (continuous) sequence of non-separator characters\n      \u25ba requires the definition of \"separator\"\n      \u25ba is a separator a token in itself? (may vary)\n      \u25ba does not fundamentally solve the former problems, only postpone them\n  2. or \n    - either an instance of a type or a (continuous) sequence of non-separator characters\n      \u25ba this confuses the problem even more.\n\nWe'd prefer to stick to definition 1 (and conceptually separate words from tokens). \nAnyway: don't bother so much about an (impossible?) absolute definition but be aware of the problem!\n\nPractice: _M. O'Connel payed \\$12,000 (V.T.A. not included) with his credit card._",
    "Key points\n\n1. The notion of words is (inherently?) ambiguous and depends on the application.\n\n2. Tokens are more useful in practice but may also depend on the application\n\n!!! be sure all your NLP modules do indeed share the same definition of what tokens are!!! (otherwise, it's really a way to shoot yourself in the foot)",
    "Lexicon\n\nWhat for?\n\n\u27f6 to recognize and classify \"correct words\" of the language (as we want to define them)\n\nfor \"incorrect\" forms \u27f6 specific treatments (see next lecture)\n\nWhat content?\n\nList of records structured in fields, describing the correct forms, with all the related relevant information, e.g.:\n\n- surface form: boards\n- Part-of-Speech tag: $N_p$ (= Noun plural)\n- lemma: board$N$ (\u2192 a surface form and a PoS tag)\n- probability: $3.2144e-05$\n- pronunciation: $b\\ oa\\ r\\ d\\ z$\n- etc...\n\n\u27f6 set of \"records\" identified by a reference (e.g. a database with primary keys)",
    "Field representation\n\n\u261e External vs. Internal structure (i.e. serialization vs. memory representation)\n\nInternal structure: suited for an efficient implementation of the two access methods (by value and by reference) for each field\n\u261e not necessarily the same for all fields\n\u261e not even necessarily the same for the two methods of a given field",
    "field           by_value access   $f^o$         reference  \nvalue            by_reference access  $f^o$\n\n\n\\begin{array}{|c|c|c|c|c|c}\n\\hline\nreference & surface form & PoS & lemma & prononc. & ... \\\\\n\\hline\n25 & board & Ns & board#Ns & b o a r d z & \\\\\n26 & boards & Np & board#Ns & b o a r d z & \\\\\n34 & fly & Vx & fly#Vx & f l a\u026a & \\\\\n35 & fly & Ns & fly#Ns & f l a\u026a & \\\\\n... & & & & & \\\\\n\\hline\n\\end{array}\n\nby_value$_{surface}$(fly) =  {34,35}\n\nby_ref$_{PoS}$(26)  $\\rightarrow  N_P$\n\nAll PoS tags for \"fly\" :\n         \nby_ref$_{PoS}$ (by_value$_{surface}$(fly)) =  $\\{V_X, N_S\\}$",
    "Surface forms: implementation\n\nSurface form field implementation:  \nFormally: list of strings...  \n...which do share many substrings in common (morphology of the language)  \n\nImplementations:\n- Lists/Tables\n- Hash Tables\n- Tries (= lexical trees)\n- Finite-State Automata (FSA)\n- Transducers (FST)",
    "List/Tables implementation\n\nneeds an order on the values (e.g. alphabetical order)\n\n- easy and fast to implement\n- efficient by-reference access function ($\\mathcal{O}(1)$)\n- access in $\\mathcal{O}(\\log N)$, insertion in $\\mathcal{O}(N)$ ($N$ = number of records)\n- large size (replication of all (sub-)strings)\n\nby-reference access function: list of pointers ordered by reference",
    "Hash Tables\n\nH(board)=3212\n\n341   fly    [34, 35]\n342   tree   [7432]\n3212  car    [11, 12]\n      zulu   [548143]\n      board  [25]\n\n- easy and fast to implement\n- complexity of access and insertion difficult to predict (collisions)\n- no by-reference access-function (\u2192 extra inversion table)\n- large size (replication of all (sub-)strings)",
    "Implementation of methods for lexica with FSA\n\nFinite-State Automata (reminder?):\n* Equivalence between DFSA and NFSA (with and without \\epsilon)\n* Equivalence between regular expressions and DFSA\n* For a given regular language, existence of a unique minimal DFSA\n* Can be numbered so as to do monotone minimal perfect hashing (by-value and by-reference access functions)\n\nPros and cons:\n\n- $+ \\;- \\;\\cdot \\;$ regexp (e.g. numbers, dates, ...)\n- $+ \\;- \\;\\cdot \\;$ access in $\\sigma(1)$ \n- $+\\;- \\;\\cdot \\;$ optimal size (minimal number of states)\n- $+\\;- \\;\\cdot \\;$ Implementation\n- $+\\;- \\;\\cdot \\;$ Update (insertion or deletion of strings)",
    "Summary of surface-form field implementations\n\n\\[\n\\begin{array}{|l|c|c|c|}\n\\hline\n & \\text{existence test} & \\text{by\\_value access} & \\text{by\\_ref access} \\\\\n\\hline\n\\text{lists/tables} & \\checkmark & \\checkmark & \\checkmark \\\\\n\\text{hash-tables} & \\checkmark & (\\checkmark) & \\checkmark \\\\\n\\text{Tries} & \\checkmark & \\checkmark &  \\textemdash \\\\\n\\text{Tries + labeled leaves} & \\checkmark & \\checkmark & \\checkmark \\\\\n\\text{Tries with invertion}^1 & \\checkmark & \\checkmark & \\checkmark \\\\\n\\text{FSA} & \\checkmark & \\checkmark & \\textemdash \\\\\n\\text{FSA + numeration} & \\checkmark & \\checkmark & \\checkmark \\\\\n\\text{Transducers} & \\checkmark & \\checkmark & \\checkmark \\\\\n\\hline\n\\end{array}\n\\]\n\n1. e.g. bidirectional links or inversion codes\n",
    "Language models\nBack to start:\nWhat is the input of a NLP system? Where to start from?\n\ud83d\udd04 it\u2019s a sequence of characters \u279d sequence of tokens\n\nHow to choose among sequences (of characters/tokens)?\nHow to decide which sequence is the best (e.g. comparing two)?\n\nExamples:\n\u25ba tokenization: fullcapacitytocarryon (coming from OCR) vs. full capacity to carry on\n\u25ba language identification: rendez-vous vs. gestalt\n\u25ba spelling-error correction: error vs. eror\n\u25ba collocations: real car wheel vs. real estate market\n\nOne approach: probabilities: n-grams of characters and n-grams of tokens\n(for that approach: the more probable = the best)\n\nNotes:\n\u25ba all modern neural NLP techniques actually focus on n-grams, estimating various\nkinds of related probabilities\n\u25ba probabilization of n-grams of tokens a.k.a. \"language model\"\n\nEPFL",
    "n-gram approach\n\nConsider sequence of xs (characters, tokens, ...)\n\nmake use of (n-1)-order Markov assumption: $P(x|x_{1} \\cdots x_{i-1}) = P(x|x_{i-n+1} \\cdots x_{i-1})$\n\nto end up with:\n\n\\[ P(x_{1} \\cdots x_{N}) = P(x_{1} \\cdots x_{n-1}) \\prod_{i=n}^{N} P(x_{i}|x_{i-n+1} \\cdots x_{i-1}) \\]\n\nUse this as a score to compare sequences ($n \\geq 2$):\n\n\\[ \\frac{P(x_1 \\cdots x_{i+n-1})}{\\frac{N-n+1}{N-n+1} P(x_1 \\cdots x_{n-2})} \\]\n\n$P(x_{i} \\cdots x_{i+n-1})$: parameters estimated on some corpus\n\nReminder: $P(x_i \\cdots x_{i+n-2}) = \\sum_{x} P(x_i \\cdots x_{i+n-2}x)$",
    "Probabilities: Notation (abuse)\n\n$X, Y, \\ldots, X_1, \\ldots$: (discreate) random variables\n\n$x, y, \\ldots, x_1, \\ldots$: values \n\n$x \\in X$: values for $X$\n\n$P(x)$: same as $P(X = x)$ when $X$ is clear by context\n\n$P(X)$: distribution (set of all $P(X = x)$ for all $x \\in X$)\n\n(Note: for continuous variables, $P(X)$ denotes in fact the density function $dP(X)$)\n\n$P(x|y)$: same as $P(X = x|Y = y)$ when $X$ and $Y$ are clear by context\n\n$P(X|Y)$: distribution knowing $Y = y$ (set of all $P(X = x|Y = y)$ for all $x \\in X$)\n\n$P(X|Y)$: shouldn\u2019t make much sense\n\n$P(x,y)$: same as $P(X = x, Y = y)$ when $X$ and $Y$ are clear by context, typically $P(X = x, Y = y)$\n\nNotice: $P(X_1 = x_1, X_2 = x_2)$ is truly the same as $P(X_2 = x_2, X_1 = x_1)$, \nwhereas $P(x_1, x_2)$ is not the same as $P(x_2, x_1)$:\n$P(X_1, X_2)$ is $P(X_1 = x_1, X_2 = x_2)$, whereas $P(x_2, x_1)$ is $P(X_1 = x_2, X_2 = x_1)$!",
    "Probabilities: quick (and dirty) reminder\n\n$\\sum_{x_i \\in x_1,\u2026,x_N} P(x_1,\u2026,x_N) = 1 \\quad (\\text{and } P(x_1,\u2026,x_N) \\geq 0)$\n\nAdditivity (a.k.a. marginalization): ($M < N$)\n$$P(x_1,\u2026,x_M) = \\sum_{x_{M+1} \\in x_{M+1},\u2026,x_{N}} P(x_1,\u2026,x_M,x_{M+1},\u2026,x_N)$$\n\nConditional probabilities: (for $P(y_1,\u2026,y_N) \\neq 0$)\n$$P(x|y_1,\u2026,y_N) = \\frac{P(x,y_1,\u2026,y_N)}{P(y_1,\u2026,y_N)}$$\n\nNote: thus\n$$\\sum_{x_i \\in x_{M+1},\u2026,x_{N}} P(x_1,\u2026,x_M|x_{M+1},\u2026,x_N) = 1$$\n\nChain rule:\n$$P(x_1,\u2026,x_N) = P(x_1) \\prod_{i=2}^{N} P(x_i|x_1,\u2026,x_{i-1})$$\n\nBayes' rule: (for $P(x) \\neq 0$ and $P(y) \\neq 0$)\n$$P(y|x) = \\frac{P(x|y) \\cdot P(y)}{P(x)}$$",
    "Assume $n = 3$ (trigrams):\n\n\\[ P(erro) = P(err) \\cdot P(r|r) \\cdot P(ro|rr) \\]\n\n\\[ = P(err) \\cdot \\frac{P(rrr)}{P(rr)} \\cdot \\frac{P(rro)}{P(rrr)} \\]\n\n\\[ P(erro) = P(err) \\cdot \\frac{P(rro)}{P(rr)} \\]\n\nParameters: trigrams probabilities: $P(aaa), \\ldots, P(err), \\ldots, P(rro), \\ldots, P(zzz)$\nbigrams probabilities are simply sums of trigrams\u2019: $P(ro) = \\sum_{x} P(roX)$",
    "Caveat!\n\nDon't compare probabilities of sequences of different sizes!!\n\n$P(x_1, \\ldots, x_m)$ and $P(x_1, \\ldots, x_N)$ usually DO NOT COMPARE\n\nThey are in two differents probalized spaces:\n\n$$\\sum_{x_1, x_2, \\ldots, x_N} P(x_1, \\ldots x_N) = 1$$\n\nfor a given $N$: in fact, $P(x_1, \\ldots, x_N)$ is a $P(x_1, \\ldots \\text{size} = N)$\n\nFor instance, do not compare $P(\\text{real estate})$, $P(\\text{real estate market})$ and $P(\\text{real estate increase})$\n\nThen how compare them if we have to?\n\n$\\Rightarrow$ put (all of them) in a broader model in which they make sense\n\nNote: we here made the assumption that $P(x_1, \\ldots, x_m, x_N | N)$ is not a decent model (for instance that $P(\\text{real estate market}) = \\sum_w P (\\text{real estate market } w)$ is of no interest for the considered application [since: the shorter, the higher])",
    "Estimation (= model learning)\n\nWhere do the $P(x_{1} \\cdots x_{n} | x_{i-n+1} \\cdots x_{i-1})$ come from?\n=> from learning corpus\n\nSimplest: maximum-likelihood estimate:\n\n$$\\hat{P}(x_{1} \\cdots x_{n}) = \\frac{\\#(x_{1} \\cdots x_{n})}{N_{n}}$$\n\nwhere $\\#(y)$ is the count of $y$ (= the number of times $y$ appears in the corpus) and $N_{n}$ is the size of the corpus = the total number of n-grams:\n\n$$N_{n} = \\sum_{x_{1} \\cdots x_{n}} \\#(x_{1} \\cdots x_{n})$$",
    "Better estimates (1/2)\n\nMaximum-likelihood estimates (MLE) are the simplest ones but suffer from unseen events: unseen rare events have a 0 frequency, thus a 0 probability MLE ($\\Leftrightarrow$ overfitting)\n\nThat could be OK in domains where the number of zeros isn\u2019t huge (e.g. maybe for categorization), but is not for language modeling.\n\nReminder: power laws\n\nwhich 0 are \u201creal zeros\u201d and which ones are simply unseen, but possible, events?\nDifficult question!",
    "Better estimates (2/2)\n\nSeveral approaches to better estimate unseen rare events (a.k.a smoothing methods):\n\n- change prior (a.k.a. \"additive smoothing\")\n  - leads to special cases known as Lidstone smoothing, Laplace smoothing or add-one smoothing\n\n- add a new word (e.g. \"<UNKNOWN>\") and estimate (held-out) probabilities accordingly\n\n- backoff smoothing: fall-back on smaller $n$: increase the chance to observe events by decreasing the context-size\n\n- interpolation: mix $n$-grams with $(n-1)$-grams, $(n-2)$-grams, etc. the mixing coefficients can be fixed or adaptative (learned on held-out data)\n\n- Good-Turing smoothing: use the count of hapaxes (events seen only once) to improve estimates of probabilities of unseen events\n\n- Kneser-Ney smoothing: considered as the most effective for $n$-grams; it's a mixture of discounting and interpolation\n\n- let's in-depth explain the first one",
    "Additive smoothing (properly explained; 1/2)\n\nn-grams is a probabilistic model, the parameters $\\theta$ of which are the probabilities of the various n-grams (i.e. $\\theta$ is a constraint vector of dimension $D = |X|^n$, with $|X|$ the number of possible values for X)  \nA (partially) Bayesian view on learning $\\theta$ from a corpus $\\mathcal{C}$ leads to estimating as:\n\n$$\n\\hat{\\theta} = \\argmax_\\theta P(\\theta | \\mathcal{C}) = \\argmax_\\theta P(\\theta)P(\\mathcal{C} | \\theta)\n$$\n\n$P(\\mathcal{C} | \\theta)$ (the likelihood of a corpus, represented here as a \"bag-of-n-grams\", i.e. by its n-grams counts) follows a multinomial law (the parameters of which are $\\theta$).\nIt's conjugate prior is the Dirichlet distribution; so let's model $P(\\theta)$ by a Dirichlet distribution (it's thus a probability density on probabilities):\n\n$$\nP(\\theta | \\alpha) = r(\\Gamma) \\prod_{i=1}^D \\frac{\\theta_i^{\\alpha_i - 1}}{\\Gamma(\\alpha_i)} \\quad (\\alpha > 0)\n$$\n\nwhere $\\Gamma(x)$ represents the \"gamma function\".",
    "Additive smoothing (properly explained; 2/2)\n\nThus the posterior $P(\\theta|x)$ is itself a Dirichlet distribution, which is maximized (MAP) for\n\n\\[\n\\hat{P}(x_1 \\cdots x_n) = \\frac{\\#(x_1 \\cdots x_n) + \\alpha_{x_1 \\cdots x_n} - 1}{N_n + (\\sum_{x_1 \\cdots x_M} \\alpha_{x_1 \\cdots x_M}) - D}\n\\]\n\nIn a \"more Bayesian view\", however, the expected value of $\\hat{P}(x_1 \\cdots x_n)$ (under posterior Dirichlet distribution) is:\n\n\\[\n\\hat{P}(x_1 \\cdots x_n) = \\frac{\\#(x_1 \\cdots x_n) + \\alpha_{x_1 \\cdots x_n}}{N_n + \\sum_{x_1 \\cdots x_M} \\alpha_{x_1 \\cdots x_M}}\n\\]\n\nand moreover (predictive distribution):\n\n\\[\nP(x_1 \\cdots x_n'|x', \\alpha) = \\hat{P}(x_1 \\cdots x_n) = \\frac{\\#(x_1 \\cdots x_n) + \\alpha_{x_1 \\cdots x_n}}{N_n + \\sum_{x_1 \\cdots x_M} \\alpha_{x_1 \\cdots x_M}}\n\\]",
    "Example (bigrams among two letters)\n\n$\\mathcal{E} = ababababababababab = \\left\\{ (ab, 7), (ba, 6), (aa, 2), (bb, 0) \\right\\}$\n\nMLE:\n\n$P(ab) = \\frac{7}{15} \\quad P(ba) = \\frac{6}{15} \\quad P(aa) = \\frac{2}{15} \\quad P(bb) = 0$\n\nPredictive distribution with uniform Dirichlet prior $\\alpha_i = 0.5$ for all $i \\in \\left\\{ ab, ba, aa, bb \\right\\}$:\n\n$P(ab \\mid \\mathcal{E}, \\alpha) = \\frac{7.5}{17} \\quad P(ba \\mid \\mathcal{E}, \\alpha) = \\frac{6.5}{17} \\quad P(aa \\mid \\mathcal{E}, \\alpha) = \\frac{2.5}{17} \\quad P(bb \\mid \\mathcal{E}, \\alpha) = \\frac{0.5}{17}$",
    "Additive smoothing = Dirichlet prior\n\nSo additive smoothing techniques\n\n$$ P(x_{1}, \\ldots, x_{n^{\\prime}} | e, \\alpha) = \\frac{#(x_{1}, \\ldots, x_{n}) + \\alpha x_{1}, \\ldots, x_{n}}{N_{h} + \\sum \\alpha x_{1}, \\ldots, x_{n}} $$\n\nresult from a Bayesian predictive distribution with a Dirichlet-prior assumption: \n\n* $\\alpha_{i} = 0$ (impossible): MLE\n* $\\alpha_{i} = 1$: \"Laplace smoothing\", a.k.a. \"add-one smoothing\"\n**  = don\u2019t use that for linguistic corpora (see next slides and reference [7])\n* $\\alpha_{i} < 1$: makes sense with power laws (a priori $\\theta$ lies \"close to the borders\")\n\nBut what does $\\alpha_{i}$ actually represent (intuitively)?\n\nThe components of $\\alpha$ represent the relative importance of each component of $\\theta$. For $\\alpha$ smaller than 1, the distribution tends to \"sharply increase\" (in other words, to discretize) to the maximum $\\alpha_{i}$ values.\nMore details in appendix for those interested.",
    "Examples of $\\alpha$ parameter in 2D\n\nFor $D = 2$ (i.e. only 1 free parameter; $n = 1$, $|X| = 2$)",
    "Examples of $\\alpha$ parameter in 3D\n\nFor $D = 3$ (i.e. 2 free parameters; $n = 1$, $|X| = 3$)\n\n$\\alpha = (6,12,12)$\n\n$\\alpha = (1,1,1)$\n\n$\\alpha = (0.6,0.7,0.8)$",
    "Keypoints\n\n- Usage of lexica: recognition and classification of language forms (words)\n- Principal functions of lexica: existence test, by value and by reference access functions to access needed information related to words\n- Tokenization may be difficult and should be properly designed/defined\n- $n$-gram approach (both on chars and on tokens) is a really effective tool for many tasks\n- Smoothing techniques for $n$-gram probabilities estimates",
    "References\n\n[1] C. D. Manning & H. Sch\u00fctze, *Foundations of Statistical Natural Language Processing*, chapters 4.2, 5 and 6, MIT Press, 1999 (6th printing 2003).\n\n[2] D. Jurafsky & J. H. Martin, *Speech and Language Processing*, chapters 2, 3 and 4, Prentice Hall, 2009 (2nd ed.).\n\n[3] E. Roche, Y. Schabes, *Finite-state Language Processing*, pp. 1-14, A Bradford Book, 1997.\n\n[4] D. E. Knuth, *The Art of Computer Programming, V. 1, Fundamental Algorithms*, pp. 232-424, Addison-Wesley, 1997.\n\n[5] M. G. Ciura, S. Deorowicz, *How to squeeze a lexicon*, Software \u2013 Practice and Experience, vol. 31, pp. 1077-1090, 2001.\n\n[6] H. Ney, U. Essen and R. Kneser, *On structuring probabilistic dependences in stochastic language modelling*, Computer Speech & Language, 8 (1): 1\u201338, jan . 1994.\n\n[7] W. Gale & K. Church, *What's Wrong with Adding One?*, in N. Oostdijk & P. de Haan (eds.), Corpus-Based Research into Language: In honour of Jan Aarts, pp. 189-200, Rodopi (1994).\n\n[8] S. F. Chen & J. Goodman, *An empirical study of smoothing techniques for language modeling*, Computer Speech and Language 13, 359\u2013394 (1999; first published in ACL proceedings in 1996).",
    "Appendix: more about Dirichlet distribution (1/3)\nA D-dimensional Dirichlet distribution parametrized by $\\alpha$ (a D-sized vector, the components of which are all strictly positive) is a distribution over the simplex with dimension D \u2013 1 such that:\n\\[ P(\\theta|\\alpha) = \\frac{\\Gamma(\\sum_{i=1}^{D} \\alpha_i)}{\\Gamma(\\alpha) \\prod_{i=1}^{D} \\Gamma(\\alpha_i)} \\theta_i^{\\alpha_i - 1} \\]\nThe components of $\\alpha$ represent the relative importance of each component of $\\theta$, the average point being \\(\\bar{\\theta} = \\frac{\\alpha}{\\sum \\alpha}\\).\n\nTheir sum $S = \\sum_{i=1}^{D} \\alpha_i$ (inversely) influences the variance around this average point:\n\n\\[ \\text{Var}(\\theta) = (\\text{diag}(\\alpha) - \\bar{\\theta} \\bar{\\theta}^T)/(S + 1) \\]\n\nWhen one of the $\\alpha_i$ approaches 1, the corresponding $\\theta$-component approaches 0 (unless they all are equal to 1).\n\nFor $\\alpha_i$ smaller than 1, the distribution tends to \u201csharply increase\u201d (in other words, to discretize) to the maximum $\\alpha_i$ values.\n\nWhen $\\alpha_i$ is larger than 1 the mode (i.e., the most probable point) is given by:\n\n\\[ \\hat{\\theta} = \\frac{S - D (S \\theta \\hat{1}) - 1}{S - D (\\alpha_1 - 1)} \\]",
    "more about Dirichlet distribution (2/3)\n\nSeveral probability densities of a single Dirichlet dimension (\u201cbeta law\u201d) corresponding to different parameters $\\alpha$: (11,22), (5,10), $(\\frac{3}{2},3)$, (1,2), (2,1), $(1,\\frac{1}{3})$, and (1,1). Note how the $S = \\alpha_1 + \\alpha_2$ parameter (inversely) influences the concentration of the probability density and how, when the components are lower than 1, the distribution tends to \u201csharply increase\u201d at the edges.",
    "more about Dirichlet distribution (3/3)\n\nSeveral Dirichlet probability densities on the 2-simplex (smaller left triangle) corresponding to different $\\alpha$ parameters. Bluer zones indicate higher values.\nNote how the $S = \\alpha_1 + \\alpha_2 + \\alpha_3$ parameter (inversely) influences the concentration of the probability density. It should also be noticed how when one of the $\\alpha$ components approaches 1 the corresponding density tends to 0 and when the components are smaller than 1 the distribution \"sharply increases\" (on (0,0) in the bottom right figure, in other words concentrates on $\\theta = (0.0,1)$).\n\n$\\alpha = (6, 12, 12) = 30 \\hspace{15pt} (2, 4, 4)$.\n\n$\\hat{\\theta} = (-.18, .41, .41)$\n\n$\\alpha = (2, 4, 4) = 10 \\hspace{15pt} (2, 4, 4)$\n\n$\\hat{\\theta} = (-.14, .43, .43)$\n\n$\\alpha = (1.1, 2.2, 2.2) = 5.5 \\hspace{15pt} (2, .4, .4)$\n\n$\\hat{\\theta} = (-.04, .48, .48)$\n\n$\\alpha = (0.6, 0.8, 0.99) = 2.39 \\hspace{15pt} (.25, .43, .31)$\n\n$\\hat{\\theta} = (0, 0, 1)$",
    "A Primer on Hidden Markov Models\n\nJ.-C. Chappelier & M. Rajman\n\nLaboratoire d'Intelligence Artificielle\nFacult\u00e9 I&C",
    "Objectives/Contents\n\nObjective:\n* Introduce fundamental concepts necessary to use HMMs for PoS tagging\n\nContents:\n* recap example\n* HMM models, three basic problems\n* Forward-Backward algorithms\n* Viterbi algorithm\n* Baum-Welch algorithm",
    "Example: PoS tagging with HMM\n\nSentence to tag: Time flies like an arrow\n\nExample of HMM model:\n\n- PoS tags: $\\mathfrak{T} = \\{ Adj, Adv, Det, N, V, \\ldots \\}$\n- Transition probabilities:\n  $$\n  \\begin{align*}\n  P(N|Adj) &= 0.1, \\ P(V|N) = 0.3, \\ P(Adj|N) = 0.01, \\ P(Adv|V) = 0.005, \\\\\n  P(Det|Adv) &= 0.1, \\ P(Det|V) = 0.3, \\ P(N|Det) = 0.5\n  \\end{align*}\n  $$\n  (plus all the others, such that stochastic constraints are fulfilled)\n\n- Initial probabilities:\n  $$\n  \\begin{align*}\n  P_{T1}(Adj) &= 0.01, \\ P_{T1}(Adv) = 0.001, \\ P_{T1}(Det) = 0.1, \\ P_{T1}(N) = 0.2, \\ P_{T1}(V) = 0.003 \\ (\\ldots)\n  \\end{align*}\n  $$\n\n- Words: $\\mathfrak{L} = \\{ an, arrow, flies, like, time, \\ldots \\}$\n\n- Emission probabilities:\n  $$\n  \\begin{align*}\n  P(time|t) &= 0.1, \\ P(limes|Adj) = 0.01, \\ P(time|V) = 0.05, \\\\\n  P(flies|N) &= 0.1, \\ P(flies|V) = 0.01, \\ P(like|Adv) = 0.005, \\ P(like|V) = 0.1, \\ (\\ldots) \\\\\n  P(an|Det) &= 0.3, \\ P(arrow|N) = 0.5\n  \\end{align*}\n  $$",
    "Example: PoS tagging with HMM (cont.)\n\nIn this example, 12 = 3 \u22c5 2 \u22c5 2 \u22c5 1 \u22c5 1 analyzes are possible, for example:\n\n$$P(\\text{time/N flies/V like/Adv an/Det arrow/N}) = 1.13 \\cdot 10^{-11}$$\n$$P(\\text{time/Adj flies/N like/V an/Det arrow/N}) = 6.75 \\cdot 10^{-10}$$\n\nDetails of one such computation:\n\n\\[\n\\begin{align*}\nP(\\text{time/N flies/V like/Adv an/Det arrow/N}) &= P(\\text{N}) \\cdot P(\\text{time}|\\text{N}) \\cdot P(\\text{V}|\\text{N}) \\cdot P(\\text{flies}|\\text{V}) \\cdot P(\\text{Adv}|\\text{V}) \\cdot P(\\text{like}|\\text{Adv}) \\cdot P(\\text{Det}|\\text{Adv}) \\cdot P(\\text{an}|\\text{Det}) \\cdot P(\\text{N}|\\text{Det}) \\cdot P(\\text{arrow}|\\text{N}) \\\\\n&= 2e - 1 \\cdot 1e - 3 \\cdot 1e - 1 \\cdot 1e - 2 \\cdot 5e - 3 \\cdot 5e - 1 \\cdot 1e - 3 \\cdot 1e - 5e - 1 \\cdot 5e - 1 \\\\\n&= 1.13 \\cdot 10^{-11}\n\\end{align*}\n\\]\n\nThe aim is to choose the most probable tagging among the possible ones (e.g. as provided by the lexicon)",
    "Markov Models\n\nMarkov model: a discrete-time stochastic process T on $\\mathcal{T} = \\{t^{1}, \\ldots, t^{m}\\}$ satisfying the Markov property (limited conditioning):\n\n\\[ P(T_{i} \\mid T_{1}, \\ldots , T_{i-1}) = P(T_{i} \\mid T_{i-k}, \\ldots , T_{i-1}) \\]\n\n$k$: order of the Markov model\n\nIn practice $k = 1$ (bigrams) or 2 (trigrams) rarely 3 or 4 (\u2192 learning difficulties)\n\nFrom a theoretical point of view: every Markov model of order k can be represented as another Markov model of order 1 (introduce $Y_{i} = (T_{i-k+1}, \\ldots, T_{i})$).\n\nVocable:\n\n\\[ P(T_{1}, \\ldots, T_{n}) = P(T_{1}) \\cdot P(T_{2} \\mid T_{1}) \\cdot \\ldots \\cdot P(T_{i} \\mid T_{i-1}) \\]\n\ninitial probabilities   transition probabilities",
    "Hidden Markov Models (HMM)\n\nWhat is hidden?\n\u261e The model itself (i.e. the state sequence)\n\nWhat do we see then?\n\u261e An observation $y$ related to the state (but not the state itself)\n\nFormally:\n- a set of states $\\mathcal{C} = \\{C_1, ..., C_m\\}$\n- a transition probabilities matrix $A: a_{ij} = P(Y_{t+1} = C_j | Y_t = C_i)$, shorten $P(C_j | C_i)$\n- an initial probabilities vector I: $I_i = P(Y_1 = C_i)$ or $P(Y_1 = C_i | \\text{\u2018start\u2019})$, shorten $P(C_i)$\n- a set of \u201cobservables\u201d $\\Sigma$ (not necessarily discrete, in general)\n- $m$ probability densities on $\\Sigma$, one for each state (emission probabilities): $B_i(o) = P(X_t = o | Y_t = C_i)$ (for o \u2208 \u03a3), shorten $P(o | C_i)$\n\nExample for PoS-tagging:\n\nPoS tags \n$\\{t^1, ..., t^m\\}$\n$P(T_{t+1} | T_t)$\n$P(T_t)$\nwords\n$\\mathcal{W} = \\{a^1(t^1), ..., a^{l^1}(t^1)\\}$\n$P(w | T_t)$",
    "Simple example of HMM\n\nExample: a cheater tossing from two hidden (unfair) coins\n\nStates: coin 1 and coin 2: $\\mathcal{S} = \\{1,2\\}$\n\ntransition matrix $\\mathbf{A} = \\begin{pmatrix} \n0.4 & 0.6 \\\\\n0.9 & 0.1 \n\\end{pmatrix}$\n\nobserved: $\\sum = \\{H,T\\}$\n\nemission probabilities:\n$\\mathbf{B}_1 = (0.49, 0.51)$ and $\\mathbf{B}_2 = (0.85, 0.15)$\n\ninitial probabilities $\\mathbf{I} = (0.5, 0.5)$\n\n$\\Rightarrow 5$ free parameters: $\\mathbf{I}_1, \\mathbf{A}_{11}, \\mathbf{A}_{21}, \\mathbf{B}_1(H), \\mathbf{B}_2(H)$\n\nObservation: HTHTHTTHHTHTTHTTHHTTHHTHTTHHT\n\n (Hidden) sequence of states: 211211211211211121121121211121211121211121",
    "HMM example for PoS tagging\n\n$\\to N \\leftarrow \\to \\to$\n\n$P(w|N)$\n\n$\\to \\leftarrow$\n\n$\\to \\leftarrow$\n\n$\\to \\leftarrow$\n\n$\\to \\leftarrow$\n\nV $\\to N \\leftarrow \\to Adj \\leftarrow \\to \\leftarrow \\to Det \\leftarrow \\to$\n\n$P(w|Adj)$\n\n$P(w|Adv)$\n\n$P(w|Det)$\n\n$P(w|V)$",
    "The three basic problems for HMMs\n\nProblems: Given an HMM and an observation sequence $w = w_1 \\ldots w_n$, \n\n\ud83d\udd04 given the parameters $\\theta$ of the HMM, what is the probability of the observation sequence:\n$$P(w|\\theta)$$\nApplication: Language Identification\n\n\ud83d\udd04 given the parameters $\\theta$ of the HMM, find the most likely state sequence $T = T_1, \\ldots, T_n$ that produces $w$:\n$$\\underset{T}{\\arg\\max} \\ P(T|w, \\theta)$$\nApplication: PoS Tagging, Speech recognition\n\n\ud83d\udd04 find the parameters that maximize the probability of producing $w$:\n$$\\underset{\\theta}{\\arg\\max} \\ P(\\theta|w)$$\nApplication: Unsupervised learning",
    "Remarks:\n\n1. $\\theta = (I, A, B)$\n\n$$= (I_1, \\ldots, I_m, A_{11}, \\ldots, A_{1m}, \\ldots, A_{nm}, B_1(w_1), B_1(w_2), \\ldots, B_1(w_L), B_2(w_1), \\ldots, B_2(w_L), \\ldots, B_m(w_L))$$\n\ni.e. $(m-1)+(L-1)+m+(m-1)m=(m+L+L-1)-1$ free parameters\n\n(because of sum-to-1 contrains), where $m=|\\mathcal{I}|$ and $L=|\\mathcal{L}|$ (in the finite case, \notherwise $L$ stands for the total number of parameters used to represent $ \\mathcal{L})$\n\n2. Supervised learning (i.e $\\arg \\max P(\u03b8 | w, T)$) is easy\n\n3. WARNING! There is a difference between $P(\u03b8 | w)$ and $P(\u03b8, \\mathcal{I} | w)$!\nThe model $ \\mathcal{I}$ is supposed to be known here, but its parameters $\\theta$:\n\ni.e. the HMM design is already done (number of states, alphabet) only the parameters are missing.",
    "Contents\n\n- HMM models, three basic problems\n- Forward-Backward algorithms\n- Viterbi algorithm\n- Baum-Welch algorithm",
    "Computation of $P(w|\\theta)$\n\nComputation of $P(w|\\theta)$ is mathematically trivial:\n\n\\[ P(w|\\theta) = \\sum_{T} P(w, T|\\theta) = \\sum_{T} P(w|T, \\theta) \\cdot P(T|\\theta) \\]\n\nPractical limitation: complexity is $o(n m^T)$ \u27f9 exponential!\n\nPractical computation: forward/backward algorithms \u27f6 complexity is $o(n m^2)$",
    "Forward-Backward algorithms\n\n\"forward\" variable : $\\alpha_t(i) = P(w_1,..., w_t, T_t = i\\mid \\theta) \\quad t \\in \\mathcal{T}$\n\niterative computation: $\\alpha_{t+1}(i') = B_{w_{t+1}}(i')\\sum_{t_j \\in \\mathcal{T}} (\\alpha_t(j) \\cdot A_{ji})$\n\n$\\alpha_1(i) = B_{t}(w_i) \\cdot i_t$\n\n\n\"backward\" variable : $\\beta_t(i) = P(w_{t+1},..., w_n\\mid T_t = i, \\theta)$\n\niterative computation: $\\beta_{t-1}(j) = \\sum_{t_{i'} \\in \\mathcal{T}} (\\beta_t(j) \\cdot A_{ji'} \\cdot B_{t_{i}}(w_t))$\n\n$\\beta_n(t) = 1 \\text{ (by convention, practical considerations)}$\n\nComputation in $\\mathcal{O}(nm^2) \\rightarrow$ efficient solutions to \"first problem\" :\n\n$P(w\\mid \\theta) = \\sum_{t_j \\in \\mathcal{T}} \\sum_{t_i \\in \\mathcal{T}} (P(w,\\ T_n = t) = \\sum_{t _ {i}} \\alpha _ t (i) $\n\n$P(w\\mid \\theta) = \\sum_{t_j \\in \\mathcal{T}} \\sum_{t_i \\in \\mathcal{T}} (\\alpha_t(i) \\cdot \\beta_t(i)) \\quad \\text{ } \\forall 1 \\leq i\\leq n$",
    "Forward-Backward algorithms (2)\n\nThere exist also \"forward-backward\" variable : $\\gamma(t) = P(T_t = i \\; | \\; \\mathbf{w}, \\boldsymbol{\\theta})$\n\n$$\n\\gamma(t) = \\frac{P(\\mathbf{w}, T_t = i \\; | \\; \\boldsymbol{\\theta})}{P(\\mathbf{w} \\; | \\; \\boldsymbol{\\theta})} = \\frac{\\alpha_i(t) \\cdot \\beta_i(t)}{\\sum_{i' \\in \\mathcal{S}} \\alpha_{i'}(t') \\cdot \\beta_{i'}(t')}\n$$\n\nuseful later for other algorithms",
    "Contents  \n\n* HMM models, three basic problems\n* Forward-Backward algorithms\n* Viterbi algorithm\n* Baum-Welch algorithm",
    "Viterbi algorithm (1)\n\nEfficient solution to the \"second problem\": find the most likely sequence of states T (knowing w and the parameters $\\theta$) : $\\underset{T}{\\arg \\max} \\; P(T|w,\\theta)$\n\n$\\Rightarrow$ maximize (in T) $P(T,w|\\theta)$.\n\n\"The\" lattice = temporal unfolding of all possible walks through the Markov chain\n\nSentence",
    "Viterbi algorithm (2)\n\nLet $\\rho_t(t) = \\max_{T_1,...,T_{t-1}} P(T_1,..., T_{t-1}, T_t = t, w_1,..., w_t | \\theta)$\n\nWe are looking for $\\max_{t \\in \\mathcal{S}} \\rho_T(t)$\n\nIt's easy (exercise) to show that \n$\\rho_t(t) = \\max_{t'} P(t' | t', \\theta) P(w_t | t', \\theta) \\rho_{t-1}(t')$\n\nfrom which the following algorithm comes:\n\nfor all $t \\in \\mathcal{S}$ do\n$\\rho_1(t) = \\pi_t B_t(w_1)$\n\nfor i from 2 to n do \n for all $t \\in \\mathcal{S}$ do\n  $\\rho_i(t) = B_t(w_t) \\max_{t'}(A_{tt'} \\cdot \\rho_{t-1}(t')$\n  mark one of the transitions from $t'$ to $t$ where the maximum is reached\n\nreconstruct backwards (from $T_n$) the best path following the marked transitions",
    "Viterbi algorithm: example\n\nTime flies like an arrow",
    "Contents\n\n- HMM models, three basic problems\n- Forward-Backward algorithms\n- Viterbi algorithm\n- Baum-Welch algorithm",
    "Expectation-Maximization\n\nOur goal: maximize $P(\\mathbf{w}|\\boldsymbol{\\theta})$\n\n$\\rightarrow$ Maximum-likelihood estimation of $\\boldsymbol{\\theta}$\n\nTo achieve it: Expectation-Maximization (EM) algorithm\n\nGeneral formulation of EM: given\n\n\\[\n\\begin{itemize}\n    \\item observed data $\\mathbf{w} = w_1, \\ldots, w_n$\n    \\item a parameterized probability distribution $P(\\mathbf{T}, \\mathbf{w}|\\boldsymbol{\\theta})$ where\n            \\begin{itemize}\n                \\item $\\mathbf{T} = T_1, \\ldots, T_n$ are unobserved data\n                \\item $\\boldsymbol{\\theta}$ are the parameters of the model\n            \\end{itemize}\n\\end{itemize}\n\\]\n\ndetermine $\\boldsymbol{\\theta}$ that maximizes $P(\\mathbf{w}|\\boldsymbol{\\theta})$ by convergence of iterative computation of the series $\\boldsymbol{\\theta}^{(l)}$ that maximizes (in $\\boldsymbol{\\theta}$) $E_T [\\log P(\\mathbf{T}, \\mathbf{w}|\\boldsymbol{\\theta})|\\mathbf{w}, \\boldsymbol{\\theta}^{(l-1)}]$",
    "Expectation-Maximization (2)\n\nTo do so, define the auxiliary function\n\\[\nQ(\\theta, \\theta') = E_T [\\log P(T, w| \\theta) | w, \\theta'] = \\sum_T P(T| w, \\theta') \\log P(T, w| \\theta)\n\\]\nas it can be shown (with Jensen inequality) that\n\\[\nQ(\\theta, \\theta') > Q(\\theta', \\theta') \\rightarrow P(w| \\theta) > P(w| \\theta')\n\\]\n\nThis is the fundamental principle of EM:\n\nif we already have an estimation $\\theta'$ of the parameters and we find another parameter configuration $\\theta$ for which the first inequality (on Q) holds,\nthen $w$ is most probable with model $\\theta$ rather than with model $\\theta'$.",
    "Expectation-Maximization (3)\n\nEM algorithm:\n\n- Estimation Step: Compute $Q(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}^{(i)})$\n- Maximization Step: Compute $\\boldsymbol{\\theta}^{(i+1)} = \\arg \\max_{\\boldsymbol{\\theta}} Q(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}^{(i)})$\n\nin other words:\n\n1. Choose $\\boldsymbol{\\theta}^{(0)}$ (and set $i = 0$)\n2. Find $\\boldsymbol{\\theta}^{(i+1)}$ which maximizes $\\sum_{\\mathbf{T}} P(\\mathbf{T} | \\mathbf{w}, \\boldsymbol{\\theta}^{(i)}) \\log P(\\mathbf{T}, \\mathbf{w} | \\boldsymbol{\\theta}^{(i+1)})$\n3. Set $i \\leftarrow i + 1$ and go back to (2) unless some convergence test is fulfilled",
    "Baum-Welch Algorithm\n\nThe Baum-Welch Algorithm is an EM algorithm for estimating HMM parameters.\n\nIt's an answer to the \"third problem\".\n\nThe goal is therefore to find\n$$\n\\text{argmax}_{\\theta} \\sum_{\\mathbf{w}} P(\\mathbf{T}, \\mathbf{w} \\mid \\theta') \\log P(\\mathbf{T}, \\mathbf{w} \\mid \\theta) = \\text{argmax}_{\\theta} \\sum_{\\mathbf{w}} P(\\mathbf{w} \\mid \\mathbf{T}, \\theta') \\log P(\\mathbf{T}, \\mathbf{w} \\mid \\theta)\n$$\nsince $P(\\mathbf{w} \\mid \\mathbf{T}, \\theta')$ does not depend on $\\theta$.\n\nWhat is $\\log P(\\mathbf{T}, \\mathbf{w} \\mid \\theta)$?\n\n$$\n\\log P(\\mathbf{T}, \\mathbf{w} \\mid \\theta) = \\log P_{1}(T_{1}) + \\sum_{i=2}^{n} \\log P_{i}(T_{i} \\mid T_{i-1}) + \\sum_{i=1}^{n} \\log P(T_{i} \\mid T_{i})\n$$",
    "$\\hat{Q}(\\theta, \\theta')$ consists therefore of 3 terms:\n\n$$\\hat{Q}(\\mathcal{I}, \\mathbf{A}, \\mathbf{B}, \\theta')= \\hat{Q}(\\mathcal{I}, \\theta') + \\hat{Q}_{A}(\\mathbf{A}, \\theta') + \\hat{Q}_{B}(\\mathbf{B}, \\theta')$$\n\nLet's compute one of these:\n\n$$\\hat{Q}(\\mathcal{I}, \\theta') = \\sum_{j=1}^{N} \\sum_{T_{1}, \\boldsymbol{\\tau}_{2:\\boldsymbol{T_{n}}}} P(T_{1}, \\boldsymbol{w}, \\mathbf{\\theta'}) \\log P_{j}(T_{1})$$\n\n$$= \\sum_{i\\in \\mathcal{S}} \\sum_{T_{1}, \\boldsymbol{\\tau}_{2:\\boldsymbol{T_{n}}}} P(T_{1}=t_{1}, \\boldsymbol{w}, \\mathbf{\\theta'})\\cdot P(t_{2},...,T_{n}, \\boldsymbol{w}, \\mathbf{\\theta'}) \\log P_{j}(T_{1})$$\n\n$$= \\sum_{i\\in S} P(T_{1}=t_{1}, \\boldsymbol{w}, \\mathbf{\\theta'})\\log I_{i}$$",
    "Similarly we have:\n\n\\[ Q_A(A, \\boldsymbol{\\theta}') = \\sum_{z \\in Z_t} \\sum_{i=1}^{n} \\sum_{j=1}^{n} P(T_{i-1} = i, T_i = t, \\boldsymbol{w} | \\boldsymbol{\\theta}') \\log A_{i,t} \\]\n\n\\[ Q_B(B, \\boldsymbol{\\theta}') = \\sum_{z \\in Z_t} \\sum_{i=1}^{n} \\sum_{j=1}^{m} P(T_i = t, \\boldsymbol{w} | \\boldsymbol{\\theta}') \\log B_{t}(w_i) \\]\n\nTherefore \\(\\hat{Q}\\) is a sum of three independent terms (e.g. \\(Q_t\\) does not depend on \\(A\\) nor on \\(B\\))\n\ntherefore the maximization over \\(\\boldsymbol{\\theta}\\) is achieved by the three terms separately, i.e. maximizing \\(Q_I(I, \\boldsymbol{\\theta}')\\) over \\(I\\), \\(Q_A(A, \\boldsymbol{\\theta}')\\) over \\(A\\) and \\(Q_B(B, \\boldsymbol{\\theta}')\\) over \\(B\\) separately.\n\nNotice that all these three functions are sums (over \\(i\\)) of functions of the form:\n\n\\[ f(x) = \\sum_{j=1}^{m} y_j \\log x_j \\]\n\nand all the above three functions have to be maximized under the constraint \\(\\sum_{j=1}^{m} x_j = 1 \\).\n\n*To be accurate: for \\(B\\), the constraint is \\(\\sum_{\\boldsymbol{w}_i} B_{t}(\\boldsymbol{w}_i) = 1\\). This changes the formulas a bit, but not the essence of the computation.",
    "Maximizing\n\n$$f(x) = \\sum_{j=1}^{m} y_j \\log x_j$$\n\nunder the constraint\n\n$$\\sum_{j=1}^{m} x_j = 1$$\n\ncan be achieved using Lagrange multipliers, i.e. looking at\n\n$$g(x) = f(x) - \\lambda \\left(\\sum_{j=1}^{m} x_j - 1\\right) = \\sum_{j=1}^{m} \\left( y_j \\log x_j - \\lambda \\cdot x_j \\right)$$\n\nSolving this by $\\frac{\\partial}{\\partial x_j} g(x) = 0$, we find that $\\lambda = \\frac{y_j}{x_j}$. Putting this back in the constraint we find:\n\n$$x_j = \\frac{y_j}{\\sum_{j = 1}^{m} y_j}$$",
    "Summarizing the obtained results, we have the following reestimation formulas (where the max. is reached):\n\n\\[ \\hat{I_t} = \\frac{P(T_1=t, \\mathbf{w} |\\boldsymbol{\\theta}^*)}{\\sum_{t' \\in \\mathcal{T} }P(T_1=t', \\mathbf{w} |\\boldsymbol{\\theta}^*)} = \\frac{P(T_1=t, \\mathbf{w} |\\boldsymbol{\\theta}^*)}{P(\\mathbf{w} |\\boldsymbol{\\theta}^*)} \\]\n\n\\[ \\hat{A}_{t t'} = \\frac{\\sum_{i=2}^n P(T_{i-1}=t, T_i=t', \\mathbf{w} |\\boldsymbol{\\theta}^*)}{\\sum_{i=2}^n \\sum_{t' \\in \\mathcal{T}}P(T_{i-1}=t, T_i=t', \\mathbf{w} |\\boldsymbol{\\theta}^*)} = \\frac{\\sum_{i=2}^n P(T_{i-1}=t, T_i=t', \\mathbf{w} |\\boldsymbol{\\theta}^*)}{\\sum_{i=2}^n P(T_{i-1}=t, \\mathbf{w} |\\boldsymbol{\\theta}^*)} \\]",
    "and:\n\n\\[ B_{t}(w) = \\frac{\\sum_{i=1}^{W} \\sum_{t=2}^{n} P(T_{1}=t, w | \\theta^{*}) \\sum_{t=2}^{n} P(T_{t} = t, w | \\theta^{*}) \\delta_{w,w^{'}}} {\\sum_{w} \\sum_{i=1}^{W} \\sum_{t=2}^{n} P(T_{1}=t, w | \\theta^{*}) \\sum_{t=2}^{n} P(T_{t} = t, w | \\theta^{*})} = \\frac{\\sum_{t=2}^{n} P(T_{t} = t, w | \\theta^{*}) \\delta_{w,w^{'}}} {\\sum_{w^{'}} \\sum_{t=2}^{n} P(T_{t} = t, w | \\theta^{*})}\\]\n\nwith $\\delta_{w,w^{'}} = 1$ if $w = w^{'}$ and 0 otherwise.",
    "Baum-Welch Algorithm: effective computation\n\nHow do we compute these reestimation formulas?\n\nLet $\\chi_i(t, t') = P(T_i = t, T_{i+1} = t' \\mid \\mathbf{w})$\n\n$\\chi_i$ is easy to compute with \"forward\" and \"backward\" variables:\n\n$$\n\\chi_i(t, t') = \\frac{\\alpha_i(t) \\cdot A_{t t'} \\cdot B_{t'}(w_{i+1}) \\cdot \\beta_{i+1}(t')}{\\sum_{t \\in \\mathscr{T}} \\sum_{t' \\in \\mathscr{T}} \\alpha_i(t) \\cdot A_{t t'} \\cdot B_{t'}(w_{i+1}) \\cdot \\beta_{i+1}(t')}\n$$\n\nNotice: $\\chi_i(t) = \\sum_{t' \\in \\mathscr{T}} \\chi_i(t, t')$ for all $1 \\le i < n$\n",
    "Effective reestimation formulas\n\n$$ \\hat{\\gamma}(t) = \\gamma(t) $$\n\n$$ A_{w'} = \\frac{\\sum_{t=1}^{T-1} \\chi_i(t, t')}{\\sum_{t=1}^T \\gamma(t)} $$\n\n$$ B_{t}(w) = \\frac{\\sum_{t=1}^T \\gamma_i(t) \\delta_{w,w_t}}{\\sum_{t=1}^T \\gamma_i(t)} $$\n\nwith $\\delta_{w,w_t} = 1$ if $w = w'$ and 0 otherwise.",
    "1. Let $\\theta^{(0)}$ be an initial parameter set\n2. Compute iteratively $\\alpha$, $\\beta$ and then $\\gamma$ and $\\chi$\n3. Compute $\\theta^{(t+1)}$ with reestimation formulas\n4. If $\\theta^{(t+1)} \\neq \\theta^{(t)}$, go to (2) [or another weaker stop test]\n\n**WARNING!**\nThe algorithm converges but only towards a local maximum of $\\mathbb{E} \\left[ \\log P(T, w | \\theta) \\right]$",
    "Other models\n\nBeyond HMMs, what\u2019s next?\n- Conditional Random Fields (CRF)\n- Bayesian Networks\n- Graphical Models\n\nHowever, the main three important aspects remains:\n1. efficient computations using dynamic programming\n2. Viterbi-like search algorithm (\u201cbelief propagation\u201d)\n3. Unsupervised learning with Expectation-Maximization",
    "CRF versus HMM\n\n(linear) Conditional Random Fields (CRF) are a discriminative generalization of the HMMs where \"features\" no longer needs to be state-conditional probabilities (less constraint features).\n\nFor instance (order 1, i.e. bigrams of tags):\n\n$$\n\\text{HMM}\n$$\n$$\nP(t, \\mathbf{w}) = P(t_1) P(w_1|t_1) \\cdot \\prod_{i=2}^{T} P(w_i|t_i) P(t_i|t_{i-1})\n$$\n\n$$\n\\text{CRF}\n$$\n$$\nP(t| \\mathbf{w}) = \\prod_{i=2}^{T} P(t_i|t_{i-1}, \\mathbf{w})\n$$\n$$\n(\\text{with } P(t_1, t_{i-1}, \\mathbf{w}) \\propto \\exp \\left(\\sum_j \\lambda_j f_j(t_{i-1}, t_i, \\mathbf{w}, i)\\right))\n$$",
    "Keypoints\n\n\u27a2 HMMs definitions, their applications\n\n\u27a2 Three basic problems for HMMs\n\n\u27a2 Algorithms needed to solve these problems:\n\u25ba Forward-Backward\n   (know what it solve and why it does exist, but not the mathematical details)\n\u25ba Viterbi\n   (know everthing and be able to do/apply it)\n\u25ba Baum-Welch\n   (be aware of its existence and properties, but not the implementation details)",
    "References\n\n[1] L. R. Rabiner, *A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition*, Proceedings of the IEEE, vol. 77, No. 2, 1989.\n\n[2] C. D. Manning, H. Sch\u00fctze, *Foundations of Statistical Natural Language Processing*, MIT, 1999.\n\n[3] A. P. Dempster, N. M. Laird, D. B. Rubin, *Maximum-likelihood from incomplete data via the EM algorithm*, Journal of Royal Statistical Society B, 1977.\n\n[4] H. Bourlard et al., *Traitement de la parole*, 2000; pp. 179-200, 202-214, 232-260.",
    "APPENDUM",
    "Justification of the maximization of the auxilary function Q for finding $\\theta$ maximizing $P(w|\\theta)$:\n\n$$\n\\log P(w|\\theta) - \\log P(w|\\theta') = \\log \\frac{P(w|\\theta)}{P(w|\\theta')} = \\log \\sum_t P(t|w, \\theta') \\frac{P(w,t|\\theta)}{P(w,t|\\theta')}\n= \\log \\sum_t P(t|w ,\\theta') \\frac{P(w,t|\\theta)}{P(w,t|\\theta')}\n$$\nJensen\n$$\n\\ge \\sum_t P(t|w,\\theta') \\log \\frac{P(w,t|\\theta)}{P(w,t|\\theta')}\n= \\mathbb{E}_T [\\log P(T,w|\\theta) | w,\\theta'] - \\mathbb{E}_T [\\log P(T,w|\\theta')] \\ge Q(\\theta, \\theta') - Q(\\theta', \\theta')\n$$\n\nTherefore:\n$$\nQ(\\theta, \\theta') > Q(\\theta', \\theta') \\implies \\log P(w|\\theta) > \\log P(w|\\theta') \\implies P(w|\\theta) > P(w|\\theta')\n$$",
    "Fundamentals in Information Retrieval\n\nJean-C\u00e9dric Chappelier\nEmmanuel Eckard\n\nLIA",
    "Information Retrieval\n\nDefinition\nselection of documents relevant to a query in an unstructured collection of documents.\n\nunstructured: not produced with IR in mind, not a database.\ndocument: here, natural language text (but could also be video, audio or images)\nquery: utterance in natural language (possibly augmented with commands, see later)\nrelevant:\nusers-wise: answering the IR requirements\nmathematically: maximising a defined \u201cproximity measure\u201d\n\n\u00a9EPFL 2013-2014\nJean-Lucien Champion\n\nComputational Linguistics Course (EPFL-MScS) \u2013 Information Retrieval \u2013 3/14",
    "Example of Information retrieval: issuing a query on an unstructured collection\n\nquery (\u201cAlan Turing\u201d)\n\nsearch among unstructured collection (Wikipedia articles)",
    "Example of Information retrieval: results returned by the system\n\n- list of results with a percentage match\n- highest matches first\n\nComputational Linguistics Course (EPFL-MLCs) - Information Retrieval - 5 / 74",
    "Ambiguity\n\nSometimes unintended results occur\n\nExample\n\nquery: \u201cChicago school\u201d\n\nwanted?\n\u25b6 schools in Chicago (IL)?\n\u25b6 body of works in sociology?\n\u25b6 architectural style?\n\u25b6 where to learn how to play Chicago (game):\n  \u25ba bridge?\n  \u25ba or poker??",
    "\"Relevant\" documents:\nWhat does \u201crelevant\u201d mean?\n\u25ba useful?\n\u25ba new?\n\u25ba topically related?\n\u25ba content related?\n  \u25ba at word level?\n  \u25ba at semantic/pragmatic level?\n\n\nComputational Linguistics Course (EPFL+McCS) - Information Retrieval",
    "Relevance?   Content versus topic\n\nSemantic content: what the document talks about (topic) vs what it says (content).\n\nExample\n\nDocument 1:\n    Note how misty the river banks are.\n\nDocument 2:\n    She got misty by the river of bank notes falling on the table.\n\nDocument 3:\n    Money had never interested her.\n\nDoc. 1 & 2 have similar word content but are not topically related.\nDoc. 2 & 3 have similar topics but opposite semantic content.",
    "How it IR done?\n\nTasks\n\u25ba have the computer represent documents (at the adequate level): preprocessing, indexing, ...\n\u25ba represent the query, not necessarily the same way as documents (short queries, operators, ...)\n\u25ba define satisfying relevance measures between representations\n\nSimilarities with other NLP tasks\n\u25ba Classification (no query)\n\u25ba Data mining (formatted data)\n\u25ba Information extraction (retrieve shorts parts of documents)",
    "IR Before computers\n\n- Colophons on clay tablets of Mesopotamia (3500 BCE)\n- Tags on scrolls of Edfu temple (from 237 BCE)\n- Middle Age: indexes of key terms of the Bible\n- Indexes for important texts: the Bible, Shakespeare\u2019s works, ...\n\nIndex of Thiers' *Histoire de la R\u00e9volution fran\u00e7aise*, 1854",
    "Simple example: Boolean model\n\nBoolean model\n\u25ba Documents are sets of terms (presence/absence)\n\u25ba Queries are boolean expressions on terms\n\nSteps\n\u25ba $V$, a finite vocabulary of indexing terms\n\u25ba $R$ representation space\n\u25ba $\\mathcal{R} : V^* \\rightarrow R$ representation function\n\u25ba matching between query and documents\n\nExample\n\u25ba feeling; ease; pain; feet; pain; ship\n\u25ba $\\{0;1\\}^{|V|}$\n\u25ba presence/absence\n\u25ba Boolean operators",
    "Simple example: Boolean model\n\nDocuments\n\nQuery",
    "Example: Boolean representation of documents\n\nExample\n\nDocument 1:\nCome on, now\nI hear you're feeling down.\nWell I can ease your pain\nGet you on your feet again.\n\nDocument 2:\nThere is no pain you are receding\nA distant ship, smoke on the horizon.\n\n$\\rightarrow$ Doc1: feeling; ease; pain; feet \n$\\rightarrow$ Doc2: pain; ship; smoke; horizon",
    "Example: Boolean representation of queries; retrieval\n\nExample\n\nQuery: $pain \\ AND \\ feeling$\n\nDoc1: feeling; ease; pain; feet\nDoc2: pain; ship; smoke; horizon\n\nResults\n- Doc1 matches\n- Doc2 does not match",
    "Limitations of the Boolean model\n\nExample\n\nQuery: \\( \\text{pain AND feeling} \\)\n\nDoc1: \\( \\text{feeling; ease; pain; feet} \\)\nDoc2: \\( \\text{pain; ship; smoke; horizon} \\)\n\\(\\Rightarrow \\text{Doc1 matches; Doc2 does not.} \\)\n\nLimitations\n\n- We might want to return Doc2 as a second best choice. The boolean model does not allow this.\n- What happens with \u201cpain OR feeling\u201d? it does not match common layman wisdom",
    "Indexing and representation of documents\n\nDefinition\nRepresentation: translating a document (words) into computable data (numbers).\nIndexing: selecting relevant elements (features) to support the representation\n\nThemes related to indexing:\n- Tokenisation\n- Stop words\n- Zipf and Luhn\n- Stemming and lemmatisation\n- Bag of words model",
    "Tokenisation\n\nDefinition\n\nTokenisation: splitting the text into words (Pre-requisite to choosing indexing terms)\n\nExample\n\n\u25ba easy: whitespaces\n\n\tNow is the winter of our discontent\n\tMade glorious summer by this son of York\n\t\n\u25ba less easy: space not always indicative of a term segmentation (compounds):\n\n\tDistributional Semantics Information Retrieval and Latent Semantics Indexing performance comparison\n\t\n\u25ba agglutinative languages are a problem: Rinderkennzeichungs- und Rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz\n\n\u25ba Technical terms",
    "Tokenisation of technical terms\n\ne.g. in Chemistry\n\nMethionyl-glutaminyl-arginyl-tyrosyl-glutamyl-seryl-leucyl-phenyl-alanyl-alanyl-glutaminyl-leucyl-lystyl-glutamyl-arginyl-lysy-glutamyl-glycyl-alanyl-phenyl-alanyl-valyl-prolyl-phenyl-alanyl-valyl-threonyl-leucyl-glycyl-aspartyl-prolyl-glycyl-isoleucyl-glutamyl-glutaminy-seryl-leucyl-lyscyl-isoleucyl-aspartyl-threonyl-leucyl-isoleucyl-glutamyl-alanyl-glycyl-alanyl-aspartyl-alanyl-leucyl-glutamyl-leucyl-glycyl-isoleucyl-prolyl-phenyl-alanyl-seryl-aspartyl-prolyl-alanyl-alanyl-aspartyl-glycyl-prolyl-threonyl-isoleucyl-glutamaminyl-asparaginyl-alanyl-threonyl-leucyl-arginyl-alanyl-tyrosyl-alanyl-glycyl-valyl-threonyl-prolyl-alanyl-glutaminyl-cysteinyl-adenyl-alanyl-glutamyl-methionyl-leucyl-alanyl-leucyl-arginyl-glutaminyl-lysyl-histidyl-prolyl-threonyl-isolecucyl-prolyl-isoleucyl-glycyl-glycyl-leucyl-methionyl-tyrosyl-alanyl-asparaginyl-leucyl-valyl-phenyl-",
    "Word Entities\n\nDefinition\nSemantic entity: compound word (group of words) bearing a semantic meaning\n\nExample\n\u25b6 \u201cInformation retrieval\u201d\n\u25b6 \u201crendez-vous\u201d\n\u25b6 \u201cradio antenna\u201d\n\u25b6 \u201cSinging Lily\u201d (a type of pastry)\n\u25b6 \u201cDolphin striker\u201d (a spar [part of boat])",
    "Conclusion on Tokenisation\n\nTokenisation is actually a NLP issue (use NLP techniques)",
    "Choice of indexing terms\n\nFiltering\nAutomated choice of indexing terms using filters:\n\u25ba on morpho-syntactic categories (e.g.: prepositions have no semantic content; nouns do)\n\u25ba on stop-words\n\u25ba on frequencies",
    "Stop words\n\nDefinition\nStop word: term explicitely to be excluded from indexing.\n\nExample\nstoplist: the; a; 's; in; but; I; we; my; your; their; then\n\nYoung men's love then lies\nNot truly in their hearts, but in their eyes.\n\nDocument: Young men love lies truly hearts eyes",
    "Stop words\n\nBenefits:\n- more informative indexes\n- cheap way to remove classes of words without semantic content\n- smaller indexes (tractability)\n\nProblems:\n_To be or not to be_\n\u2192 this sentence would be entirely stopped.",
    "Choice of indexing terms: frequencies\n\nZipf and Luhn\n\nIf $r$ is the rank of a term and $n$ is its number of occurrences (frequency) in the collection:\n\u25b6 Zipf (1949): $n \\sim 1/r$\n\u25b6 Luhn (1958): mid-rank terms are the best indicators of topics",
    "Choice of indexing terms: frequencies\n\nWord frequency\n\nWord rank\n\nWord too common\n\nUpper cut-off\n\nSignificant Word\n\nLower cut-off\n\nWord too rare\n\n\u00a9EPFL 2009-2014\nJean-Charles Chappelier\nArtificial Intelligence Laboratory\nEmanuel Canco \nComputational Linguistics Course (EPFL-MScS) \u2013 Information Retrieval \u2013 26 / 114",
    "Stemming and lemmatisation\n\nDefinition\n\nStem: morphological root of a word.\nStemming: Process of reducing words to their stem.\n\nExample\n\nprepaid, paid \u27f6 paid\ninteresting, uninteresting \u27f6 interest",
    "Stemming and lemmatisation\n\nBenefits\n\nReduces lexical variability $\\Rightarrow$ reduces index size\nincreases information value of each indexing term.\n\nNon-trivial process\n\nfactual $\\longrightarrow$ fact OK\nequal $\\longrightarrow$ eq wrong (\"eq\" is too short)",
    "Desequentialisation: bag of words model\n\nAssumption\nPositions of the terms are ignored. Term distribution is indicative enough of the meaning.\n\nModel\n\n$$\nd_1 = \\{(t_1, n(d_1, t_1)); (t_2, n(d_1, t_2)); \\ldots\\}\n$$\n\n$$\nd_2 = \\{(t_1, n(d_2, t_1)); (t_2, n(d_2, t_2)); \\ldots\\}\n$$\n\nA document is a multiset of terms\n\nExample\n\nNow so long, Marianne; it\u2019s time that we began to laugh and cry and cry and laugh about it all again.\n\n$$\n\\rightarrow ([begin,1] [cry,2] [laugh,2] [long,1] [Marianne,1] [time,1])\n$$",
    "Phrases, neighbourhoods: beyond the words\n\nPosition could be kept to allow\n\u25ba litteral search (quotations):\n    \"more things in heaven and earth\"\n\u25ba search by proximity:\n    dreamt WITHIN 5 philosophy",
    "Conclusions on indexing\n\n- Bad indexing can ruin the performances of an otherwise sophisticated IR system\n- Good indexing is anything but trivial",
    "Vector Space model\n\nObjective\nOvercome the limitations of the Boolean model by representing documents with vector describing term distributions.\n\nPrinciple\n- $V$, a finite vocabulary of indexing terms\n- $R$ representation space\n- $D : V^* \\rightarrow  R$ representation function\n- similarity: $\\mathcal{P}rox : R \\times R \\rightarrow \\mathbb{R}^+$\n\nNote: choose similarity measure well behaved for the representation (depends on the representation)\n\u2192 more in the \"Textual Data Analysis\" lecture",
    "Vocabulary of indexing terms\n\nExample\n\n\u25ba Now so long, Marianne\nit's time that we began\nto laugh and cry and cry\nand laugh about it all again.\n\n\u25ba $V$, a finite vocabulary: aardvark, begin, cry, information, laugh, long, Marianne, retrieval, time, ...\n\n\u2192 Now so long Marianne it's time that we began to laugh and cry and cry and laugh about it all again.\n\nIn practice\nthe vocabulary is several thousands of terms large",
    "Characterisation\n\nDefinition\n\ncharacterisation: projection of the document into the representation space\n\nExample\n\n\u25ba Now so long, Marianne\n  it\u2019s time that we began\n  to laugh and cry and cry\n  and laugh about it all again.\n\n\u25ba  R representation space: $\\mathbb{R}^{|V|}$\n\n\u2192([aardvark,?] [begin,?] [cry,?] [information,?] [laugh,?] [long,?] [Marianne,?] [retrieval,?] [time,?])",
    "Weightings\n\nTerm Frequency\n$\\text{tf}(w_i, d_j) = \\text{nb of occurences of term } w_i \\text{ in document } d_j$\nSometimes $1 + \\log(\\text{tf}(w_i, d_j))$ is used in place of $\\text{tf}(w_i, d_j)$\n\nTerm Frequency - Inverse Document Frequency\n$\\text{tf-idf}(w_i, d_j) = \\text{tf}(w_i, d_j) \\cdot \\text{idf}(w_i)$\nwith \n$$\\text{idf}(w_i) = \\log \\left(\\frac{|D|}{\\text{nb}(d_k \\supset w_i)}\\right)$$\n$|D|$: number of documents\n$\\text{nb}(d_k \\supset w_i)$: number of documents which contain term $w_i$",
    "Weighting\n\nExample\n\u25b6 Now so long, Marianne\n  it's time that we began\n  to laugh and cry and cry\n  and laugh about it all again.\n\n\u25b6 $R_D : V^* \\rightarrow \\mathbb{R}$ representation function: here: Term Frequency\n\n$\\rightarrow [(\\text{aardvark},0) \\ [\\text{begin},1] \\ [\\text{cry},2]$ \\ \\\n$[\\text{information},0] \\ [\\text{laugh},2] \\ [\\text{long},1] \\ [\\text{Marianne},1]$ \\ \\\n$[\\text{retrieval},0] \\ [\\text{time},1]]$\n\n$\\rightarrow (012021101...)$\n\nIn practice\nthe vector is very sparse",
    "Vector space model\n\n- indexing terms define axis\n- documents are point in the vector space (representing directions)",
    "Proximity measure between documents\n\nCosine similarity\n\n\\[\n\\cos(d_1, d_2) = \\frac{d_1 \\cdot d_2}{\\|d_1\\| \\|d_2\\|} = \\frac{\\sum_{i=1}^N d_{1i} d_{2j}}{\\sqrt{\\sum_{i} d_{1i}^2} \\sqrt{\\sum_{i} d_{2j}^2}}\n\\]\n\n- bounded (0 < cos($d_1$, $d_2$) < 1, $\\forall d_1, d_2$)\n- it is a similarity: the greater, the more similar the documents (as opposed to a metric)\n- independent on the length of the document",
    "Proximity measure between documents\n\nDocument 1\n- Now so long, Marianne, it's time that we began to laugh and cry and cry and laugh about it all again.\n- ...\n\\[ \\text{[long,1]}\\]\n\\[ \\text{[Marianne,1] [time,1]}\\]\n\\[ \\text{[begin,1] [laugh,2]}\\]\n\\[ \\text{[cry,2],}\\]\n\n\\[ \\mathbf{d_1} = (...1,1,1,1,2,2...)\\]\n\nDocument 2\n- I haven't seen Marianne laughing for some time, is she crying all day long?\n- ...\n\\[ \\text{[long,1]}\\]\n\\[ \\text{[Marianne,1] [time,1]}\\]\n\\[ \\text{[begin,0] [laugh,1]}\\]\n\\[ \\text{[cry,1],}\\]\n\n\\[ \\mathbf{d_2} = (...1,1,1,0,1,1...)\\]\n\nExample\n\\[\n\\cos(\\mathbf{d_1}, \\mathbf{d_2}) = \\frac{7}{\\sqrt{12\\cdot 5}} = 0.904\n\\]",
    "Summary\n\nChoices depending on the application\n\u25ba Weighting: allows to translate semantic notions into computable models\n\u25ba Proximity measure: fixes the topology of the representation space\n\nConstants\n\u25ba $|V|$-dimensional vector space\n\u25ba very sparse vectors",
    "Queries: definition\n\nDefinition\nQueries (or \"topics\") are \"questions\" asked to the system\n\nTypically keywords, possibly augmented with operators\n\n$$\\text{dreamt WITHIN 5 philosophy}$$\n\nSupposed unknown at indexing time (difference between IR and classification or clustering)\nVisit http://www.google.com/trends for real-life examples",
    "Query representation\n\nExample\n\u25ba easy: as for documents\nmore things in heaven and earth\n\u25ba less easy (verbatim sentence)\n\"more things in heaven and earth\"\n\u25ba quite different from the document (positional information)\ndreamt WITHIN 5 philosophy\n\nConclusion:\nQuery representation is not necessarily trivial (not always the same as representation of documents).",
    "Problem of short queries\n\nWeb queries\nOn the web,\n\u27a4 the average query length is under three words\n\u27a4 very few users use operators\n\nLanguage being ambiguous, three-word queries are difficult to satisfy.\n\nSolutions\n\u27a4 query expansion: use knowledge about the query terms to associate them with other terms and improve the query.\n\u27a4 query term reweighting: weight the terms of the query as to obtain maximum retrieval performance.\n\u27a4 relevance feedback: User provides the system an evaluation of the relevance of its answers.",
    "Evaluation campaigns\n\nEvaluation set\n1. Document collection\n2. Query set\n3. Referential\n\nDefinition\nReferential: list of documents of a collection to be retrieved for one given query (handmade).\n\nExamples of evaluation campaigns\n- Smart (1970s)\n- TREC (since the 1990s; large collections)\n- AMARYLLIS (French)",
    "Performances of IR systems\n\nReminder:\nGiven an IR system, a document collection, queries, referential and an answer by the system:\n\nDefinition\nPrecision is the proportion of the documents retrieved by the system that are relevant (according to the referential)\n\nDefinition\nRecall is the proportion of the relevant documents which were retrieved by the system\n\n- Precision can be cheated by returning no document\n- Recall can be cheated by returning all documents",
    "Performances of IR systems\n\nGiven an IR system, a document collection and a referential; for a query $q$, the results returned by the system is evaluated with:\n\n- Precision: Pr$(q) = \\frac{|R(q) \\cap S(q)|}{|S(q)|}$\n- Recall: Rec$(q) = \\frac{|R(q) \\cap S(q)|}{|R(q)|}$",
    "Performance measures: R-Precision\n\nDefinition\n\nPrecision at $n$ document:\n\n$$\nPr_n(q) = \\frac{|R(q) \\cap S_n(q)|}{|S_n(q)|}\n$$\n\nwith $S_n(q) = n$ first documents to be retrieved\n\nR-Precision\n\nprecision obtained after retrieving as many documents as there are relevant documents, averaged over queries\n\n$$\n\\text{R-Precision} = \\frac{1}{N} \\sum_{i=1}^N Pr_{|R(q_i)|}(q_i)\n$$",
    "Performance measures: Mean Average Precision\n\nAverage Precision\nAverage of the precisions whenever all relevant documents below rank rk(d,q) are retrieved:\n$$\\text{AvgP}(q) = \\frac{1}{|\\mathcal{R}(q)|} \\sum_{d \\in \\mathcal{R}(q)} \\text{Pr}_{\\text{rk}(d,q)}(q)$$\n\nMean Average Precision\nMean over the queries of the Average Precisions\n$$\\frac{1}{N} \\sum_i \\text{AvgP}(q_i)$$\nMAP measures the tendency of the system to retrieve relevant documents first.",
    "Plotting average Precision and Recall\n\nAim of the game: push the curve towards the upper right corner\n\nComputational Linguistics Course (EPFL-MSc) - Information Retrieval",
    "Probabilistic models\n\nIdea\nThe best possible ranking returns documents sorted by probability to be relevant given a query.\n\nfor instance: Sparck-Jones' model\n\n- Estimate the probability that a given document $d_i$ is relevant ($d_i \\in R(q)$) to given query $q$: $P(d_i \\in R(q)|q)$\n- Invert the probability (here $R$ is a boolean variable, standing for $d_i \\in R(q)$): $P(d_i|R,q)$\n- Write $P(d_i|R,q)$ as a function of the probabilities of occurrence of the terms (assuming that terms are conditionally independant): $P(t_j \\in d_i|R,q)$",
    "Document $d$ contains term $t_i$ (of the query)\n\n$$w(t_i, d) = \\log \\frac{p(t_i \\in d \\mid d \\in R)}{p(t_i \\in d \\mid d \\notin R)}$$\n\nDocument $d$ does not contain term $t_i$ (of the query)\n\n$$w(t_i, d) = \\log \\frac{p(t_i \\notin d \\mid d \\in R)}{p(t_i \\notin d \\mid d \\notin R)} = \\log \\frac{1 - p(t_i \\in d \\mid d \\in R)}{1 - p(t_i \\in d \\mid d \\notin R)}$$\n\nCombining the two\n\n$$w(t_i, d) = \\log \\frac{p(t_i \\in d \\mid d \\in R)}{p(t_i \\in d \\mid d \\notin R)} - \\log \\frac{p(t_i \\in d \\mid d \\in R)}{p(t_i \\in d \\notin R)} = \\log \\frac{p(t_i \\in d \\mid d \\in R)[1 - p(t_i \\in d \\notin R)]}{p(t_i \\in d \\mid d \\notin R) [1 - p(t_i \\in d \\in R)]}$$",
    "**Okapi BM25**\n\n**Idea**\n\nRefine Sparck-Jones' model by including term frequencies\n\n$$\nw = \\log \\frac{p(\\text{freq}(t,d) = tf | d \\in R)p(t \\notin d | d \\in R)}{p(\\text{freq}(t,d) = tf | d \\notin R)p(t \\notin d | d \\notin R)}\n$$\n\n**BM25 weight for term \\(i\\)**\n\n$$\nw_i^{BM25} = \\frac{tf_i (k_1 + 1)}{tf_i + k_1 ((1 - b) + b \\frac{dl}{avdl})} \\cdot idf_i\n$$\n\nwith \\(dl = \\text{document length}\\)\n\n\\(avdl = \\text{average document length}\\)\n\nBM25 is a very good model and used as reference for comparison with new models",
    "Introduction to topic-based models\n\nProblem\nInformation retrieval has problems notably with\n\u25ba Polysemy\n\u25ba Synonymy",
    "Polymesy\n\nExample\nQuery includes term Bank\n\u2192 Bank of England? Bank of fishes? Grand bank? Airplane bank?\n\nConsequences\nNegative impact on precision",
    "Synonymy\n\nExample\nQuery includes term $freedom$\n\u2192 $liberty$ will not be seen as relevant\n\nConsequences\nNegative impact on $recall$",
    "Topic-based models\n\nIdea\nApply a transformation to the representation space as to emphasise the most relevant features: index senses rather than mere words.\n\nNote\nStemming is already a step in this direction (less dependent on mere words)\n\nReminder\nOccurence matrix: term \u00d7 document matrix containing the weights $w_{ij}$ associated to document $d_i$ and term $t_j$",
    "Latent Semantic Indexing\n\nIdea\n\nReduction of dimensionality of the original representation space\nCreate a matrix close to the occurrence matrix but of smaller rank",
    "Latent Semantic Indexing\n\nReduction of dimensionality\n\u25ba approximation of the occurrence matrix\n\u25ba filtering of the occurrence matrix\n\nExample\nSingular Matrix Decomposition with $k$ values ($k$ between 100 to 300).",
    "Latent Semantic Indexing\n\nIllustration\n\n\\[ [w_{ij}] \\rightarrow [w'_{ij}] \\]\n\n\\[ (D \\times T) \\]           \\[ (D \\times k) \\]\n\n\\[ \\{ \\text{flower} \\} \\quad \\{ \\text{flower} \\} \\]\n\\[ \\{ \\text{car} \\} \\quad \\sqrt{12} \\cdot \\{ \\text{car} \\} + \\pi \\cdot \\{ \\text{truck} \\} \\quad (\\cong \\{ \\text{vehicle} \\}?) \\]\n\\[ \\{ \\text{truck} \\} \\]",
    "Latent Semantic Indexing\n\nAdvantages\n\u25ba More significant representation\n\nDrawbacks\n\u25ba Out-performed by other models\n\u25ba Too expensive to compute on large bases (requires iterative methods)\n\u25ba Meaning of axis ??\n\u25ba Query projection is problematic",
    "Idea\n\nThere is a high degree of correlation between the observable distributional characteristics of a term and its meaning:\n\"a word is characterized by the company it keeps\";\nZ. Harris (1954), J.R. Firth (1957)\n\nExample\n\nSome $X$, for instance, naturally attack rats.\nThe $X$ on the roof was exposing its back to the shine of the sun.\nHe heard the mewings of $X$ in the forest.\n$X$ is a: . . .",
    "X is a . . .",
    "Co-occurrence profile\n\nDefinition\nCo-occurrence profile: characterisation of a word by its co-occurrences with indexing terms\n\nExample\nDocument 1\nNow so long, Marianne,\nit's time that we began\nto laugh and cry and cry\nand laugh about it all again.\n\nDocument 2\nIt seems so long ago,\nNancy was alone\nlooking at the Late Late show\nthrough a semi-precious stone.\n\n\u2192 Co-occurrence profile of long=([cry,2] [begin,1] [Marianne,1] [Nancy,1] [time,1] [late,2] [laugh,2])",
    "Co-occurence matrix\n\nDefinition \nCo-occurence matrix: words $\\times$ terms matrix of the co-occurence profiles with terms \n$t_{ij}$: number of times that the word $w_i$ and the indexing term $t_j$ occur together.\n\nDSIR Document representation\n$$\nF_D = F_{\\text{Ooccurence}} \\cdot F_{\\text{Co-occurence}}\n$$\n\u2192 ponderation of the words in documents by the co-occurrences\n\nNote\nWhen indexing a collection C, the co-occurrence matrix would typically be evaluated on a control collection representative of the language/domain (could be C itself, but not necessarily)",
    "Computing co-occurrences\n\nThe actor was wearing a grimacing mask of ancient theatre",
    "Co-occurencies and syntactic features\n\nUse heads of phrases\n\n(The actor) (was wearing) (a grimacing mask) (of ancient theatre)\n\n*actor\n*wear\ngrimacing *mask\nancient *theatre\n\nActor   Mask\n\nWear    Grimacing\n\nTheatre   Ancient\n\nComputational Linguistics Course (EPFL-MSc) - Information Retrieval - 68 / 74",
    "Using syntactic rules and semantic roles\n\nThe actor was wearing a grimacing mask of ancient theatre\n\n$SUBJ(actor, wear)$\n$OBJ(wear, mask)$\n$ADJ(mask, grimacing)$\n$ADJ(theatre, ancient)$\n$CNOUN(mask, theatre)$",
    "DSIR results",
    "Other more advanced Topic Models\n\nLDA: Latent Dirichlet Allocation (Blei, Ng, Jordan 2003)\n(not to be confused with Linear discriminant analysis!!)\n\n$$\\text{probabilistic model with hidden states (\"topics\")}$$\n\nReference:\n\n- D. Blei. Probabilistic topic models. Communications of the ACM, 55(4):77\u201384, 2012.\n\n- J.-C. Chappelier, Topic-based Generative Models for Text Information Access, In Textual Information Access \u2013 Statistical Models, E. Gaussier and F. Yvon eds, ch. 5, pp. 129-178, Wiley-ISTE, April 2012.",
    "Summary / Keypoints\n\n- Vector-space model;\n- Indexing (and its important role);\n- Weighting schemes, tf-idf;\n- Evaluation: Precision and Recall.",
    "References\n\n[1] C. D. Manning, P. Raghavan and H. Sch\u00fctze, \"Introduction to Information Retrieval\", Cambridge University Press. 2008.\n[2] R. Baeza-Yates and B. Ribeiro-Neto, \"Modern Information Retrieval\", Addison Wesley, 1999.\n[3] \"Topics in Information Retrieval\", chap. 15 in \"Foundations of Statistical Natural Language Processing\", C. D. Manning and H. Sch\u00fctze, MIT Press, 1999.",
    "Modern Neural-Networks approaches to NLP\n\nJ.-C. Chappelier\n\nLaboratoire d'Intelligence Artificielle\nFacult\u00e9 I&C",
    "Objectives of this lecture\n\nSo, is this course a Machine Learning Course?\n\nNLP makes use of Machine Learning (as would Image Processing for instance)\nbut good results require:\n - good preprocessing,\n - good data (in term [sic] of relevant annotations\n - good understanding of the problems, features, outputs, results, ...\n\nThe goal of this course is to provide you with the core concepts and baseline\ntechniques to achieve the above mentioned requirements.\n\nThe goal of this lecture is to make give a broad overview on modern Neural Network approaches to NLP.\n\nThis lecture is worth deepening with some full Deep Learning course; e.g.,:\n  - F. Fleuret (Master) Deep learning (EE-559)\n  - J. Henderson (EDOC) Deep Learning For Natural Language Processing (EE-608)",
    "Contents\n\n1. Introduction\n   \u25b6 What is it all about? What does it change?\n   \u25b6 Why now?\n   \u25b6 Is it worth it?\n\n2. How does it work?\n   \u25b6 words (word2vec (CBow, Skip-gram), GloVe, fastText)\n   \u25b6 documents (RNN, CNN, LSTM, GRU)\n\n3. Conclusion\n   \u25b6 Advantages and drawbacks\n   \u25b6 Future",
    "What is it all about?\n\nModern approach to NLP heavily emphasizes \"Neural Networks\" and \"Deep Learning\"\n\nTwo key ideas (which are, in fact, quite independent):\n* make use of more abstract/algebraic representation of words:\n  * use \"word embeddings\":\n    * go from sparse (& high-dimensional)\n    to dense (& less high-dimensional) representation of documents\n* make use of (\"deep\") neural networks (= trainable non-linear functions)\n\nOther characteristics:\n* supervised tasks\n* better results (at least on usual benchmarks)\n* less? preprocessing/\"feature selection\"\n* CPU and data consuming",
    "How does it work?\n\nKey idea #1: Learning Word Representations\n\nTypical NLP: Corpus --> some algo --> word/tokens/n-grams vectors\n\nKey idea in recent approaches: can we do it task independant?\n\nso as to reduce whatever NLP (processing) to some algebraic vector manipulation:\n\nno longer start \"core (NLP)\" from words anymore,\nbut from vectors (learned once for all) that capture general syntactical and semantic information\n\nKey idea #2: use Neural Networks (NN) to do the \"from vectors to output\" job\n\nA NN is simply a $\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ non-linear function with (many) parameters",
    "Neural Networks (NN): a 4-slides primer\n\n\u25ba NN are non-linear non-parametric (= many parameters models) functions\n\n\u25ba The ones we're here talking about are for supervised learning\n     \u21d2 make use of a loss function to evaluate how their output fits to the desired output usual loss: corpus (negative) log-likelihood \u221d P(output|input)\n\n\u25ba non-linearity: localised on each \"neuron\" (1-D non linear function) sigmoid-like (e.g. logistic function $ \\frac{1}{(1 + e^{-x})} $) or ReLU (weird name for very simple function: max(0,x))\n\n     *Graph 1*\n     *Graph 2*\n\n\u25ba the non-linearity is applied to a linear combination of input: dot-product of input (vector) and parameters (\"weight\" vector)",
    "Softmax output function\n\nAnother famous non-linearity is the \"softmax function\"\n\nsoftmax = generalization from 1D to n-D of logistic function (see e.g. \"Logistic Regression\", 2 weeks ago)\n\nPurpose: turns whatever list of values into a probability distribution\n\n$$(x_1, ..., x_m) \\longrightarrow (s_1, ..., s_m)$$\n\nwhere\n$$s_j = \\frac{e^{x_j}}{\\sum_{j=1}^m e^{x_j}}$$\n\nExamples:\n\n$$x = (7, 12, -4, 8, 4) \\longrightarrow s = (0.0066, 0.9752, 1e-6, 0.01798, 0.0003)$$\n\n$$x = (0.33, 0.5, 0.1, 0.07) \\longrightarrow s = (0.266, 0.316, 0.211, 0.206)$$",
    "Multi-Layer Perceptrons (MLP) a.k.a. Feed-Forward NN (FFNN)\n\nMLP (Rumelhart, 1986): neurons are organized in (a few) layers, from input to output:\n\nParameters: \"weights\" of the network = input weights of each neurons\n\nMLP are universal approximators: input : $x_1, ..., x_n$ (n-dimensional real vectom), output :\n$\\simeq f(x_1, ..., x_n) \\in \\mathbb{R}^m$ to whatever precision decided a priori\nIn a probabilistic framework: very often used to approximate the posterior probability $P(y_1, ..., y_m | x_1, ..., x_n)$\n\nConvergence to a local minimum of the loss function (often the mean quadratic error)",
    "NN learning procedure\n\nGeneral learning procedure (see e.g. Baum-Welch):\n\n1. Initialize the parameters\n\n2. Then loop over training data (supervised):\n    1. Compute (using NN) output from given input\n    2. Compute loss by comparing output to reference\n    3. Update parameters: \"backpropagation\":\n        update proportional to the gradient of the loss function\n    4. Stopping when some criterion is fulfilled\n        (e.g. loss function is small, validation-set error increases, number of steps is reached)",
    "about Deep Learning (more later)\n\n- not all Neural Network models (NN) are deep learners\n- there is NO need of deep learning for good \"word\"-embeddings\n- models: convolutional NN (CNN) or recurrent NN (RNN, incl. LSTM)\n- still suffer the same old problems: overfitting and computational power\n\na quote, from Pr. Michel Jordan (IEEE Spectrum, 2014):\n\"deep learning is largely a rebranding of neural networks, which go back to the 1980s. They actually go back to the 1960s; it seems like every 20 years there is a new wave that involves them. In the current wave, the main success story is the convolutional neural network, but that idea was already present in the previous wave.\"\n\nWhy such a reborn now?\n=> many more data (user-data pillage), more computational power (GPUs)",
    "What is Deep Learning after all?\n\ncomposition of many functions (neural-net layers) taking advantage of\n- the chain rule (aka \"back-propagation\")\n- stochastic gradient decent\n- parameters-sharing/localization of computation (a.k.a. \"convolutions\")\n- parallel operations on GPUs\n\nThis does not differ much from networks from the 90s: several tricks and algorithmic improvements backed-up by\n1. large data sets (user-data pillage)\n2. large computational resources (GPU popularized)\n3. enthusiasm from academia and industry (hype)",
    "Corpus-based linguistics: the evolution\n\nbefore corpora (< 1970): hand written rules\n\nfirst wave (\u2248 1980-2015): probabilistic models (HMM, SCFG, CRF, ...)\n\nneural-nets and \"word\" embeddings (1986, 1990, 1997, 2003, 2011, 2013+):\n* MLP: David Rumelhart, 1986\n* RNN: Jeffrey Elman, 1990\n* LSTM: Hochreiter and Schmidhuber, 1997\n* early NN Word Embeddings: Yoshua Bengio et al., 2003; Collobert & Weston (et al.) 2008 & 2011\n* word2vec (2013), GloVe (2014)\n\ntransfer learning (2018--):\n* ULMFiT (2018), ELMo (2018), BERT (2018), OpenAI GPT2 (2019)\nuse even more than \"word\" embeddings: pre-trained early layers to feed the later layers of some NN, followed by a (shallow?) task-specific architecture that is trained in a supervised way",
    "Is it worth it?\nImproved performances on well known benchmarks\nsee e.g. https://aclweb.org/aclwiki/PoS_Tagging_(State_of_the_art),\nhttps://nlpprogress.com/#\nhttp://nlpprogress.com/\n\nConstituency Parsing \u201cWallStreet Journal\u201d corpus: \n\\[\n\\begin{array}{lll}\n\\text{Model} & \\text{publication} & \\text{F1 (\\%)} \\\\\n\\hline\n\\text{Probabilistic context-free grammars} & \\text{Petrov et al. (2006)} & 91.80 \\\\\n\\text{Recursive neural networks} & \\text{Socher et al. (2011)} & 90.20 \\\\\n\\text{Feature-based transition parsing} & \\text{Zhu et al. (2013)} & 91.30 \\\\\n\\text{seq2seq learning with LSTM+Attention} & \\text{Vinyals et al. (2015)} & 93.50 \\\\\n\\end{array}\n\\]\n\nPoS-tagging on the \u201cWallStreet Journal\u201d corpus:\n\\[\n\\begin{array}{llll}\n\\text{name} & \\text{technique} & \\text{publication} & \\text{accuracy (\\%)} \\\\\n\\hline\n\\text{TnT} & \\text{HMM} & \\text{Brants (2000)} & 96.5 \\\\\n\\text{GENIA Tagger} & \\text{MaxEnt} & \\text{Tsuruoka et al. (2005)} & 97.0 \\\\\n\\text{Averaged Perceptron} & \\text{} & \\text{Collins (2002)} & 97.2 \\\\\n\\text{SVMTool} & \\text{SVM} & \\text{Gim\u00e9nez and M\u00e0rquez (2004)} & 97.3 \\\\\n\\text{Stanford Tagger 2.0} & \\text{MaxEnt} & \\text{Manning (2011)} & 97.24 \\\\\n\\text{SNN} & \\text{CRF} & \\text{Sun (2014)} & 97.3 \\\\\n\\text{structReg} & \\text{} & \\text{Sun (2014)} & 97.3 \\\\\n\\text{Flair} & \\text{LSTM-CRF} & \\text{Akbik et al. (2018)} & 97.8 \\\\\n\\end{array}\n\\]",
    "Contents\n\n\u2460 Introduction\n    \u25b6 What is it all about? What does it change?\n    \u25b6 Why now?\n    \u25b6 Is it worth it?\n\n\u2461 How does it work?\n    \u27a0 words\n         \u25b6 word2vec (CBOW, skipgram)\n         \u25b6 GloVe\n         \u25b6 fastText\n    \u25b6 documents\n\n\u2462 Conclusion\n    \u25b6 Advantages and drawbacks\n    \u25b6 Future",
    "Starting point (reminder)\n\n$N$ \"row\" objects (e.g., documents) $x^{(i)}$ characterized by $m$ \"features\" (e.g., \"words\") $x_{j}^{(i)}$\n\n$x_{j}^{(i)} = $ \"importance\" of feature $j$ for object $i$\n\ntokens/words define the axis\n\ndocuments are point in the vector space",
    "From \"word\" vectors to \"word\" embeddings\n\nembedding = vectorial representation + dimension reduction\n\nfrom sparse ($m \\approx 10^4 - 10^5$) to dense ( = more compact) representation ($m \\approx 10^2 - 10^3$)\n\nWhy should dense vectors be better?\n- More efficient (shorter dimension: less data to handle, store, estimate, ...)\n- capture \"the essence\" (capture statistical invariants): less noisy? ( =? generalize better)",
    "Distributional Semantics\n\nIdea (dates back to Harris (1954) and Firth (1957))\nThere is a high degree of correlation between the observable co-occurence characteristics of a term and its meaning\n\nExample\n- Some $X$, for instance, naturally attack rats.\n- The $X$ on the roof was exposing its back to the shine of the sun.\n- He heard the mewings of $X$ in the forest.\n- $X$ is a: . . .\n\nTypically, word embeddings are trained by \"predicting a word based on its context\" (or vice-versa) on a large (unlabeled) corpus",
    "Key idea: illustration\n\nword 1\n\ncontext A\n\nword 2",
    "Word Embeddings\n\n\u201cWord embedding\u201d:\n\u25ba numerical representation of \u201cwords\u201d/\u201ctokens\u201d) \n\u25ba a.k.a. \u201cSemantic Vectors\u201d, \u201cDistributional Semantics\u201d\n\n\u25ba objective: relative similarities of representations correlate with syntactic/semantic similarity of words/phrases.\n\n\u25ba two key ideas:\n1. representation(composition of words) = vectorial-composition(representations(word))\n   for instance: representation(phrase) = $\\sum_{word \\in phrase}$ representation(word)\n\n2. remove sparseness, compactify representation: dimension reduction\n\n\u25ba have been around for a long time\n   Harris, Z. (1954), \u201cDistributional structure\u201d, Word 10(23):146-162.\n   Firth, J.R. (1957), \u201cA synopsis of linguistic theory 1930-1955\u201d, Studies in Linguistic Analysis. pp 1-32.",
    "Word Embeddings: different techniques\n\n\"Many recent publications (and talks) on word embeddings are surprisingly oblivious of the large body of previous work [...]\"\n(from https://www.gavagai.se/blog/2015/09/30/a-brief-history-of-word-embeddings/)\n\nMain techniques:\n\u25ba co-occurrence matrix; often reduced (LSI, Hellinger-PCA (2013), GloVe (2014))\n\u25ba probabilistic/distribution (DSIR, LDA)\n\u25ba shallow (Mikolov et al. 2013) or deep Neural Networks (ELMo)\n\nThere are theoretical and empirical correspondences between these different models [see e.g. Levy, Goldberg and Dagan (2015), Pennington et al. (2014), \u00d6sterlund et al. (2015)].\n\nPopular word embedding are not from Deep Learning but can then serve as input to Deep Learners",
    "Word embedding \u201cgeometry\u201d\n\nThe geometry of embeddings should account for desired properties (e.g. syntactic, semantics, synonymy, word classes,...)\n\ne.g. predict new word representation (embedding) from the sum of embeddings of words around it\n\nWord embedding indeed exhibit some semantic compositionality\n\nSome theoretical justification for this behavior was recently given by Gittens et al. (2017):\nwords need to be uniformly distributed in the embedding space.\n\nA. Gittens et al. (2017), \u201cSkip-Gram \u2013 Zipf + Uniform = Vector Additivity\u201d, proc. ACL.",
    "word2vec (Mikolov et al. 2013)\n\nPredict new word representation (embedding) from the sum of the embeddings of the words around it\n\ncontext = (2k+1)-gram around (not including) word:\n\n$w_{i-k}, \\ldots, w_{i-1}, \\mathbf{(w_i)} , w_{i+1}, \\ldots, w_{i+k}$\n\nExample:\n\nThe black cat ate the white mouse\n\nWith $k=2$, $w= ``ate\"$, then $c=``black cat ate the white\"$ (if no other preprocessing)\n\nword2vec comes with 2 flavors:\n- CBoW (Continuous Bag-of-Words): predicts the current \"word\" based on its context\n- Skip-gram: predict the context from the current \"word\"\n\nT. Mikolov et al. (2013a), \"Distributed Representations of Words and Phrases and their Compositionality\", proc. NIPS.\nT. Mikolov et al. (2013b), \"Efficient Estimation of Word Representations in Vector Space\", proc. ICLR.\n\nModern Neural Networks approaches to NLP \u2014 p. 21 / 42",
    "CBoW architecture\n\n$ x_{ik} $\n$ x_{i2} $\n$ x_{i3} $\n...\n$ x_{in} $\n\n$ x_{ic} $\n\n$ W_{nn} $\n$ W_{vw} $\n\nHidden layer\n\n$ W_{wv} $\n$ W_{vw} $\n\nOutput layer\n\n$ y_i $\n\n$ N $-dim\n\n$ V $-dim\n\n$ C \\cdot V $-dim",
    "Skip-gram architecture\n\n$x_c$\n\nInput layer\n\n$V$-dim\n\nHidden layer\n\n$h_i$\n\n$N$-dim\n\n$y_{i,j}$\n\n$y_{i,j}$\n\n$y_{i,j}$\n\n$C * V$-dim\n\nOutput layer",
    "word2vec key ideas\n\n\u25ba idea #1:\nunsupervised co-learning of context c representation and word w representation so as to maximize either $P(c|w)$ (skip-gram model) or $P(w|c)$ (CBOW model).\n\n\u25ba idea #2 (\u201cnegative sampling\u201d):\nminimize as well $P(w\u2019|c)$ for $w\u2019$ not having c as context\n\nActual other key simplification:\n\u25ba turn word prediction ($P(w|c)$) into binary classification ($P(y = 1|w,c)$)\nExample:\nTurn $P(! Ok | black cat X the white)$ (for all words X)\ninto: $P(! Ok | black cat ate the white)$ (1 number)",
    "Illustration\n\ncontext A\n\nword 2\n\nword 1\n\n(neg.) cont. C\n\n(neg.) cont. B",
    "word2vec method\n\nMore formally:\nthe \u201cword embeddings\u201d (i.e. vectors) $h_i = h(w^{(i)}) \\in \\mathbb{R}^d$ (for each word $w^{(i)} \\in \\mathcal{L})$ are optimized at the same times as \u201creverse projection\u201d $m_j \\in \\mathbb{R}^d$ (i.e. matrix $M = (m_j)$ projects \u201cword embeddings\u201d back into input space; this corresponds to the weight of the output layer) such that the context log-likelihood\n\n$$\nL = - \\sum_{w \\in corpus} \\log Q(c, w)\n$$\n\nis minimized, where:\n\u25ba in CBoW, using a softmax output layer, $Q(c, w) = P(w|c)$ could be modeled as\n\n$$\nP(w^{(i)}|c) = \\frac{\\exp(m_{k}, h(c))}{\\sum_{w_k \\in \\mathcal{L}}\\exp(m_{k}, h(c))}\n$$\n\n(for a context c of word $w^{(i)}, h(c) = \\frac{1}{|w_e \\in c|} \\sum_{w_e \\in c} h(w_e))$\n\n\u25ba and in skipgram $Q(c, w) = P(c|w)$ modeled similarly.",
    "word2vec actual loss\n\nIn fact, softmax is too expensive too compute (and less stable, it seems) so, rather than softmax, the output is directly $\u03c3(m_j \u22c5 h(c))$ with $\u03c3(\\cdot)$ the sigmoid function\n\nThis in fact replaces $Q(c, w) = P(w|c)$ with $Q(c, w) = P(y = 1|w, c)$ the probability of genuine co-occurrence (i.e. simplifies a word-prediction task into a binary classification task)...\n\n...which then leads to the idea of learning $P(y = 0|w', c)$ as well (for some other words $w'$): negative sampling\n\nTo do this, word2vec draws $R$ negative random samples from the words distribution loss function then becomes:\n\n$$\n\\sum_{w \\in \\text{corpus}}  \\left( \\log\\left(1 + \\exp(-m_j \\cdot h(c))\\right) + \\sum_{r=1}^R \\log \\left(1 + \\exp(+m_{j(r)} \\cdot h(c)) \\right) \\right)\n$$\n\n(where $c$ is the context of $w$, $j$ is the index of $w$ in the lexicon (i.e. $w = w^{(j)}$) and $j(r)$ is drawn at random)",
    "GloVe (Pennington et al. 2014)\n\nGloVe (Global Vectors) is another famous (non NN) \"word\" embedding method which works directly on the word co-occurrence matrix\n  \u25b6 normalizing the co-occurrence counts,\n  \u25b6 log-smoothing them,\n  \u25b6 then factorizing the matrix to get lower dimensional representations\n      by minimizing some \"reconstruction loss\" (difference between the dot-product \n      of word embeddings and the log of the probability of co-occurrence)\n\nGloVe embeddings work better on some data sets,\nwhile word2vec embeddings work better on others\n\nJ. Pennington, R. Socher, and C. D. Manning (2014) \"GloVe: Global Vectors for Word Representation\", proc. EMNLP.",
    "In practice\n\nIn practice, you can either:\n- construct your own embeddings\n  CBOW: for corpus with short sentences but high number of samples\n  Skip-gram: for corpus with long sentences and low number of samples (infrequent words)\n  or GloVE, fastText, ELMo\n- use existing word embeddings\n  word embeddings provide generally helpful features without the need for a lengthy training (for NN)\n\nSome softwares/models:\n  word2vec, GloVe, Gensim, fastText, ELMo, ...\n\nAdvice:\nWhen using already computed \"word\" embeddings:\n  use the same preprocessing that has been used:\n  get your vocabulary (words?tokens?) as close to the embeddings as possible\n  e.g. gensim.utils.tokenize(): \"maximal contiguous sequences of alphabetic characters (no digits!)\" (sic)",
    "fastText (Joulin, Bojanowski, Mikolov et al. 2017)\n\naim to address the token/OoV issue:\nuse n-grams of characters (< token) embedding\n\nMore usefull for less semantic but more lexical task (e.g. morphology, POS-tagging or even NER)\nalso usefull for OOV\n\nfastText = skip-gram on n-grams of characters\n\nThe method is fast, which allows quick training of new models on large corpora. \nlooks promising in terms of speed, scalability, and effectiveness. \n\nbetter model: Embedding for Language Models (ELMo): compute a different word embedding for different contexts\n\nA. Joulin et al. (2017), \"Bag of Tricks for Efficient Text Classification\", proc. EACL.\nP. Bojanowski et al. (2017), \"Enriching Word Vectors with Subword Information\", Trans. ACL, vol 5.\nE. P. Matthew et al. (2018), \"Deep Contextualized Word Representation\", proc. NAACL.",
    "Contents\n\n\u2460 Introduction\n    \u25b6 What is it all about? What does it change?\n    \u25b6 Why now?\n    \u25b6 Is it worth it?\n\u2461 How does it work?\n    \u25b6 words\n    \u25b6 documents\n        \u25b6 Convolutional Neural Networks (CNN)\n        \u25b6 Recurrent Neural Networks (RNN): LSTM, GRU\n\u2462 Conclusion\n    \u25b6 Advantages and drawbacks\n    \u25b6 Future",
    "From \"words\" to sentences/documents\n\nword2vec: how to go from tokens to compound words, phrases, sentences, documents?\n\nCompounds/Name Entities/Phrases:\nidioms like \u201chot potato\u201d or named entities such as \u201cBoston Globe\u201d does not represent the combination of meanings of individual words.\nOne solution to this problem, as explored by Mikolov et al. (2013), is to identify such phrases based on word co-occurrence and train embeddings for them separately.\nMore recent methods have explored directly learning n-gram embeddings from unlabeled data\n\nHow to represent a document: average/sum of its word vectors?\n= not so good\n\nSolution:\neffective feature function that extracts higher-level features from constituting tokens-grams: CNN and RNN",
    "Convolutional Neural Nets (CNN; Fukushima (1980), Le Cun (1998))\n\noriginal key idea (inspired from visual cortex): share weights\n\nINPUT  CONVOLUTION  RELU  POOLING  CONVOLUTION  RELU  POOLING\nFLATTEN  FULLY CONNECTED  OUTPUT\n\nFEATURE LEARNING\n\ninput  conv1  pool1  conv2  pool2  hidden4  output",
    "CNN for NLP (example)\n\nI \nlike \nthis \nmovie \nvery \nmuch",
    "Recurrent Neural Networks (Elman 1990)\n\nDesigned to deal with sequences (of vectors)\nby composing former intermediate representations (= outputs)\noutput is a function of input an previous output:\n\n$\\mathbf{h}_{t} = f (\\mathbf{h}_{t-1}, \\mathbf{x}_{t}$)\n\nRNN are generalized to\n\u25ba bidirectional RNN\n\u25ba RNN with gates:\n   \u2022 Long Short-Term Memory (LSTM; Hochreiter and Schmidhuber (1997))\n   \u2022 Gated recurrent unit (GRU; Cho et al. (2014))",
    "$x_i$: \"word\" embedding for i-th word/token\n\n$\\tilde{y}_i$: output = probability distribution; e.g. $\\tilde{y}_i \\approx P(\\text{Class} \\mid w_i, \\ldots, w_j)$ \"Classif.\": a MLP",
    "RNN with gates\n\nLimitations of classical RNNs:\n* vanishing gradients: addressed with gate neuron/vector: learning to forget some parts of the memory\n* exploding gradients: addressed by gradient clipping\n\nGate neuron: a 0/1 selection (elementwise product) of input component\ninput/memory information filter(= gate)\n\n$$ z_t = \\sigma \\left( W_z \\left[ h_{t-1}, x_t \\right] \\right) $$\n$$ r_t = \\sigma \\left( W_r \\left[ h_{t-1}, x_t \\right] \\right) $$\n$$ \\hat{h}_t = \\text{tanh} \\left( W \\left[ r_t * h_{t-1}, x_t \\right] \\right) $$\n$$ h_t = (1 - z_t) * h_{t-1} + z_t * \\hat{h}_t $$",
    "LSTM vs. GRU\n\n",
    "Neuron-type summary\n\nfrom D. Jurafsky & J. H. Martin, _Speech and Language Processing_, draft 3rd edition",
    "Example applications (1/2)\n\nImage caption generator:\n\nfrom Vinyals et al. (2015)\n\nModern Neural Networks approaches to NLP -- 41 / 67",
    "Example applications (2/2)\n\nImage question answering engine:\n\nWhat     is     behind     the     table     ?     \nLSTM     LSTM     LSTM     LSTM     LSTM     LSTM     LSTM     \n                                           chairs     window     <END>\n\nfrom Malinowski et al. (2015)\n\nModern Neural Networks approaches to NLP   \u2014   41 / 42",
    "Conclusion\n\nModern approach to NLP heavily emphasizes \"Neural Networks\" and \"Deep Learning\"\n\nTwo key ideas (which are, in fact, quite independant):\n* \"word embeddings\":\n  \u25ba go from sparse (& high-dimensional)\n  to dense (& less high-dimensional) representation of documents\n* make use of (\"deep\") neural networks ( = trainable non-linear functions)\n\nModels:\n* word embeddings: word2vec (CBoW, Skip-gram), GloVe, fastText, ELMo\n* neural networks: CNN, LSTM, GPU\n  (software: spaCy, Keras, Torch/PyTorch, TensorFlow, scikit-learn, DarkNet)",
    "Pros and Cons\n\n\u25ba Best performances, but lots of data (unsupervised for word embeddings, supervised for tasks-oriented NN) and lot of CPU/GPU)\n\u25ba word embeddings are dependent on the applications in which it is used.\n  Labutov and Lipson (\"word re-embedding\", 2013) proposed task specific embeddings which retrain the word embeddings to align them in the current task space.\n\u25ba Traditional word embedding algorithms assign a distinct vector to each word. This makes them unable to account for polysemy.\n  Several approaches address this issue :\n  e.g. Upadhyay et al. (2017), ELMo (E. P. Matthew et al. (2018))\n\u25ba discussions on the relevance of word embeddings in the long run have cropped up recently\n  e.g. Lucy and Gauthier (2017) has recently tried to evaluate how well the word vectors capture the necessary facets of conceptual meaning. The authors have discovered severe limitations in perceptual understanding of the concepts behind the words, which cannot be inferred from distributional semantics alone.",
    "Future(?): Transfert Learning\n\nTransfer learning (2018--):\nULMFIT (2018), ELMo (2018), BERT (2018), OpenAI GPT2 (2019)\n\nuse even more than \"word\" embeddings:\npre-trained early layers on some task 'A' to feed the later layers of some NN trained in a supervised way on a task 'B'\n\nbased on \"transformer\" models:\ninclude \"attention\" (Vaswani et al. NIPS 2017) layers in FFNN",
    "References\n\n- D. Jurafsky & J. H. Martin, *Speech and Language Processing*, draft 3rd edition, chap. 6,7 & 9 https://web.stanford.edu/~jurafsky/slp3/, 2019.\n\n- Y. Goldberg *Neural Network Methods for Natural Language Processing*, Morgan & Claypool Publishers, 2017. https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037",
    "Word Embeddings: some references\n\nR. Lebret and R. Collobert (2013), \"Word Embeddings through Hellinger PCA\", proc. EACL.\nT. Mikolov et al. (2013a), \"Distributed Representations of Words and Phrases and their \nCompositionality\", proc. NIPS.\nT. Mikolov et al. (2013b), \"Efficient Estimation of Word Representations in Vector Space\", \nproc. ICLR.\nJ. Pennington, R. Socher, and C. D. Manning (2014) \"GloVe: Global Vectors for Word \nRepresentation\", proc. EMNLP.\nO. Levy, Y. Goldberg and I. Dagan (2015), \"Improving distributional similarity with lessons \nlearned from word embeddings\", Journ. Trans. ACL, vol. 3, pp. 211-225.\n\u00d6sterlund et al. (2015) \"Factorization of Latent Variables in Distributional Semantic Models\", \nproc. EMNLP.\nA. Joulin et al. (2017), \"Bag of Tricks for Efficient Text Classification\", proc. EACL.\nP. Bojanowski et al.(2017), \"Enriching Word Vectors with Subword Information\", Trans. ACL, \nvol. 5.\nA. Gittens et al. (2017), \"Skip-Gram - Zipf + Uniform = Vector Additivity\", proc. ACL.\nE. P. Matthew et al. (2018), \"Deep Contextualized Word Representation\", proc. NAACL.",
    "1.1: What's the internet?\n\nThe internet is a computer network that interconnects hundreds of millions of computing devices throughout the world. End systems are connected together by a network of communication links and packet switches. Different links can transmit data at different rates, with the transmission rate of a link measured in bits/second. Packets are packages of data comprised of header bytes and the actual data needing to be transmitted.\n\nA packet switch takes a packet arriving on one of its incoming communication links and forwards that packet on one of its outgoing communication links. The route or path a packet takes is the sequence of communication links and switches it passes through.\n\nEnd systems access the Internet through Internet Service Providers (ISPs). Each ISP is in itself a network of packet switches and communication links. ISPs also provide Internet access to content providers, connecting Web sites directly to the Internet. This lower-tier ISP hierarchy is interconnected through national and international upper-tier ISPs such as Level 3 Communications, AT&T and Sprint.\n\nEnd systems, packet switches, and other pieces of the Internet run protocols that control the sending and receiving of information within the Internet. The Transmission Control Protocol (TCP) and the Internet Protocol (IP) are two of the most important protocols in the Internet. The IP protocol specifies the format of the packets that are sent and received among routers and end systems. The Internet's principal protocols are collectively known as TCP/IP.\n\nThe Internet offers a number of services to applications, such as Web surfing, instant messaging, etc. that are provided by end systems. They include methods and rules by which these services are created and how they can communicate. An application programming interface (API) specifies how different software components should interact with each other. Through these methods, the Internet provides a service between applications running on different end systems.\n\nThe network architecture used to design the Internet was based on a particular design principle of layering. TCP/IP divides the job into several tasks, each for a separate layer responsible for different functions in the network, such as data transfer and routing. These services form an infrastructure that provides further services, such as allowing users to request and receive information stored on Web servers.\n\nA network protocol is similar to a human protocol, except that the messages and actions are not people, but rather, software running on devices that control the sending and receiving of messages in the Internet. What happens when you want to receive content from the Internet like a web page? You make a request to a Web server, that is, when you type the URL of a",
    "Web page into your Web browser? First, your \ncomputer will send a connection request \nmessage to the Web server and wait for a reply. \nThe Web server will eventually receive your \nconnection request and return a \nconnection response message, meaning that it is \nnow OK to request the Web document, your \ncomputer does this in the name of the Web page \nrequest, and then Web server in a GET message. Finally, \nthe Web server returns the Web page (file) to your computer. \nFormally, a protocol defines the format and the order of messages\nexchanged between two or more communicating entities, as well \nas the actions taken on the transmission and/or receipt of a \nmessage or other event.\n\n1.2: The network edge: End-Systems\nEnd systems are also referred to as hosts because they \nhost (run) user application programs such as a Web browser \nprogram. Hosts are sometimes further divided into \ntwo categories: clients and servers. Into the \ndesktop and mobile PCs, smartphones, and so on, whereas \nservers tend to be more powerful machines that store \nand distribute Web pages, stream video, relay e-mail, \nand so on. Today, most of the servers from which we receive information reside \nin the large data centers.\n\nHow do homes connect to the internet? Today, the two most prevalent types of broadband \nresidential access are digital subscriber line (DSL) and cable. Access \nDSL typically obtained from the local telephone company, while cable Internet access \nobtained (I)n the local cable company. \nTypically, a residence has twisted-pair copper wires. Each customer\u2019s DSL modems use the existing \ntelephone line to exchange data with a digital subscriber line above the 400kHz (that is, below 4kHz) \nand a frequency-division \nmodem located in the central office telephone internet \ndata resides between the frequencies. On the customer \nend, a splitter separates the data and telephone signals \nand forwards the data to the DSL modem. On the telephone company \nend, splitter separates the data and telephone signals \nand sends data to the internet. Hundreds or thousands of \nhouses connect to a single DSLAM.",
    "While DSL makes use of the telco\u2019s existing local telephone infrastructure, cable Internet access makes use of the cable television company\u2019s existing cable television infrastructure. Fiber optics connect the cable head end to neighborhood-level junctions, from which traditional coaxial cable is then used to reach individual houses and apartments. Each neighborhood typically supports 500 to 5000 homes. Because both fiber and coaxial cable are employed in this system, it is often referred to as hybrid fiber coax (HFC). Cable internet access requires special modems, called cable modems. At the cable head end, the cable modem termination system (CMTS) serves a similar function as the DSL network\u2019s DSLAM\u2014turning the analog signal sent from the cable modems in many downstream homes back into digital format. Cable modems divide the HFC network into two channels, a downstream and an upstream channel. As with DSL, access is typically asymmetric, with the downstream channel typically allocated a higher transmission rate than the upstream channel. But unlike DSL, which dedicates a separate downstream and upstream channel to each user, the cable modem system uses a shared broadcast medium. In particular, every packet sent by the head end travels downstream on every link to every home and every packet sent by a home travels on the upstream channel to the head end. For this reason, if several users are downloading a video from the same server, they will be sharing the downstream transmission rate of the same single downstream channel.\n\nLocal Area Access Networks. While DSL and cable modems use telco and cable networks, respectively, to connect a home end system to an Ethernet switch, to connect a home end system into the Internet. Used in universities, companies, the internet.\n\n1.3: The Network Core\n\nIn a network application, end systems exchange messages with each other. Messages can contain anything the application designer wants. Messages may perform a control function (e.g., the \u201cHi\u201d messages) or can contain data (e.g., a JPEG image), connect end systems, but other types of network devices in the core, they source breaks long messages into smaller chunks known as packet switches before these are two predominant types, routers and link-layer switches).",
    "Most packet switches use store-and-forward transmission at the inputs to the links. This means that the packet switch must receive the entire packet and store it in a buffer before it can begin to transmit the first bit of the packet onto the outbound link. Switches also contain forwarding tables that store the packet meta-data and indicate where the packet is to be sent.\n\nEach packet switch has multiple links attached to it. Each one has an output buffer which stores packets that the router is about to send into that link. If an arriving packet needs to be transmitted onto that link but finds the link busy with its transmission of another packet, the arriving packet must wait in the output buffer. If the switch can transfer a packet only when the arrival of buffer space is finite, an arriving packet may find that the buffer is completely full with other packets waiting for transmission. In this case, the packet will be dropped, and a route to send that packet will be dropped.\n\nThere are two types of switching: Packet switching where packets are treated as demands and switches them on the duration of the forwarding decision and is more practical to define an effective set of reservations but is unpredictable, it needs congestion control, which is done by critical mass for congestionless switching. The amount of even packet forwarding at the same node is determined either by certain specific admission and resource configuration in order to ensure pure congestionless within the two systems. Admission control and the forwarding set-up configuration define the mean response value within the reserved function and the specific configuration of the user.\n\nThe Internet has a number of special routing protocols that are used to automatically set the forwarding tables in the packet switches. For example, these protocols provide ways to use the available bandwidth to get the shortest path routes to configure the forwarding tables in the routers.\n\n1. Regional, Access and even connect providers (or ISPs) and Exchanges provide connections for higher Transmissions and inserting in IXPs (Internet Exchange Points). In summary, packet switching to set-up the links as needs depends on various factors. There are three kinds of ISPs: consumer ISPs, lower-tier ISPs, and lower-or upper ISPs. The ISPs are diverse in their composition. Higher tiers intermingle more in peerings and access methods pour geographic regions. The lower-tier ISPs connect end systems, homes, and other lower-tier ISPs interconnected at either under or higher ISPs, and the highter-tier ISPs interconnected also with other consumer, lower and high-tier ISPs. Lower ISPs and such have their associated bandwidths and even higher ISPs where possible.",
    "1.4: Delay, Loss and Throughput\n\nThere are a couple different types of delay that will slow a packet from one source to another. The delay that is created when a switch examines a packet\u2019s header and determines where it must be sent is called the Processing Delay. It\u2019s usually very short (milliseconds). While waiting to be transmitted onto a link, a packet will experience a Queuing delay. It depends on the arrival rate at the queue (on the switch), the nature of the arriving traffic (is it bursty or not), and the transmission rate of the outgoing link. If the bit arrival rate is bigger than the departure rate, the wait can go towards infinity (with an infinite buffer). Otherwise it depends on the traffic. The queuing delay is characterized by statistical models. Losses in the queue create delay elements, variations of queueing delay and the probability that it reached a certain value. The Transmission delay is the amount of time it takes to push the bits of the packet onto the link. It\u2019s proportional to the packet size and inversely proportional to the divided by the transmission rate of the link. To get the total nodal delay, it is just about the (processing delay + queueing delay + transmission delay + propagation delay).\n\nThe Propagation delay is the amount of time it takes to propagate a bit from one end of the link to another. It\u2019s determined by the speed at which an electromagnetic wave propagates through a medium. It\u2019s the distance divided by the speed. E.g. if the distance is $d$ and the propagation delay is $s$, the propagation delay is $d/s$.\n\nThere is a very simple model for this. A lot of information is lost like acknowledgement.\n\nAll of the components are normalized to a constant data size driven by the global transfer time. The propagation is infinite. And only one queue is taken into account (bottleneck). The total delay is brought to exclude data in the transmission phase and only flows that go through the bottleneck remain. All the bit-times shift. This four large line $R$, doesn\u2019t matter. Only the slowest $R$ is taken into account (bottleneck).",
    "1.5: Layering\n\nJust like many other systems out there, the internet is layered to reduce its complexity. Each layer, along with the layers beneath it, implements some functionality. A layered architecture allows us to discuss a well-defined, specific part of a larger and complex system. This simplification itself is of considerable value. By providing modularity, making it much easier to change the implementation of the service provided by the layer. As long as the layer provides the same service to the layer above it, and uses the same services from the layer below it, the remainder of the system remains unchanged when a layer\u2019s implementation is changed.\n\nTo provide structure to the design of network protocols, network designers organize protocols \u2014 and the network hardware and software that implement the protocols \u2014 in layers. Each layer belongs to one of the services. We are again interested in the services that a layer offers to the layer above it: the layer service model of a layered architecture has two purposes: (1) it allows specification of the layer service and, by (2) using the services of the layer below and the layer above it.\n\nAs a summary, we can say that layering offers two main advantages. It decomposes the problem of designing a complex system into more manageable pieces. The second advantage is that it provides modularity when designing a network. If we change the implementation of a service while keeping acceptable performance.\n\napplication | FTP HTTP SMTP DNS \ntransport | TCP UDP \nnetwork | IP \nlink | Ethernet PPP DSL Cable \nphysical | Fiber Copper radio \n\nHTTP message \nTCP segment \nIP packet \nETHERNET frame \n\napplication message \nTCP segment \nIP packet \nETHERNET frame ",
    "1.6: Security\n\nTwo fundamental questions in networks is how does one react to adversarial behavior and how it assumes the behavior of end-users and packet switches. There are a couple security issues that can happen with networks.\n\nEve, the eavesdropper. Tries to listen in on the communication to obtain copies of the data. Quite easy over a wireless network, and also possible if she has access to the switch the packets switch on you. Wouldn\u2019t be possible on a quantum channel (can\u2019t read data without modifying it).\n\nBob, the impersonator. Pretends to be Alice to other end-users or switches. See Bob. The ability to inject packets into the Internet with a false source address is known as IP spoofing, and is bit complex than an unauthenticated user can masquerade as an authorized user. Both are bad.\n\nDenis the denial of service impersonator. Makes Alice or Bob crash/disconnect and disrupts the communication. As the name suggests, a DoS attack disrupts the communication and is different from the eavesdropper/impersonator in that it\u2019s active and end users/disconnect servers, and a congested network are all suspect to DoS attacks. A specific, novel attack that can happen is to make a server's buffer facesize to a vulnerability with repeated http requests, is called GET attack. Denis can try resource exhaustion; that is, he sends enough packets to a server that it doesn\u2019t operate. For example, he starts more jobs than he can finish. Bandwidth flooding is different because it can stop end user hence, the host cannot operate, therefore providing little access. TCP hijacking is when user IP addresses are impersonated. One of the ways this flooding is done by making sure the number of half open TCP connections numerous.\n\nMalika, the virus/software attacker. Can kill the whole system (affects your new viruses). This attack can be anywhere in the payload of data or burst DaS. Malware can also be self-propagated. It\u2019s a method of injecting infected end-systems.\n\n2.1: Network applications\n\nA network application consists of pairs of processes that send messages to each other over a network.\n\nThe application architecture is designed by the application developer and dictates how the application is structured over the various end systems. The possible structures will be described shortly. With respect to network applications, an application architecture is always one of two types: the application developer will choose either a client-server architecture or a peer-to-peer (P2P) architecture for his application.",
    "In a client-server architecture, there is an always-on host, called the server, which services requests from many other hosts, called clients. Clients do not directly communicate with each other. The server has a fixed, well-known address, called an IP address. Often in a client-server application, a single-server host is incapable of keeping up with all the requests from clients. For this reason, a data center, housing a large number of hosts, is often used to create a powerful virtual server. A data center can have hundreds of thousands of servers, which must be powered and maintained. Additionally, the service provider must pay recurring costs for renting, owning, and bandwidth costs for sending data from their data centers.\n\nIn a P2P architecture, the application exploits direct communication between pairs of intermittently connected hosts, called peers, which are desktop and laptops controlled by users. They don\u2019t have fixed IP addresses. Many of today\u2019s most popular and traffic-intensive applications are based on the P2P architecture. As an example, file distribution applications, VolP applications, and streaming video apps use P2P elements. For applications with P2P messaging applications, servers are used to track the IP addresses of users, but user-to-user messages are sent directly between user hosts. One of the most compelling features of P2P architectures is their self-scalability.\n\nThere are many challenges for P2P: the legality of the transferred files, most residential ISPs (including cable and some ISPs) have been deploying mechanisms to limit residential users\u2019 upload rates (in order to increase revenue), they depend on finding one another. But besides these, they must be able to work properly when exposed to different network conditions (which can happen frequently when user\u2019s link type changes). Therefore, P2P systems usually have to run much simpler than in place.\n\nAn analogy to a piece of operating systems is, it is not actually programs but processes: processes communicate by message to a program that will be sending it the message and then send it. Processes then respond to or exceed the resource quotas if they exceed resource quotas. For access to its own operating system, the applications create seeds and sends messages within the link. A receiving process receives these messages and possibly responds by sending messages back.",
    "each pair of communicating processes, we typically label one of the two processes as the client and the other process as the server. In P2P, the client is the one who is downloading the file.\n\nA process sends messages into, and receives messages from, the network through a software interface called a socket. If an IP address is a door handle, then label it as a transport protocol (TCP or UDP).\n\nTransport layers have the responsibility of getting the messages to the socket of the receiving process. There are different reasons an application might choose an transport protocol:\n\u2022 Reliable data transfer. Is it important that all bits get to the destination, and in the proper order? As discussed before, some of it can be tolerated.\n\u2022 Loss-tolerant. If an application. E: Mails vs. websites, . . . .\n\u2022 Timing. Is it important that message sent arrives time-sensitive data with tolerance. If the multiplier value goes down, polls . . . .?\n\u2022 Security. Does the application need security? . . . ?\n\nThe Internet makes two transport protocols available to applications, UDP and TCP. Neither TCP nor UDP provide any encryption\u2014the data that is transported application for the socket in the same data travels over the network to the destination process. An exhausting that TCP has to provide end-to-before Server packets (SSL), not sensitive applications, handle transport is, Similarly, encryption, end-point restrictions.\n\nTCP is a connection-oriented service. It has the client and server exchange transport-layer control information with each other before the application-level messages begin to flow.",
    "After the handshaking phase, a TCP connection is said to exist between the sockets of the two processes. TCP code at the server (client) machine keeps a record with information about each active client (server) process. Both processes can send messages to each other over the connection at this stage. When the application finishes sending messages to the other side of the connection, it has to inform the data transfer service. This service will close the connection. TCP code to deliver all data sent without error and in the proper order. Reliable includes a congestion-control mechanism. When web client-server interaction is taking place over TCP, the application developer has to make an important decision: should each object be sent over a separate TCP connection between the two end systems (non-persistent connections)? Or should all objects sent and their corresponding responses be sent over the same (persistent) TCP connection?\n\nThe TCP is the main existing transport protocol, providing semi-connection services. To do so there is a handshaking before the two processes start to communicate. It provides a unique, reliable port to port connection that the message will never reach the receiving process, guaranteeing the arrival of the data.\n\nReceiving process may through one of four:\n1. The process did not start up yet.\n2. No application is waiting for UDP traffic.\n3. Arrived package or port error. TCP guarantees the in-order delivery of data.\n4. Applications agree and communicate directly. The connection is established, all data is exchanged and errors are detected and corrected. That makes it the most reliable system possible, with no lack of guaranteed.\n\nAn important concept defines how an application exchanges data with one of the defined systems, pass information between remote systems. Addressing defines an end system communication method (host). We distinguish between an identifier and an address. The host has a hostname, network (host) and the application name, translated into an IP address. \n\nWhen creating an application, you need to design the architecture Ethernet uses PPP, the communication should choose the application (TCP/IP), can be exchanged among others how the transport service (TCPSSL or UDP).\n\nA URL is an address for web objects with a hostname + file name format (www.epfl.ch is an end-system (is host), index.html is a file).",
    "2.2: The web and HTTP\n\nThe web is a combination of HTTP, web browser and server processes and HTML language. The HyperText Transfer Protocol (HTTP), the Web\u2019s application-layer protocol, is at the heart of the Web. It\u2019s implemented in two programs: a client program and a server program, executing on different end systems, talking to each other by exchanging HTTP messages.\n\nA Web page (also called a document) consists of objects. An object is simply a file (HTML file, a JPEG image, a Java applet, ...), that is addressable by a single URL. Most Web pages consist of a base HTML file and several referenced objects. For example, if a Web page has some HTML text and five JPEG images, then the Web page has six objects. The base HTML file references the other objects in the page with the objects\u2019 URLs.\nEach URL has two components: the hostname of the server that houses the object and the object\u2019s path name. When a browser requests a Web page, it first obtains the base HTML file (for example, www.someSchool.edu/someDepartment/pic.html) from an HTTP server at someSchool.edu. Then, with the base HTML file, the browser knows the names of the JPEG images to be fetched. The browser obtains the images by specifying the URLs for the images. URL references to nonlocal servers (that is, servers not in the same domain) are also common; for example, a Web page at www.someSchool.edu might contain HTML text that references an image at an HTTP server in another university. Web browsers can also run scripts or applets.\n\nTo obtain a Web page, for each object in the page, the browser sends an HTTP request to the server. The server responds with the requested object. HTTP uses a client-server architecture, in which the client (typically a Web browser) sends a request message and the server returns a response message. In the context of HTTP, we call the client the user agent.\n\nHTTP is known as a stateless protocol. An HTTP server maintains no information about the clients. For example, if a client asks for the same object twice in two different connections, the server does not keep any of the cookie data of the previous connection. \n\nHTTP messages are categorized as request messages and response messages. A typical HTTP request consists of: a request line, header lines, and an entity body. The request line has three fields: the method field, the URL field, and the HTTP version field. The method field can have values like GET, POST, PUT or DELETE. The header lines provide additional information about the client and the server.\n\nHTTP request can also use different methods like GET, POST, etc.\n\nIn the case of GET, POST, PUT, or DELETE, a message from the client will have the value of methods. The status code will be one of 200: OK, Not Found.\n\nHTTP messages are transferred over TCP. HTTP uses TCP as its underlying transport protocol (rather than running on top of UDP). The HTTP client first initiates a TCP connection with the HTTP server (this is done by sending a TCP segment to the server, port number 80). Once the connection is established, HTTP messages are passed between browser and Web server via TCP connection. The connection will be remained open until either the client requests else or server gets closed. \n\nHTTP can persist the data or can use a stateless connection for transferring data. Connection can remain persistent or can become non-persistent. Non-persistent connection: TCP restriction to stop HTTP connections. Typically, a client sends a request to the server, then gets a response back. Typically, only older websites and servers use non-persistent connections.\n\n11 of 49",
    "This is why HTTP servers can also be programmed to leave the TCP connection open after sending a response. This is called a persistent connection. Subsequent requests and responses between the same client and server are then sent over the same connection. In particular, an entire Web page (in the example above, the base HTML file and the ten images) can be sent over a single persistent TCP connection. Moreover, multiple Web pages residing on the same server can be sent from this server to the same client over a single persistent TCP connection. These requests for objects can be made back-to-back without waiting for replies to be received for previous requests. Typically, the HTTP server closes a connection when it isn\u2019t used for a certain time (a configurable timeout interval). When the server receives the back-to-back requests, it can reply back-to-back. The default mode of HTTP/1.1 uses persistent connections with pipelining.\n\nHTTP servers maintain no information about its clients (it\u2019s a stateless protocol). This simplifies server design and has permitted engineers to develop high-performance Web servers that can handle thousands of simultaneous TCP connections. But because a website often wants to identify users, or remember past user activity, websites want to create stateful sessions with users. Cookies allow sites to keep track to users. To better understand cookies, we need to keep track of state. Cookie technology has four components: (1) a cookie header line in the HTTP response message; (2) a cookie header line in the HTTP request message; (3) a cookie file kept on the user\u2019s end system and managed by the user\u2019s browser; (4) a back-end database at the website.\n\nCookies can be used to identify a user. The first time a user visits a site, the user can provide a user ID (possibly his or her name) when prompted by the site. The site then creates an entry in its back-end database to this user ID, then lets the user ID be a string. Thereafter, when the browser receives a cookie header line, it appends a line to the special cookie file that it manages. Typically, this special file is stored in the user\u2019s browser cache. In (3), when the user revisits the same site, the browser sends the same HTTP request message with a cookie header line that contains the user ID. Upon receiving the request, the site then extracts the user ID from the cookie header line, and looks up the corresponding entry in its back-end database. With this mechanism, a Web site can learn a lot about you over time.\n\nA Web cache (also called a proxy server) is a network entity that satisfies HTTP requests on the behalf of an origin Web server. The Web cache has its own disk storage and keeps copies of recently requested objects in this storage. A Web cache is both a server and a client at the same time. When it receives a request for an object from a browser, it acts as a server. When it receives a request for an object from a browser, it acts as a server. When it receives requests from a client browser, it checks to see if it has a copy of the object. If it does, it returns the object.",
    "installed by an ISP. For example, a university might install a cache on its campus network and configure all of the campus browsers to point to the cache. Or a major residential ISP (such as AOL) might install one or more caches in its network and preconfigure its shipped browsers to point to the installed caches.\n\nWeb caching has seen deployment in the Internet for two reasons. First, a Web cache can substantially reduce the response time for a client request, particularly if the bottleneck bandwidth between the client and the origin server is much less than the bottleneck bandwidth between cache and client. Second, if a high-speed connection exists between the cache and the client, then the cache and, if the cache has the requested object, then the cache will be able to deliver the object to the client faster. Second, Web caches can substantially reduce traffic on an institution's access link to the Internet. By caching the copies of the objects, they reduce, for the company or a university, cost due to having to upgrade bandwidth capacity, thereby reducing costs. Consequently, new costs are reduced. Web traffic in the Internet as a whole, thereby improving performance.\n\nTo make sure the proxy server doesn\u2019t serve stale data to its clients, it can send conditional GET's to the server stating either its staleness (the origin server). If it sees it as more recent it sends the most recent version or informs that its copy is already updated, otherwise it just retransmits.\n\n2.5: DNS\n\nHosts are both identified by their IP-Address and by Hostnames. An IP address consists of four bytes and has a rigid hierarchical structure. An IP address looks like 121.7.0.12. A Host name, on the other hand, can be an alphanumeric name up to 255. To get the corresponding IP address, one must use a DNS (Domain Name Service) The DNS is a distributed database implemented in a hierarchy of DNS servers and an application layer protocol that allows hosts to query the distributed database. The DNS protocol runs over UDP and uses port 53.\n\nIn order for a user's host machine to send an HTTP request message to a Web server www.hostname.com, the user\u2019s host must first obtain its IP address. This is how it is done:\n\n1. The same user machine runs the client side of the DNS application.\n2. The browser extracts the hostname from the URL and passes it to the client side of the DNS application.\n3. The DNS client sends a query containing the hostname to the DNS server.\n4. The DNS client eventually receives a response, which included the IP-Address desired. \n\n13 of 49",
    "5. Once the browser receives the IP address from DNS, it can initiate a TCP connection to the HTTP server process located at port 80 at that IP address.\n\nWe see from this example that DNS adds an additional delay that can sometimes be substantial. Fortunately the desired IP address is often cached in a \u201cnearby\u201d DNS server, which helps to reduce DNS network traffic as well as the average DNS delay. DNS provides a few other important services in addition to translating hostnames to IP addresses:\n\nI. Host aliasing. A host with a complicated hostname can have one or more alias names. For example, a hostname such as \u201crelay1.west-coast.enterprise.com\u201d could have, say, two aliases such as \u201centerprise.com\u201d and www.enterprise.com.\u201d In this case, the hostname relay1.west-coast.enterprise.com is said to be a canonical hostname. Alias hostnames, when present, easily: popular con: mente need the canonical hostname in numerous aliases.\nII. Mail server aliasing. DNS can be invoked by a mail application to obtain the canonical hostname for a supplied alias hostname. For example, the mail server alias hostname can receive an alias name such as \"mail.enterprise.com, which is more mnemonic than simply \u201chotmail.com.\u201d DNS can be configured by a mail administrator to return the canonical hostname for a supplied alias hostname. MX records, discussed in more detail below, contain canonical hostname from supplied host alias.\nIII. Load distribution DNS is also used to perform load distribution among replicated Web servers. For replicated Web servers, a set of IP addresses is associated with one canonical hostname. When a client makes a DNS query for a Name, the DNS server responds with the entire set of IP addresses, but rotates the ordering of the addresses within each reply, When a client makes a DNS query for a Web server, a set of IP addresses is associated with one canonical hostname.\n\nFrom the implementation perspective, with the application in the user's host, DNS is a black box providing a service for translating hostnames to IP addresses. However, from a broader perspective, a DNS is a well-organized, hierarchical system with distributed databases. The structure, called the DNS infrastructure, consists of the DNS servers that collectively implement the DNS distributed database, as well the application-layer protocol that allows the DNS servers to communicate among themselves and with the DNS clients residing in the hosts. The mapping of a hostname to an IP address is primarily performed by three classes of DNS servers - root, top-level domain (TLD), and authoritative DNS servers.\n\nTo get needed information for a hostname (say, cnn.com), the client first contacts one of the root servers, which then contacts the TLD servers for the com domain, which in turn contacts the authoritative DNS server for cnn.com. The authoritative DNS server provides the IP address for the hostname, which is then returned to the client. \n\nEvery organization with publicly accessible hosts (such as Web servers and mail servers) on the Internet must provide publicly accessible DNS records that map the names of those hosts to IP addresses.",
    "to IP addresses. They can choose to implement their own servers to hold these records or pay to have them stored by some service provider.\n\nThere is another important type of DNS server called the local DNS server (or default name server). It doesn\u2019t strictly belong to the hierarchy of servers. Each ISP has a local DNS server. When a host connects to an ISP, it provides the host with the IP addresses of one or more of its local DNS servers (along with the IP address of its first-hop router). When a host makes a DNS query, the query is sent to the local DNS server. Thus, this server acts as a proxy, forwarding the query into the DNS server hierarchy if it cannot satisfy the query from its cache. In theory, any DNS query can be iterative or recursive. In practice, the queries typically follow the pattern in figure 2.21: the requesting host makes a query to the local DNS server which is performed recursively. The local DNS server is likewise to the remaining queries iterative.\n\nDNS extensively exploits DNS caching in order to improve the delay performance and to reduce the number of DNS messages exchanging among the internet. In the early days, when a DNS server receives a DNS reply, it caches the mapping in the local memory. For a name server, the IP address and name of the authoritative name server is cached as well as any other information that arrives in the reply but that might not have been directly requested. For example, in figure 2.1, not only is the IP address mapping from hostname to IP address cached but so is the mapping from hostname to IP address for one or more of the name servers involved in the earlier steps in the iterative query. The local DNS servers can \u201cpoison the cache\u201d of another DNS server. If a DNS or TLD server crashes, extensive caching allows the rest of the network to operate below normal. The actual DNS protocol defines the freedom given to each DNS server to cache DNS records (RRs). When a DNS query is received, the cache items are returned either negated or positively. The DNS server is instructed to delete the records when they expire. As a result, cached information can become out-of-date, just when this record should have been removed from a cache. It is also important to remove data from the cache for security reasons.\n\nThe DNS database contains many types of records. The most common are:\nI. If Type=A, then Name is a hostname and Value is the IP address for the hostname.\nII. If Type=NS, then Name is a domain (such as foo.com) and value is the hostname of an authoritative DNS server that knows how to obtain the IP address for the hosts in the domain. This record is used to route DNS queries further along in the query chain.\nIII. If Type=CNAME, then Value is a canonical hostname for the alias hostname. This record can provide querying hosts the canonical name for a hostname.",
    "IV. If Type=MX, then Value is the canonical name of a mail server that has an alias hostnameName.\n\nIf a DNS server is authoritative for a particular hostname, then the DNS server will contain a Type A record for the hostname. If a server is not authoritative for a hostname, then it will contain a Type NS record for the domain that includes the hostname. If we follow it, a Type A record provides the IP address of the DNS server in the Value field of the NS record.\n\nHow would you like to send a DNS query message directly from the root server to the server(s) who know the (some NS server)? This can easily be done with the nslookup program. After invoking nslookup, you send into its DNS query any DNS server (e.g., your local DNS server). After typing nslookup, you specify the desired DNS server, nslookup will display the records included in the reply (in a human-readable format).\n\nHow can DNS be attacked? The first type of attack that comes to mind is a DoS bandwidth-flooding attack. This way the majority of legitimate DNS queries never get answered. There are other, more interesting, DNS attacks that result, for example, in the entering of fictitious mappings into a DNS server. In an attack that has successfully injected ... the DNS service, ...\n\n2.6: Peer-to-Peer applications\n\n... Denote the size of the server\u2019s access link in bits, the upload rate of the peer\u2019s access link by $u_{i}$ and the download rate of the peer\u2019s access link by $d_{i}$. For the entire download to be completed, ...\n\n... it remains in the system. Assuming there be $N$ number of peers, given the server\u2019s upload rate is $u_{s}$, then we have,\n$$\\dfrac{D_{inst}}{NF_{s}} < \\dfrac{F}{d_{i}}$$\n\n... after the bottleneck disappears, the distribution time $D_s$, can be:\n\n$$D_{s} = max \\left( \\dfrac{NF_s}{u_s}, \\dfrac{F}{min(d_{i})} \\right)$$\n\n... Since each of the $N$ peers download rate as follows:\n\n$$u_{s} + \\sum_{i=1}^{N} u_{i} = \\dfrac{F}{\\min(d_{i})}$$\n\nFor $N$ large enough, $NF_{s}$ the greater number and thus the distribution time grows linearly with the number of clients.",
    "In a P2P architecture, when a peer receives some file data, it can use its own upload capacity to redistribute the data to other peers, thus reducing the download time. At the beginning of the distribution, each peer serves the file data. Thus the minimum set seed at the Fab of the last one less one is exactly that low. Thus, the minimum time is when at least each Flo. If the peer with the lowest download rate cannot obtain all F bits of the file in less than Flast seconds. Thus the minimum distribution time is at least Flast. The total uploading capacity of the system as a whole is equal to the upload rate of the server plus the sum of the upload rates of all the individual peers, that is, $u_{tot} = u_s + f_i$. The system must deliver a total of N F bits. This can be done at a rate faster than $u_{tot}$. Thus, the minimum distribution time is also at least $\\dfrac{NF}{u_{tot}}$. Thus we have:\n\n$$\nD_{P2P} = max \\lbrace F_{last},  \\dfrac{NF}{u_s + \\sum u_i} \\rbrace\n$$\n\nIn reality, this serves as a good approximation of the actual minimum distribution time. With N large enough, the time is determined by the third term. Because it grows in sub-linear time, with many peers a P2P architecture will perform better than a server-client one. Additionally, the P2P architecture is almost self-scaling. This scalability is a direct consequence of peers being redistributors as well as consumers of bits.\n\nBitTorrent is a popular P2P protocol for file distribution. In BitTorrent lingo, the collection of all peers participating in the distribution of a particular file is called a torrent. Peers in a torrent form an overlay network: they maintain a list of other peers in the torrent. The file is divided into chunks. For a given file, a peer can be in one of three states. A peer that has not downloaded the entire file is called a leech. As long as the peer is in this state, it is both downloading chunks it doesn't have yet and uploading chunks it has already downloaded to other peers. Once the peer has the entire file, it becomes a seed, and it continually uploads chunks to other peers in the torrent. \n\nEvery BitTorrent user runs a program called a tracker. When a peer joins a torrent, it registers itself with a tracker to receive a random list of peers in the torrent. It uses this list to join the torrent's overlay network and obtain chunks it doesn't already have. To reduce the load on the tracker, peers exchange portions of their peer list with other peers, so that peer lists are propagated rather than always using the tracker. To provide an incentive to discourage peers from leaving the torrent after obtaining the entire file, BitTorrent uses a technique called 'tit-for-tat.' Alice downloads a chunk from Bob only if Alice has uploaded chunks to Bob. Alice tries to obtain chunks she doesn't have from peers that are locally unchoked and then uploads her own chunks to the top four peers sending her data at the highest rate. At any given time, each peer will have a subset of neighboring peers not in the torrent. \n\n17 of 49",
    "chunks from the file. Periodically, Alice will ask each of her neighboring peers (over the TCP connections) for the list of the chunks they have. In deciding which chunks (that she doesn\u2019t have yet) to request, Alice uses a technique called rarest first. The idea is to determine the chunks that are the rarest among her neighbors and then request those rarest chunks first. In this manner, she not only gets high-priority, interesting info to optimize the number of copies of each chunk in the torrent.\n\nTo determine which requests for chunks from neighbors she responds to, Alice gives priority to those neighbors that are currently supplying her data at the highest rate. Specifically, Alice maintains the download rate from each of her peers and then constantly sends requests to the four peers that are feeding her bits at the highest rate. She then sends chunks to these same four peers (called her **unchoked** neighbors) and newly requests chunks from them. Every 10 seconds, Alice recalculates this. Every 30 seconds, she also picks a fifth peer at random (which is said to be\n\n**optimistically unchoked**) and sends it chunks. Because while sending data to Bob, she may optimize for the high-bandwidth peers, she also needs new peers. With each tenth turn to unchoke one more peer, Alice ensures that new peers get an opportunity. Bob would send a start and then stops uploading data, but by choosing a new random peer, neighbors benefit mutually.\n\n**Tit-for-tat** algorithm operation can be considered as a barter system where resources (file chunks) need to be fairly exchanged. This prompts those who are highly contributing peers to urgently receive data.\n\nOne should have clarified the concept of an efficient to simulate an evolved torrent; to find a substantial amount of public content, noticing the torrents that are publicly indexed and those carrying recognized content across networks. Note that one must develop an emerging set of rules that just add the shared tokens utilized in the tit-for-tat protocol.\n\nTo know how to ask for the content you\u2019re looking for in a P2P network, you must have some distributed set of entities. A usual problem arises when the user doesn\u2019t know where to start with. Specific content and locations would return the IP addresses that had the content often. To build a distributed and to effectively implement a DHT as well, less storage is needed. This makes lookups far more efficient. It can be done through a Distributed Hash Table (DHT).\n\nIf some shared facilities to any peer, which are identified as almost in range, the lookup of itself keys in sort. But closest are being sought (not excessive range), making the peers form a \u201cskin\u201d. To search in this skin, use the hash functions. Assign each (key, value) pair to it, in the hash space, represented by the id nearest to.\n\n To insert a (key, value) pair into the DHT, Alice determines the peer whose ID is nearest to the key to store. She sends a message to request this peer to store the <key, value> pair. Bob might likely look up another peer whose ID is the closest but hasn\u2019t maintained the responsibility their lookup would occasionally not always be practical if peers are becoming active in range therefore circularly looking up an entire space. She tries to find other important locations.\n\nTherefore proposes issues are in peer availability. Th is circular message passing might become etc...\n\nIn the bottom right corner, a major use case: \nClose neighbors are always informed to be accurately aware of each peer verified by the peers, resulting the round trip occasionally resulting.\nThe querying loads can be forwarded in real-time computations to the intervals usually ring topology.\n",
    "Because a peer can come and go without warning, we also must be concerned about maintaining the DHT overlay. To do this, each peer tracks its first and second successors. Each peer periodically verifies that its two successors are alive. When a peer leaves, its predecessor replaces the left peer with its second peer, and sets its second successor from its first. Its predecessor becomes the peer that contacted him.\n\nFor a peer to join, it asks what his predecessor and successor needs to be based on his identifier, and then arranges for the peers around him to update their information.\n\n2.7: Socket programming\n\nRecall that a typical network application consists of a pair of programs \u2013 client program and a server program \u2013 residing in two distinct end systems. When these two programs are to communicate, the client program first initiates a contact with the server program and then the two programs send messages to each other.\n\nFig. 2.13 illustrates socket programming in a UDP (User Datagram Protocol) environment and Fig. 2.14 illustrates socket programming in a TCP (Transmission Control Protocol) environment. To simplify the discussion, we adopt the client\u00a0program, the server program, and the message from Chapter 2 of the text Computer Networking: A Top-Down Approach.\n\nTo explain the basic idea of socket programming, let us consider Fig. 2.13. Suppose a process in one host wants to send a small packet of data to a process in another host over a UDP connection. The sending process first creates a socket. This is done by the socket() call. A socket is the interface between the application layer and the transport layer within a host. The process then sends the packet of data into the socket via the\u00a0\u00a0call. When the packet passes through the network to the destination host, within the destination host the packet is directed to the corresponding socket by the TCP/IP protocol.\n\nNow let us consider the second scenario in Fig. 2.14. Suppose a process in one host wants to send a large file to a process in another host over a TCP connection. This can be achieved by first establishing a connection between the sender and the receiver. Once a connection is established, data is transferred through a reliable, in-order byte-stream between the two processes.\n\nEach TCP segment has source port number and destination port number fields. These fields are used to direct the segment to the appropriate socket at the destination. In our socket programming examples shown in Figure 2.14, we only need to concentrate on the TCP socket. The UDP socket is similar, except that UDP doesn't provide reliable data transfer but is connectionless. Hence, it's simpler to implement.\n\nEach UDP segment has source port number and destination port number fields. These fields are used to direct the segment to the appropriate socket at the destination. In our socket programming example shown in Fig. 2.13, we use a UDP socket instead of a TCP socket because UDP socket programming is simpler to provide.",
    "When using TCP, before the client and server can start to send data to each other, they first need to handshake and establish a TCP connection. One end of the TCP connection is attached to the client socket and the other end is attached to a server socket. When accepting the connection, we associate it with the client socket address and the server socket address. With the TCP connection established, when some data needs to be sent, then that data is fed into the TCP connection via its socket. As in the case of UDP, the TCP segment sits inside an IP datagram before that datagram is sent.\n\nNote that the server program must have a special socket (the listening socket) that is listening for incoming connection connection requests. The client process initiates a TCP connection to the server. This involves the client program by creating a TCP socket. When the connection is established, the client socket is assigned a port number. TCP port 12000 is the server port number.\n\nWhen the client socket is established, the server enters a wait state. Immediately after the server receives a packet from the client with destination port number 12000, it creates a new socket (the welcoming socket) and a new port number (12015). The connection between the client and server is now established with the client address and port number associated with the server address and port number.\n\n\\[\n\\text{clientSocket = socket(AF_INET, SOCK_STREAM)}\n\\] python\npython\n\n\\[\n\\text{clientSocket.send(\u2018Hey, I am the client\u2019)}\n\\]\n\n3.1 - 3.4: Transport layer services\n\nA transport-layer protocol provides for logical communication between application processes running on different hosts. By logical communication, we mean that from the application\u2019s perspective, it is as if the hosts running the processes were directly connected. Transport-layer protocols are implemented in the end systems but not in network routers. On the sending side, the transport layer converts the application-layer messages it receives from a sending application process into transport-layer packets, known as transport-layer segments. The transport layer in the receiving end system then processes the received transport-layer segments, making them available to the receiving application.\n\nWhen talking about a transport layer (possibly) hacking the processes of the upper layers and binding them with a simpler interface, we should think about IP fragmentation, different scheduling techniques, TCP delay based performance.\n\nAt the sender side, the transport layer converts the application-layer messages it receives from a sending application process into transport-layer packets known as segments. At the receiver\u2019s side, the transport layer converts the segments it receives into application-layer messages. As noted earlier, this done by a clear process of demultiplexing \u2013 the job of delivering the data in a transport-layer segment to the correct socket. The transport layer at the receiving host does not actually deliver data directly to a process, but instead to an intermediate socket that will later pull the data out from the kernel. \n\nThe transport layer is the first layer of the OSI model that introduces reliable end-to-end communication. TCP distinguishes the data for multiple connections by tagging each TCP segment with a Port Number, an IP address. This process is called multiplexing. Once on the receiving side, the transport layer will look at these identifiers to deliver the data to the correct process to send it into the application layer. This is called demultiplexing.\n\n\n",
    "The Internet\u2019s network-layer protocol has a name\u2014IP, for Internet Protocol. IP provides logical communication between hosts. The IP service model is a best-effort delivery service. This means that IP makes its best effort to deliver segments between communicating hosts, but it makes no guarantees. In particular, it does not guarantee segment delivery, it does not guarantee orderly delivery of segments, and it does not guarantee the integrity of the data in the segments. For these reasons, IP is said to be an unreliable service.\n\nThe most fundamental responsibility of UDP and TCP is to extend IP\u2019s delivery service between two end systems to a delivery service between two processes running on the end systems. Extending host-to-host delivery to process-to-process delivery is called transport-layer multiplexing and demultiplexing. UDP and TCP also provide integrity checking by including error-detection fields in their segments\u2019 headers. These two minimal transport-layer services\u2014process-to-process data delivery and error checking\u2014are the only two services that UDP provides! In particular, like IP, UDP is an unreliable service\u2014it does not guarantee that data sent by one process will arrive intact to the destination process. For these reasons, TCP provides reliable data transfer. It ensures that data is delivered from sending process to receiving process, correctly and in order. These services are not offered by UDP. Also, TCP provides congestion control. This service regulates the rate at which the sending process can send traffic into the network, thereby reducing network congestion. UDP does not provide this service.\n\nWhen sending a message, the transport layer adds a checksum in the header to be able to detect any corrupted data. When the segment arrives at the destination, the checksum is recalculated b the bits in the message. If the newly calculated one is different than the checksum, the bits have been altered. The receiver can now verify the integrity of the segment and remove all error-added segments.\n\nUDP takes messages from the application process, attaches source and destination port number fields for the multiplexing/demultiplexing service, adds two other small fields, and passes the resulting segment to the network layer. The network layer encapsulates the transport-layer segment into an IP datagram and then makes a best-effort attempt to deliver the segment to the receiving host. If the segment arrives at the receiving host, UDP uses the destination port number to deliver the segment\u2019s data to the correct application process. Note that with UDP there is no handshaking between sending and receiving transport-layer entities before sending a segment. For this reason, UDP is said to be connectionless.\n\nThe most straightforward way to provide reliable data transfer is for the sending side to keep a copy of the transmitted segment. If no acknowledgment is received within a certain amount of time, the sender simply resends the segment. As discussed in the previous chapter, this simple approach requires waiting for acknowledgment for every segment sent, and thus is very slow. A more effective error-recovery technique, which is used in TCP, is based on the retransmission of only the missing segments.\n\nThe reason we still use UDP to transport application data is its speed. Without the need to set up a connection and to guarantee the delivery of the data, the speed of a UDP connection is higher than TCP. However, this means that it is up to the application layer to use the suitable protocol depending on whether it can tolerate packet loss or not. Generally, the below list gives a good outline of where it is preferable to use TCP:\n\n1. Accuracy is critical (i.e., packets must be accurate) over transmission time\n2. Packets must be processed in sequence\n\nOtherwise, use UDP. Note also that because UDP is connectionless, it provides little to no security. Note that it is always possible to capture the information on a specific UDP connection. Another aspect is that some applications prefer to use UDP rather than TCP. The protocol overhead with UDP is lower than TCP because UDP\u2019s header is only 8 bytes of overhead.",
    "TCP is harder to implement as a transfer protocol. How can you guarantee correct transmission in the transport layer when the network layer doesn\u2019t?\n\nFirst of all, let\u2019s see how the transport layer would work if the underlying layers were 100% reliable. There would be no need for any checks, and thus it would just send the data through on one side and decrypt it on the other.\n\nNow, more realistically, imagine no packets are ever lost, but packets can be corrupted. In this case, the receiver would use the checksum to determine if he has a corrupted packet and if he does, send a NACK (NegativeAcknowledgement) back to the sender. The sender would then resend the packet. If the packet is valid, he sends an ACK (Acknowledge) and the sender can send the next packet.",
    "Next, imagine packets can also be lost. In this case you need to be able to have a timeout (used to overcome data loss) function for the sender here, if he hasn\u2019t an ACK or NACK after a certain amount of time, considers the packet he sends as lost. In this case, when he receives it, the receiver must know that it was sending the previous packet (it might be the ACK that was lost, in which case he already has the packet). For this reason a sequence number is added in the header. This can only be one bit if we wait for the ACK between each set bit.\n\nThese are tools that can be used when designing a reliable data transfer protocol. Checksums can be used to detect data corruption at the receiver. ACKs and retransmissions can be used to overcome data loss. ACKs, retransmissions and timers delay can be used to overcome data loss.\n\nWhen a full RDT is used (checksums, ACKs, retransmissions and timeouts) the time delay can be quite significant. The sender is only active a small proportion of the total transfer time, which means the transfer itself works less efficiently. An example is illustrated in the following diagram.\n\nSuppose we have four data packets to send and no errors, the source will send segments 1, 2, 3, 4, and thanks to the timer, they should be received successfully at the destination.  \nAssume the sender starts sending packets 1, 2, 3 and 4 at time 0, 1, 2, 3 and these arrive successfully at times 1, 2, 3 and 4.  \nAfter receiving a packet, the receiver will take some time to process the data (e.g., thanks to the process the segment before, checksums) and generate an acknowledgment.  \nAcknowledgment thus reaches the sender at times 1.5, 2.5, 3.5, 4.5 for packets 1, 2, 3, 4 leading to a propagation latency of 0.5 between nodes.\n\nThis poor sender utilization can be improved by sending more than 1 packet at the same time, without waiting for ACK of each packet as it is shown in the following example. This is called pipelining: the sender",
    "sends up to N un-ACKed segments, using a sliding window of size N. There are two ways of implementing pipelining. Either the receiver must receive all packets in the right order, or he has a window too and can receive them one at a time.\n\nGo-Back-N:\n* The receiver accepts 0 out of order packets\n* ACKs are cumulative (an ACK for segment m means all segments up to m have been received correctly)\n* The sender retransmits all unACKed segments\n\nSelective repeat:\n* The receiver accepts N-1 out of order packets\n* ACKs are selective (an ACK for segment m means segment m has been received correctly)\n* The sender only retransmits one segment \n\n3.5: TCP\nTCP is the Internet's transport-layer, and is a connection-oriented, reliable transport protocol. In order to implement reliability, TCP relies on retransmissions of un-acknowledged segments, flow control, multiplexing for error detection, retransmissions, cumulative acknowledgments, sliding windows, timers, and other congestion-avoidance mechanisms. Most of the understanding of pipelined protocols applies to TCP. Each endpoint has 16-bits that are TCP port numbers and are associated with one application program. The source and destination port numbers are the application between two applications, but they must establish some primary data structures on their respective system's TCP layer in order for their data to be transmitted to the correct application. \n\nThe initial sequence number (ISN) is randomly chosen at the start (if the IP addresses are the same, the ISN is only incremented by 1). The 16-bit source and destination port numbers are used to maintain TCP connections. In fact, node addresses, TCP, and IP addresses combine to assure that the segment gets to the right place on the network and device.\n\nA TCP connection provides a full-duplex service. If there is a TCP connection between Process A on one host and Process B on another host, then Process A can send data to Process B at the same time as application-layer data flows from Process B to Process A.\n\n24 of 49",
    "TCP connections are also always point-to-point (they are between a single sender and a single receiver).\n\nWhen a client wants to establish a connection to a server, the client application process first informs the client transport layer that it wants to establish a connection to a process in the server. TCP in the client proceeds to establish a TCP connection with TCP in the server. To do this, the client first sends a special TCP segment (a TCP SYN); the server responds with a second special TCP segment (a TCP SYN ACK); and finally the client responds again with a third special segment. The two halves of the application (application-layer objects), the sending and receiving sockets, are treated together as a single \u201ccommunication endpoint\u201d. In this manner, a two-way connection is established between the two hosts. This connection-establishment procedure is often referred to as a three-way handshake. Once a TCP connection is established, the two application processes can send data to each other. In TCP either the client and server, or both, are allowed to send/receive data (data can go both ways at the same time -> full-duplex service).\n\nTo send data from a sender to the client-process a segment as shown through the packet network and data link network and data link protocols, among others), the sender will encapsulate the data bounded by the segment's boundaries into an IP datagram with this data. Then TCP will pass the segment IP packet to the different networking layers. This way, the TCP segment is encapsulated in an IP datagram. Once the datagram reaches the destination host, the IP packet is passed to the transport layer, where they are separately encapsulated and is passed back up to the receiving process, as shown in the figure. From time to time, TCP will grab chunks of data from the sending process, encapsulate each chunk within a TCP segment, and pass the segment to the network layer. TCP provides a reliable data transfer by using positive acknowledgements and retransmissions. Therefore, if a segment is dropped by the network, TCP will retransmit that segment. Since segments may take different paths, they may arrive at the other end in order.\n\nMS is typically of a few tens of kilobytes, TCP segment includes: (i) source and destination process addresses, (ii) 32-bit streaming number, (iii) 32-bit ack. A byte number if packet byte missing, cumulative field.\n\nTCP segments consists of header fields and a data field. The data field contains a chunk of application data. As with UDP, the TCP header includes source and destination port numbers, that is to say, they are functions of upper-layer applications, and an application field, no length of field indicates a sequence number (or missing byte). It also contains fields: (i) ack number (if of oldest byte missing, cumulative field).",
    "TCP views data as an unstructured, but ordered, stream of bytes. The sequence number for a segment is the byte-stream number of the first byte in the segment. The acknowledgement number that Host A puts in its segment is the sequence number of the next byte Host A is expecting from Host B. The bytes are implicitly numbered.\n\nTCP uses a quite sophisticated mechanism to recover from lost segments. The sender retransmits the segment with oldest unACKed sequence number. To calculate the length of the timeout interval, there are a couple of things to take into account: Clearly, the timeout should be larger than the connection\u2019s round-trip time, But, how big should it be? The sample RTT for a segment is the amount of time between when the segment is sent and when an acknowledgment for that segment is received. As the time taken RTT value is generally estimated at Host at the sender side, but randomly sampled segments, a long RTT value is significant and is ignored by estimating average RTT. Also, TCP over computes a SampleRTT for a Segment that has been retransmitted. Because the sender cannot know if the ACK/received was for the first transmissions of the segment or for second transmission, the TCP never computes a SampleRTT for a retransmitted segments. In order to estimate a typical RTT, we must take the average off the sampleRTTs values. TCP calculates the weighted average of the sampleRTT values over time. When obtaining a new sampleRTT, TCP calculates Estimated RTT according to the formula:\n$$\n\\text{EstimatedRTT} = 0.875 \\times \\text{EstimatedRTT} + 0.125 \\times \\text{SampleRTT}\n$$\nIn addition to having an estimate of RTT, it is also valuable to have a measure of the variability of the RTT. The RTT variance, DevRTT is an estimate of how much SampleRTT typically deviates from EstimatedRTT. It is a function of the variance of the RTT. The final timeout value is calculated as:\n$$\n\\text{Timeout} = \\text{EstimatedRTT} + 4 \\times \\text{DevRTT}\n$$\nOne inaccuracy with timeout-triggered retransmissions is that the timeout period can be relatively long when compared with the amount of time that it takes to send a small number of packets. This can result in an unnecessarily high amount of sender idling, a problem that can be largely avoided by using a fast retransmission and fast recovery mechanism. In this case, a sender can often detect packet loss by the arrival of ACKs (at the sender) that don\u2019t advance the sequences number for already received packets. Instead of waiting a sender quickly retransmits the lost segment before that segment\u2019s timer expires. Before explaining how fast retransmission is used to detect and repair lost segments, we must discuss the flow of data between a sender and receiver in a TCP connection in a little more detail. During connection establishment, each side of the connection records the initial sequence number of the other side of the connection, and initializes its own sequence number for the connection (it chooses the initial send sequence number). As part of the data that is sent, the sender also sends a sequence number to which the sender expects.\n\nIn the case that multiple ACKs are received, the TCP sender performs a fast retransmit: the sender retransmits the segment with oldest un-ACKed sequence number. There are two 26 of 49",
    "events that trigger a retransmit are timeouts or three duplicate ACKs received. Selective acknowledgment allows a TCP receiver to acknowledge out-of-order segments selectively rather than just cumulatively acknowledging the last correctly received in-order segment. When combined with selective retransmission\u2014triggering the retransmissions of segments that have already been selectively acknowledged by the receiver\u2014we can see that TCP\u2019s error-recovery mechanism is probably best categorized as a hybrid of GBN and SR protocols.\n\nTCP provides a flow-control service to its applications to eliminate the possibility of the sender overflowing the receiver\u2019s buffer. When a TCP connection ensures bytes that are correct and in sequence, it places them in the receiver buffer. The associated application will retrieve data from this buffer, but as with any shared resource that has multiple consumers and producers, the receiver buffer may also overflow at some point since it may not always be emptied at the same rate as data arrives from the sender. In such a situation, even exactly transferred data would eventually have nowhere to be stored. For this reason, a flow-control service is needed to control the rate at which a sender generates data so that the receiver can receive this data.\n\nFlow control is a speed-matching service\u2014matching the rate at which the sender is sending against the rate at which the receiving application is reading. A TCP sender will use a window to advertise the amount of free space available. This sender control is referred to as congestion control.\n\nTCP maintains a shared state between the sender and receiver through a flow receiving window. Furthermore, this receiving window operates as the value $\\mathrm{rcvbase} +\\mathrm{rwnd} -1$, where $\\mathrm{rcvbase}$ is the value of the next byte the TCP is waiting to receive. When the receiver buffer fully empties, this value will reach $\\mathrm{rcvbase}$. The TCP receiver then sends the updated value $\\mathrm{rcvbase}$ to inform the sender of how much free room it has in the connection buffer by making rwnd. rwnd stands for the value of the received window size.\n\nImagine that B\u2019s window is full, and he tells this total to A in the ACK for the last message he sent. During the time needed for this message to reach A, how does A learn about which byte it needs to be sent preceded again? The results of the TCP connection will require retransmission. The packet headers will negate the rwnd value given by B\u2019s specific rwnd. As these messages propagate, A will use the segmentation number. Eventually the buffer will begin to empty and the acknowledgments will contain a nonzero rwnd value.",
    "Here is a brief explanation on the setup and the tear down of TCP connections.\n\nConnection:\nI. The client-side TCP first sends a special TCP segment to the server-side TCP. This special segment contains no application-layer data. This special segment is referred to as a $SYN$ segment. In addition, the client randomly chooses an initial sequence number and puts this number in the sequence number field. There has been considerable interest in properly randomizing the choice of this number in order to avoid certain security attacks.\nII. Once the IP datagram containing the TCP $SYN$ segment arrives at the server host, the server extracts the segment from the datagram, allocates the TCP buffers and variables to the connection, and sends a connection-granted segment to the client TCP. This connection-granted segment also contains no application-layer data. The server also chooses a random initial sequence number and puts this value in the sequence number field of this $SYNACK$ segment header, which is the second segment in the three-way handshake. This second segment is referred to as a $SYNACK$ segment.\nIII. Upon receiving the $SYNACK$ segment, the client also allocates buffers and variables to the connection. The client then sends yet another segment; this last segment acknowledges the server\u2019s $SYNACK$ segment. The $SYN$ bit is set to 0, since the connection is established. However, the client does include in the acknowledgment field the server\u2019s initial sequence number incremented by 1. This third segment may contain application data.\n\nDisconnection:\nI. To close a TCP client deallocates the source, the states for this transport connection, as shown in Figure 3.40. The client application issues a close command to TCP.\nII. The TCP client sends a $FIN$ bit segment to the TCP server. The server notifies the application about the closing test.\nIII. The server then sends his own shutdown $FIN$ bit segment.\nIV. Finally the TCP client issues an acknowledgment $ACK$ segment to the server. When the side FIN bit is on, the connection moves from established state to FIN-wait or close-wait states. For a full-duplex connection, there are two profiles are closed so there is a $FIN$ bit and $ACK$ bit for both, and the connection moves into a closed state.\n\nTCP hijacking: In this type of attack, a hijacker impersonates one of the parties and provides fake content. In the example of a client making an HTTP request, the hijacker impersonates the client on a given local area network to guess when the client will ask the server for a certain info, and attempts to respond faster on behalf of the server.",
    "server does. He must determine (or guess) which port was used (or contact all of them), and \nspoof his IP. He must also respond with the correct sequence and ack numbers. When the servers \ndata gets there, if the client has already accepted the hijackers data, it simply rejects it. There is \nsimple defence to this attack, which is to just randomize sequence numbers (the stacks might not \nimplement it though). \n\nThe SYN flood attack: We\u2019ve seen that a server allocates and initializes connection variables \nand buffers in response to a received SYN. The server then sends a SYNACK in response, and \nwaits for an ACK segment from the client. If the client does not send an ACK to complete the second \nstep of this 3-way handshake, eventually (often after a minute or more) the server will terminate \nthe half-opened connection and reclaim the allocated resources. This TCP connection management \nas discussed before. This is also known as the SYN flood attack. In the SYN flood attack, the attacker \nsends a large number of TCP SYN segments, without completing the third handshake step. With this belligerent SYN segments, the server\u2019s connection resources become exhausted. As a consequence, the server is then bogged down with false connection requests, and may even be prevented from accepting legitimate connection requests. Defenses against the SYN flood attack include \nallowing connections to be in a half-open state for only a short time and selectively authenticating \nclients during the 3-way handshake. By limiting the duration that a client has to be authenticated, this \ncan mitigate some SYN flooding. Another defense mechanism is to limit the number of half-open \nconnections from a single IP address. In such a case, a specific time frame is used to identify a particular address's high connection requests, which can assist in preventing a flood from overburdening the server's connection queues. Implementing SYN cookies is another powerful defense \ntactic. The idea of SYN cookies is to encode the server's initial sequence number with information \nabout half-open connections. This means the server does not need to maintain state information on \nhalf-open connections it can decode the value in the initial sequence number of a received ACK to \nreconstruct the necessary information about the connection. This stateless way of handling connection requests though SYN cookies makes the server less vulnerable to SYN flooding, as the attacker \ncannot exhaust the server's state memory, since the server is not storing any unnecessary information \nfor connections. By using SYN cookies, the server defers the resource allocation until after the \nreceipt of the ACK segment, ensuring that resources are allocated only for legitimate connections.\n\nInstead of creating a half-open TCP connection for every SYN, the server creates IP \ntables to store IP request numbers that it is a hash function of source and destination IP \naddress. SYN cookies further avoid SYN flood. Before sending SYNACK, the server can \ninitialize the server\u2019s counter and initial sequence number in such a way that the server \ndoes not need to establish and delete a SYNACK packet till the resourceful check \u201ceore \narKs that is completed. A legitimate client will remain with an ACK segment, hold the server \nresources using cookies. It is a more flexible solution than traditional IP address and port \nhashing. It helps in detecting the faulty client and ignore as the destination IP address of the \nclient as faulty. Hence, rotating the server cookies adds\u00a0using the same SYN cookie, the server\nlimits a bad attack. The SYN-cookie eliminates initial sequences of a maximum segment \nlife (MSL) until the check is valid. The server then creates a fully open connection in that \nway assigning the resources. In such a case acknowledge responses segment need not \nrequire implementation time. Hence, the server, since the server hasn\u2019t yet allocated any \nresources in response to the original bogus SYN.\n\n3.7: TCP Congestion Control\nIf a senders always try to send data at the maximum possible throughput (the rate of the \nbottleneck link), this would lead to congestion. This means the routers and links would get so \nfilled and thus they will have to share their common link\u2019s data. This is called congestion. This \nsituation leads to delay in data number of times and thus TCP is implemented using the \ncongestion control and avoidance algorithm. Most of the routers in a given path to multiple \nswitches transmitting output packets and the switches transmitting packet that will be dropped",
    "(resource waste). The effective throughput is the throughput that is actually used to send new packets. It's always smaller or equal to the throughput.\n\nThere are two main approaches to congestion control. Either the network layer does the work (packet switches signal congestion to end-hosts), or the transport layer does it (end-hosts signal congestion to each other). TCP must use end-to-end congestion control rather than network-assisted congestion control, since the IP layer provides no explicit feedback to the end systems regarding network congestion. The approach taken by TCP is for the end-hosts to infer congestion based on loss. The sending rate is then a function of perceived network congestion. If the TCP sender perceives that there is little congestion on the path between itself and the destination, then the sender can pump its segments into the network more aggressively; if the sender perceives that there is congestion on the path, then the sender reduces its sending rate.\n\nThe TCP congestion-control mechanism operating at the sender keeps track of an additional variable, the congestion window. The congestion window, denoted $cwnd$, imposes a constraint on the rate at which a TCP sender can send traffic into the network. Let $b d p$ denote an estimate of the bandwidth-delay product of the connection (see Sect. 2.3). LastTimeout informs the sender to reduce its sending rate, the first ACK, and is, thus, simply, the maximum sender window size.\n\n$$ b d p = R\\ bps \\times R T T \\ sec$$\n\nLet us define a loss event at the TCP sender as the occurrence of either a timeout or the receipt of three duplicate ACKs from the receiver. When there is a loss event, the sender's rate should be decrease in proportion to the severity of congestion. When there is no congestion, a TCP sender should increase its sending rate presumes acknowledgement is not acting as explicit signaling taken by the sender to be an indication of congestion on the sender-to-receiver path.\n\nTCP uses three broad classes of mechanisms more than one is often, uses acknowledgments for coverage of congestion windows. This will be achieved at the very least. But loss event observed after sending of multiple segments will be indicated to end-host as $c w n d / 2$. TCP sender reduces its sending rate by shrinking its window and the TCP.\n\nTCP uses acknowledgments to trigger (or elicit) its increase in congestion window size (it's said to be self-clocking). In fact, the algorithm requires every ACK received to increase the $a w\\ n d$ and subsequent loss event will increase or decrease its congestion window based on this information.",
    "How should a TCP sender determine the rate at which it should send? If TCP senders collectively send too fast, they can congest the network, leading to congestion collapse. If TCP senders are too cautious and send too slowly, they could under utilize the bandwidth in the network. TCP answers these questions using the following guiding principles:\n\nI. A lost segment implies congestion, and hence, the TCP sender\u2019s rate should be decreased when a segment is lost.\n\nII. An acknowledged segment indicates that the network is delivering the sender\u2019s segments to the receiver, and hence, the sender\u2019s rate can be increased when an ACK is received for a previously unacknowledged segment.\n\nIII. Bandwidth probing. TCP\u2019s strategy for adjusting its transmission rate is to increase its transmission rate in response to arriving ACKs until a loss event occurs, at which point, the transmission rate is decreased.\n\nHow do we increase the window size, to increase it fast enough to utilize the networks capabilities but without being misled?\n\ni. Increase the window size exponentially; by 1 MSS for every ACKed segment (which will be denoted additive increase every RTT), when we don\u2019t experience a congestion loss.\nii. When congestion occurs use linearity; by 1 MSS every RTT, when we see congestion losses.\n\nWhen a TCP connection begins, the value of cwnd is typically initialized to a small value. If TCP senders began with a large value of the cwnd this might possibly trigger losses. Starting slow ensures that the TCP sender\u2019s rate is much larger than MSS/RTT. The TCP sender must also keep track of a threshold value called ssthresh.\n\nIn the slow-start state, the value of the window begins at 1 MSS and increases exponentially; i.e., the window is doubled by the sender in every RTT. The TCP sender sets the value of cwnd to 1 and increments the value of cwnd by 1 MSS for every ACK received. Hence, the value of cwnd is doubled every RTT. When the value of cwnd reaches the value of ssthresh, TCP sender goes into a new state called congestion avoidance state. The slow start phase ends when one of the following conditions is reached:\ni. Before the value of the window cwnd reaches the value of the threshold this case where duplicate acks increments (three acks lost) TCP has gone into recovery mode.\nii. the receiver window rwnd\n\n In this new mode, the window is increased linearly, and at the same time a fast retransmit is done. When the ACK for the lost segment is received, TCP enters congestion avoidance state.\n\nWhen the value of the window reaches the threshold ssthresh, TCP enters congestion avoidance Congestion avoidance mode. TCP increases the size of the window linearly from there.\n\n31 of 49",
    "consecutive Acks are received, TCP goes back to recovery mode. If a timeout occurs, it goes back to the slow-start state.\n\n4.1: Introduction to the network layer\nFigure 4.1 shows a simple network with two hosts, H1 and H2, and several routers on the path between H1 and H2. Suppose that H1 is sending information to H2. We refer to the path that packets take from H1 to H2 as a route. In its simplest form, a network layer can be remarkably simple and elegant. The network layer in a datagram network provides a communication service between two network layer entities: at the sending host, a network layer entity takes segments from the transport layer, encapsulates each segment into a datagram, and delivers the segments to the transport layer at the receiving host. The primary role of the routers is to forward datagrams from input links to output links.",
    "The role of the network layer is to move packets from a sending host to a receiving host. To do so, two important network-layer functions can be identified:\n1. Forwarding. When a packet arrives at a router\u2019s input link, the router must move the packet to the appropriate output link. It operates at the per-router timescales of\ntransmitting a packet from an input link to the appropriate output link.\n2. Routing. The network layer must determine the route or path taken by packets as they flow from a sender to a receiver. The algorithms that calculate these paths are referred to as routing algorithms. It refers to the network-wide process that determines\nthe end-to-end paths that packets take from source to destination. This means that it populates the forwarding table.\n\nEvery router has a forwarding table. A router forwards a packet by examining the value of a field in the arriving packet\u2019s header, and then searching for this header value in the forwarding table. Depending on the network-layer protocol, the header value could be the destination address of the packet or an indication of the connection to which the packet belongs. The forwarding table is filled \"manually\" by network administrators or can be filled automatically as a result of the routing process, depending on specific purposes, depending on the protocol.\n\nThe routing process determines the values that are inserted into the routers' forwarding tables. If a router contains \ud835\udc51 links, its forwarding table has up to \ud835\udc51 possible entries. When a packet arrives on one of the input links, it matches the label and is assigned to the corresponding output link. More generally, it can also happen that the input label can match multiple output links. In this case, the packet is duplicated on all possible output links. The forwarding process has to make one choice. The routing process can then implement global mechanisms that consider the state of the network.\n\nSome network-layer services require the routers along the chosen path from source to destination to maintain \"state\" information. From a network-layer standpoint, the service can adopt two principles: connection-oriented and connectionless. Just as a point-to\u00ac point telephone call is connection-oriented, so too are today's telephone networks. Computer networks as the Internet do not provide connection-oriented service, but packet networks have been designed that do.\n\nThe network-layer connection and connectionless services have inspired two types of packet switching techniques: datagram networks and virtual circuits. Datagram networks are the basis of the Internet, today's most widespread computer network. Virtual circuit networks can be controlled by the transport layer (this is the case of ATM where the transport layer passes packets to the network-layer through virtual circuits). The definition of a virtual circuit network depends on the state information that is stored in the routers and switches. At a specific moment, a virtual circuit can be defined with a succession of entries in the forwarding tables of the routers. This state information is called the virtual circuit connection. At each hop of the path, a path identifier can be associated with it. Virtual circuits can, however, guarantee quality of service better than the Internet can. The other routing technique is packet switching based on datagrams. Depending on the network-layer protocol and routing algorithm, routing processes the forwarding tables and connection setup also involves forwarding tables.\n\nNetwork-layer connection and connectionless services in many ways parallel transport-layer connection-oriented and connectionless services. The network-layer connection service is\n\n33 of 49",
    "implemented in the routers in the network core as well as in the end systems. Keeping state would also be very complicated, because of the high complexity that so many connections would bring, and also for security reasons.\n\n4.2: Virtual circuit and datagram networks\n\nComputer networks that provide only a connection service at the network layer are called virtual-circuit (VC) networks. A packet belonging to a virtual circuit will carry its VC number in its header. It uses connection switching, for network-layer connections, and it uses need network-layer guarantees (like minimum throughputs) are needed. The forwarding table and minimum connection state information for the ongoing connections (the forwarding state is kept per connection). The forwarding tables are populated by the connection setup.\n\nWhen Alice wants to send data to Bob, and she wants the network to guarantee minimum throughput for her traffic, she first sets up a path that the network will then allocate resources to and manage for Bob. When this virtual path has been established, a bit more information is included in the header of subsequent messages. It is forwarding table that any message, once it has reached a node, that belong to a certain output link (it figures out which output it is without looking through the full address). When Alice then sends her first packet to Bob, the router does this and leaves the VC number on the input packet alone and looks in the forwarding table. Then forwards this packet through the output link. When Bob notices a mismatch in the VC number in the header it messages Alice to Alice. When Alice then sends data to Bob, she writes the VC number in the header of every packet.\n\nFor example: When Alice sets up a packet switched VC number on each link, each intervening router replaces the incoming VC number on each traveling packet with a new VC number. The new VC number is used on the succeeding link.\n\nThis is referred to as circuit switching: Tables in the nodes must keep state information for every VC, where the router maps a call handle of the first incoming line to the line it emerges from millions of seconds later. If they didn\u2019t the problem would be that incoming time interfering packets(s).\n\nThe network layer of the internet doesn\u2019t provide any form of guarantee. It provides best-effort delivery. The way it\u2019s organized is described as a datagram network. In this network, all the routers just keep separate destination paths for the internet, and each system has an IP Address. Routers use forwarding tables store information about the IP Address. For instance, if multiple paths around 34 of 49",
    "that an end-system with certain IP can be reached through a certain output link. Every router knows how to reach every IP in the world. When a source wants to send information to a certain destination, it writes the IP of the destination in the network-layer header of the packet. The router that receives the packet reads the IP and forwards it to the correct output link.\n\nTo reduce the information that needs to be kept in forwarding tables of each router, forwarding tables are filled with mappings from ranges of IPs to output links. To implement this, the network-layer of the Internet uses something called longest-pattern matching. This means that the table stores, for instance, entries corresponding to networks A, B and C. So, some ranges in the table and some ranges that aren\u2019t complete \nquitte \u00e0 allouerange. For example, we might have a routing table as below, where the range 0-3 (0*) covers 3 bits, (1*) which actually the range (0-3). and a specific entry for IP address 3 is indicate digs. \n  \n| $$ \\text{dest. address range} $$ | $$ \\text{output link} $$ |\n|---------------------| -------------|\n| 00* | 0 |\n| 01* | 1 |\n| 100* | 2 |\n| 101* | 3 |\n| 110* | 3 |\n| 111* | 2 |\n\nWhen the router receives a packet with a destination IP, it will look in its forwarding table and perform the longest match to the destination IP.\n\nTo have ranges as homogeneous and \u201cfull\u201d as possible, it\u2019s important that end-systems that are physically close to one another have similar IPs, which means that the IP addresses depend on the end location information.\n\nEvery IP address is kept as it is since they look binary because it scales better (no need for new connection states), and it makes the network simpler (no need to stop and tear-down connections).\n\nIP addresses are numbers from 0 to 2^8 -1, represented by 4 sets of bytes, written in their decimal form (from 0 to 255). An IP prefix is a range of IP addresses.\n$$\\texttt{Example: The IP address is a but. That means that when a prefix to be written. The number of MSBs we will take from the IP address must be there and set how many bits are there. This is represent in the example from 10.32 to 10.43 the first 16 bits is the IP prefix. Another word to explain prefixes, this called as writing the IP prefix, and then \u201cdot star\u201d (*), which means that from there the bits can be anything.}$$\n",
    "4.3: Routers\n\nWhen Alice sends a packet to Bob, that packet crosses multiple packet switches. Some of them are link-layer switches, and some of them are network-layer switches (which are also called IP routers). Routers are made of two general parts: the control plane (routing, resource management) which is software, and the data plane (forwarding) which is hardware. Their main role is to move each packet towards its destination. The input ports also have some forwarding table copies and buffers. An input port performs the lookup, and if the packet can be forwarded, among all incoming physical links, at a router. It is also here that the forwarding table is consulted to determine the outer output port to which an arriving packet will be forwarded via the switching fabric. The switching fabric connects the router's input ports to its output ports.\n\nAn output port stores packets received from the switching fabric and transmits these packets on the outgoing link by performing the necessary link-layer and physical-layer functions. The switching fabric receives routing protocol routing, maintains routing tables, and attached link state information, and computes forwarding tables based on these routing tables. This can be done by software. A router's input ports, output ports, and switching fabric are almost always implemented in hardware. Modern routers are switching via a switching fabric capable of transferring packets from an input port to an output port at the same speed as the line speed.\n\nThe switch fabric design often uses memory. In this case, input and output ports functioned as traditional I/O devices in an operating system. Input port signaling for the memory access first signals the routing processor. The packet is then copied from the input port into processor memory. The routing processor then extracts the destination address from the header, consults the forwarding table to determine the output port, and copies the packet to the output port's buffers.",
    "If the memory bandwidth is such that 2R packets per second can be written into, or read from, memory, then the overall forwarding throughput must be less than R (because the data must be put into memory, and then taken out).\n\nQueuing delay will occur in input ports, in the case where two packets coming from two inputs going to the same output link arrive to the router at the same time. In this case, some of the packets will need to wait a while, waiting for output port to free up.\n\nHead of line blocking can happen when a router is experiencing queuing delay, and a new packet should experience less queuing delay than packets behind it. In this case, the arriving packet will be blocked along with the rest.\n\n4.4: The Internet Protocole\nThe world is separated in IP Subnets that each have their own IP prefix. Informally, an IP Subnet is a region in the world that does not include any IP address that belongs to the same IP address. In other words each Subnet is the white area that has the same prefix, that is, the leftmost bits of the IP address. Each IP subnet is separated by routers.\n\nThe subnet that is local to a host contains the host, but there are many. Each router also has an IP address for the subnet that it is connected to. Routers that are directly interconnected can forward packets, this process is referred to as \u201chops\u201d. According to the subnet designation rules, within means that routers will need another layer of bits to be added to the address for each subnet they belong to.",
    "Organizations obtain IP prefixes from its ISP or a regulatory body, and then a network operator assigns IP addresses to router interfaces manually, and to end-systems either manually or through DHCP (an automatic process).\n\nBecause there are only a finite number of IP addresses, it\u2019s possible that a network runs out of them, and that actually happens quite often. In that case, the network administrator can\u2019t give any new IP address to a potential new user. The solution to this problem is to use private IP address spaces. A private IP address is one that is only meaningful inside the local network itself. This means that if a router outside of the local network sees the IP address, it won\u2019t recognize it.\n\nTo communicate with users outside of this local network, a user with a private IP address will need to use the local gateway router, which must deinstantiate addresses. Indeed, the local network is allowed of course to translate itself per own method. The router located on the border of the local network will select the outgoing interface based on the TCP port number. It associates a new outgoing TCP port number with the same IP address and stores this information in its translation table. When the router receives its report number of the private IP address from the same end system, it will replace it in the outgoing datagrams with its own port value, and the data is sent forward. Likewise, for the response, the router replaces the port added back by the public IP address and the destination port, with the correct TCP port number. That way when the end system responds, the user is able to recognize it and properly deliver the inbound response back to the application user. This is the main usage of NAT (Network Address Translation). For private networks, the following address spaces are selected [RFC 1918]:\n\n$10.0.0.0 - 10.255.255.255$\n$172.16.0.0 - 172.31.255.255$\n$192.168.0.0 - 192.168.255.255$\n\nThis helps administrators give a meaningful number of network addresses.\n\n4.5: Routing Algorithms\n\nWhether the network layer provides a datagram service (in which case different packets between a given source-destination pair may follow different routes) or a VC service (in which case all packets between a source and destination will follow the same route), the network layer must determine the route or path taken by packets as they flow from a sender to a receiver. The algorithms that calculate these paths are referred to as routing algorithms. A routing algorithm would determine, for example, the path along which packets flow from H$1$ to H$2$. Routing algorithms can be classified into two broad categories: global routing algorithms and decentralized routing algorithms. In a global routing algorithm, the algorithm computes the least-cost path between a source and a destination using complete, global knowledge about the network. That is, the algorithm takes the connectivity between all nodes and all links costs as inputs. This then requires that the algorithm somehow obtain this information before actually performing the calculation. As with an LS algorithm, in a link-state algorithm, the algorithm has complete information about connectivity and link costs. In a decentralized routing algorithm, the calculation of the least-cost path is carried out in an iterative, distributed manner. No node has complete information about the costs of all network links. Instead, a node begins with only the knowledge of the costs of its own directly attached links. Then, through an iterative process of calculation and exchange of information with its neighboring nodes, a node gradually calculates the least-cost path to a destination or set of destinations. The prominent example of a decentralized routing algorithm is the distance-vector routing algorithm. In both global and decentralized routing algorithms, a router typically only has a partial information about the network, it knows only the state of its directly attached links and the costs associated with it. Therefore, the routing algorithm needs to carry out the calculation such that it effectively determines the least-cost path between the endpoints.\n\n38 of 49",
    "routers, with links connecting the routers, a routing algorithm finds a \"good\" (which usually\nmeans least-cost) path from source router to destination router.\n\nA network can be seen as a weighted graph with routers as vertices and links as edges. The goal\nof the least-cost path routing algorithm is to find the least-cost path from each source router to\neach destination router. In our version of the problem, we will only look at the cost of each link\nas it is propagating delay. In reality, it\u2019s different.\n\nA global routing algorithm computes the least-cost path between a source and destination using\ncomplete, global knowledge about the network. It takes as input the router graph and the link\ncosts, and outputs the least-cost path from every source router to every destination router. This\nis another procedure that, although containing this information about costs and members, is\ncalculable. This is done by having each node broadcast link-state packets to all other nodes in the\nnetwork, so that all nodes have complete knowledge including the identities and costs of the\nnetwork. The well-known Dijkstra\u2019s Algorithm that we learn in general is an example of such\nmethod. In this centralized algorithm. The calculation itself can be run in the form centralized \ncontrolled manner at a central agent. A global algorithm is also referred an as link-state (LS) algorithm\nsince it has a connection to all the other nodes for information including means all the nodes at most\nand links between them. This explains each link in the network.\n\nAn algorithm example of each further that can be used is Dijkstra's algorithm. It computes the\nleast-cost paths from one node (the source) to all other nodes in the network. It is iterative and has the\nproperty that after the k iteration, the least-cost paths are known to k destination nodes. In the\nnetwork as such has not only fewer nodes, and that the each iterations a node is minimum (if there are\ncommon vertices), and updates the paths to its neighbors. Consequently, the vector will then be\nupdated for closest possibility.\n\nA decentralized routing algorithm, the calculation of the least-cost path is carried out in an\niterative, distributed manner in which no node has complete information about the costs of all\nnetwork links. The term decentralized means components of the algorithm is distributed among\nthe members of the network including each node knows only the connectivity of its neighbors to its\nown storage calculating information will be local. The calculation is carried out iter by iter in\nmedium-sized and large-sized links as a result. It begins due to many sendings, the distance of\ninformation available is neighbor to neighbor information from its starting points to other nodes\nincluding its neighbors\u2019 neighbors. It is a global information as opposed to individual nodes\npropagates it around its neighbors. The algorithm is also sometimes problematic if it does not\nawait fully for the weight edges to achieve the highest path. The Bellman-Ford algorithm is one\nsuch example.\n\nThe basic idea of the propagation of information is as follows. Each node begins with $D(v)$ , an\nestimate of the cost of the least-cost path from itself to node v. Let $C(v)$ be the cost of the path. The\npaths calculate sum of the tables mostly empty, but as neighbors transfer information from one",
    "When looking for the distance at which an edge not directly connected to i is, the routing algorithm can use the Bellman-Ford equation. For this example, it's:\n\n$$d_{i}(x) = \\min(\\text{cost}_{ix} + d_{j}(x)) \\ \\forall \\ j \\ \\text{neighbors in x}$$\n\nWhen a node running the DV algorithm detects a change in the link cost from itself to a neighbor, it updates its distance vector and, if there's a change in the cost of the least-cost paths, it informs its neighbors of its new distance vector. In the case that a link is deleted, the next node j returns infinity for $d_{j} ($cost in neighbor j$)$. \n\nThe idea here is that each node has to go and update the distance. In this example, $X$ updates its information to say \nthat it can't see a router; this change is \u03b4 = 1 as but Y\nsees distance to Z=2; therefore $\u03b4_j=3+1$=4. The sum of 4 is too high, therefore we have a loop infinity in between j and X. The node it would repeat would receive it 3 simply and see that the \nlink is not unstable.\n\nWhen considering another path is found with distance smaller. Therefore there is needed to avoid foundational stability,  The arrows to z would be negative. As well update continuously until another path is found with distance smaller. Therefore it takes time until routing writes\n\n$$d_{i}(x) = min_{(d^{\\infty}+d_j(x))}$$\n\nTo avoid this problem, we can use a poison reserve Thereby, J and X say, infinite to all more frequent to of the network destination nodes \n\nthat is currently not able to identify the the loops as high to. Know $D_{i}(x)$ is infinity. this will be able to guess either or not $(d_i v=w))$ we have loops in Distance up to as long as identify to rid to set the limits the iterations route i to via x; as long as i can continue route X via y (and just about doing so).",
    "4.6: Routing in the internet \n\nLink-state routing converges faster than distance-vector, but DV requires less messages. Between the two, it\u2019s a tradeoff between convergence and message overhead. In the internet, the challenge is that LS would cause flooding, by sending too many messages to broadcast information; while DV would actually never converge. This is why the internet chooses to use administrative autonomy. Each ISP can choose the routing protocol it wants. ISPs don\u2019t necessarily want to do least-cost routing, and may also want to hide their link costs from the world. The internet is separated in autonomous systems, and each ISP has one or more autonomous systems in which it uses an intra-AS routing algorithm. DV is usually used for public places in the system. All routers inside the AS run the same algorithm, and learns how to reach every destination AS-level hop. It prefers its peers, its ISPs, or chooses the closest AS.\n\nIn the end of the route, we have the added task of being responsible for forwarding packets to\nendpoints in an AS, as these routers are called gateway routers.\n\nTo connect ASes, an inter-AS routing algorithm is defined (BGPv3). It\u2019s run by all Internet routers, and every router learns how to reach every foreign prefix. To do this, every AS (i.e., every ISP) has one or more BPG peers, and they exchange BGP messages, binary over a TCP stream. BGP uses path vector and, unlike intra-AS routing, prefixes never carry information about specific destinations inside different ASes.\n\nThere are two kinds of edges in the internet. The first, eBGP, carries packets in between ASes. The second, iBGP, carries information about subsets from another AS through an AS.\n\nHow does a route look like from iBGP to another AS? It\u2019s basically from one point to another AS hop, one router to a BPG peer to another one, to another one in an AS, and plenty more. It will run from an algorithm using the next-AS information to choose where to go. The BGP takes iBGP information to update where the next external BGP information should go, building a path from private router to the point of exit. The packet on the public side will be forwarded. Each router on the way in the AS will be responsible of routing the packet to its ultimate destination.\n\n41 of 49",
    "When more than one gateway router is present, a router will make its choice based on a couple factors. First of all, it can choose to bypass some ASes (for example, if it doesn't have a good commercial relationship with the company managing it). Otherwise, it could also just choose to take the path that goes through the smallest number of AS, or the path to the destination, which would deliver the fastest path. There is no fixed protocol.\n\nThe solution to the problems caused by internet routing was to introduce hierarchy. To scale, an Internet router does not need to learn how to reach every other Internet router; it just needs to know every router in the local AS, and one router per foreign IP prefix.\n\nNetwork Security\n\nThere are a few security properties that can be important when transferring information on a network:\n\nI.   Confidentiality: Only the sender and the receiver understand the contents of the message.\nII.  Authenticity: the message is from whom it claims to be.\nIII. Integrity: the message was not changed during transfer.\n\nTo maintain confidentiality, the end-users can use an encryption algorithm. When Alice wants to send a letter to Bob, she puts it inside a closed envelope (or container), and this container is locked with a key, so nobody without the key can open it (i.e., confidentiality is guaranteed). The encryption algorithm takes as input the ciphertext, meaning the message plus the key. Bob will then use a key to decrypt the message, i.e., this removal algorithm converts it into plain text. This means that even if an adversary intercepts the message, without the key they will not be able to read it.\n\nIn symmetric key cryptography, the same key is used to both lock and decrypt the message. An important aspect of this is that the sender and the receiver already need to share the same key.\n\nThe sender and receiver share this secret key in advance, and they use algorithms such as AES, DES, stream ciphers, Block ciphers, RC4, AES and Blowfish. The main disadvantage of symmetric key cryptography is the key between the users. For it to be kept confidential, the key has to be \u201cagreed out of hand\u201d.\n\nAsymmetric key cryptography uses two keys per key \n\n$key + key-(plaintext) = plaintext$\n\n$key + key+(plaintext) = plaintext$",
    "user: a public key and a private key. The public key can be known by everyone, while the public key needs to be kept private. In this scenario, Alice \n                                                planet \n                                +-----------------------------+\n                                | policylen                   |\n                                | ephemeralen                 |\n                                +---------+---------+---------+               planettext \n                                | ciphertext         |         |\n                                +---------+---------+---------+\n \nwill encrypt the plaintext with Bob's public key $K_{\\text{pubB}}$, and because this is the only one to know his private key $K_{\\text{privB}}$, Bob will be the only person able to decrypt the message. It's important that with the \u201ckey\u201d, it is impossible to find \u201ckey.\u201d The challenge for asymmetric key cryptography is that it\u2019s computationnally expensive. There needs to be sophisticated encryption/decryption algorithms, such as RSA or DSA. \n\nTo conclude, symmetric key cryptography is faster but asymmetric key cryptography doesn\u2019t require out of band key sharing. Confidentiality can be achieved through both systems. \n\nA cryptographic hash function maps a large input to a smaller output key. The hash shouldn\u2019t reveal any information about the input. It should also be very difficult to find two input that output the same hash. As with encryption, the hash isn\u2019t perfect and needs to be applied with care. But it is often the first important tool about cryptography. It turns out that people, more typically, recover the hash.\n\n                    Alice                               Bob\n                    +---------------------------------------->\n                    |   I am Alice (hash key I am Alice)     |\n                    +--------------------------------------- +\n                                                    Message Authentication Code \n                                                            (MAC)\n                    +---------------------------------------->\n                    |I am Alice (hash key 123456789)         |\n                    +----------------------------------------+\n \nThe final most important goal of authenticity in the use of asymmetric and symmetric keys needs to be understood. When a sender and a receiver have agreed on a key they can verify the hash output for every command they encrypt. A message typically contains hash output at the end of the message and concatenates with a key so the hash codes can be compared. This is known as message authentication code and it can help authenticating the identity. In cryptography, why use cryptography as the basis for verifying identity using key cryptography? Alice and Bob have keys and she wants to make sure of his identity so she sends a hash output message with the key message to \n                                            message\n                                        +--------------------------+\n                        Bob             |      text                                                    +..  \n                    +---------------------------------------->\n\n which Bob of the pair knows can only open the message sent and then resend it some time later. This is a problem for time sensitive messages. To protect herself from this, Alice will ask for a\n",
    "special \"number\" from Bob, called a nonce. It\u2019s randomly generated by Bob, and is only valid for a given amount of time, which depends on the type of interaction which is to go on between Alice and Bob. She will thus calculate hash of her message, and prevent Persa from later replaying the message, and thus must include timing information. This would be called a replay attack. Alice appends, depending on the type of authentication used, either\n\\[ \n\\text{key} = \\text{hash}(\\text{nonce}| \\text{message})\n\\]\nor \n\\[\n\\text{key} = \\text{hash}(\\text{sharedKey}|\\text{nonce}|\\text{message})\n\\]\n\nBecause even slightly modifying a message will modify the hash (with a good hash function), integrity can be provided the same way as authenticity.\n\nIn a Man-in-the-middle attack, the attacker Manuel will be on the network between Alice and Bob, and will thus see both the keys sent by Bob to Alice and Alice to Bob. And, Manuel will have Bob\u2019s public key. He then intercepts the string $s$ that Bob sends to Alice\u2019s side. This can happen because these rely on non-vertify public-keys. The solution to this is to have public key certificates, that are to be generated by authorities (CA). In this case, Bob and Alice will trust each other, if only, the string $s$ has both Bob\u2019s public key and the trusted CA certifcate. To encrypt a message $s$:\n\\[ \nc = E(k_{\\text{bobPub}}, s)\n\\text{BobPublicKey} = (\\text{bobCert}, \\text{bobPubKey})\n\\]\nThis means the key is digitally signed by the CA.\n\nSecuring sender\u2019s identity => Authentification. Every secure communication requires that period. On shared state (either a shared key, or the public key of a CA (stored in the browser)). Generally speaking, asymmetric encryption, has more challenges.\n\nTo have authenticity for simply sending e-mails, we thus need to be sure of the keys in advance, or have access to a trusted CA. To verify the signature, we need to verify the public key of CA, which will verify itself that Bob\u2019s private key and public key are accurate. They can certify the pair $(\\text{Bobpriv, BobPub})$. Bob and Alice will know their public and private key in advance. For example, sending Bob\u2019s private key",
    "To secure TCP applications, the server starts by sending its certificate (which includes its public key). Then the client creates and sends (encrypted with the servers public key) a shared master key. Both then use the master key to create 4 session keys:\n\nI. One key to encrypt data to server\nII. One key to create a MAC for client data\nIII. One key to encrypt server -> client data\nIV. One key to create a MAC for server -> client data\n\nBecause more information sent from the client to the server must be remembered (the client who opened the application, its account name, used sequence numbers are reduced, an attempt to reuse old sequence numbers). It also creates a MAC for each record and then encrypts the data and the MAC for each record.\nonline store\n\nThe main elements to remember to secure networks is to use a combination of symmetric and asymmetric algorithms (main tools are used to exchange shared keys, symmetric keys for confidentiality, authenticity and integrity), and use sequence numbers to avoid recording attacks.\n\nThe Link Layer\nThe link layer is responsible of taking a packet from one device to the next, across each physical link. As mentioned now, we know that other layers take a packet from device to end-system from end-system to exchange data, but it must be moved in order for a change at each node between the two host-to-destination hosts, as it is the overall work of each of the individual layers of the model is discussed in each name of the devices.\n\nFor example, the implementation looks as follows: from at source, a node sends the data through a link-layer traverses a node, so the system understands and forwards a switch, a hub (this being representative), and switches the data to the network layer, a router. In reality, packets are from higher level devices the end-to-end data link is automatically destroyed, like any device that wants to connect to the internet.",
    "The basic service of any link layer is to move a datagram from one node to an adjacent node over a single communication link, but the details of the provided service can vary from one link-layer protocol to the next. Possible services that can be offered by a link-layer protocol include:\nI. Framing. Almost all link-layer protocols encapsulate each network-layer datagram within a link-layer frame before transmission over the link. A frame consists of a data field, in which the network-layer datagram is inserted, and a number of header fields. The structure of the frame is specified by the link-layer protocol.\nII. Link access. A medium access control (MAC) protocol specifies the rules by which a frame is transmitted onto the link. For point-to-point links that have a single sender at one end of the link and a single receiver at the other end of the link, the MAC protocol is simple: transmit as soon as the frame is ready. The more interesting case is when multiple nodes share a single broadcast link (multiple access), e.g., with Ethernet and 802.11 wireless LANs. In this network, i.e., here, the MAC protocol serves to coordinate the frame transmissions of the many nodes.\nIII. Reliable delivery. When a link-layer protocol provides reliable delivery service, it guarantees to move each network-layer datagram across the link without error. Recall that certain transport-layer protocols also provide a reliable delivery service, e.g., TCP. Similar to a transport-layer reliable delivery service, a link-layer reliable delivery service is achieved with acknowledgments and retransmissions. A link-layer reliable delivery service is often used for links that are prone to high error rates, such as wireless links, but is rarely used for low bit-error links, such as fiber, coax, or twisted-pair copper wire. However, wireless networks are becoming increasingly important in residential, enterprise, and mobile networks, and we\u2019ll cover link-layer reliability in that context in Chapter 7.\nIV. Error detection and correction. The link-layer hardware in a receiving node can incorrectly decide that a bit in a frame is zero when it was transmitted as a one, and vice versa. Such bit errors are introduced by signal attenuation and electromagnetic noise. Because there is only a single sender at the link layer, frame retransmissions can fix this error, so error correction is more important in this context. The error detection can be performed using some techniques.\nThe link layer uses redundant information that also helps detecting errors within the frame. This is done by reducing the frame length and reducing the redundancy. So error detection is a technique in the link layer and this is achieved by frame detection, which means that transmitters and receivers then determine exactly where the frame starts and ends.\nThe link layer\u2019s role is to take a packet across from one device to the next, across the physical link, inside one IP-Subnet. The end-to-end transport layer is used across subnets, from sources system across the entire network, through the destination end system.",
    "multiple IP-Subnets. Hosts and routers have link-layer addresses, called MACs. This address is 6 bytes long, giving $2^{48}$ possible MAC addresses. These 6-byte addresses are typically expressed in hexadecimal notation, with each byte of the address expressed as a pair of hexadecimal numbers. MAC addresses were designed to be permanent (if possible burned into the chip, but now we\u2019ll pretend that they still are). One interesting property of MAC addresses is that no two adapters have the same address (the IEEE manages the MAC address space). MAC addresses have a flat structure (as opposed to the hierarchical structure of IP addresses) and don\u2019t change when users take their adapters. A laptop with an Ethernet interface always has the same MAC address independent of where it is plugged in. When an adapter wants to send a frame to some definite adapter, the sending adapter inserts the destination adapter\u2019s MAC address into the frame before transmitting the frame.\n\nBecause there are both network-layer addresses (for example, Internet IP addresses) and link-layer addresses (that is, MAC addresses), there is a need to translate between the LAN addresses and Internet. At this point, it is where Address Resolution Protocol enters. ARP resolves IP addresses to MAC addresses. In many ways it is analogous to DNS, which resolves host names to IP addresses. One important difference that we have between an IP node and DNS is that nodes automatically create the table without the users\u2019 participation. MAC address tables are often built in this way. In order to obtain a mapping of IP addresses to MAC layer addresses, ARP only has to interact once. The resultant MAC address can then remain in the table for some little while. There are many ways in which ARP could have been designed, but ARP has a simple way in which the protocol works.\n\nNow suppose that we have a node with a standard address that is IP-addressed to another node for the first time. This is an ARP packet request. First, the node sends an ARP packet to all the adapters in the LAN by means of a broadcast Ethernet frame. The Ethernet frame contains the sending adapter\u2019s MAC address and IP address, and the destination MAC address is all FF-FF-FF-FF (all 1s in binary). All the adapters receive the broadcast ARP request message, but only one adapter recognizes its IP address, sends back an ARP message with its IP and MAC addresses, and also indicates to whom it is sending back. ARP packet responses are sent back to the node reminding how the adapter IP on the earlier IP datagram was to be provided. The node responds to the earlier ARP by sending back another ARP packet, but this time directly to that node adapter. As a result, it will complete the query to ARP memory in the ARP table, and given by a certain period, storing the destination IP address and the MAC address that is a response. The purpose of the ARP query packet is to query all the other hosts and routers in the LAN to find the MAC of the target host with a specific IP address. It is then possible for the nodes to send an 802.11 frame on the source adapter with the corresponding address that are directly configurable. In summary, the ARP translates the network-layer (that is IP) address to the MAC address, and only then does the sending node act. Upon obtaining the MAC address, it sends the datagram containing a \u201cblack box,\u201d delivering a datagram $X$ by using this MAC address in the out box to be sent to the next hop (generally the router).\n\nARP tables are built automatically\u2014they don\u2019t have to be configured by a system administrator. If a host becomes disconnected from the LAN, its entry will be deleted after a short timeout. ARP tables are usually available in an ARP cache that can be given an address to an entry with a certain MAC address. When they receive a packet with source MAC address to host $X$ in it.",
    "the switch adds to its table the fact that packets with destination MAC addresses it needs to be forwarded through link b. When a packet with an unknown MAC address arrives at a switch, it broadcasts a message to learn where it needs to forward it. Thus the self-learning relies on actual traffic. If the table was self-filled by administrators, the deployments would be less maintainable.\n\nARP request has to go to communicate. All nodes can't be trusted, not to say almost all edges. A node can't be removed without bringing the whole network into a mess. Edge is containing Dp and some are port routers (RP).\n\nThe link layer was designed for flexibility, while the network layer was designed for scalability. There are usually three layers of hierarchy here:\n\nII. IP Solution: Uses link-layer (L2) forwarding, self-learning and broadcasting\nIII. Automatic Switch Process: Liler (L3) forwarding, anti-theta (manual), L15) routing\nIV. AP Solution: LIS forwarding, anti-delta (manual), distance-vector, IGR) rooting\n\nNow an example. What happens when Alice types in \"http:Al.com\" in her browser?\nSuppose the server that uses ARP packets as shown in the image Alice sends ARP packets we need four ARPs:\n\nI. ARP sent to home local DNS server\nII. Local DNS server to respond to A\nII. It\u2019s A's HTTP GET request to home SC\nIV. Web server's response to A    \nSo how will those packets be translated along the links to the correct destination?\n\nFirst, the transport protocol process will create the DNS request, it's passed down to the transport, network layers. It will have to serve A's places IP address, and as destination address, the correct DNS IP. Then it's passed down to the Link layer, with the correct SRC MAC address.\n\nThe switch SW2 has MAC address table DC. Here it has learned that A's IP address is on subnet 10 as it comes back to MAC addresses as it learnt the switch's routing table along with the SRC address through Alice's DNS router at SW. The server's MAC and IP addrses get verified. Once the DNS servers know their addresses, the switch table is. All along through the switches there's no broadcast, as the DNS server is checked from the DNS server\u2019s address and learns the server's MAC address. The DNS server will respond. When it has it, it will pass the packet through to the server.\n\n48 of 49",
    "II. The DNS server extracts the DNS query message and determines the IP address linked to it (either it's already in its cache, or he uses DNS to find it), then responds to Alice directly (it has her MAC address, because she sent the request to him).\n\nIII. Alice performs the HTTP get request, which is pushed down to the link layer again, after having the right headers added, which will send out an ARP request to resolve the web server's MAC address. Router R1 will respond to the request with his MAC address, because the DNS server is not in Alice's IP subnet. Alice will then send the packet to router R1, who upon receiving it will transfer it to its next layer, but won't determine that R2 is responsible for the IP prefix through its routing table and forward it to R2. Upon receiving the packet, R2 will send an ARP broadcast request in that subnet to determine the server's MAC address. The web server will respond. When it has IP, it will pass the packet through to the server. The server will then receive the HTTP GET request, and answer with the web page.\n\nIV. The server already has Alice's MAC and IP addresses, so the packet will just be forwarded through the same route Alice's packet arrived.",
    "Computer Security Course\n\nTamine Yann Kouritirin \nChalot Juliette Claire Marie\n\nOctober 2020",
    "Chapter 3\n\n3.4 Mandatory Access Control\n\n3.4.1 DAC VS MAC : what\u2019s the difference\nDiscretionary Access Control is defined by the order of the system, MAC: Mandatory Access Control protocols are determined by the security policy and models; the owner may not have any power to change anything or their policy as he sees fit.\n\n3.4.2 Security Model : Bell La Padula\nMany aspects are not covered by the model; they are general guidelines to apply and there are many levels chosen to be taken when the whole situation becomes clearer.\n\nLevels of confidentiality\nExecute, Read, Append and Write, which are defined in an access control matrix:\n\nDominance relationship\nA security level $L_A$ dominates level $L_B$ and only if it\u2019s bigger than $L_B$ AND $C_A$ is a subset of $C_L$.\nThe strict first definition above is if the biggest label is bigger set, is a dominance lattice, the number includes the dominance relationship.\n\nClearance level\n$$L_C = <S, \\{N_1, N_2 \\}>$$\nS clearance: Maximum security level a subject has been assigned\nCurrent Security Level: subjects can acquire new level\n\nNo read up ($S1$ security level)\nNo write Up: Problem is, if a user receives an authorization into a higher level temporarily, he can create a file, mark the file to the higher security level; the user who loses the higher still has access to. This creates a security problem because the SS property becomes easily violated.",
    "star property\n\nNo Write Down\nCannot write Append/Write on a lower level, and can only append and write on the higher level and read on a low level. It is back to the problem of the first SS property.\n\nDiscretionary property (ds property)\n\nIf an action takes place it must be in the access control matrix.\nInformation should be accessed on a need to know basis, * DAC: Least privilege inside the security model.\n\nBe careful\n\nIf an entity wants to obtain information, usually simply knowing that it is there is a certain security model and not all entities have access to track it is exactly level and gain information defining the exact level of its security.\n\n3.4.3. Covert channel\n\nThe more resources are shared, the harder it is to make sure there is no information flow. For example CPU and file systems. We are trying to eliminate information going to places where it should not go. Covert channels are the properties that we use in order to safeguard hardware from being exploited by spy programs so that no information flow takes place (start-up CPU & mails). But it is very hard to prevent information leaking this way.\n\nThe need for dedicated hardware to work this\n\nThere arises the need for dedicated hardware to be installed in case if there are covert channels abusable for the information stream, which is a bad thing. For example, Microsoft wood reviews game software to make sure there is no hidden information disguised and covered there.\n\n3.4.4 CONCLUSION\n\nBell-La Padula is like confidentiality but for integrity, availability, it\u2019s too low level and not intended to provide it. As these models were not good enough to actually ensure confidentiality and their inclusion in certain parts was very important.\n\n3.5 MAC: Integrity Models\n\nThis is like the Bell-La Padula, only it is for integrity.\nLiba is Public Service or confidentiality. It\u2019s good for military environments. But they are used to lock down information and to make sure that all the files are keeping the highest integrity. Integrity means files are not hackable or modifiable in their data file elements. They're only allowing particular lines and their items to go through.\nBiba and Libla are very similar, but it\u2019s conceptually different from confidentiality.\n\n3.5.1 The BIBA model for integrity\n\nWe only have two ops., read and write.",
    "Two key rules that are very strict\n\nSimple integrity: No read down, protects higher integrity principals from being corrupted by lower integrity data.\nSimple integrity *: write up, prevents lower integrity principals from corrupting high integrity data.\nIn the Beka: directors can establish a red and grey employees roles. Employees can\u2019t rewrite rules.\n\nBIBA variant 1: low watermark for subject\n\nThe Low-Water Mark Policy is a dynamiek policy with three rules that barely impact on\nthe integrity level of an object: a read donw de the principal integrity level of the subject and\nlowering his integrity level is the only operation that really inconfidents him.\n\nBIBA variant 2: low watermark for object\n\nWhen an subject is modified by a few integrity, the high integrity subjects can\u2019t read it anymore.\nBetter no subjets' modification.\n\nBIBA additional action: invoke\n\nSimple invocation: Only allow subjects to invoke subjects with a label they dominate. This protects\nhigh-level subjects from corruption: an high-level actor does not share what he wants (elig in).\nConflic input: when a subject X invokes, he passes his low-level label; the low-level then prevents co-\nprivate firmly of foreign data. His not defect infolding information.\n\n\\section{3.6 Multi-Property security models}\n\n\\subsection{Combining security properties}\n\nBPL brings confidentiality but no integrity; BIBA integrity but not confidentiality and the chinese\nwall.\n\n\\subsection{Who secure the TCB?}\n\nThe standard her boss: Trusted Hardware and Advanced cryptography. Chinese wall, kinds choo policy:\nImportant parameters creation (two people can make their knowledge common in the files of a third\nparty for example).",
    "Chapter 4\n\nApplied Cryptography\n\n4.1 Cryptography basics\n\nIt matters because it frees us from physical security and reduces TCB to the confidentiality and integrity of keys.\n\nCryptography primitives\n\nSecure function: true (either you can\u2019t break it down or there is no secrecy argument if you break it down more. Easy way to crack basic cryptography systems. Frequency analysis, if the patterns are not random. Easy be there transformation code. It is very easy to identify letter by letter what corresponds to what.\n\n4.1.1 OTP : One Time Pad, perfect secrecy\n\nKey: Stream of a lot of random bits as long as the message; must never be reused; goal : destroy patterns. After a single use:  xor. XOR takes two bit and the answer : same source destroy/noise anymore there is 0 or 1. Apply to the long bit to all 300 is: now frequency analysis will work to recognize 300bit of non-random message, we will know patterns where the message suffers. \n\n$XOR$; Apply and transform it in a transposition mode.\n\n4.2 Symmetric encryption / Confidentiality\n\nStream Ciphers\n\nFixed shared secret key $k$ : initialization vector IV (non predictable but not secret = not reusable more times). Same key generates random stream op pseudo-random. IV: used once. XOR the message and this key. This principle is vector mode which you will decrypt it with key. Be careful storage algorithm (DRGB - non-predictable sequence) Time is fast. W. Note here nore IV bits distinguish from next.\n\nBlock cipher : differs from stream ciphers: basis is serial permutation. Even the size of bits did not affect the encryption of the first bits: considered as n encrypted symbol. Easy to insert text, can be difficult to detect.",
    "Block Ciphers\n\nVery short random string, short key size blocks: we need to use this block by block, how?\nFirst and oldest: Electronic Code Book, block2-block1 are independent and provide only one key block to encrypt another block. Permits Bleichenbacher.\nSecond mode: Cipher Block Chaining, takes k2 from k1 output, or the last block to see the next (with IV for the first). Supposedly, no regular lots: Permits Bleichenbacher (and not for a substitution system and not better against the analysis block: ECB(no) or CBC (yes), like XOR (k k)). Problem is we have to wait for the Block Cipher to translate the last one.\nThird mode: Counter mode CTR. Transforms a block cipher to a stream cipher. Need an always changing key. In a wireless environment, having sufficiently long keys because of problems with adversaries.\nFourth mode: Use an initialization vector and/or by wrapping: because when you need a long output bit, XOR can be a problem and there are different solution. Key can be calculated quickly. Therefore, for  _better analysis_ of course security we still have an attack.\n\n4.3 Symmetric encryption / Integrity\n\nWe want to make sure the message is not modified. MAC: Message Authentication Codes. Instead of creating a tag, use MAC generation. \u00a0\u00a0\n\nCBC-MAC\n\nC1 = ENC(k1 XOR (k1)) and MAC is the last one. This guarantees that if the message has been tampered with, the MAC generated is different from the other that was sent. Deterministic behaviour.\n\nHow to obtain confidentiality AND integrity?\nThere is Data-MAC. Instead of using the plaintext as we use the key in the MAC function and there is every other MAC generation to verify from the last one: but can lead to errors. Instead we use AEAD (Authenticated encryption with associated data).",
    "4.4 Asymmetric Cryptography\n\nLimitations\n\nComputationally costly\nNot suitable to encrypt large amounts of data.\nWhen we actually do encrypt the symmetric key. Or we use a hash function on a message, and we send the message and Sign(S, h). This allows us to check that the sent message has not been altered or replaced.\n\nDigital signatures\n\nCompared to MAC (see below), it allows us to verify that the user and key of Bob is actually correct.\nImagine you know the advantage is that since we encrypt the signature together between Bob and Alice, no one other than Alice knows it. This allows Alice updates the message from you to Bob is there, allowing you that he is the only one to red from you and you make sure that Bob is the only one signing. The idea is to be able to send you now.\n\nHash function properties\n\nPre-image resistance - given h(x), hard to recover $x$\nCollision resistance - hard to find $x$, $x'$ so that $h(x)=h(x')$\nHaving a common input/output hash, so if Bob has $S \\rightarrow \\{0,1\\}^k$\nCompress: input can be arbitrary large, output fixed length\nComputational, easy and already known - because we are sending out the message in the clear they know that the running time is manageable.\n\nHybrid encryption\n\nTo pre-distribute symmetric keys using \"key transport\"\nZ then uses that symmetric key for the rest of the conversation.\n\nDesirable property forward secrecy\n\nWe don't want old messages to be compromised if our long term key is compromised. We need a new independent key formed for each session.\n\nDiffie-hellman exchange\n\nBasically we share g of the exponential so that both of them have $g^{ab} (Z)$ as an encryption key and that's it. The hard part belongs to in between to decode because logarithm is a very expensive computation.",
    "Chapter 5\n\nAuthentication\n\n5.1 Basics\nThe system needs to bind your identity to an authentication state.\nHow? Show what you know, what you are, or what you have.\nModern = where you are, how you act, who you are.\n\n5.2 Authentication : passwords\n\nSecure transfer\nHow do we safely transfer the password?\n\nSecure check\nHow do we make sure we don\u2019t leak the password?\n\nSecure storage\nIf the system is stolen make sure it\u2019s not compromised\n\nSecure password\nHard to guess passwords\n\n5.2.1 How to have a secure transfer?\nBy using TLS/HTTPS which is a combination of Diffie-Hellman (establish a shared secret key), (digital) signature/authentication and (symmetric key) hybrid encryption. (best concession)\n\nBeware of replay attacks\nA system that reads your message and then tries to reuse it to send you fake information for some reason. How do we solve this? Instead of sending a message, we first have to step a login through a",
    "random R sent (a challenge) which was stored by the server. $(R=R_e \\cup h(R_e))$. And THEN, we derive R from the server in this black box as it seemed by an attacker.\n\n### 5.2.2 How to have a secure storage?\n\nOf course, don\u2019t store in the clear. We have several options.\n\n#### Hashing the Message\n\nStore hashed messages: the data has to have the property of pre-image resistance, we don\u2019t need message and hash to be secure. If the attacker already has in their hands our data and can find an item\u2019s hash and password, but doesn\u2019t modify neither data nor the hash, the system is secure: we can recognize it is spoilt. We can use salted hash: before storing the hashed pass we hash it together with a random number (nonce) to avoid that the same password from two users create the same final message (without it, two identical passwords of two people would produce the same salted and encoded message). Our strategy now is to identify the user and see if he matches the hash table.\n\n#### Hashing and Salting the message\n\nHashed passwords have a distinct hash function and need to be secure, it\u2019s just to make sure you need to know every time itis salted. The system has to leverage all the previous (verify an input) in the hashing domain. When the user consults his webmail for instance, he makes an input and the system checks the password by searching for matches with his input. Salting helps to make passwords unique, even in case two users have the same pass. Salts are kept secret and are different for each user. An attacker cannot guess the password because there is not salted password tables available for a Rainbow attack, no collision - but such attacks are harder to implement, thus our scheme prevents easiest attacks.\n\n### 5.2.3 Secure checking\n\n#### Checking Letter by Letter\n\nThe system asks the user to transmit basic information about the password (the longer it takes length) to let the system know about discrepancies right from the login. Systems might ban such common passwords and enforce multi factor authentication. The system needs to know the user\u2019s legitimate password via a hash function stored. They will be prompted to provide some security information at time of password updates, answer a special query. The system should validate the letter / digit / number of chosen passwords letter by letter, but in a randomized way (so far if thief hits successfully letter by letter, he may be careful in his choice of a well studied).\n\n#### Problems and solutions:\n\nStress against the human, to remember people tend to write their own password or reuse them among different user. Fortunately, they can use tricks (logbook, shoulder surfing, phishing, social engineering).\n\n### 5.3 Authentication : Biometrics\n\nBiometrics is the measurement and statistical analysis of people\u2019s unique physical characteristics. Advantages : nothing to remember, passive, difficult to delegate (can\u2019t share your face, fingerprint).",
    "Authentication process has 2 phases :\nEnrollment and verification.\n\nEnrollment\n- The biometric of the user is introduced in the system and associated to their login :\n  Capturer : width sensor\n  Operation : store a stream of bits = biometric template\n\nCheck : system\n\nVerification\n- The bitstreams are captured and processed as before and the template obtained is compared to the stored one\n\nWhat is the reference biometry ?\n- Used in face recognition where images are recolored and stored.\n\nBiometry is strong because :\n- Proxies are used to verify attributes are being backed process.\n\nBiometry is weak because :\n- False positives : some biometry system are not reliable and difficult to update. Storing many templates is problematic and some (< 10) positions are hard to update\nFalse unfounds : people (low rates), can definitely do this if people wear \"machining\" means and many possible issued by its use in technology & its association with credentials\nConstraints must be enforced & the proposed structure is unacceptable\n\nProblems with biometry \n- Biometries are hard to keep secret (fingerprints ad door locks, pictures on social media...) so more and more systems add second authentication factors. This problem is convenient (quick access...)\n\nForensics use biometry as evidence in courts but, fingerprints and other biometric evidence must be used with caution. Not quite as precise but used as complementary tool. \n\nEmpirical chances measuring frequent precise chance levels still a problem using more sophisticated methods in devices/natively emails/other cookies/email usage work. Biometric still used in safety factors for recognition aspects and concise understanding. \n\n5.4 Authentication : Tokens\n\nTokens are portable devices that authenticate an individual\u2019s identity electronically by storing user specific personal information. This information can be presented for online verification by applying a private key to a cryptographic function such as a \"signed\" hash value. \n\nExample : a password, a cryptographic function, or a pre-agreed \u201cseed\u201d problem as follows :\n\nStep 1 : Offline-Initialization\n- User and server establish a common \u201cseed\u201d (a common random number) and synchronize their clocks.\n\nStep 2 : Prove-the-user Operations\n- Nonce = a random number from the seed that can only be compared to the token\n- Token : has rules\n- Token : rules signature\n- Token computes $s = H(nonce) deployment$, applies $s = P(seed)$ where $H$ is a cryptographic function and $P$ is the seed.\n",
    "sends the result to the server\n\nServer computes its and does \n\nnot\n\n \n$e' = f(k_{serv})$ and checks if $e = e'$.\n\nRq. : Using a hash instead of a keyed function would be bad because anyone can compute a hash \nand then using it, anyone could produce new factor $v'$ by hashing the value.\n\n5.5 Authentication : Two factors authentication\n\nCombine two out of the three factors : What you know, what you have, what you are.\n\n5.6 Authentication : What machines have\n\nWe use authentic machines, this is done using a public key cryptography. The secret keys to \nproduce digital Signature to authenticate parties.",
    "Chapter 6\n\nAdversarial thinking\n\n6.1 Why do we study attacks?\n\nVery good attackers are very good defenders.\n\nThe attack engineering process\n\nDefine a security policy, a threat model\n\nOne needs to be careful not to forget principals, assets or properties in the security model as these must be maintained in time. Security and principal focus is particularly true in ad hoc networks (trust model, social network for example) or applications (most processed data / machine learning algorithm / output is confidential).\n\nSo: if adding an axe is allowed:\n\nSend features to the BSM (Hardware Secure Modules). If retrieving the key is forbidden (in real networks, requirements are to move from a restriction to buy it later, there are still features).\n\nQ: Can I access any software updates?\n\nA: If no, creating an access to the data is controlled by a system that is connected to the site of service, if it does not collect anything, then you have to go to the site/software system taking care of the security mechanism.\n\nDefine the security mechanisms that support the policy given the threat model\n\nUnder hypnotized data for both vulnerabilities: this can be made to resemble systems looking properly with mechanisms. However, adversaries may find and exploit its vulnerabilities. it is possible.\n\nBuild an implementation that support/embodies that mechanism\n\nImplementation of operations problems may allow an adversary to subvert the mechanism / infiltrate the TCB.",
    "6.2 Defender : threat modelling\n\nAttack Trees\nAttack goal is the root, the ways to achieve this goal are branches and the leafs are weak resources.\n\nSTRIDE\n\n|---------------|-----------------------|-----------------------------------------------------------------|\n|       Type             |              Definition                |                                  Example                                                        |\n|---------------|-----------------------|-----------------------------------------------------------------|\n| Spoofing        |    Authentication                  | A member of the crowd of Black conceives Marty that he |\n|                         |                                              | is the host, in fact they belong to rare.                                |\n|---------------|-----------------------|----------------------------------------------------------------|\n| Tampering    |    Integrity                             | Tamper with subsequent orders from Marty Black without        |\n|                         |                                              | being detected by authenticity services and information integrity. |\n|---------------|-----------------------|----------------------------------------------------------------|\n| Repudiation   |    No-repudiation                   | Someone claims from both Marty Black and asks for                |\n|                         |                                              | something he doesn\u2019t want to do.                                           |\n|---------------|-----------------------|----------------------------------------------------------------|\n| Information   |    Confidential                      | Someone is listening to Marty Black and retrieving his             |\n| disclosure     |                                              | competitively valuable information.                                       |\n|---------------|-----------------------|----------------------------------------------------------------|\n| Denial of        |    Availability                        | Attackers harm services so that users of the system are delayed      |\n| Service           |                                              | or even denied access to them.                                               |\n|---------------|-----------------------|----------------------------------------------------------------|\n| Escalation of |    Authorization                   | Attackers play the roles assigned in the system,                               |\n| Privilege        |                                              | like administer to set any role on GitHub.                                  |\n|---------------|-----------------------|----------------------------------------------------------------|\n\nP.A.S.T.A.\nStart from business goals, processes and use cases. Find threats from within the business model, assess impact and prioritize based on risk.\n\n6.3 CWE : Common Weaknesses enumeration\nDatabase of software errors on internet.\n\nMost dangerous software errors :\n\nRisky resource management\nThe system acts on inputs that are not sanitized.\n\nInsecure Interaction between Components\nInputs are not inspected; files containing dangerous data are not sanitized. This non-sanitized information is used by the program and results in unintended behavior.\n\nCWE 78 : OS command injection attack\nInjection contains into uncoded data receiver to make the system do things you want the system to do. Technical impact SID \u201cand back ticks\u201d not updating twitter user name of userName then this will fail; return the lesser line of the self then achieve everything without nothing.",
    "CWE 79 : Cross site Scripting (XSS)\nThe script that takes the external input does not run a command but uses the input to dynamically generate a web page.\nEx: attempt this simple URL: ```http://randbiesbank.co.za/login.php?username=``` <script>alert('You've been attacked !')</script> and then try to close one of the fictitious username fields it inserts in the source and \"yourPC\" code and verify it is now benign / incapable. The page serves up a pop-up that just alerts \"Your PC\".\nTest data: wscript links: ```http://randbiesbank.co.za/login.php?sessionid=sookien-does-doom&eacute;\n```http://randbiesbank.co.za/login.php?sessionid=sookienn%2dipg%3``` and these were figured as \"evil\" results. They will contain the SEP \"USER_1stname\" validating what constitute valid xss injections into 'functional user 1st' oriented transactions.(May contain sensitive information)\n\nCWE 352 : Cross site request forgery (CSRF)\nCreate a bait vehicle (Rick and Morty images in the case of big boss Carewlt\u00e4) and use hidden portions such as hidden forms or cookies that are embedded into the same image set, process user authentication and trust assumption. Once logged in, leverage access to download distribution installed malware. This verifies how well session and authentication tokens are protected. Invoke actions that could impersonate a different trusted user \"subsequently\"(checking for XSRF through sessions.)\nTest if the application protects cookies and if they cannot be abused: ```xbook2click?ookico=TnwxiZcaFcz``` and capturing session data headers to verify their handling of sessions to check if they are CAPTCHA secured.\n\nTest data: cross testing to fail transaction if not CAPTCHA acknowledged. ```javascript'document_token'object```\n\nDescription: The script that checks the external input loads an existing site cookie, used in HTTP entity, indirectly affects functional capacity, indirectly monitoring cookies variation to identify XSRF.\n\nCWE 494 : risky resource management\nNever allow dynamic inputs have been properly verified first in the TCB.\nThe initial test data: ```http rand-mck orb.jquery content compile?mouse=xx iswer``` and accomplishes to detect open 'f' source resource systems that are vulnerable to resource arbitrary access. One key system: RAT and resizing and ``` w3c resource enabled``` .\n\nVerify download data packages to check if the resource link isn\u2019t positively identified. VNC to verify the origin integrity.\nEx: ```push sourcerat```\n\nThe TCB is the \"trusted computing base\" (TCB) of a computer system is the set of all hardware, firmware, and/or software components that are critical to its security.",
    "CWE 829 Inclusion of functionality from untrusted control sphere\n\nInstead of including untrusted code directly into an application, use secure frames to separate this\ncode so that other parts of the potentially less safe code remain unable to interfere with its corre\u00ad-\n\nCWE Porous defenses\n\nDefenses fail to provide full protections or complete avoidance through missing checks or partial\nsolutions.\n\n*defense techniques that are often misused, abused or bypassed.\n\nAuthentication and Authorization design failures and bugs\n\nEncryption failures\n\n$\\begin{array}{ll}\n[5] & \\text{CWE-306} \\quad \\text{Missing Authentication for Critical Function} \\\\\n[5] & \\text{CWE-862} \\quad \\text{Missing Authorization} \\\\\n[6] & \\text{CWE-798} \\quad \\text{Use of Hard-coded Credentials} \\\\\n[11] & \\text{CWE-311} \\quad \\text{Missing Encryption of Sensitive Data} \\\\\n[6] & \\text{CWE-807} \\quad \\text{Reliance on Untrusted Inputs in a Security Decision} \\\\\n[13] & \\text{CWE-250} \\quad \\text{Execution with Unnecessary Privileges} \\\\\n[6] & \\text{CWE-863} \\quad \\text{Incorrect Authorization} \\\\\n[17] & \\text{CWE-732} \\quad \\text{Incorrect Permission Assignment for Critical Resource} \\\\\n[17] & \\text{CWE-326} \\quad \\text{Inadequate Encryption Strength} \\\\\n[17] & \\text{CWE-327} \\quad \\text{Use of a Broken or Risky Cryptographic Algorithm} \\\\\n[19] & \\text{CWE-307} \\quad \\text{Improper Restriction of Excessive Authentication Attempts} \\\\\n[25] & \\text{CWE-759} \\quad \\text{Use of a One-Way Hash without a Salt} \\\\\n\\end{array}$",
    "Chapter 7\n\nSofware security\n\nSoftware needs high performance : we use low level languages (e.g, c++) which trades type safety and memory safety for performance but not important safety mechanisms themselves.\n\n7.1 Memory Safety\n\nBlah bla bla the fact that if there is no sanitized archive check, we can access to memory parts that are part of the stack and extend information. How do we solve this? sanitize your input and by making sure that the return follows a strict string format.\n\nMemory Corruption\n\nUnintended modification of memory location due to missing/ faulty safety check.\n\nTemporal Error\nEx : use wild/revoke (fake \u2018free\u2019)\n\\[\n\\begin{aligned}\n\\text { wild($\\&ptr$)} \\\\\n\\operatorname{free(R2)} \\\\\n\\operatorname{use(R2)} \\\\\n\\end{aligned}\n\\]\n\nSpatial Error\nEnsure that all memory areas in a program are within the bounds of their pointers valid object.\nEx : use wild spills\n\\[\nptr = '\\&s.t[d+4]' \\\\\n*p = m2\n\\]\n\nEnsure this++\n*ptr m2",
    "7.2 Execution attacks and defenses\n\nAttack scenario : code injection\n\nForce memory corruption to trigger an attack. Redirects control flow to injected code.\n\nCode injection attack\n\n\\begin{verbatim}\nvoid vuln(char *u) {\n    // strncpy()?\n    strncpy(u? ....);\n    char temp[MAX];\n    strcpy(temp, u);\n}\nvuln(deposit);\n\\end{verbatim}\n\nMemory safety Violation\n\nIntegrity\t&C\n\nLocation\t&C\n\nUsage \t\\&\\&C\n\nShellcode (executable attack code)\n\nDon't care\nPointer to shellcode\n\n* Specify result\nas \"saved return address\" function.\n\nAttack\n\nTo counter this problem, we can either check carefully the inputs that are given to the function, but in this way the protection is really hard or put something right before the function. So instead, we use searching.",
    "called DEP (Data Execution Prevention).\n\nDefense : Data Execution prevention\nRefuse to code integrity to one per executable. Each page in the memory have an executable bit. In order to be run, they have this bit on. That implies that everything that is executable cannot be written or use the code reuse cannot be executed or even modify. This is a hardware level control for which software launches overhead. The only drawback is that we can\u2019t execute code that is self-modified and we can still execute on runtime (and thus languages like JavaScript).\n\nMitigation\n3 properties : effectiveness against attack, efficiency and compatibility.\n\nSandboxing\nPrevents a process from accessing system resources or corrupting other processes.\n\nAttack scenario : code reuse\nFind addresses of code gadgets within the control flow of the program to gather chains and then these changes allow the attacker to prevent while rewriting its own copies. It is possible to change the return pointer of the function. It is also possible to gadget (using the return2lib) ...\n\nDefense : Address Space Layout Randomization : ASLR\nRandomize the address of data regions and code. This is a probabilistic defense that depends heavily on the implementation and also on the precision with which the attack can find the address targeted. Thus this should be combined with random space ranger (mprotect, mmap) and extract libraries in one big and linear rather than in the personalized and spread out manner.\n\nDefense : Stack canaries\nUse a virtual canary. Set this bit that likens to or fool them if such an overwritten is the aim at getting return address, the part where the expected code sequence begins. Thus canaries are placed at the validation to understand if the attacker altered the control plane. Virtual canaries are words on stack knowing that is the end thus should be fetched after set amount of operations. Identify which part is corrupted the value get the round trip, which is stored at the stack top after as regular operation the one on return must be before access next operation or next operand. \\\n\nDefense : Safe exception handlers\nPre-defined list of handler address and non that are after an error there is no undefined behavior. However the systems can only execute a predefined set of error handling functions.\n\n17",
    "7.3 Software Testing\n\n\u201cTesting can only show the presence of bugs\u201d. Testing is the process of executing a program to find errors. An error is a deviation between observed behavior and specified behavior, a violation of the specification. Probabilities-based testing attempts (as opposed to proofs), completed by inspections & code reviews potentially. (code audits, security requirements)\n\nExploitation seams: Exploit all paths (too much!), narrow hypotheses -> tie building problem. Practical example: executable lines versus total lines expanding the program 10x.\n(Use Perl. All inputs pre-designed should do geometric series: line -10, combs of sequences, features... anywhere, any place.)\nControl Flow: All potential values for the variables considered in the test set. Path coverage.\n\nCases: Decides wether an instruction executed or not that the result of the execution depends on content flow.\n\n  if(x==101)\n      x=100;  // x=101 and x=2 shows no content flow\n  if (z < 100)\n      z = 100; // an if-100 results in a bug due to different data flow\n\n\n7.3.1 How to test security properties?\n\nManual Testing\nSearches by:\n- Tools usage (code review, heuristic test cases)\n- code reviews (self inspect manually)\n- Testers from an all qualified liability\n- structured audits\n- offensive usage of test asserts\n\nAutomated Testing\nTesting is decided automatically (develop analysis that discovers bugs and enforce security properties):\n\nWrite initial tests: code provenly right without execution. This should however take intrinsic benefits also.\n\nGoal: derive program of analyzing a program to determine what input causes each part of the program to execute. This should be displayed prominently by proper tests should be passed before changes.\n\nRandom tests (each rewriter output randomly (Binary)): Impact the program by executing analysis but deterministic function.\n\n7.3.2 Coverage as metric\n\nApproaches: how easily detected if flawed current is executed. Effectiveness of tests therefore dependent from the target metric (code coverage).\n\nStatement coverage: doesn\u2019t imply full coverage.",
    "Branch coverage : cannot cover all paths, try to evaluate every statement to both true and false but will not try all possible combinations of statements this is incomplete path coverage.\n\n7.3.3 Fuzzing\nFuzz testing is an automated software testing technique that mutates inputs to improve code coverage, expose crashes, input validation bugs and memory leaks. Improving and maintaining an effective program depends on how fast a tester can see the first program crash if it is crashed, on a valid input and next on invalid inputs.\n\nInput generation\nDumb fuzzing by nature of the input structure: it randomly mutates inputs.\nContrarily smart fuzzing has a model that describes inputs, smart generation produces new input based on this model.\nGeneration and fuzzing leverage a set of valid and invalid inputs: smart generation modifies inputs based on the model, dumb fuzzing does not.\n\nA beverage program structure\nAfter execution, inputs can be modified based on program structure (past and post executions) to reach deeper execution levels.\nOnly for fuzzing\nReaching an example of the inputs based on program inputs (new information).\nIf the fuzzer reaches several program layers to generate new inputs (more coverage).\nWith feedback programming the fuzzer performs even better to mutate input (more coverage) based on Dynamic Taint Propagation (DTA).\n\nCoverage Walk\nNo important program because checks of the program are complex and it is unlikely that a fuzzer will reach every program input that satisfy all these checks.\n\nDifferent types of fuzzers\nDumb fuzzing:\nStandard, generates random input.\nDoes not adjust to feedback based on input to generate new inputs.\nMost likely to generate invalid inputs.\n\nTaint can detect bugs\nIn parallel with mutation; static analysis, segmentation faults, division by zero traps, unhandled exceptions or any expected (yet dangerous) behavior, inputs known to be giving erroneous syntax help in detecting behavior of new input. In high cost and correct determine a wrong behavior if it's based on the program specifications.",
    "Address sanitizer (ASan)\n\nAddress sanitizer detects memory errors. It places red zones around objects and checks those objects $<$16 bytes earlier. Can also be for situations when type of object is not valid anymore in heap stack and the object is deleted, hence hooked by ASan to den_mem golden, free, invalid free, memory leaks.\nThe typical slowdown introduced by ASan is $2 \\times - 4 \\times$.\n\n\\textbf{Bug:} ASan only detects writes to red zones but does not protect or check the pointed itself.\n\nUndefined Behavior Sanitizer (UBSan)\n\nUBSan detects undefined behaviors. It instruments code to trap on typical undefined behaviours in C/C++ language. Enriched typology of mistake is undefined, illegal use of Null pointers are illegal, pointer arithmetic, $...$ involves grey out the amount and frequency of check. This is the only sanitizer that can be used in production.",
    "Chapter 8\n\nNetwork security\n\n8.1 Introduction\n\nActually, a network is a much more complicated construction with a lot of intermediate nodes.\n\nDesired properties\n\nNaming security\n\nThe association between lower level names (eg: network addresses) and higher level names (AR-Aliases) must be authenticated to help security. \u2013 Integrity, authentication, availability.\n\nRouting security\n\nThe route over the network and the eventual delivery of messages must not be influenced by the adversaries. \u2013 Integrity, authentication, availability, authorization.\n\nSession security\n\nMessages within the same session cannot be modified (keep ordering; end to adding/removing messages). \u2013 Integrity, authentication.\n\nConfidentiality\n\nThe content of the messages must not be readable or influenced by adversaries. \u2013 Integrity, confidentiality.\n\nWhere are the problems ?\n\nSockets : SSL, TLS.\nTransport : Transport control protocol (TCP).\nThrough routers : Authentication and routing (DNS, BGP).\nDatalink : Naming and routing ARP.",
    "8.2 ARP spoofing\nEthernet\nLocal area network (LAN) technology. Machines have unique 48 bit MAC address. (Medium Access Control).\n\nInternet protocol (IP) on the LAN\nHosts communicate using the IP protocol. Each machine has an IP address (4 bytes in IPv4). Part of the address identifies the network, and part the host.\n\n8.2.1 How does IP routing works ?\nRouting: routing IP on an Ethernet LAN\nHow does IP routing work?\n\n- Alice needs:\n  - an IP address on the LAN 128.59.15.55\n  - a subnet mask 255.255.255.0\n  - a gateway, in this case 128.59.15.1\n\nOption 1: Alice and Bob are on the same subnet\n  - Alice needs to know Bob\u2019s MAC address\n\nOption 2: They are on different subnets\n\nInside the LAN, ether uses ARP packets for networks attached via Bob\u2019s MAC address.\n\nHow can she learn about Bob\u2019s MAC ?\nARP is a translation table for ethernet address and MAC addresses. Each host maintains a cached table of around 30 neighboring MACs. So when Alice joins the same network, she sends a request via ARP. ARP asks \u201cwho has IP address 128.0.0.1 ?\u201d. The ARP table are conceptually simple. ARP is a LAN IP infrastructure service. Sending ARP request for the same IP and receiving an answer from the host. The table is regularly updated.\n\n8.2.2 ARP Spoofing (only for local networks)!\nWhen can you use it:\n  - Intercept communications between two hosts (node/router) with your MAC address/ monitor ethernet traffic.\nMan in the middle attacks: \n  - Violate authentication: we can have backward limits by changing MAC\u2019s anytime they are asked over the ethernet.\n  - Denial Of Service: avoid that packets arrive to one host.",
    "8.2.3 ARP spoofing: Defenses\nUse of static, send only address for critical services in the ARP cache of the host.\n\nARP spoofing detection and prevention software\n\u2022 Check if one IP has more than one MAC or use MAC correspondents to multiple IPs.\n\u2022 Identify regular devices (example: address of other machines of the same organization, if the administrator of the latter realizes a problem. (Expansion of privileges because the adversary wants to have or share rights).\n\u2022 Check and see if there is a MAC/IP association change.\n\n8.3 DNS spoofing\nWhat can you achieve?\n\u2022 Denial of Service (DoS): example,\n\u2022 Send victims to a malicious web server. That later can attack them (serving malware) or act as a middle man (man in the middle attack).\n\n8.3.1 How does DNS work? (Domain Name System)\nWe send the request to a resolver resolver, that contacts the authoritative servers. There are no integrated authoritative and resolvers. The attack can be realized in two ways:\n\nCache poisoning\nCompromise the DNS resolver cache (IP/domain pairs). This resolver will then send these erroneous pairs to machines asking for the IP of a specific domain.\n\nDNS hijacking\nRedirect all queries to a third party resolver, so we can directly hijack the pairs to corrupt the responses, no need to poison the caches, happens live.\n\n8.3.2 DNS spoofing: Defenses\nUse of Secure DNS authentication (DNSSEC)\nDNSSEC (specific option during configuration) Responses are digitally signed by authoritative servers (private servers authenticate itself), the responses can not be tampered with by intermediate hosts.\n\nDNS over HTTPS (DoH)\nDNS queries are sent through HTTPS protocol, which provides integrity and confidentiality through encryption. It prevents DNS poisoning and dropping, but does not solve live reading problems.",
    "Other protocols : DNS TLS, DNS crypt, DNSCurve\n\n8.4 BPG spoofing : Border Gateway Protocol\n\nBNS provides the low level address (IP level) details. We are assuing now that the adversary does not target users but that DNS replies go to the destination address, so now we guarantee the right IP address of the target.\n\nUser A proposes to B (with some identification to connect to). A reconstruct the routing table before this identification to find an AS with high level trust.\n\n- Routing is mainly under control of Border M (non neutral)\n- Border has mainly core administrators.\n- Routing connects trusted members of the BGP (also speaks constantly).\n- According to the definition, only the members of the BGP protocol have the perfect world always guarantees (the node located in between).\n\n8.4.1 characteristics of BGP\n\nWeak authentication characteristics between routers (this aims at preventing DoS attacks mainly), are authenticated by a vector of trust (AS). This means a router from AS1 goes to AS2. The route is weak and sends keys (MD5 auth). Routing is guaranteed to these AS/neT,T nodes. The adversary can reconstruct a conversation along a path which can then be tam-tam copied, modifying data on each hop of the attack making a comparison of routes easy.\n\nBGP hijacking\n\nAdds incorrect prefixes or computations at router somewhere in the Internet. He injects false low-cost information overloading some morphological manners by promoting intermediate propagation to routing tables until again t.\n\nWhat can we achieve ?\n\nInduce source redirection, injection, identification or censorship.\n\n8.4.2 BGP Spoofing - Defenses\n\nStill a semi static vector of trust identification has to be authority to self by authority to guarantee the origin and the termination of a BGP communication. This does include the passing and reception factors or routers as the original end node\n\nThis technology is called Good BGPsec. This adds BGPsign et. al. It is another clearer but this is complex for IoTs (objects). Updates are needed as soon as an adversary has identified attack. Security level of BGP is vectorized to provision deployable hack detections.\n\n8.4.3 Lessons to be learned from spoofing\n\nThe tool needs to be: Routing key stacks, facilities and good experienced resolution of high level and low level states. And this means identification of network resources through key indexes trust identification added to the routes. The protocol has good seasoned decentralized key indexes mechanisms. Also there are no authorities to set a ruler certificate of policy or provide a TCP ...",
    "it\u2019s hard to centralise. The solution is similarly linked to cryptography (asymmetric cryptography being particularly useful for mutually distrusting actors).\n\n8.5 IP Spoofing\n\nNo integrity or authentication mechanism for source address.\n\nWhat can we achieve ?\n- Man in the Middle\n- Data theft or service theft (or send invoice to owners to have messages bounce malicious user)\n- Denial of Service (DoS): Attacker uses our source to send lots of requests to server with Alice IP as source. Server will reply to Alice.\n- Session Attacks (hijacking)\n\n8.5.1 IPSec : Internet Protocol Security\nCryptographic security properties at the IP level :\n- No integrity and authentication, only encryption, shared symmetric keys.\n- Each exchange (sender/receiver) has a unique key (Identifier); protection from replay attacks (normally each packet has attributes to identify it).\n- Encapsulating Security Payload (ESP): confidentiality.\n\nTwo modes\n\nTransport\nProtects IP packet using AH/ESP, sent with the original IP.\n\nTunnel\nProtect the whole packet (Header+Payload) by placing it inside another packet.\n\nVirtual Private Network (VPN)\nIPSec in tunnel mode\nThe IPSec runs over a logical network. The routing is done internally and is tagged with \u201cVPN <name>\u201d. When packets enter the DeMilitarized Zone, the IPSec header is used to access targets.\nWe use transport mode to go from the VPN exit node to final targets, since they are target packets. VPN is the solution for companies where proxy encryption not practical (proxy impractical).\n\nIP limitations\n- No reliability (messages can get dropped).\n- No anonymity: Source usually encrypted to avoid corruption\n- No access to a way to access mapping tables.\n\n25",
    "8.6 TCP : a transport protocol\n\nThe previous examples we saw were at the network level. Now we are at transport level, it maps an \"end-to-end\" (i.e., process to process) communication. We already referred to this earlier with TCP header like Port Src, Destination Port Dst, seq, ack, win, window); the first one above line optional. The first two guarantee reliability and congestion control and the last one ensures flow control.\n\n8.6.1 TCP 3-way handshake\n\nClient time\n```\n                       SYN Sent\nConnect Y         \u27f6\n                           Port X | Port Y\n                        seq = i | ack = t\n\n                                                    <-- Port X | Port Y\n                                                    seq = t | ack = i+1\n                                                    Acknowledgment\n```\n\n                                                     Established\n                                                   \n                                                    Port X | Port Y\n               Established                        seq = i+1 | ack = t+1\n```\nIt is easy to map on this protocol which of the messages generated by the three-way handshake take integer values; Do not interrupt AFTER the three-way handshake if you do not intend to.\nLet X and Y be network addresses (with an ephemeral UDP source port and connecting to port 7734 on server A and port 80 on server B).\nLet the client send segments 0..3 and ACK with Syn(j.. ) being the standard acknowledgment in the case where an ACK flag is raised.\n\n8.6.2 Basic steps of TCP Hijacking\n\n1. Abuse in the middle adversary to scan network communications for important and inject packets.\n2. Wait for TCP session to be established between client and server.\n3. Wait for authentication phase to be over.",
    "3- Use knowledge of seq number to take over the session and inject malicious traffic \n4- Use malicious traffic to execute commands \n5- The attacker executes the inject standard (browserbased or root) \n\n8.6.3  TLS Transport Layer Security \nCryptographic protocol above TCP/IP. \nAuthentication (over connection): \nLess vulnerability from non-prime nrs for asymmetric parts. \nMore secure due to frequency in changing public key cryptography. \nPreshared key: \nKeyed-Hashing for MAC. \nProve forward secrecy: leaking a secret at one point in time does not reveal anything about the past. \n\nThe TLS handshake: \nAgree on cryptographic algorithms and establish session keys. \n\nClient \n(e.g. browser) \n1. ClientHello, Version, CipherSuite, SessionID, ... \n2. \n  --------> \n2. ServerHello, ChosenCipher, ServiceCertificate, ServerChangeKey, \nRequestedCert, ServerHelloDone \n3. <--------\n3. ClientCertificate, ClientChangeKey, ChangeCipherSpec\nClientFinished \nServer\n(e.g. webserver) \n4. -------->\n4. ChangeCipherSpec \n5. <------- \n4.1 ServerFinish \n\nTLS offers no mode to obtain a shared key between server and client. \nAny authenticated message to be transmitted to the client, the client answers with a separate key (not forward secrecy). \nKey-agreement using Diffie Hellman, the client and server agree on an ephemeral key for every communication and sign it. \n\n8.7  Denial of Service \nGoal: prevent systems/networks from accessing a service, attacker sends the availability. \nThe 2 most-known attacks: \n- Send so many packets to a host with a service that the service is not able to respond. \n- Use several hosts to send packets to a server by exploiting IP spoofing, so victim hosts are bombarded by replies (smurfing). \n\n* To prevent DoS, filter based on orig. address, or separating packets with different addresses through TCP (TCP Syn flooding).",
    "8.7.1 TCP SYN flood\n\nThe adversary exploits that fact that after receiving a SYN and sending a SYN/ACK, the server\nwaits for a response (the third ACK) from the client. By not sending it, or at least not sending it\nsoon, many half open connections are kept on the server, which can lead to a resource exhaustion.\nAn adversary might decide to ignore TCP\u2019s the three contact open man connections anymore the next legitimate SYN request is rejected.\n\n8.7.2 TCP SYN prevention\n\nReduce the amount of state kept by the server until the handshake is done (to \u201cexpensive TCP).\nInstead the server stores a very small state that enables how the question of musting the reduction.\n\nDoS prevention cookies\n\nThe goal is to make the TCP but need to stall the client. The client has to provide cookies back\nto the server to initiate. THESE ARE NOT THE COOKIES OF INTERNET. So as soon as the\nserver receives the next the SYN/ACK and by cookies. The server allows the server state to\na cookies. When the server gets back the cookies the client that is it the client. Thus prevention\nis the resources to accept or a result.\n\nProof of work\n\nEconomic measure to prevent DoS attacks. Rely on requiring the client to work before engaging\nwith. Often request the client to by solving cryptographic puzzles with a moderate difficulty, or\nmore instructions that takes order to complete.\n\n8.7.3 Snuff attack\n\nThe sender generates the packets that (DOS) transport level protocol within TCP/IP which reset\nsent ACK connections. The adversary send a \u2018reset\u2019 to them to close their connections and avoid\nany require the packets to have used for the specification of the stream sends it \u2018to disconnect any\naccess\u2019. SYN flooding is generated responses the victim. attack also floods it - and bandwidth is\nexhausted much when the packets and legitimate.\n\n8.7.4 Tvarattack\n\nGive the victims fragmented packet with false information so that it waits indefinitely for packets\nthat will never arrive.\n\n8.7.5 DoS without flooding : TCP RST injection\n\nThe TCP stream keeps headers packets generated of requesting leaving thus the server, the\nanother. The next with and build for packet TCP for all data is. When receiving from packets.\nthus ongoing communication, to the server still sends stream. This way the DoS happens\nblocks the server later, instead.",
    "8.8 Other protections\n\n8.8.1 NAT : Network Address Translation\nRouter that maintains contact tables of the form $(Internal\\ IP, Port) \\leftrightarrow (External\\ IP, Port)$. This ensures that an outside IP address and implies that an external entity can\u2019t access the NAT client it has already mapped (thus does not stop all attacks but makes attacks harder).\n\n8.8.2 Network Firewalls\nA firewall is a network router, that connects and internal network to an external public network. The goal is to inspect the traffic, and take some appropriate decision based on policy. A state can also be used to make policing rules. Network firewalls include :\n\n* Simple packet filter : Inspects each packet for source and destination address, and action (allow/deny) based on table lookup.\n* Stateful firewalls: can also maintain lookup to a high port from a returning client. We can also use deep packet inspection.\n\nFirewall access control\nInspect characteristics of the traffic. \u201cAllow\u201d or \u201cdeny\u201d traversal across the firewall and prevents the packet that does not conform to security policy in the internal network.\n\nSimple packet filter 1980s:\nInspect each packet for initiation and reply (allow/deny) on certain rules (equal, not equal, in range, less than, etc.). E.g. only ports 0-1023 (super user). There are various operations available in the commercial products; this is the way packet filter is differentiated. E.g. check on header fields at layers 3,4, else drop.\n\nStateful Firewalls 1990s:\nCan inspect all packets, deciding on the state based on layer information TCP/UDP semantic. This enables Advanced lookup on traffic patterns to support more esoteric business rules. E.g.: deep packet inspection (HTTP) - to examine a connection into the server, and then the server\u2019s response. E.g.: look for a particular user session. Popular examples : Snort, ZoneAlarm.\n\n* Packet inspection: can also inspect the payload for certain keywords etc. E.g. Block all executable/pdf attachments in emails.\n* Reject malformed packet (such as changes in dynamically valid and non-valid connection).\n* Check TCP sequence # for packet inspection.\n\nProxy-based firewalls 1990s:\nAn application-layer firewall - checks at the user level, and allow/deny based on its state and the information of the packet.\nExamples include filtering of HTTP traffic to a local proxy to have bandwidth-cum-blocking of non-business traffic.\nFielding: Using pattern lists, the traffic is inspected to stop non-commercial traffic to divert to a local proxy server.\nE.g. Check if consignee list in the header, apply rules by scrutinizing mails to the firewall or virus filtering malware detection and spam detection.\nAlert threshold: Apply behavioral rules or monitoring tools to detect block of sensitive documents, ensuring downloads available for users.",
    "Downsides with Firewalls\n\nKey problem:\n- Data on firewall is slow (read/check/write). Observation is cheaper (read/logging).\n- But need to keep playing in order to make decisions about vulnerabilities or authorization at application layer.\n\nIssue also with non-adaptability or authenticity \u2192 how can the firewall be seen to act as authoritative and adaptive?\nA firewall is not a full substitute for other host and network security mechanisms.\n\n8.8.3 Defence in depth: the De-Militarized Zone (DMZ)\nDefence in depth: the De-Militarized Zone (DMZ)\n \nSplit \u201cthe world\u201d into 3 zones\n- WAN \u2192 outside\n- DMZ \u2192 with public services\n- LAN \u2192 for internal users only\n\nRelies on a firewall to\n- Ensure only traffic to well-known services traverses outer firewall.\n- Ensure only traffic from \u201cknown hosts/clients\u201d LAN from DMZ. Thus the possibility for an external process control and filtering (eg. VPN/IPSec, Proxy).\n- Though LAN can access DMZ and WAN; DMZ can access WAN. But flows particularly processes are enforced, monitored and authenticated.\n- In case a service is compromised internal resources are safe!",
    "Chapter 9\n\nPrivacy\n\n9.1 The Context : Availability of data\n\nIntelligent data based app get a legitimate amount of data that can be used to learn every aspect of our lives.\n\n9.2 Privacy is a Security property\n\nFor individuals\n\nPrivacy is needed to protect online accounts, protect against attacks (rfid). Privacy is important to control who gets access to our life (emails/pictures/ manipulation).\n\nFor companies\n\nDigital interactions may reveal a lot about business decision/trade secrets/launch of new product...\n\nFor governments\n\nAs for companies, digital traces reveal a lot about intentions such as who is being investigated by the police, which government are talking with each other...\n\nOverall privacy is important for everyone because\n\nWe all share the same infrastructure (use internet) and when people know they are watched, they change their behavior.\n\n9.3 What is privacy ?\n\nIt's a very abstract concept and is subjective : depends on our culture and education, the context it is being used. In addition to being tedious to formalize, it is very hard to quantify, to see who has access to information. This also linked to the difficult ethical question about liberty (the right to keep some information private) and the need for more information to ensure a safer society (one can be an oppressor). Nissenbaum tries to formalize it with contextual integrity theory (some info can be directly used to design systems).",
    "There exist 3 different types of Privacy Enhancing Technologies depending on:\n- The concerns they address and who defined these concerns\n- The materials needed for them and obtained from them\n- How far they go in protecting privacy (their limitations and challenges)\n\n9.3.1 Social Privacy (the adversaries are others)\n\nConcerns\nThe privacy problem is defined by all Users.\n\nGoals\n1- Stop annoying the User. Two main approaches:\n- Support decision making: tools which help the user choose who can see what\n- Provide awareness and control: let the user know who is/was visualizing the information they put\nAlso help the users to agree if it is worth sharing\n\nLimitations\nOnly protects from other users - Trusted service providers\nLimited by users' capability to understand policies and learn each user's expectations...\n\n9.3.2 Institutional Privacy (the provider may be adversarial)\n\nConcerns\nThe privacy problem is defined by legislation. Data should not be released without user consent or legal enforcement reasons. The data should be correct, securely stored, kept private.\n\nGoals\nOnly release information that is needed to serve a legal purpose while protecting individual freedoms.\n\nComplaints\nCompliance: protection principles -\n- Make the end user aware of when and what data information is going to be collected and explained to users which data is required for which purpose.\n- Minimize the data that is collected to the minimum amount necessary to serve the goal of the smart environments.\n- Data integrity: incorrect data has to be detected and as it is an accessory for the sacred purpose of executing the legal principle inherent in smart environments data collection.\n- Data retention: personal data has to be protected and ground to collect must be deleted.\n- Abrupt data access: the data has to be anonymized and encrypted to avoid attacks.\nTransparency must be provided with an open innovation, transparent and evaluation mechanism.\n\nLegal/Social effects\n- Help the end user make better informed guidelines for the data, aided by:\nTools: defined policies, know better about their own privacy policies.\n- Institution transparency allows faster understanding on the data, and it also helps letting\ntaking the principal that common sense falls to logic.",
    "Anonymisation is tech that aims at decoupling data from the identity so that it is not considered personal data anymore. Once it\u2019s not personal data, it\u2019s not subject to the data protection regulation.\n\nLimitations:\nPrivacy-preserving designs are newer and it\u2019s difficult to create \u201cgeneral purpose privacy.\u201d There is high adoption rate both for developers and users (preferential attachment): nobody already uses privacy tools.\nEnd-to-end encryption has an edge and is more powerful: once a message is on the network, it is not readable by anyone but the user recipient; the provider itself has no enforcement responsibility with a subpoena, or intelligence agencies that know which service providers.\n\n9.4 End to end encryption\nUsing encryption to achieve confidentiality of the content.\nWhat are the pros and cons of this?\nPros: Whatever institution the adversary is using to intercept and decrypt the data stores the encryption key in a single place. Telephone line operators can log calls metadata but not messages even if the line is wiretapped. Encryption keys can be very carefully handled by the recipient.\nCons: Encryption can fail in many places within the system, which is why forward secrecy (TLS) comes in. Passively, there is often a single point of compromise in communication.\nHowever, data is in the clear and can be accessed by the provider and we can assume that once force majeure context is established, the provider will help.\nForward secrecy solves the problem of key theft by regularly invalidating old keys to force communications to become unintelligible for the adversary. This provides no usage information across communications making correlation in time harder for the adversary.\nA given message cleartext is not recoverable from another communication encrypted. Thus asleep adversaries cannot later decide to decrypt previously seen ciphertext when the malware forces the network operator to reveal the key.\nAlso note that metadata can be useful, such as the device hardware, the software, the time and the location, though communication content is not often as determinative even as it cannot coerce an unwilling user that no machine message cleartext retrieval be based on such heuristic means.\n\n9.4.1 Traffic analysis\nIt\u2019s for passive analysis summarization associated communications such as identity of the participants. When observed, the fact of how you login states who they are, which devices they use, gossips network topologies, and so on.\n\n9.5 Anonymous communications\nIt protects target individuals against traffic analysis. It\u2019s an advantage to criminals but it\u2019s also beneficial for human rights activists.\nThis approach involves encrypting the message header and payload separately.\nHow: Encryption: multiple stages / mixing and random injections to slow the network correlation communication path. Relaying packets like a chain.\nExample: hopping onion architecture or using random delays to route packets: (1) Packet-chopping is sending packets at regular intervals or adding random delays to the packets.",
    "These two properties are needed but with most mixlike anonymous com systems (this system) :\n- has limited throughput\n- the user has to trust all mixes because a single point of failure for anonymity. If it\u2019s forced to reveal its logs there are fewer anonymous users\nModern ACS can address both as follows:\nModern ACS do not assign users to different jurisdictions and messages are not only reencrypted and rescheduled at the mixes but\nspread in a predecided pattern to achieve pattern destruction, load balanced, scaled and distributed trust.\n\n9.5.1 The Tor network-Onion routing\n\nMain example of an active ACS = Tor Network. Tor uses onion encryption.\n\n9.5.2 How does it work ?\n\nThe user chooses a path\n\nTor node IP addresses and their public keys can be obtained from directory authorities that maintain a list of available Tor nodes at every point in time.\n\nThe user prepares the circuit\n\nIt appears an SSL connection with each of the nodes using an established DH key agreement. Here encryption is mixed with the Tor node public keys in layers. Message is encrypted with the public key of the next server the message will visit first. This layer decrypted by assigned server only in the first layer the second layer deals with the message forward, this again is encrypted with the next BP. Using nodes are only aware of earlier and later nodes. Entry and exit nodes thus need not know each other. An adversary needs to have over 50% of both entry-exit nodes to launch an effective attack.\n\nThe user sends a stream\n\nThe user sends the message (not too fast using message). Tor node unwraps a layer and encrypts it with encryption function X for the first circuit node. New wrapping is done by each Tor node and a message enters the Tor where it only has the in-behalf message layer. The last node unwraps the next encryption layer using the correct safe keys (when the message is fully unwrapped the recipient receives the complete message only the final node knows the entry-exit info)\n\n9.5.3 Low latency ACS\n\nEg. Tor network mixing and encryption.\nThe main feature is near real-time message relayed to the next sign without any delay between the communications. Normal message speed hindered due to flow. Sends message fragments. Cannot detect the global adversary (Tor assumes that the adversary can not be both always active and passive).\n\n9.5.4 High latency ACS\n\nEg. Synchronous batching\nEach deadline all the waiting users wait to receive a pre-defined number of messages (threshold).\nWhen threshold is reached the mix changes the appearance of the messages through decryption and",
    "flushes all of them to the next mix or to the messages\u2019 destination.\nAdvantages: - One route per message and no direct relation between the messages coming in the network and the messages going out \u2192 Global advisory resistance. \n\n9.5.5 Onion routers or mixes\n\nThey operate at the application layer -> nodes different from internet routers.\nAC can employ mixes, or message relay nodes that are linked to form a router network but even if there are anonymous routers, anonymity must be complemented with services requiring authentication.\n\n9.5.6 Anonymous communications VS VPN\n\nAC provide a much stronger protection than a VPN (decentralized trust) because none of the nodes in the path can breach the anonymity of the users (assumption of policing). A message privacy and time (e.g. adversary cannot see both client VPN connection in parallel to the routing, cross linking). If this node gets compromised there is no anonymity guarantee for the users (centralized trust).",
    "Chapter 10\nMalware\n\nIntroductions\n\nIn previous attacks, the adversary actively exploits social/design/implementation errors. They require the adversary to apply the protocol and produce the code that exploits the vulnerability. These are not technically attacks. They are popular attacks (80% of most exploits). Malware software intentionally strives to cause adverse effects. Viruses are a kind of malware but they only represent 25% of malware written for windows which is the most common target of malware.\n\n10.1 Malware: why the rise?\n\nHomogenous Computing Base\nIncrease in devices connected to the network, with same OS such as Windows or Android.\n\nClueless user base\nUsers are not experts anymore.\n\nUnprecedented connectivity\nComputers are connected to network, increasing the surface of attack.\n\nMalicious code has become profitable\nCompromised computers can be sold or used to make money (Bitcoin)\n\nAttacker engineering process\nExploit new capabilities, new entities that were less prepared than expected in the design phase.",
    "10.2 Malware: Taxonomy\n\nThere are different kinds of malware. The main different are how they spread and whether they are self-contained.\n* Viruses and Worms are spread by themselves. Viruses tend to need some human action that triggers their spread, worms act on their own.\n* Trojans and other spyware are hidden on the users to automate their spread and only move to new systems when they are downloaded by users.\n* Viruses and trojans often work independently, they do not need to infect another program (infected files can be standalone and be transferred with them).\n* Modern malware combines features from the different categories to increase their impact.\n\n10.3 Virus\n\nIt\u2019s a piece of software that infects other programs to perform malicious actions such as monitor operations, delete/infect/program other files. Viruses often have two parts: (i) Infection part spreads the virus or payload. A vector is a way that a virus or worm spreads to new systems: through clicking on malware attachment, connecting USB infected by other attacks (system attack). A carrier is an infected file with a virus (host object). (ii) A payload does something undesirable when executed: monitor activity, hide, deleting objects or information.\n\nThere are 3 main types of viruses. We need to know that a virus can adapt multiple characteristics.\n* Itself: A virus is a malicious code that is fairly independent.\n* It needs an infected host (application to deliver it) that contains malicious code that infects the host spreading to another object.\n* It can launch and duplicate itself.\n\nWhere can they run?\n * File infector - Overwrites, parasitic (append legally)\n  * Hypervisors: Kernel rootkit\n * Macro Virus: Infect code contained in a program like load (MS Excel, word)\n * Boot sector: infects location on hard disk used to boot system\n\nHowever different malicious software blend: like a dropper: writes viral into other current payload into new vector.\nTo invest in malware: users have been shown to doing a certain action or the user pays money to act.\n\nDefenses\n\nKey mitigation -> give programs least privileges.\n\nAntivirus Software\nSignature-based detection: activities tries to find exact signature in the load. Signature are pieces of data used to identify viruses but they\u2019re matched previously identified viruses (we fail to patch).\nHeuristic-Based: tries to find general way that malicious software work. Only happen when you already know how to find.\nEmulation: uses a virtual system to find patterns that are known to be produced by viruses or make use of access to the register, syntactic changes in function borders \u2026 (same for passive).",
    "Sandboxing\n\nRun untrusted applications with least privileges/restricted environment.\n\n10.4 Worm\n\nIt\u2019s a standalone piece of software that can generate malicious actions. Self-replicated computer program that uses a network to send copies of itself to other nodes. To cause damage to replicate, it uses host tables or searches on the applications layer (e-mail server, Internet - search for known IP addresses).\nIt\u2019s easier to detect when compared to passive listeners, especially under heavy machine load - Slower than other applications and bandwidth consumption.\nIf it uses bandwidth for attack: (buffer overflow) in Microsoft SQL server.\n\n$\\blacksquare$ Causes DoS (SYN, SYN-ACK, bandwidth).\n$\\blacksquare$ Consume CPU and RAM, could reset user of resources. Encrypt data and ask for ransom in BitCoin. Wannacry 2017.\n$\\blacksquare$ If it uses one attack vector (NetBios) that the worm (uses for reconnection has been fixed by a practical firewall).\n$\\blacksquare$ If the worm used a Table for easy concession and the worm is controlled conditions:\nAV-based on a vulnerability in a NSA bundle toolkit.\n\nDefences\n\nHost level\nWorm uses vulnerabilities for exploiting vulnerabilities in hosts. Protection from remote exploitation vulnerabilities includes a shutdown of any attack before that: reduce the possibility of execution on hosts.\nAntivirus software may have signatures of recognizable behaviours that can be identified by an instance.\nAdequate diversity in OS (operating system) intrusion technique - require architectural knowledge and software development.\n\nNetwork level\nIt is possible to stop the damage done by worms to limit their capability to spread. This can be done by:\nAutomatically filtering out malicious content from a suspected worm infection.\nIP blacklisting, if the IP is generating massive flux from a nodnetwork with typical behaviour (sending a massive scan) it can rapidly limit the blacklisting rule.\nPossible only if it uses the same vector and same exploit to infect the system.\n\nInstruction Detection System (IDS)\nIt is useful for detecting unknown attacks and network traffic in a malicious way. IDS can run a list of known attack signatures to be able to look for the traffic patterns of malicious activity (and the traditional signature-based IDS fails here).\nSignificantly limited in known patterns (for false alarms that require observation because needs up-to-date signatures, can\u2019t find new attacks).",
    "- Anomaly based: attempts to identify behaviour different than legitimate (adapt to new attacks but high number of false Alarms).\n\n10.5  Trojan Horse\n\nA trojan horse is a piece of software that appears to perform a desirable function (misleading the user) but, instead, performs other malicious actions. The best example is the performance of other malicious actions in the background. They conceal an item or an item within its delivery that use to execute the program that contains the trojan.\n\nDefense\nBest antivirus programs with their link privileges and train the user to not run programs that come from untrusted sources.\n\nEx:\n\n- Fire binder trojan, awesome Zeus (Heb of Operation)\n- To steal the passwords from users or sniff a banking website.\n- MITM for example, attacker put the trojan to behave (keylogger) before encryption (TLS).\n- Use SSL Strip so that only hard to read.\n- Man A programs B so that when he fires for users to know a banking website\n\n- Steal the session cookies.\n- Bank operations to use as a pop-up \u2014> attack server to malware server.\n\n10.6  Rootkit\n\nThe malicious code that the adversary has managed to install in the core of the OS and then inside the kernel. The role of the Trojan is to gain access to the compromised host, but the role of the rootkit is to get access to IC of the root so that it can perform the malicious operation with privilege access (when compromised root access). Rootkits modify the host's operating system and infiltrate the kernel to a low level in the machine's boot sequence, and can be stored somewhere apparatus ROM-BIOS, different from the OS (kernel) only varied with firmware in hardware architecture. That is what makes them difficult to detect.\n\n10.7  Backdoor\n\nA hidden functionality that allows the adversary to bypass more strictly authentication (open ports that are not authorized by the policy, open connections to applications without authentication).\n\n10.8  How to find whether a program has a backdoor, trojan, rootkit?\n\nAnalyze programs to inspect the source code but if it is clean, a backdoor can be introduced by the compiler itself.\nWatch the program: software that translates high-level code into low-level code that can be understood by the machine.",
    "Challenge : you have the trace table of two examples C(E(c)=c) and C2(E(c)=c2) you want to know\nif they are hitting a backdoor.\n1. Find an initial couple: CA account and accounts applit with the two computer credentials: Ex=1\nand Ey=2. Find (CA,AA)', thus E(A1) = A2. First Example E(A1) = Ex=2\n2. Test another example: E(A2)= Martin A.A2 and E(A2)' =to compute CA again. The two binaries should\nbe coherent CA1+ (ALCA1)' = Ey=2 E(A1+A2)\n3. If true, if one of the bans account is introducing a backdoor.\n\n10.9 Botnets\n\nMultiple (militant) compromised hosts (\"zombies\" or bots) under the control of a single entity (Bot-\nnet command and control) is to keep track of bot and sends commands/codes.\n\nStar topology\nSimple configuration to realize the command control (CC) on one machine controlled by the hacker.\nThe CC makes for a single point of failure which makes the host common gathering.\n\nP2P topology\nTotally distributed system in which there is no isolator that issues commands but the bots them-\nselves issue and replicate commands to one another. This makes for much harder takedown be-\ncause there is no single target the hacker is coordinating the increment load with these issues\naforementioned for one attack to facilitate redundant groups of bots to back up when bots are\nsuppressed (tledom samples).\n\nThis rings closer to akin to completely arbitrary defections against other bots until the bot loss thres-\nhold reached.\n\nHybrid\nYou begin from the CC talking to other their in a P2P fashion, under the strict control of the leader.\nEvery scheme issues a request for control information other components within Node itself. The CC\nhands the P2P incremental control calculus to random ones under its controller.\n\nFake super nodes are found in task serialization issues for a P2P group. Here, infecting, DDoS\nfloods etc. simplifies the overall task under the control of the same heterosystem.\n\nDefenses\nAttack the CC infrastructure\nFilter (ingr) packets(s) joining in nodes ensuring that they are issued communicate with the nodes\n(noting that some will redirect known DNS to issue traffic to block holes).\n\nHoneypots\nMake the bots are vulnerable on purpose so that the botnet takes them with them and then their\nbehavior can be observed.",
    "10.10 Other malware\n\nRabbit\nCode that replicates itself without limit to exhaust resources.\n\nLogic (time) bomb\nCode that triggers action when condition (time) occurs.\n\nDropper\nCode that drops other malicious code.\n\n{tool/ toolkits}\nPrograms used to assemble malicious code (not malicious itself).\n\nScareware\nFalse warning of malicious code attack.\n\nAnd we are done !!!"
]